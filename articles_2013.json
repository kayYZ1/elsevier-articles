{
    "10.1016/j.protcy.2013.12.254": {
        "Title": "Experiments on the Use of Feature Selection and Machine Learning Methods in Automatic Malay Text Categorization",
        "Date": "2013",
        "Text": "serial JL 282073 291210 291871 291884 31 90 Procedia Technology PROCEDIATECHNOLOGY 2014-01-29 2014-01-29 2014-11-05T06:02:14 1-s2.0-S2212017313004088 S2212-0173(13)00408-8 S2212017313004088 10.1016/j.protcy.2013.12.254 S300 S300.3 HEAD-AND-TAIL 1-s2.0-S2212017313X00064 2015-05-15T07:33:56.892449-04:00 0 0 20130101 20131231 2013 2014-01-29T00:00:00Z rawtext articleinfo articletitlenorm authfirstinitialnorm authfirstsurnamenorm cid cids confeditor contenttype copyright crossmark dateloaded dateloadedtxt datesearch datesort dateupdated dco docsubtype doctype doi eid ewtransactionid hubeid indexeddate issn issnnorm itemstage itemtransactionid itemweight oauserlicense openaccess openarchive pg pgfirst pglast pii piinorm pubdateend pubdatestart pubdatetxt pubyr sortorder srctitle srctitlenorm srctype ssids alllist content oa subj suppl tomb vol volfirst volissue volumelist webpdf webpdfpagecount yearnav affil articletitle auth authfirstini authfull authkeywords authlast primabst ref 2212-0173 22120173 false 11 11 C Volume 11 101 748 754 748 754 2013 2013 2013-01-01 2013-12-31 2013 4th International Conference on Electrical Engineering and Informatics, ICEEI 2013 Prof. Dr. Juhana Salim Prof. Dr. Mahamod Ismail Prof. Dr. Ir. Suwarno article fla Copyright \u00a9 2013 The Authors. Published by Elsevier Ltd. EXPERIMENTSUSEFEATURESELECTIONMACHINELEARNINGMETHODSINAUTOMATICMALAYTEXTCATEGORIZATION ALSHALABI H SEBASTIANI 2002 1 47 F CAVNAR 1994 161 175 W FURNKRANZ 1998 1 10 J TAN 2006 290 298 S APTE 1994 233 251 C JOHNSON 2002 428 437 D JOACHIMS 2002 T THEORYALGORITHMS LEARNINGCLASSIFYTEXTUSINGSUPPORTVECTORMACHINESMETHODS LI 2009 692 700 S ALSHALABIX2013X748 ALSHALABIX2013X748X754 ALSHALABIX2013X748XH ALSHALABIX2013X748X754XH Full 2014-01-28T20:43:58Z ElsevierWaived http://creativecommons.org/licenses/by-nc-nd/3.0/ OA-Window item S2212-0173(13)00408-8 S2212017313004088 1-s2.0-S2212017313004088 10.1016/j.protcy.2013.12.254 282073 2014-11-05T05:50:09.972444-05:00 2013-01-01 2013-12-31 1-s2.0-S2212017313004088-main.pdf https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S2212017313004088/MAIN/application/pdf/022334f4337b5325212868a4a5dac8fa/main.pdf https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2212017313004088/MAIN/application/pdf/022334f4337b5325212868a4a5dac8fa/main.pdf main.pdf pdf true 283812 MAIN 7 1-s2.0-S2212017313004088-main_1.png https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2212017313004088/PREVIEW/image/png/499e6dc56f12ed64b915df9dfa9bba3e/main_1.png https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S2212017313004088/PREVIEW/image/png/499e6dc56f12ed64b915df9dfa9bba3e/main_1.png main_1.png png 49518 849 656 IMAGE-WEB-PDF 1 P r o c e d i a T e c h n o l o g y 1 1 ( 2 0 1 3 ) 7 4 8 \u00e2\u20ac\u201c 7 5 4 2212-0173 2013 The Authors. Published by Elsevier Ltd. Open access under CC BY-NC-ND license. Selection and peer-review under responsibility of the Faculty of Information Science & Technology, Universiti Kebangsaan Malaysia. doi: 10.1016/j.protcy.2013.12.254 The 4th International Conference on Electrical Engineering and Informatics (ICEEI 2013) Experiments on the Use of Feature Selection and Machine Learning Methods in Automatic Malay Text Categorization Hamood Alshalabi*, Sabrina Tiun, Nazlia Omar, Mohammed Albared Faculty of Information Science and Technology, Universiti Kebangsaan Malaysia, Malaysia Abstract Due to the rapid growth of documents in digital form, research in automatic text categorization into predefined categories has witnessed a booming interest. Although, there is a wide range of supervised machine learning methods have been applied to categorize English, relatively, only a few studies have been done on Malay text categorization. This paper reports our comparative evaluation of three machine learning methods on Malay text categorization. Two feature selection methods (Information gain (IG) and Chi-square) and three machine learning methods (K-Nearest Neighbor (k-NN), Naive Bayes (NB) and N-gram) were investigated. The three supervised machine learning models were evaluated on categorized Malay corpus, and experimental results showed that the k- NN with the Chi-square feature selection gave the best performance (Macro-F1 = 96.14). \u00c2\u00a9 2013 The Authors. Published by Elsevier B.V. Selection and peer-review under responsibility of the Faculty of Information Science & Technology, Universiti Kebangsaan Malaysia. Keywords: Feature selection;Machine Learning Methods; N-gram; Na\u00c3\u00afve Bayesian; K-Nearest Neighbour. 1. Introduction Due to the rapid growth in the compilation of documents, Information Retrieval (IR) system faces much harder task in accessing and retrieving relevant documents. In order to improve the IR performance system, text categorization plays key roles for handling and organizing the text data. Most of categorization systems categorized documents into a number of pre-defined categories. Each document can be categorized into multiple, exactly one, or no category at * Corresponding author. E-mail address: hmoud.shalabi@gmail.com Available online at www.sciencedirect.com 2013 The Authors. Published by Elsevier Ltd. Open access under CC BY-NC-ND license. Selection and peer-review under responsibility of the Faculty of Information Science & Technology, Universiti Kebangsaan Malaysia. ScienceDirect 749 Hamood Alshalabi et al. / Procedia Technology 11 ( 2013 ) 748 \u00e2\u20ac\u201c 754 all [1]. There are many machine learning methods which have been proposed for text categorization, such as N-gram, Na\u00c3\u00afve Bayes (NB), k-Nearest Neighbor (k-NN), Decision Tree, and Support Vector Machine (SVM). Many studies evaluated the performance of these methods based on general Newswire articles, and most of the studies focused on automatic text categorization for documents written in English. Previous works on Malay text categorization is very limited. This may be due to the nature of Malay language and also to the lack of Malay language resources such as labelled corpus. The automatic text categorization process foresees a set of tasks universally recognized by the research community [2]. These tasks include features design in which the corpus processing, extraction of relevant information, feature selection and feature weighting processes are performed. In addition, these tasks also include training task in which a machine learning classifier is trained using a set of labelled documents. Finally, the last task is the Testing task the accuracy of the classifier is evaluated by using a set of pre-labelled documents (i.e. test-set) that are not used in the training phase In this paper, we have designed several supervised classification models for Malay text categorization. It presents an empirical comparison of two feature selection methods (Information Gain (IG) and Chi-Square), and three supervised machine learning classifiers (NB, N-Gram and k-NN). In order to evaluate those classification models, we collected Malay pre-defined categorized documents from online Malay newspapers archives, namely; Bernama, and Utusan on-line. This corpus has eight categories: Arts, Business, Crime, History, Healthy, Medicine, Politics, Religion and Sport. The rest of this paper is organized as follows: Section 2 reviews related work in the area of text categorization. Methodology and the different key techniques and approaches are described in Section 3 and Section 4. In Section 5 and 6, we present the experiment setup and discuss on the experimental results. Finally, we conclude our work and indicate its future directions in Section 7. 2. Related work Text categorization methods were first proposed in the 1950s where the word frequency was used to categorize documents automatically [2]. Applications of machine learning techniques help to reduce the manual effort required in analysis and the accuracy of the systems also improved through the use of these techniques. In addition, many machine learning methods have been proposed for text categorization in the past studies, such as N-gram [3-6], k- NN [3, 7-9], Decision Tree [10, 11] and SVM [12, 13]. Many researchers attempted to obtain better classification algorithms performance for automatic text categorization. K-NN is considered as the common method to text categorization[16]. Therefore, k-NN has been treated as the base method for categorizing text. Thus, in this paper, we include k-NN, N-gram and NB, and the other two feature selections, IG and Chi-square, in our experiment to find out the most suitable method in categorizing Malay text. 3. Feature selection Feature selection method (FSS) is one of the most crucial tasks that will make the performance of text categorization improved, as they will select the most predictive features. FSS improves the performance of text categorization tasks in terms of learning speed and effectiveness. FSS also reduces the number of data dimensions, additionally, it removes irrelevant, redundant, and noisy data[1]. In this section, we give a brief introduction of the used feature selection methods: Information Gain (IG) : IG measures the number of information bits that is obtained to predict categorization by recognizing whether a term in a document is present or absent [14], [15] and [16]. As result, IG is recruited in this context to select features that disclose the most information about the classes [17] . The values of IG were calculated as the following: \u00e1\u02c6\u00ba\u00c2\u2013\u00e1\u02c6\u00bb \u00e0\u00b5\u0152 \u00e0\u00b5\u2020\u00cf\u0192 \u00dd\u0152\u00e1\u02c6\u00ba\u00dc\u00bf \u00dd\u2026 \u00e1\u02c6\u00bb \u00c2\u017d\u00c2\u2018\u00c2\u2030\u00dd\u0152\u00e1\u02c6\u00ba\u00dc\u00bf \u00dd\u2026 \u00e1\u02c6\u00bb\u00e0\u00b5\u2026 \u00dd\u0152\u00e1\u02c6\u00ba\u00dd\ufffd\u00e1\u02c6\u00bb\u00cf\u0192 \u00dd\u0152\u00e1\u02c6\u00ba\u00dc\u00bf \u00dd\u2026 \u00c8\ufffd\u00dd\ufffd\u00e1\u02c6\u00bb \u00c2\u017d\u00c2\u2018\u00c2\u2030 \u00dd\u0152\u00e1\u02c6\u00ba\u00dc\u00bf \u00dd\u2026 \u00c8\ufffd\u00dd\ufffd\u00e1\u02c6\u00bb\u00e0\u00b5\u2026 \u00dd\u0152\u00e1\u02c6\u00ba\u00dd\ufffd \u00d2\u00a7 \u00e1\u02c6\u00bb\u00cf\u0192 \u00dd\u0152\u00e1\u02c6\u00ba\u00dc\u00bf \u00dd\u2026 \u00c8\ufffd\u00dd\ufffd \u00d2\u00a7 \u00e1\u02c6\u00bb \u00c2\u017d\u00c2\u2018\u00c2\u2030 \u00dd\u0152\u00e1\u02c6\u00ba\u00dc\u00bf \u00dd\u2026 \u00c8\ufffd\u00dd\ufffd \u00d2\u00a7 \u00e1\u02c6\u00bb \u00c8\ufffd\u00dc\u00bf\u00c8\ufffd \u00dd\u2026\u00e0\u00b5\u0152\u00cd\u00b3 \u00c8\ufffd\u00dc\u00bf\u00c8\ufffd \u00dd\u2026\u00e0\u00b5\u0152\u00cd\u00b3 \u00c8\ufffd\u00dc\u00bf\u00c8\ufffd \u00dd\u2026\u00e0\u00b5\u0152\u00cd\u00b3 (1) 750 Hamood Alshalabi et al. / Procedia Technology 11 ( 2013 ) 748 \u00e2\u20ac\u201c 754 In which\u00c2\u2019\u00e1\u02c6\u00ba\u00c2\u2026 \u00c2\u2039 \u00e1\u02c6\u00bb denotes the probability that class \u00c2\u2026 \u00c2\u2039 occurs; \u00c2\u2019\u00e1\u02c6\u00ba\u00c2\u2013\u00e1\u02c6\u00bb denotes the probability that word \u00c2\u2013 occurs; \u00c2\u2019\u00e1\u02c6\u00ba\u00c2\u2013 \u00d2\u00a7 \u00e1\u02c6\u00bb denotes the probability that word \u00c2\u2013 \u00d2\u00a7 does not occurs. Chi Square: It measures the absence of independence between t (term) and c (category) [15, 16] . Chi-square can be calculated as follows: 2 (AD-BC) (,) N ct AC BC ABC D \u00ce\u00a6 \u00cf\u2026 (2) \u00df\u00af \u00dd\u2030\u00dc\u00bd\u00dd\u201d \u00cd\u00b4 \u00e1\u02c6\u00ba\u00dd\ufffd\u00e1\u02c6\u00bb\u00e0\u00b5\u0152\u00dd\u2030\u00dc\u00bd\u00dd\u201d \u00dd\u2026 \u00e1\u02c6\u00ba 2 \u00ce\u00a6\u00e1\u02c6\u00ba\u00dd\ufffd\u00c7\u00a1 \u00dc\u00bf \u00dd\u2026 )) (3) where A is the number of documents that contain the term, t, and also belong category, c. B is the number of documents that contain the term, t, but do not belong to category, c. C is the number of documents that do not contain the term, t, but belong to category, c. D is the number of documents that do not contain the term, t, and do not belong to category, c. N is the number of training documents [18]. 4. Classification methods As we mentioned before, we choose three classifier methods that are used in Malay text classification; the k-NN, NB and N-gram methods due to their simplicity, effectiveness and accurateness. Brief descriptions of these methods are given, as follows: 4.1. k-Nearest Neighbor (k-NN) The k-NN is a well-known example-based classifier. It is one of the most popular classification techniques due to its simplicity and accuracy. The k-NN is also known as lazy learners, since it delays the decision on how to generalize beyond the training data until each new query instance is encountered. In order, to categorize a document, the k-NN classifier ranks scores of the document\u00e2\u20ac\u2122s neighbors among the training documents. Then, the k-NN uses the class labels of the k most similar neighbors. Given a test document d, the system finds the K nearest neighbors among training documents. The similarity score of each nearest neighbor document to the test document is used. The weighted sum in k-NN classification is written as follows: (d) (,) (, )(,) j ijj d KNN Score d d sim d d d c \u00cf\u2030 \u00c6\u2019 (4) where KNN(d) indicates the set of K nearest neighbors of document d. If \u00c2\u2020 \u00c2\u0152 belongs to \u00c2\u2026 \u00c2\u2039 , \u00c9\ufffd\u00e1\u02c6\u00ba\u00c2\u2020 \u00c2\u0152 \u00c7\u00a1\u00c2\u2026 \u00c2\u2039 \u00e1\u02c6\u00bb equals 1, or other- wise 0. For test document\u00c2\u2020, it should belong to the class that has the highest resulting weighted sum. In order to compute \u00dd\ufffd\u00c2\u2039\u00c2\ufffd \u00e0\u00b5\u00ab\u00c2\u2020\u00c7\u00a1 \u00c2\u2020 \u00c2\u0152 \u00e0\u00b5\u00af, we use the Euclidean distance, which represents the usual manner in which humans think of distance in the real world [19]: \u00dc\u00a6 \u00c2\u2014\u00c2\u2026\u00c2\u017d\u00c2\u2039\u00c2\u2020\u00c2\u2021\u00c2\u0192\u00c2\ufffd \u00e1\u02c6\u00ba\u00dd\u201d\u00c7\u00a1 \u00dd\u2022\u00e1\u02c6\u00bb\u00e0\u00b5\u0152\u00e0\u00b6\u00a9\u00e0\u00b7\ufffd\u00e1\u02c6\u00ba\u00c2\u0161 \u00c2\u2039 \u00e0\u00b5\u2020 \u00c2\u203a \u00c2\u2039 \u00e1\u02c6\u00bb \u00cd\u00b4 \u00c2\ufffd \u00c2\u2039\u00e0\u00b5\u0152\u00cd\u00b3 (5) 751 Hamood Alshalabi et al. / Procedia Technology 11 ( 2013 ) 748 \u00e2\u20ac\u201c 754 4.2. The Naive Bayes (NB) The NB algorithm is a widely used as an algorithm for document classification. It is a probability based classifier, based on the features independent probability value is calculated for each and every model. NB is often used in text category tasks based on Bayes\u00e2\u20ac\u2122 formula: \u00e1\u02c6\u00ba \u00c2\u2039 \u00c8\ufffd\u00c2\u2020\u00e1\u02c6\u00bb \u00e0\u00b5\u0152 \u00e1\u02c6\u00ba \u00c2\u2039 \u00e1\u02c6\u00bb \u00e1\u02c6\u00ba\u00c2\u2020\u00c8\ufffd \u00c2\u2039 \u00e1\u02c6\u00bb \u00e1\u02c6\u00ba\u00c2\u2020\u00e1\u02c6\u00bb (6) Where \u00e1\u02c6\u00ba \u00c2\u2039 \u00c8\ufffd\u00c2\u2020\u00e1\u02c6\u00bb is the posterior probability of class \u00c2\u2039 given a new document d, \u00e1\u02c6\u00ba \u00c2\u2039 \u00e1\u02c6\u00bb is the probability of class \u00c2\u2039 which can be calculated by: \u00dc\u00b2\u00e1\u02c6\u00ba\u00dc\u00a5 \u00dd\u2026 \u00e1\u02c6\u00bb\u00e0\u00b5\u0152 \u00dc\u00b0 \u00dd\u2026 \u00dc\u00b0 (7) Where \u00dc\u00b0 \u00dd\u2026 is the number of documents assigned to class \u00c2\u2039 , and N is the number of classes, \u00e1\u02c6\u00ba\u00c2\u2020\u00c8\ufffd \u00c2\u2039 \u00e1\u02c6\u00bb is the probability of a document d given a class \u00c2\u2039 , and \u00e1\u02c6\u00ba\u00c2\u2020\u00e1\u02c6\u00bb is the probability of document d, and because the independence assumption of NB, the probability of document d can be calculated by: \u00dc\u00b2\u00e1\u02c6\u00ba\u00dc\u00a5 \u00dd\u2026 \u00c8\ufffd\u00dd\u20ac\u00e1\u02c6\u00bb\u00e0\u00b5\u0152\u00dc\u00b2\u00e1\u02c6\u00ba\u00dc\u00a5 \u00dd\u2026 \u00e1\u02c6\u00bb\u00e0\u00b7\u2018\u00dd\u0152\u00e1\u02c6\u00ba\u00dd\ufffd \u00dd\u2021 \u00c8\ufffd\u00dc\u00a5 \u00dd\u2026 \u00e1\u02c6\u00bb \u00dd\u0160 \u00dd\u2021\u00e0\u00b5\u0152\u00cd\u00b3 (8) where \u00dd\ufffd \u00dd\u2021 is a feature that occurs with class C i , and also we can calculate \u00dd\u0152\u00e1\u02c6\u00ba\u00c2\u2013 \u00c2\ufffd \u00c8\ufffd \u00c2\u2039 \u00e1\u02c6\u00bb by: \u00dc\u00b2\u00e1\u02c6\u00ba\u00dd\ufffd \u00dd\u2021 \u00c8\ufffd\u00dc\u00a5 \u00dd\u2026 \u00e1\u02c6\u00bb \u00e0\u00b5\u0152 \u00cd\u00b3\u00e0\u00b5\u2026\u00dd\u0160 \u00dd\u2021\u00dd\u2026 \u00cd\u00b3\u00e0\u00b5\u2026\u00cf\u0192 \u00dd\u0160 \u00dd\u201e\u00dd\u2021 \u00dd\u02c6 \u00dd\u201e\u00e0\u00b5\u0152\u00cd\u00b3 (9) where \u00dd\u0160 \u00dd\u2021\u00dd\u2026 is the total number of documents that contain feature \u00dd\ufffd \u00dd\u2021 and belong to class \u00c2\u2039 , l is the total number of distinct features in all training documents that belong to class Ci. NB calculates posterior probability for each class, and then assigns document d to highest posterior probability's class, i.e. \u00dc\u00a5\u00e1\u02c6\u00ba\u00dd\u20ac\u00e1\u02c6\u00bb \u00e0\u00b5\u0152 \u00c2\u0192\u00c2\u201d\u00c2\u2030\u00c2\ufffd\u00c2\u0192\u00c2\u0161 \u00dd\u2026\u00e0\u00b5\u0152 \u00c8\ufffd\u00dc\u00a5\u00c8\ufffd \u00e1\u02c6\u00ba\u00dc\u00b2 \u00e1\u02c6\u00ba\u00dc\u00a5 \u00dd\u2026 \u00c8\ufffd\u00dd\u20ac\u00e1\u02c6\u00bb\u00e1\u02c6\u00bb (10) 4.3. N-gram Classifier An N-gram is a continuous sequence of n characters or n words of a longer portion of a text. In this work, character level N-grams classifier has been used. In the N-gram training process, the N-gram profile needs to be generated. The generated N-gram profile consisted of the text which is spilt into tokens consisting letters only. Only the most frequent N-grams are kept. This gives us the N-gram profile for the document. In order for each document to be classified, each document need to go through the text preprocessing phase, then, the N-gram profile will be generated as described above. The N-gram profile of each document will then be compared against the profiles of all documents in the training classes (class profile) in terms of similarity. Specifically, cosine similarity measurement is used. It measures the similarity between two documents training document Di and test document \u00c2\u0152 : \u00dc\u00b5\u00dd\u2026\u00dd\u2030 \u00dc\u00bf\u00dd\ufffd\u00dd\u0160\u00dd\u2026\u00dd\ufffd\u00dd\u2039 \u00e1\u02c6\u00ba \u00c2\u2039 \u00c7\u00a1 \u00c2\u0152 \u00e1\u02c6\u00bb\u00e0\u00b5\u0152 \u00cf\u0192 \u00e1\u02c6\u00ba \u00dc\u00b9 \u00dd\u2026\u00dd\u2021 \u00e0\u00b5\u02c6 \u00dc\u00b9 \u00dd\u2020\u00dd\u2021 \u00e1\u02c6\u00bb \u00dd\u2030 \u00dd\u2021\u00e0\u00b5\u0152\u00cd\u00b3 \u00e0\u00b6\u00a7\u00cf\u0192 \u00dc\u00b9 \u00dd\u2026\u00dd\u2021 \u00cd\u00b4\u00dd\u2030 \u00dd\u2021\u00e0\u00b5\u0152\u00cd\u00b3 \u00e0\u00b5\u02c6 \u00cf\u0192 \u00dc\u00b9 \u00dd\u2020\u00dd\u2021 \u00cd\u00b4\u00dd\u2030 \u00dd\u2021\u00e0\u00b5\u0152\u00cd\u00b3 (11) 752 Hamood Alshalabi et al. / Procedia Technology 11 ( 2013 ) 748 \u00e2\u20ac\u201c 754 5. Evaluation and result In order to evaluate the used classification algorithms, several experiments have been conducted. We have measured the performance of these classification algorithms on manually classified Malay corpus collected from online Malay newspapers archives, namely; Bernama, and Utusan on-line. This corpus contains 3040 documents that are different in length and divided into eight categories: Arts, Business, Crime, History, Healthy, Medicine, Politics, Religion and Sport. All algorithms are evaluated using 5-fold cross-validation. To measure the performance of these classification methods, we use the Macro-averaged (Macro-F1) measure. This measure combines Recall and Precision in the following way metrics: 1 TP Precision TP FP TP Recall TP FN 2*Recall*Precision F Recall Precision macro 11 1 1 () m i FFi m \u00c6\u2019 In which, True Positive (TP) is the set of document that is correctly assigned to the given category, False Positive (FP) is the set of documents that incorrectly assigned to the category, False Negative (FN) is the set of documents that is incorrectly not assigned to the category and True Negative (TN) is the set of the set of documents correctly not assigned to the category. 5.1. Experimental results In order to test the efficiency of three classifiers k-NN, NB and N-gram, and in combination with the two feature reduction methods on Malay text categorization, we evaluate these methods individually, in which, features are selected from feature space at different size: 100, 200, 300, 400, 500 and 600. All of those classifiers have been evaluated using the 5-fold cross-validation. The results presented are in terms of macro-averaged F-measure where averaged values calculated across all 5-fold cross-validation experiments. We have examined the overall performance of the NB, N-gram and k-NN classifiers with the two feature selection methods, Chi-square and IG, applied to reduce the dimension of feature spaces. In the phase, the effects of the individual feature selection method on classifiers performances have been examined. Result on the performance (see Table 1) is displayed with features ranked in decreasing order and feature space at different size: 100, 200, 300, 400, 500 and 600. In Table 1, the best performance of 96.14 is the k-NN classifier when 400 of the features selected using by Chi-square feature selection. In addition, the best accuracy of 95.60 with NB classifier is achieved when 600 of the features selected by IG method are used, and the highest performance with N-gram classifier has been obtained when 600 of the features by IG method are used. When the classifier performances are compared, the k-NN algorithm achieves a higher performance than the NB and N-gram algorithms. We can see that the highest performance is obtained when the feature selection operations made by Chi-square. This observation indicates that the k-NN and NB classifiers are both suitable for Malay text categorization. In order to examine the overall performance based on document categories, all of parameters for the three classifiers, k-NN, NB and N-gram, are fixed according to their best results in Table 1. The experimental results with the k-NN, NB and N-gram for Malay text categorization are shown in Fig 1. As seen in Fig. 1, the KNN achieves the best result in the Religious, Business, Crime, Politic, Art and Health domain, meanwhile the NB achieves its best result in History and Sport domains. 753 Hamood Alshalabi et al. / Procedia Technology 11 ( 2013 ) 748 \u00e2\u20ac\u201c 754 Table 1: The performance (Macro-F1) of NB, N-gram, and KNN classifiers (feature selection methods vs. features sizes). k-NN NB N-gram Chi IG Chi IG Chi IG 100 94.97 94.16 84.84 84.26 75.62 78.36 200 95.95 95.66 90.20 91.37 81.40 83.32 300 95.34 95.75 93.62 94.19 84.17 84.64 400 96.14 95.43 93.89 94.11 86.13 87.67 500 94.29 94.92 95.11 94.83 87.34 88.10 600 92.78 94.91 94.13 95.60 87.80 90.05 Fig. 1. The performance (F-measure) on each class of k-NN, NB and N-gram classifiers 6. Conclusion and future works This paper presents our results on categorizing Malay documents. We have evaluated six classification models which are formed by combining two traditional feature selection methods, information gain (IG) and Chi-square, with three learning methods, k-NN, NB and N-gram In order to conduct the experiment, we have collected categorized Malay documents from online Malay newspapers archives, namely; Bernama, and Utusan on-line, and treated it as our Malay corpus. The corpus contains 3040 documents that are different in length and divided into eight categories: Arts, Business, Crime, History, Healthy, Medicine, Politics, Religion and Sport. Based on the carried out experiments, the obtained results showed that Chi-square feature selection method performed the best for terms selection, and both k-NN and NB exhibit the best classifiers for Malay text categorization. In the future, we plan to will expand the size of the corpus and to add more categories for evaluation. We also plan to add other advanced classification models to be tested on the expanded Malay corpus. 76 78 80 82 84 86 88 90 92 94 96 98 100 KNN NB N-GRAM 754 Hamood Alshalabi et al. / Procedia Technology 11 ( 2013 ) 748 \u00e2\u20ac\u201c 754 References [1] F. Sebastiani. Machine learning in automated text categorization. ACM computing surveys (CSUR) 2002; 34: 1-47. [2] A. Dasgupta, P. Drineas, B. Harb, V. Josifovski, and M. W. Mahoney. Feature selection methods for text classification. Proceedings of the 13th ACM SIGKDD international conference on Knowledge discovery and data mining; 2007. p. 230-239. [3] W. B. Cavnar and J. M. Trenkle. N-gram-based text categorization. Ann Arbor MI 1994; 48113: 161-175. [4] J. F\u00c3\u00bcrnkranz. A study using n-gram features for text categorization. Austrian Research Institute for Artifical Intelligence 1998; 3:1-10. [5] F. Mohammed, L. Zakaria, N. Omar, and M. Albared. Automatic Kurdish Sorani text categorization using N-gram based model. International Conference on,Computer & Information Science. 2012. p. 392-395. [6] M. Farhoodi, A. Yari, and A. Sayah. N-gram based text classification for Persian newspaper corpus. International Conference on Digital Content, Multimedia Technology and its Applications (IDCTA); 2011. p. 55-59. [7] P. Soucy and G. W. Mineau. A simple KNN algorithm for text categorization. International Conference on Data Mining; 2001.p. 647-648. [8] S. Tan. An effective refinement strategy for KNN text classifier. Expert Systems with Applications 2006; 30: 290-298. [9] S. Manne, S. Kotha, and S. Sameen Fatima. Text Categorization with K-Nearest Neighbor Approach. Proceedings of the International Conference on Information Systems Design and Intelligent Applications; 2012 .p. 413-420. [10] C. Apt\u00c3\u00a9, F. Damerau, and S. M. Weiss. Automated learning of decision rules for text categorization. ACM Transactions on Information Systems (TOIS) 1994;12: 233-251. [11] D. E. Johnson, F. J. Oles, T. Zhang, and T. Goetz. A decision-tree-based symbolic rule induction system for text categorization. IBM Systems Journal 2002; 41: 428-437. [12]T. Joachims. Text categorization with support vector machines: Learning with many relevant features. Machine learning: ECML-98;1998. p. 137-142. [13]T. Joachims. Learning to classify text using support vector machines: Methods, theory and algorithms. USA: Kluwer Academic Publishers Norwell; 2002. [14]S. Li, R. Xia, C. Zong, and C.-R. Huang. A framework of feature selection methods for text categorization. Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNL 2009; 2: 692-700. [15]Y. Yang and J. O. Pedersen. A comparative study on feature selection in text categorization. MACHINE LEARNING-INTERNATIONAL WORKSHOP THEN CONFERENCE;1997.p. 412-420. [16]M. Rogati and Y. Yang. High-performing feature selection for text classification. Proceedings of the eleventh international conference on Information and knowledge management; 2002. p. 659-661. [17]R. Mukras, N. Wiratunga, R. Lothian, S. Chakraborti, and D. Harper. Information gain feature selection for ordinal text classification using probability re-distribution. Proceedings of the Textlink workshop at IJCAI; 2007. [18]F. Thabtah, M. Eljinini, M. Zamzeer, and W. Hadi. Na\u00c3\u00afve Bayesian based on Chi Square to Categorize Arabic Data. Proceedings of The 11th International Business Information Management Association Conference (IBIMA) Conference on Innovation and Knowledge Management in Twin Track Economies, Cairo, Egypt,; 2009. p. 930-935. [19]J. He, A.-H. Tan, and C.-L. Tan. A comparative study on Chinese text categorization methods. Proceedings of PRICAI\u00e2\u20ac\u21222000 International Workshop on Text and Web Mining; 2000. p. p24-35. selection method performed the best for terms selection, and both k-NN and NB exhibit the best classifiers for Malay text categorization. In the future, we plan to will expand the size of the corpus and to add more categories for evaluation. We also plan to add other advanced classification models to be tested on the expanded Malay corpus. 76 78 80 82 84 86 88 90 92 94 96 98 100 KNN NB N-GRAM 754 Hamood Alshalabi et al. / Procedia Technology 11 ( 2013 ) 748 \u00e2\u20ac\u201c 754 References [1] F. Sebastiani. Machine learning in automated text categorization. ACM computing surveys (CSUR) 2002; 34: 1-47. [2] A. Dasgupta, P. Drineas, B. Harb, V. Josifovski, and M. W. Mahoney. Feature selection methods for text classification. Proceedings of the 13th ACM SIGKDD international conference on Knowledge discovery and data mining; 2007. p. 230-239. [3] W. B. Cavnar and J. M. Trenkle. N-gram-based text categorization. Ann Arbor MI 1994; 48113: 161-175. [4] J. F\u00c3\u00bcrnkranz. A study using n-gram features for text categorization. Austrian Research Institute for Artifical Intelligence 1998; 3:1-10. [5] F. Mohammed, L. Zakaria, N. Omar, and M. Albared. Automatic Kurdish Sorani text categorization using N-gram based model. International Conference on,Computer & Information Science. 2012. p. 392-395. [6] M. Farhoodi, A. Yari, and A. Sayah. N-gram based text classification for Persian newspaper corpus. International Conference on Digital Content, Multimedia Technology and its Applications (IDCTA); 2011. p. 55-59. [7] P. Soucy and G. W. Mineau. A simple KNN algorithm for text categorization. International Conference on Data Mining; 2001.p. 647-648. [8] S. Tan. An effective refinement strategy for KNN text classifier. Expert Systems with Applications 2006; 30: 290-298. [9] S. Manne, S. Kotha, and S. Sameen Fatima. Text Categorization with K-Nearest Neighbor Approach. Proceedings of the International Conference on Information Systems Design and Intelligent Applications; 2012 .p. 413-420. [10] C. Apt\u00c3\u00a9, F. Damerau, and S. M. Weiss. Automated learning of decision rules for text categorization. ACM Transactions on Information Systems (TOIS) 1994;12: 233-251. [11] D. E. Johnson, F. J. Oles, T. Zhang, and T. Goetz. A decision-tree-based symbolic rule induction system for text categorization. IBM Systems Journal 2002; 41: 428-437. [12]T. Joachims. Text categorization with support vector machines: Learning with many relevant features. Machine learning: ECML-98;1998. p. 137-142. [13]T. Joach PROTCY 1023 S2212-0173(13)00408-8 10.1016/j.protcy.2013.12.254 The Authors \u2606 Selection and peer-review under responsibility of the Faculty of Information Science & Technology, Universiti Kebangsaan Malaysia. Experiments on the Use of Feature Selection and Machine Learning Methods in Automatic Malay Text Categorization Hamood Alshalabi \u204e Sabrina Tiun Nazlia Omar Mohammed Albared Faculty of Information Science and Technology, Universiti Kebangsaan Malaysia, Malaysia \u204e Corresponding author. Due to the rapid growth of documents in digital form, research in automatic text categorization into predefined categories has witnessed a booming interest. Although, there is a wide range of supervised machine learning methods have been applied to categorize English, relatively, only a few studies have been done on Malay text categorization. This paper reports our comparative evaluation of three machine learning methods on Malay text categorization. Two feature selection methods (Information gain (IG) and Chi-square) and three machine learning methods (K-Nearest Neighbor (k-NN), Naive Bayes (NB) and N-gram) were investigated. The three supervised machine learning models were evaluated on categorized Malay corpus, and experimental results showed that the k- NN with the Chi-square feature selection gave the best performance (Macro-F1 = 96.14). Keywords Feature selection ;Machine Learning Methods N-gram Na\u00efve Bayesian K-Nearest Neighbour References [1] F. Sebastiani Machine learning in automated text categorization. ACM computing surveys (CSUR) 34 2002 1 47 [2] A. Dasgupta, P. Drineas, B. Harb, V. Josifovski, and M. W. Mahoney. Feature selection methods for text classification. Proceedings of the 13th ACM SIGKDD international conference on Knowledge discovery and data mining; 2007. p. 230-239. [3] W.B. Cavnar J.M. Trenkle N-gram-based text categorization Ann Arbor MI 48113 1994 161 175 [4] J. F\u00fcrnkranz A study using n-gram features for text categorization Austrian Research Institute for Artifical Intelligence 3 1998 1 10 [5] F. Mohammed, L. Zakaria, N. Omar, and M. Albared. Automatic Kurdish Sorani text categorization using N-gram based model. International Conference on,Computer & Information Science. 2012. p. 392-395. [6] M. Farhoodi, A. Yari, and A. Sayah. N-gram based text classification for Persian newspaper corpus. International Conference on Digital Content, Multimedia Technology and its Applications (IDCTA); 2011. p. 55-59. [7] P. Soucy and G. W. Mineau. A simple KNN algorithm for text categorization. International Conference on Data Mining; 2001.p. 647-648. [8] S. Tan An effective refinement strategy for KNN text classifier Expert Systems with Applications 30 2006 290 298 [9] S. Manne, S. Kotha, and S. Sameen Fatima. Text Categorization with K-Nearest Neighbor Approach. Proceedings of the International Conference on Information Systems Design and Intelligent Applications; 2012 .p. 413-420. [10] C. Apt\u00e9 F. Damerau S.M. Weiss Automated learning of decision rules for text categorization. ACM Transactions on Information Systems (TOIS) 12 1994 233 251 [11] D.E. Johnson F.J. Oles T. Zhang T. Goetz A decision-tree-based symbolic rule induction system for text categorization IBM Systems Journal 41 2002 428 437 [12] T. Joachims. Text categorization with support vector machines: Learning with many relevant features. Machine learning: ECML-98;1998. p. 137-142. [13] T. Joachims Learning to classify text using support vector machines: Methods theory and algorithms 2002 Kluwer Academic Publishers Norwell USA [14] S. Li R. Xia C. Zong C.-R. Huang A framework of feature selection methods for text categorization Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNL 2 2009 692 700 [15] Y. Yang and J. O. Pedersen. A comparative study on feature selection in text categorization. MACHINE LEARNING-INTERNATIONAL WORKSHOP THEN CONFERENCE;1997.p. 412-420. [16] M. Rogati and Y. Yang. High-performing feature selection for text classification. Proceedings of the eleventh international conference on Information and knowledge management; 2002. p. 659-661. [17] R. Mukras, N. Wiratunga, R. Lothian, S. Chakraborti, and D. Harper. Information gain feature selection for ordinal text classification using probability re-distribution. Proceedings of the Textlink workshop at IJCAI; 2007. [18] F. Thabtah, M. Eljinini, M. Zamzeer, and W. Hadi. Na\u00efve Bayesian based on Chi Square to Categorize Arabic Data. Proceedings of The 11th International Business Information Management Association Conference (IBIMA) Conference on Innovation and Knowledge Management in Twin Track Economies, Cairo, Egypt,; 2009. p. 930-935. [19] J. He, A.-H. Tan, and C.-L. Tan. A comparative study on Chinese text categorization methods. Proceedings of PRICAI\u20192000 International Workshop on Text and Web Mining; 2000. p. p24-35."
    },
    "10.1016/j.procs.2013.05.336": {
        "Title": "Cost-Sensitive Support Vector Machine for Semi-Supervised Learning",
        "Date": "2013",
        "Text": "serial JL 280203 291210 291871 31 90 Procedia Computer Science PROCEDIACOMPUTERSCIENCE 2013-06-01 2013-06-01 2014-11-04T06:36:39 1-s2.0-S1877050913004791 S1877-0509(13)00479-1 S1877050913004791 10.1016/j.procs.2013.05.336 S300 S300.6 HEAD-AND-TAIL 1-s2.0-S1877050913X00043 2021-10-14T13:14:58.733356Z 0 0 20130101 20131231 2013 2013-06-01T00:00:00Z rawtext articleinfo articletitlenorm authfirstinitialnorm authfirstsurnamenorm cid cids confeditor contenttype copyright crossmark dateloaded dateloadedtxt datesearch datesort dateupdated dco docsubtype doctype doi eid ewtransactionid hubeid indexeddate issn issnnorm itemstage itemtransactionid itemweight oauserlicense openaccess openarchive pg pgfirst pglast pii piinorm pubdateend pubdatestart pubdatetxt pubyr sortorder srctitle srctitlenorm srctype ssids alllist content oa subj suppl tomb vol volfirst volissue volumelist webpdf webpdfpagecount yearnav affil articletitle auth authfirstini authfull authkeywords authlast primabst ref 1877-0509 18770509 false 18 18 C Volume 18 175 1684 1689 1684 1689 2013 2013 2013-01-01 2013-12-31 2013 2013 International Conference on Computational Science Vassil Alexandrov Michael Lees Valeria Krzhizhanovskaya Jack Dongarra Peter M.A. Sloot article fla Copyright \u00a9 2013 The Authors. Published by Elsevier B.V. COSTSENSITIVESUPPORTVECTORMACHINEFORSEMISUPERVISEDLEARNING QI Z QIX2013X1684 QIX2013X1684X1689 QIX2013X1684XZ QIX2013X1684X1689XZ Full 2013-07-16T12:28:30Z http://creativecommons.org/licenses/by-nc-nd/3.0/ OA-Window ElsevierWaived 0 item S1877-0509(13)00479-1 S1877050913004791 1-s2.0-S1877050913004791 10.1016/j.procs.2013.05.336 280203 2014-11-04T04:59:23.387075-05:00 2013-01-01 2013-12-31 1-s2.0-S1877050913004791-main.pdf https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1877050913004791/MAIN/application/pdf/d5da5f1f319d325e652b2ef34eeb81e7/main.pdf https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1877050913004791/MAIN/application/pdf/d5da5f1f319d325e652b2ef34eeb81e7/main.pdf main.pdf pdf true 122598 MAIN 6 1-s2.0-S1877050913004791-main_1.png https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1877050913004791/PREVIEW/image/png/944f4705c4b4226cb65ea9ee8480faf9/main_1.png https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1877050913004791/PREVIEW/image/png/944f4705c4b4226cb65ea9ee8480faf9/main_1.png main_1.png png 63413 849 656 IMAGE-WEB-PDF 1 Procedia Computer Science 18 ( 2013 ) 1684 \u00e2\u20ac\u201c 1689 1877-0509 2013 The Authors. Published by Elsevier B.V. Selection and peer review under responsibility of the organizers of the 2013 International Conference on Computational Science doi: 10.1016/j.procs.2013.05.336 International Conference on Computational Science, ICCS 2013 Cost-Sensitive Support Vector Machine for Semi-Supervised Learning Zhiquan Qi a , Yingjie Tian a,\u00e2\u02c6\u2014 , Yong Shi a,\u00e2\u02c6\u2014 , Xiaodan Yu b a Research Center on Fictitious Economy & Data Science, Chinese Academy of Sciences, Beijing 100190, China b College of Information Science & Technology, University of Nebraska at Omaha, Omaha, NE 68182, USA. Abstract Cost-sensitive learning has been a hot research topic in machine learning. Many cost-sensitive methods have been successfully applied in many real-world applications such as disease diagnosis, fraud detection and business decision making. In this paper, we proposed a new Cost-Sensitive Laplacian Support Vector Machine(called Cos-LapSVM) , which can deal with the cost- sensitive problem in Semi-Supervised Learning. The effectiveness of the proposed method is demonstrated via experiments on UCI datasets. Keywords: SVM, Cost-Sensitive, Semi-Supervised Learning 1. Introduction Semi-Supervised Learning (SSL) [1, 2, 3] has attracted an increasing amount of interests in machine learning [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]. One main reason is that the labeled examples are always rare but there are large amount of unlabeled examples available in many practical problems. Several novel approaches for making use of the unlabeled data to improve the performance of classifiers have been proposed. Graph based methods are very important branch, where nodes in the graph are the labeled and unlabeled points, and weighted edges reflect the similarities of nodes. The initially assumption of these methods is that all points are located in a low dimensional manifold, and the graph is used to approximate the underlying manifold. Neighboring point pairs connected by large weight edges tend to have the same labels and vice versa. By the means, the labels associated with data can be propagated throughout the graph. By using the graph Laplacian, [16] proposed a novel Laplacian Support Vector Machine (LapSVM). Unlike other methods based on graph [17, 18, 19], LapSVM is a natural out-of-sample extension, which can classify data that becomes available after the training process, without having to retrain the classifier or resort to various heuristics [16]. A lot of experiments show that LapSVM achieves state of the art performance in semi-supervised classification [20]. In many real-world applications, different misclassifications often have different costs, such as disease di- agnosis, fraud detection, business decision making [21, 22] and object recognition [23, 24] and so on. These classification problem is usually called cost-sensitive learning problem [25, 26, 27, 28, 29, 30], which aimed to minimize the total misclassification costs. \u00e2\u02c6\u2014 Corresponding author Email addresses: qizhiquan@ucas.ac.cn (Zhiquan Qi), tyj@ucas.ac.cn (Yingjie Tian) Available online at www.sciencedirect.com Open access under CC BY-NC-ND license. 1685 Zhiquan Qi et al. / Procedia Computer Science 18 ( 2013 ) 1684 \u00e2\u20ac\u201c 1689 In this paper, we consider the problem of how to extend LapSVM algorithms to solve the cost-sensitive learn- ing problem and proposed a new algorithm: Cos-LapSVM. The remaining parts of the paper are organized as follows. Section 2 describes the detail of Cos-LapSVM; All public datasets experiment results on real data sets are shown in the section 3; The last section gives the conclusions. 2. Cost-Sensitive Laplacian Support Vector Machine(Cos-LapSVM) 2.1. Laplacian Semi-supervised Learning Framework Regularization [31] is a key technology for obtaining smooth decision functions and thus avoiding over-fitting to the training data, which is widely used in machine learning [32, 16]. Recently, the regularization framework has been recently extended in SSL field by [16] as follows. Given a set of labeled data T = {(x 1 , y 1 ), \u00c2\u00b7\u00c2\u00b7\u00c2\u00b7 , (x l , y l )}\u00e2\u02c6\u02c6( n \u00c3\u2014Y) l , (1) where x i \u00e2\u02c6\u02c6 n , y i \u00e2\u02c6\u02c6Y= {1,\u00e2\u02c6\u20191}, i = 1, \u00c2\u00b7\u00c2\u00b7\u00c2\u00b7 , l, and a set of unlabeled data (x l+1 , \u00c2\u00b7\u00c2\u00b7\u00c2\u00b7 , x l+u ), (2) where x i \u00e2\u02c6\u02c6 n . For a kernel function K(\u00c2\u00b7, \u00c2\u00b7) , which associated with a reproducing kernel Hilbert space H k , the decision function can be obtained by minimizing f \u00e2\u02c6\u2014 = argmin f\u00e2\u02c6\u02c6H k l \u00e2\u02c6\u2018 i=1 V(x i , y i , f ) + \u00ce\u00b3 H \u00e2\u20ac\u2013 f \u00e2\u20ac\u2013 2 H + \u00ce\u00b3 M \u00e2\u20ac\u2013 f \u00e2\u20ac\u2013 2 M , (3) where f is a unknown decision function, V represents some loss function on the labeled data, \u00ce\u00b3 H is the weight of \u00e2\u20ac\u2013 f \u00e2\u20ac\u2013 2 H and controls the complexity of f in the reproducing kernel Hilbert space. \u00ce\u00b3 M is the weight of \u00e2\u20ac\u2013 f \u00e2\u20ac\u2013 2 M and controls the complexity of the function in the intrinsic geometry of marginal distribution, \u00e2\u20ac\u2013 f \u00e2\u20ac\u2013 2 M is able to penalize f along the Riemann manifoldM. 2.2. Cos-LapSVM Similar to the LapSVM, we use the decision function f (x) = (w \u00c2\u00b7 \u00ce\u00a6(x)) + b, (4) where\u00ce\u00a6 is a nonlinear mapping from a low dimensional space to a higher dimensional Hilbert spaceH . According to Hilbert space theory([33]), w can be expressed as w = \u00e2\u02c6\u2018 l+u i=1 \u00ce\u00b1 i \u00ce\u00a6(x i ). So, the decision function is written as f (x) = l+u \u00e2\u02c6\u2018 i=1 \u00ce\u00b1 i K(x i , x) + b, (5) where K is an chosen kernel function: K(x i \u00c2\u00b7 x j ) = (\u00ce\u00a6(x i ) \u00c2\u00b7 \u00ce\u00a6(x j )). Also, the regularization term \u00e2\u20ac\u2013 f \u00e2\u20ac\u2013 2 H can be expressed as \u00e2\u20ac\u2013 f \u00e2\u20ac\u2013 2 H = \u00e2\u20ac\u2013w\u00e2\u20ac\u2013 2 = (\u00ce\u00a6\u00ce\u00b1) (\u00ce\u00a6\u00ce\u00b1) = \u00ce\u00b1 K\u00ce\u00b1. (6) For the manifold regularization \u00e2\u20ac\u2013 f + \u00e2\u20ac\u2013 2 M , a data adjacency graph W (l+u)\u00c3\u2014(l+u) is defined by nodes W i, j , which repre- sents the similarity of every pair of input samples. The weight matrix W may be defined by k nearest neighbor or graph kernels as follows([16]): W ij = { exp(\u00e2\u02c6\u2019\u00e2\u20ac\u2013x i \u00e2\u02c6\u2019 x j \u00e2\u20ac\u2013 2 2 /2\u00cf\u0192 2 ), if x i , x j are neighbor; 0, Otherwise, (7) 1686 Zhiquan Qi et al. / Procedia Computer Science 18 ( 2013 ) 1684 \u00e2\u20ac\u201c 1689 where \u00e2\u20ac\u2013x i \u00e2\u02c6\u2019 x j \u00e2\u20ac\u2013 2 2 denotes the Euclidean norm in n . So the manifold regularization is defined by \u00e2\u20ac\u2013 f \u00e2\u20ac\u2013 2 M = 1 (l + u) 2 l+u \u00e2\u02c6\u2018 i, j=1 W i, j ( f (x i ) \u00e2\u02c6\u2019 f (x j )) 2 = f Lf, (8) where L = D \u00e2\u02c6\u2019 W is the graph Laplacian, D is a diagonal matrix with its i-th diagonal D ii = \u00e2\u02c6\u2018 l+u j=1 W ij , and f = [ f (x 1 ), \u00c2\u00b7\u00c2\u00b7\u00c2\u00b7 , f (x l+u )] = K\u00ce\u00b1, here we drop the bias term b. According to the cost-sensitive learning method of [30], the primal problem of Cos-LapSVM can be written as min \u00ce\u00be\u00e2\u02c6\u02c6R l ,\u00ce\u00b1\u00e2\u02c6\u02c6R n [\u00ce\u00bb 1 \u00e2\u02c6\u2018 {i|y i =1} \u00ce\u00be i + \u00ce\u00bb 2 \u00e2\u02c6\u2018 {i|y i =\u00e2\u02c6\u20191} \u00ce\u00be i ] + \u00ce\u00b3 H \u00ce\u00b1 K\u00ce\u00b1 + \u00ce\u00b3 M \u00ce\u00b1 KLK\u00ce\u00b1, s.t. l+u \u00e2\u02c6\u2018 j=1 \u00ce\u00b1 i K(x i , x j ) + b \u00e2\u2030\u00a5 1 \u00e2\u02c6\u2019 \u00ce\u00be i , y i = 1, l+u \u00e2\u02c6\u2018 j=1 \u00ce\u00b1 i K(x i , x j ) + b \u00e2\u2030\u00a4\u00e2\u02c6\u2019\u00ce\u00bb 3 + \u00ce\u00be i , y i = \u00e2\u02c6\u20191, \u00ce\u00be i \u00e2\u2030\u00a5 0, i = 1, \u00c2\u00b7\u00c2\u00b7\u00c2\u00b7 , l, (9) where \u00ce\u00bb 1 = C 1 ,\u00ce\u00bb 2 = 2C \u00e2\u02c6\u20191 \u00e2\u02c6\u2019 1,\u00ce\u00bb 3 = 1 2C \u00e2\u02c6\u20191 \u00e2\u02c6\u2019 1 , (10) C 1 and C \u00e2\u02c6\u20191 are the penalty factors for the positive and negative class. By introducing its Lagrange function L(\u00ce\u00be, \u00ce\u00b1,b,\u00ce\u00b2,\u00cf\ufffd,\u00ce\u00b7) =[\u00ce\u00bb 1 \u00e2\u02c6\u2018 {i|y i =1} \u00ce\u00be i + \u00ce\u00bb 2 \u00e2\u02c6\u2018 {i|y i =\u00e2\u02c6\u20191} \u00ce\u00be i ] + \u00ce\u00b3 H \u00ce\u00b1 K\u00ce\u00b1 + \u00ce\u00b3 M \u00ce\u00b1 KLK\u00ce\u00b1 \u00e2\u02c6\u2019 \u00e2\u02c6\u2018 {i|y i =1} \u00ce\u00b2 i ( l+u \u00e2\u02c6\u2018 j=1 \u00ce\u00b1 i K(x i , x j ) + b \u00e2\u02c6\u2019 1 + \u00ce\u00be i ) + \u00e2\u02c6\u2018 {i|y i =\u00e2\u02c6\u20191} \u00cf\ufffd i ( l+u \u00e2\u02c6\u2018 j=1 \u00ce\u00b1 i K(x i , x j )+ b + \u00ce\u00bb 3 \u00e2\u02c6\u2019 \u00ce\u00be i ) \u00e2\u02c6\u2019 l \u00e2\u02c6\u2018 i=1 \u00ce\u00b7 i \u00ce\u00be i , (11) where \u00ce\u00b2 i ,\u00cf\ufffd i ,\u00ce\u00b7 i \u00e2\u02c6\u02c6 R are the Lagrange multipliers, therefore the dual problem of (11) can be formulated as max \u00ce\u00be,\u00ce\u00b1,b,\u00ce\u00b2,\u00cf\ufffd,\u00ce\u00b7 L(\u00ce\u00be, \u00ce\u00b1,b,\u00ce\u00b2,\u00cf\ufffd,\u00ce\u00b7), (12) s.t.\u00e2\u02c6\u2021 \u00ce\u00be,\u00ce\u00b1,b L(\u00ce\u00be, \u00ce\u00b1,b,\u00ce\u00b2,\u00cf\ufffd,\u00ce\u00b7) = 0, (13) \u00ce\u00b2 i ,\u00cf\ufffd i ,\u00ce\u00b7 i \u00e2\u2030\u00a5 0. (14) From equation (13) we get \u00e2\u02c6\u2021 b L = \u00e2\u02c6\u2018 {i|y i =1} \u00ce\u00b2 i \u00e2\u02c6\u2019 \u00e2\u02c6\u2018 {i|y i =\u00e2\u02c6\u20191} \u00cf\ufffd i = 0, (15) \u00e2\u02c6\u2021 \u00ce\u00be i L = \u00ce\u00bb 1 \u00e2\u02c6\u2019 \u00ce\u00b2 i \u00e2\u02c6\u2019 \u00ce\u00b7 i = 0, y i = 1, (16) \u00e2\u02c6\u2021 \u00ce\u00be i L = \u00ce\u00bb 2 \u00e2\u02c6\u2019 \u00cf\ufffd i \u00e2\u02c6\u2019 \u00ce\u00b7 i = 0, y i = \u00e2\u02c6\u20191, (17) \u00e2\u02c6\u2021 \u00ce\u00b1 L = (2\u00ce\u00b3 H K + 2\u00ce\u00b3 M KLK)\u00ce\u00b1 \u00e2\u02c6\u2019 KJ 1 \u00ce\u00b2 \u00e2\u20ac\u00b2 + KJ 2 \u00cf\ufffd \u00e2\u20ac\u00b2 = 0, (18) 1687 Zhiquan Qi et al. / Procedia Computer Science 18 ( 2013 ) 1684 \u00e2\u20ac\u201c 1689 where J 1 = [E 1 0] is a l\u00c3\u2014 (l+u) matrix with E 1 as l\u00c3\u2014 l diagonal matrix ((E 1 ) ii = 1, if y i = 1, otherwise, (E 1 ) ii = 0); similarly, J 2 = [E 2 0] is a l \u00c3\u2014 (l + u) matrix with E 2 as l \u00c3\u2014 l diagonal matrix ((E 2 ) ii = \u00e2\u02c6\u20191, if y i = \u00e2\u02c6\u20191, otherwise, (E 1 ) ii = 0); \u00ce\u00b2 \u00e2\u20ac\u00b2 \u00e2\u02c6\u02c6 R l ,ify i = \u00e2\u02c6\u20191, \u00ce\u00b2 \u00e2\u20ac\u00b2 i = 0; \u00ce\u00b7 \u00e2\u20ac\u00b2 \u00e2\u02c6\u02c6 R l ,ify i = 1, \u00ce\u00b7 \u00e2\u20ac\u00b2 i = 0. Substituting the above equations into problem (13), the dual problem can be expressed as max \u00ce\u00b2 \u00e2\u20ac\u00b2 ,\u00cf\ufffd \u00e2\u20ac\u00b2 \u00e2\u02c6\u2019 1 2 (\u00ce\u00b2 \u00e2\u20ac\u00b2 J 1 \u00e2\u02c6\u2019 \u00cf\ufffd \u00e2\u20ac\u00b2 J 2 )K(2\u00ce\u00b3 H + 2\u00ce\u00b3 M KL) \u00e2\u02c6\u20191 (J 1 \u00ce\u00b2 \u00e2\u20ac\u00b2 \u00e2\u02c6\u2019 J 2 \u00cf\ufffd \u00e2\u20ac\u00b2 ) + l \u00e2\u02c6\u2018 i=1 (\u00ce\u00b2 \u00e2\u20ac\u00b2 i + \u00ce\u00bb 3 \u00cf\ufffd \u00e2\u20ac\u00b2 i ) s.t. \u00e2\u02c6\u2018 {i|y i =1} \u00ce\u00b2 i \u00e2\u02c6\u2019 \u00e2\u02c6\u2018 {i|y i =\u00e2\u02c6\u20191} \u00cf\ufffd i = 0, 0 \u00e2\u2030\u00a4 \u00ce\u00b2 i \u00e2\u2030\u00a4 \u00ce\u00bb 1 , y i = 1, 0 \u00e2\u2030\u00a4 \u00cf\ufffd i \u00e2\u2030\u00a4 \u00ce\u00bb 2 , y i = \u00e2\u02c6\u20191. (19) It is not difficult to find that (19) will degenerate to the standard LapSVM when C 1 = C \u00e2\u02c6\u20191 = 1. 3. Experiments Table 1. Parameters and Samples on UCI datasets Datasets Dimensions Number of cost(P, N) cost(N, P) samples Hepatitis 19 155 0.67 0.33 Australian 14 690 0.75 0.25 BUPA liver 6 345 0.8 0.2 CMC 9 844 0.83 0.17 Credit 19 690 0.85 0.15 Diabetis 8 768 0.87 0.13 Flare-Solar 9 1066 0.88 0.12 Table 2. Results on UCI datasets Datasets Cos-LapSVM LapSVM TSVM Hepatitis 0.208 0.223 0.254 Australian 0.424 0.476 0.462 BUPA liver 0.389 0.412 0.433 CMC 0.485 0.521 0.553 Credit 0.343 0.432 0.411 Diabetis 0.457 0.460 0.471 Flare-Solar 0.477 0.501 0.535 The performance of the Cos-LapSVM was evaluated in UCI datasets (see Table 1). We compare the Cos- LapSVM against LapSVM and TSVM[34]. LapSVM and TSVM are cost-blind. We use sampling method [35] to make these two method solve the cost-sensitive problem. Each data set is split into two equal halves, one for training and the other for testing. Each training set contains 20% labeled examples. The RBF kernel is always used. The testing accuracies of all experiments are computed using standard 10-fold cross validation. \u00ce\u00b3 H ,\u00ce\u00b3 M and RBF kernel parameter \u00cf\u0192 are all selected from the set {2 i |i = \u00e2\u02c6\u20197, \u00c2\u00b7\u00c2\u00b7\u00c2\u00b7 , 7} by 10-fold cross validation on the tuning set comprising of random 10% of the training data. Once the parameters are selected, the tuning set was returned 1688 Zhiquan Qi et al. / Procedia Computer Science 18 ( 2013 ) 1684 \u00e2\u20ac\u201c 1689 to the training set to learn the final decision function. We use the Average Cost(AC) to evaluate these algorithms\u00e2\u20ac\u2122 performance. The AC can be expressed as AC = FP\u00c3\u2014 cost(N, P) + FN \u00c3\u2014 cost(P, N) TP+ TN+ FP+ FN , (20) where TP is true positive, TN is true negative, FP is false positive and FN is false negative; cost(N, P) is the cost of which negative data is classified into positive one and cost(P, N) is the cost of which positive data is classified into negative one. All algorithms are implemented by using MATLAB 2010. The experiment environment: Intel Core i7-2600 CPU, 4 GB memory. From Table 2, we find that Cos-LapSVM significantly outperforms the cost-sensitive extensions of LapSVM and TSVM. LapSVM has a better performance than TSVM in most cases. The main reason is that our cost- sensitive method roots in the method of [30], which is derived as the minimizer of the associated risk and can avoid the shortcomings of previous approaches to cost-sensitive SVM design. 4. Conclusion In this paper, we proposed a new Cost-Sensitive Laplacian Support Vector Machine(called Cos-LapSVM). All experiments in datasets show that the performance of the Cos-LapSVM is better than that of the LapSVM and the TSVM. However, since Cos-LapSVM needs to computing an extra inverse matrix before solving the quadratic programming, so in the future work, we will try to solve the Cos-LapSVM in its primal formulation. 5. Acknowledgment This work has been partially supported by grants fromNational Natural Science Foundation of China( NO.70921061, NO.11271361, No. 61202226), the CAS/SAFEA International Partnership Program for Creative Research Teams, Major International( Ragional) Joint Research Project(NO.71110107026), the President Fund of GUCAS. References [1] M. Seeger, Learning with labeled and unlabeled data, Tech. rep. (2001). [2] O. Chapelle, B. Scho\u00c2\u00a8lkopf, A. Zien (Eds.), Semi-Supervised Learning (Adaptive Computation and Machine Learning), The MIT Press, 2006. [3] X. Zhu, Semi-supervised learning literature survey (2006). [4] Y. Tian, Y. Shi, X. Liu, Recent advances on support vector machines research, Technological and Economic Development of Economy 18(1) (2012) 5\u00e2\u20ac\u201c33. [5] Z. Qi, Y. Tian, S. Yong, Twin support vector machine with universum data, Neural Networks 36C (2012) 112\u00e2\u20ac\u201c119. doi:doi: 10.1016/j.neunet.2012.09.004. [6] Z. Qi, Y. Tian, S. Yong, Robust twin support vector machine for pattern classification, Pattern Recognition 46(1) (2013) 305\u00e2\u20ac\u201c316. doi:doi:10.1016/j.patcog.2012.06.019. [7] Z. Qi, Y. Tian, Y. Shi, Structural twin support vector machine for classification, Knowledge-Based Systems. [8] C. Zhang, Y. Shao, Y. Tan, N. Deng, Mixed-norm linear support vector machine, Neural Comput & Applicdoi:10.1007/s00521-012- 1166-0. [9] N. C.Zhang, Y.Tian, The new interpretation of support vector machines on statistical learning theory, Science China Mathematics 53(1) (2010) 151\u00e2\u20ac\u201c164. [10] Y. Shao, C. Zhang, X. Wang, N. Deng, Improvements on twin support vector machines, Neural Networks, IEEE Transactions on 22 (6) (2011) 962\u00e2\u20ac\u201c968. [11] Y. Li, Y. Shao, N. Deng, Improved prediction of palmitoylation sites using pwms and svm, Protein and Peptide Letters 18 (2) (2011) 186. [12] Z. Qi, Y. Tian, S. Yong, Regularized multiple criteria linear programming via linear programming, in: Procedia Computer Science, Vol. 9, 2012, pp. 1234\u00e2\u20ac\u201c1239. [13] Z. Qi, Y. Tian, S. Yong, Regular multiple criteria linear programming for semi-supervised classification, in: ICDM(OEDM), 2012. [14] Z. Qi, Y. Tian, S. Yong, Multi-instance classification based on regularized multiple criteria linear programming, Neural Computing & Applicationsdoi:10.1007/s00521-012-1008-0. [15] Z. Qi, S. Yong, Structural regular multiple criteria linear programming for classification problem, International Journal of Computers, Communications & Control 7(4) (2012) 732\u00e2\u20ac\u201c742. doi:doi: http://dx.doi.org/10.1016/ j.neunet. 2012.07.011. [16] M. Belkin, P. Niyogi, V. Sindhwani, Manifold Regularization: A Geometric Framework for Learning from Labeled and Unlabeled Examples, Journal of Machine Learning Research 7 (2006) 2399\u00e2\u20ac\u201c2434. 1689 Zhiquan Qi et al. / Procedia Computer Science 18 ( 2013 ) 1684 \u00e2\u20ac\u201c 1689 [17] T. Joachims, Transductive learning via spectral graph partitioning, in: In ICML, 2003, pp. 290\u00e2\u20ac\u201c297. [18] M. Belkin, P. Niyogi, Using Manifold Structure for Partially Labelled Classification, in: NIPS, 2002, pp. 953\u00e2\u20ac\u201c960. [19] X. Zhu, Z. Ghahramani, J. Lafferty, Semi-supervised learning using gaussian fields and harmonic functions, in: IN ICML, 2003, pp. 912\u00e2\u20ac\u201c919. [20] Z. Qi, Y. Tian, S. Yong, Laplacian twin support vector machine for semi-supervised classification, Neural Networks 35 (2012) 46\u00e2\u20ac\u201c53. doi:doi: http://dx.doi.org/10.1016/ j.neunet. 2012.07.011. [21] X. Yu, D. Khazanchi, An exploratory study of the impact of it capabilities adaptation on shared mental models similarity, in: MWAIS 2011, 2011. [22] X. Yu, D. Owens, D. Khazanchi, Building socioemotional environments in metaverses for virtual teams in healthcare: A conceptual exploration, in: Health Information Science, Springer, 2012, pp. 4\u00e2\u20ac\u201c12. [23] Z. Qi, Y. Xu, L. Wang, Y. Song, Online multiple instance boosting for object detection, Neurocomputing 74 (10) (2011) 1769\u00e2\u20ac\u201c1775. doi:10.1016/j.neucom.2011.02.011. URL http://dx.doi.org/10.1016/j.neucom.2011.02.011 [24] Z. Qi, Y. Tian, S. Yong, Efficient railway tracks detection and turnouts recognition method using hog features, Neural Computing & Applicationsdoi:10.1007/s00521-012-0846-0. [25] M. Kubat, S. Matwin, Addressing the curse of imbalanced training sets: One-sided selection, in: In Proceedings of the Fourteenth International Conference on Machine Learning, Morgan Kaufmann, 1997, pp. 179\u00e2\u20ac\u201c186. [26] S. ichi Amari, S. Wu, Improving support vector machine classifiers by modifying kernel functions, NEURAL NETWORKS 12 (1999) 783\u00e2\u20ac\u201c789. [27] N. V. Chawla, K. W. Bowyer, L. O. Hall, W. P. Kegelmeyer, Smote: Synthetic minority over-sampling technique., J. Artif. Intell. Res. (JAIR) 16 (2002) 321\u00e2\u20ac\u201c357. [28] G. Wu, E. Y. Chang, KBA: Kernel Boundary Alignment Considering Imbalanced Data Distribution, IEEE Transactions on Knowledge and Data Engineering 17 (6) (2005) 786\u00e2\u20ac\u201c795. doi:10.1109/TKDE.2005.95. [29] H. Masnadi-Shirazi, N. Vasconcelos, Cost-Sensitive Boosting, IEEE Transactions on Pattern Analysis and Machine Intelligence 33 (2) (2011) 294\u00e2\u20ac\u201c309. [30] H. Masnadi-Shirazi, N. Vasconcelos, Risk minimization, probability elicitation, and cost-sensitive SVMs, in: J. Fu\u00c2\u00a8rnkranz, T. Joachims (Eds.), Proceedings of the 27th International Conference on Machine Learning (ICML-10), Omnipress, Omnipress, Haifa, Israel, 2010, p. 759\u00e2\u20ac\u201c766. URL http://www.icml2010.org/papers/376.pdf [31] A. Tikhonov, Regularization of incorrectly posed problems, Sov. Math. Dokl. 4 (1963) 1624\u00e2\u20ac\u201c1627. [32] T. Evgeniou, M. Pontil, T. Poggio, Regularization Networks and Support Vector Machines, Advances in Computational Mathematics 13 (1) (2000) 1\u00e2\u20ac\u201c50. [33] B. Scho\u00c2\u00a8lkopf, A. J. Smola, Learning with kernels: support vector machines, regularization, optimization, and beyond, Adaptive compu- tation and machine learning, MIT Press, 2002. [34] V. N. Vapnik, The Nature of Statistical Learning Theory, Springer New York, 1996. [35] C. Elkan, The foundations of cost-sensitive learning, in: In Proceedings of the Seventeenth International Joint Conference on Artificial Intelligence, 2001, pp. 973\u00e2\u20ac\u201c978. 1234\u00e2\u20ac\u201c1239. [13] Z. Qi, Y. Tian, S. Yong, Regular multiple criteria linear programming for semi-supervised classification, in: ICDM(OEDM), 2012. [14] Z. Qi, Y. Tian, S. Yong, Multi-instance classification based on regularized multiple criteria linear programming, Neural Computing & Applicationsdoi:10.1007/s00521-012-1008-0. [15] Z. Qi, S. Yong, Structural regular multiple criteria linear programming for classification problem, International Journal of Computers, Communications & Control 7(4) (2012) 732\u00e2\u20ac\u201c742. doi:doi: http://dx.doi.org/10.1016/ j.neunet. 2012.07.011. [16] M. Belkin, P. Niyogi, V. Sindhwani, Manifold Regularization: A Geometric Framework for Learning from Labeled and Unlabeled Examples, Journal of Machine Learning Research 7 (2006) 2399\u00e2\u20ac\u201c2434. 1689 Zhiquan Qi et al. / Procedia Computer Science 18 ( 2013 ) 1684 \u00e2\u20ac\u201c 1689 [17] T. Joachims, Transductive learning via spectral graph partitioning, in: In ICML, 2003, pp. 290\u00e2\u20ac\u201c297. [18] M. Belkin, P. Niyogi, Using Manifold Structure for Partially Labelled Classification, in: NIPS, 2002, pp. 953\u00e2\u20ac\u201c960. [19] X. Zhu, Z. Ghahramani, J. Lafferty, Semi-supervised learning using gaussian fields and harmonic functions, in: IN ICML, 2003, pp. 912\u00e2\u20ac\u201c919. [20] Z. Qi, Y. Tian, S. Yong, Laplacian twin support vector machine for semi-supervised classification, Neural Networks 35 (2012) 46\u00e2\u20ac\u201c53. doi:doi: http://dx.doi.org/10.1016/ j.neunet. 2012.07.011. [21] X. Yu, D. Khazanchi, An exploratory study of the impact of it capabilities adaptation on shared mental models similarity, in: MWAIS 2011, 2011. [22] X. Yu, D. Owens, D. Khazanchi, Building socioemotional environments in metaverses for virtual teams in healthcare: A conceptual exploration, in: Health Information Science, Springer, 2012, pp. 4\u00e2\u20ac\u201c12. [23] Z. Qi, Y. Xu, L. Wang, Y. Song, Online multiple instance boosting for object detection, Neurocomputing 74 (10) (2011) 1769\u00e2\u20ac\u201c1775. doi:10.1016/j.neucom.2011.02.011. URL http://dx.doi.org/10.1016/j.neucom.2011.02.011 [24] Z. Qi, Y. Tian, S. Yong, Efficient railway tracks detection and turnouts recognition method using hog features, Neural Computing & Applicationsdoi:10.1007/s00521-012-0846-0. [25] M. Kubat, S. Matwin, Addressing the curse of imbalanced training sets: One-sided selection, in: In Proceedings of the Fourteenth International Conference on Machine Learning, Morgan Kaufmann, 1997, pp. 179\u00e2\u20ac\u201c186. [26] S. ichi Amari, S. Wu, Improving support vector machine classifiers by modifying kernel functions, NEURAL NETWORKS 12 (1999) 783\u00e2\u20ac\u201c789. [27] N. V. Chawla, K. W. Bowyer, L. O. Hall, W. P. Kegelmeyer, Smote: Synthetic minority over-sampling technique., J. Artif. Intell. Res. (JAIR) 16 (2002) 321\u00e2\u20ac\u201c357. [28] G. Wu, E. Y. Chang, KBA: Kernel Boundary Alignment Considering Imbalanced Data Distribution, IEEE Transactions on Knowledge and Data Engineering 17 (6) (2005) 786\u00e2\u20ac\u201c795. doi PROCS 2115 S1877-0509(13)00479-1 10.1016/j.procs.2013.05.336 The Authors \u2606 Selection and peer review under responsibility of the organizers of the 2013 International Conference on Computational Science. Cost-Sensitive Support Vector Machine for Semi-Supervised Learning Zhiquan Qi a Yingjie Tian a \u204e Yong Shi a \u204e Xiaodan Yu b a Research Center on Fictitious Economy & Data Science, Chinese Academy of Sciences, Beijing 100190, China b College of Information Science & Technology, University of Nebraska at Omaha, Omaha, NE 68182, USA \u204e Corresponding authors. Cost-sensitive learning has been a hot research topic in machine learning. Many cost-sensitive methods have been successfully applied in many real-world applications such as disease diagnosis, fraud detection and business decision making. In this paper, we proposed a new Cost-Sensitive Laplacian Support Vector Machine(called Cos-LapSVM), which can deal with the cost- sensitive problem in Semi-Supervised Learning. The effectiveness of the proposed method is demonstrated via experiments on UCI datasets Keywords SVM Cost-Sensitive Semi-Supervised Learning References [1] M. Seeger, Learning with labeled and unlabeled data, Tech. rep. (2001). [2] O. Chapelle, B. Sch\u00f6lkopf, A. Zien (Eds.), Semi-Supervised Learning (Adaptive Computation and Machine Learning), The MIT Press, 2006. [3] X. Zhu, Semi-supervised learning literature survey (2006). [4] Y. Tian, Y. Shi, X. Liu, Recent advances on support vector machines research, Technological and Economic Development of Economy 18(1) (2012) 5-33. [5] Z. Qi, Y. Tian, S. Yong, Twin support vector machine with universum data, Neural Networks 36C (2012) 112-119. doi:doi: 10.1016/j.neunet.2012.09.004. [6] Z. Qi, Y. Tian, S. Yong, Robust twin support vector machine for pattern classification, Pattern Recognition 46(1) (2013) 305-316. doi:doi:10.1016/j.patcog.2012.06.019. [7] Z. Qi, Y. Tian, Y. Shi, Structural twin support vector machine for classification, Knowledge-Based Systems. [8] C. Zhang, Y. Shao, Y. Tan, N. Deng, Mixed-norm linear support vector machine, Neural Comput & Applicdoi:10.1007/s00521-012-1166-0. [9] N. C. Zhang, Y. Tian, The new interpretation of support vector machines on statistical learning theory, Science China Mathematics 53(1) (2010) 151-164. [10] Y. Shao, C. Zhang, X. Wang, N. Deng, Improvements on twin support vector machines, Neural Networks, IEEE Transactions on 22 (6) (2011) 962-968. [11] Y. Li, Y. Shao, N. Deng, Improved prediction of palmitoylation sites using pwms and svm, Protein and Peptide Letters 18 (2) (2011) 186. [12] Z. Qi, Y. Tian, S. Yong, Regularized multiple criteria linear programming via linear programming, in: Procedia Computer Science, Vol. 9, 2012, pp. 1234-1239. [13] Z. Qi, Y. Tian, S. Yong, Regular multiple criteria linear programming for semi-supervised classification, in: ICDM(OEDM), 2012. [14] Z. Qi, Y. Tian, S. Yong, Multi-instance classification based on regularized multiple criteria linear programming, Neural Computing & Applicationsdoi:10.1007/s00521-012-1008-0. [15] Z. Qi, S. Yong, Structural regular multiple criteria linear programming for classification problem, International Journal of Computers, Communications & Control 7(4) (2012) 732-742. doi:doi: http://dx.doi.org/10.1016/j.neunet. 2012.07.011. [16] M. Belkin, P. Niyogi, V. Sindhwani, Manifold Regularization: A Geometric Framework for Learning from Labeled and Unlabeled Examples, Journal of Machine Learning Research 7 (2006) 2399-2434. [17] T. Joachims, Transductive learning via spectral graph partitioning, in: In ICML, 2003, pp. 290-297. [18] M. Belkin, P. Niyogi, Using Manifold Structure for Partially Labelled Classification, in: NIPS, 2002, pp. 953-960. [19] X. Zhu, Z. Ghahramani, J. Lafferty, Semi-supervised learning using gaussian fields and harmonic functions, in: IN ICML, 2003, pp. 912-919. [20] Z. Qi, Y. Tian, S. Yong, Laplacian twin support vector machine for semi-supervised classification, Neural Networks 35 (2012) 46-53. doi:doi: http://dx.doi.org/10.1016/j.neunet. 2012.07.011. [21] X. Yu, D. Khazanchi, An exploratory study of the impact of it capabilities adaptation on shared mental models similarity, in: MWAIS 2011, 2011. [22] X. Yu, D. Owens, D. Khazanchi, Building socioemotional environments in metaverses for virtual teams in healthcare: A conceptual exploration, in: Health Information Science, Springer, 2012, pp. 4-12. [23] Z. Qi, Y. Xu, L. Wang, Y. Song, Online multiple instance boosting for object detection, Neurocomputing 74 (10) (2011) 1769-1775. doi:10.1016/j.neucom.2011.02.011. URL http://dx.doi.org/10.1016/j.neucom.2011.02.011. [24] Z. Qi, Y. Tian, S. Yong, Efficient railway tracks detection and turnouts recognition method using hog features, Neural Computing & Applicationsdoi:10.1007/s00521-012-0846-0. [25] M. Kubat, S. Matwin, Addressing the curse of imbalanced training sets: One-sided selection, in: In Proceedings of the Fourteenth International Conference on Machine Learning, Morgan Kaufmann, 1997, pp. 179-186. [26] S. ichi Amari, S. Wu, Improving support vector machine classifiers by modifying kernel functions, NEURAL NETWORKS 12 (1999) 783-789. [27] N. V. Chawla, K.W. Bowyer, L.O. Hall, W.P. Kegelmeyer, Smote: Synthetic minority over-sampling technique., J. Artif. Intell. Res. (JAIR) 16 (2002) 321-357. [28] G. Wu, E.Y. Chang, KBA: Kernel Boundary Alignment Considering Imbalanced Data Distribution, IEEE Transactions on Knowledge and Data Engineering 17 (6) (2005) 786-795. doi:10.1109/TKDE. 2005.95. [29] H. Masnadi-Shirazi, N. Vasconcelos, Cost-Sensitive Boosting, IEEE Transactions on Pattern Analysis and Machine Intelligence 33 (2) (2011) 294-309. [30] H. Masnadi-Shirazi, N. Vasconcelos, Risk minimization, probability elicitation, and cost-sensitive SVMs, in: J. F\u00fcrnkranz, T. Joachims (Eds.), Proceedings of the 27th International Conference on Machine Learning (ICML-10), Omnipress, Omnipress, Haifa, Israel, 2010, p. 759-766. URL http://www.icml2010.org/papers/376.pdf. [31] A. Tikhonov, Regularization of incorrectly posed problems, Sov. Math. Dokl. 4 (1963) 1624-1627. [32] T. Evgeniou, M. Pontil, T. Poggio, Regularization Networks and Support Vector Machines, Advances in Computational Mathematics 13 (1) (2000) 1-50. [33] B. Sch\u00f6lkopf, A.J. Smola, Learning with kernels: support vector machines, regularization, optimization, and beyond, Adaptive compu- tation and machine learning, MIT Press, 2002. [34] V. N. Vapnik, The Nature of Statistical Learning Theory, Springer New York, 1996. [35] C. Elkan, The foundations of cost-sensitive learning, in: In Proceedings of the Seventeenth International Joint Conference on Artificial Intelligence, 2001, pp. 973-978."
    },
    "10.1016/j.apm.2013.03.041": {
        "Title": "Single machine SLK/DIF due window assignment problem with learning effect and deteriorating jobs",
        "Date": "1 October 2013",
        "Text": "serial JL 271589 291210 291692 291715 291818 291882 291883 31 Applied Mathematical Modelling APPLIEDMATHEMATICALMODELLING 2013-04-06 2013-04-06 2013-12-04T16:51:59 1-s2.0-S0307904X13002151 S0307-904X(13)00215-1 S0307904X13002151 10.1016/j.apm.2013.03.041 S300 S300.1 FULL-TEXT 1-s2.0-S0307904X13X00095 2017-09-30T20:34:10.488662-04:00 0 0 20131001 2013 2013-04-06T00:00:00Z articleinfo crossmark dco dateupdated tomb dateloaded datesearch indexeddate issuelist volumelist yearnav articletitlenorm authfirstinitialnorm authfirstsurnamenorm cid cids contenttype copyright dateloadedtxt docsubtype doctype doi eid ewtransactionid hubeid issfirst issn issnnorm itemstage itemtransactionid itemweight openaccess openarchive pg pgfirst pglast pii piinorm pubdatestart pubdatetxt pubyr sectiontitle sortorder srctitle srctitlenorm srctype subheadings volfirst volissue webpdf webpdfpagecount table body mmlmath acknowledge affil articletitle auth authfirstini authfull authkeywords authlast primabst ref alllist content subj ssids 0307-904X 0307904X true 37 37 18 19 18 19 Volume 37, Issues 18\u201319 10 8394 8400 8394 8400 20131001 1 October 2013 2013-10-01 2013 Research Articles article fla Copyright \u00a9 2013 Elsevier Inc. All rights reserved. SINGLEMACHINESLKDIFDUEWINDOWASSIGNMENTPROBLEMLEARNINGEFFECTDETERIORATINGJOBS WANG J 1 Introduction 2 Problems description 3 SLK due window assignment 4 DIF due window assignment 5 Conclusions Acknowledgments References PINEDO 2002 M SCHEDULINGTHEORYALGORITHMSSYSTEMS BROWNE 1990 495 498 S CHENG 2004 198 203 T CHENG 2005 355 366 T HUANG 2011 1349 1353 X LI 2011 747 751 S KUO 2008 857 859 W WANG 2011 1765 1770 J YANG 2011 4819 4826 S CHENG 2011 1760 1765 T WANG 2012 87 98 J ZHAO 2012 1300 1303 C WANG 2012 643 649 J SUN 2012 195 200 L WANG 2013 547 557 J ALIDAEE 1999 711 720 B CHENG 2004 1 13 T GAWIEJNOWICZ 2008 S TIMEDEPENDENTSCHEDULING BISKUP 1999 173 178 D BISKUP 2008 315 329 D CHENG 2000 273 290 T LEE 2011 5515 5522 W LEE 2011 2095 2100 W WANG 2012 130 137 J BAI 2012 829 835 J SHEN 2013 5444 5451 L LEE 2012 813 818 W LEE 2013 327 334 W NEMBHARD 2002 297 306 D WANG 2006 827 833 J WANG 2007 397 402 J YANG 2011 2069 2073 D LEE 2004 83 89 W WANG 2007 245 261 J WANG 2007 57 70 X CHENG 2008 972 982 T CHENG 2010 326 331 T WANG 2010 309 313 J WANG 2011 4017 4022 J YANG 2011 3321 3329 S LEE 2011 1164 1170 W LEE 2012 W LAI 2013 4509 4516 P ADAMOPOULOS 1996 1280 1285 G BAKER 1990 22 36 K LIMAN 1996 68 74 S LIMAN 1998 1007 1010 S KRAMER 1993 262 275 F MOR 2012 222 230 B MOSHEIOV 2010 185 195 G MOSHEIOV 2008 997 1003 G PANWALKER 1982 391 399 S SEIDMANN 1981 393 399 A SHABTAY 2008 25 40 D WENG 1994 843 851 M HARDY 1967 G INEQUALITIES WANGX2013X8394 WANGX2013X8394X8400 WANGX2013X8394XJ WANGX2013X8394X8400XJ Full 2017-10-01T00:22:35Z OA-Window ElsevierBranded http://www.elsevier.com/open-access/userlicense/1.0/ item S0307-904X(13)00215-1 S0307904X13002151 1-s2.0-S0307904X13002151 10.1016/j.apm.2013.03.041 271589 2013-12-04T23:58:07.411044-05:00 2013-10-01 1-s2.0-S0307904X13002151-main.pdf https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/MAIN/application/pdf/75e342499a901bd64c235c64b58564c2/main.pdf https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/MAIN/application/pdf/75e342499a901bd64c235c64b58564c2/main.pdf main.pdf pdf true 261025 MAIN 7 1-s2.0-S0307904X13002151-main_1.png https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/PREVIEW/image/png/26912163ab310d16fa15792e90fcf8f9/main_1.png https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/PREVIEW/image/png/26912163ab310d16fa15792e90fcf8f9/main_1.png main_1.png png 55463 849 656 IMAGE-WEB-PDF 1 1-s2.0-S0307904X13002151-si113.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/886f4aaea3f5a090f035c1542d862099/si25.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/886f4aaea3f5a090f035c1542d862099/si25.gif si113 si113.gif gif 2971 46 299 ALTIMG 1-s2.0-S0307904X13002151-si89.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/48f85edebd24f4e35d9588a046426c5e/si89.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/48f85edebd24f4e35d9588a046426c5e/si89.gif si89 si89.gif gif 12875 236 508 ALTIMG 1-s2.0-S0307904X13002151-si88.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/5409cdc252b6c055a7e0c30626e4f572/si88.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/5409cdc252b6c055a7e0c30626e4f572/si88.gif si88 si88.gif gif 38707 460 846 ALTIMG 1-s2.0-S0307904X13002151-si87.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/579328aba65fe3b90f689ed99c3bdb32/si87.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/579328aba65fe3b90f689ed99c3bdb32/si87.gif si87 si87.gif gif 13997 209 470 ALTIMG 1-s2.0-S0307904X13002151-si84.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/6b57af1b72f462c470f18d86e0643f51/si84.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/6b57af1b72f462c470f18d86e0643f51/si84.gif si84 si84.gif gif 14579 167 690 ALTIMG 1-s2.0-S0307904X13002151-si73.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/b389ee4f4672c679e3735cde67a58645/si73.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/b389ee4f4672c679e3735cde67a58645/si73.gif si73 si73.gif gif 3611 43 382 ALTIMG 1-s2.0-S0307904X13002151-si72.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/d5d21b93bca5cda8b9c47f160724547e/si72.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/d5d21b93bca5cda8b9c47f160724547e/si72.gif si72 si72.gif gif 3669 43 342 ALTIMG 1-s2.0-S0307904X13002151-si68.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/887bc4458a703cf4cb59bef1fa6f4310/si68.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/887bc4458a703cf4cb59bef1fa6f4310/si68.gif si68 si68.gif gif 8253 109 593 ALTIMG 1-s2.0-S0307904X13002151-si66.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/bcdbf5b06db7c5232fc6d41affe77d1c/si66.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/bcdbf5b06db7c5232fc6d41affe77d1c/si66.gif si66 si66.gif gif 7389 109 772 ALTIMG 1-s2.0-S0307904X13002151-si41.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/ebf19591830e6da4488cd4e38b6aeb74/si41.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/ebf19591830e6da4488cd4e38b6aeb74/si41.gif si41 si41.gif gif 3175 23 555 ALTIMG 1-s2.0-S0307904X13002151-si35.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/ab6ea01cb43e1ba923ac219bdc6e1534/si35.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/ab6ea01cb43e1ba923ac219bdc6e1534/si35.gif si35 si35.gif gif 5545 46 636 ALTIMG 1-s2.0-S0307904X13002151-si29.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/87ff7e3dc2b2488604fe979949bf047f/si29.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/87ff7e3dc2b2488604fe979949bf047f/si29.gif si29 si29.gif gif 941 23 92 ALTIMG 1-s2.0-S0307904X13002151-si27.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/5004eded65a931a2e5104f86422a445a/si27.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/5004eded65a931a2e5104f86422a445a/si27.gif si27 si27.gif gif 925 23 92 ALTIMG 1-s2.0-S0307904X13002151-si25.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/886f4aaea3f5a090f035c1542d862099/si25.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/886f4aaea3f5a090f035c1542d862099/si25.gif si25 si25.gif gif 2971 46 299 ALTIMG 1-s2.0-S0307904X13002151-si6.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/a5c1bf3b583e588468f39f9aaa4b4a7a/si6.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/a5c1bf3b583e588468f39f9aaa4b4a7a/si6.gif si6 si6.gif gif 2133 20 351 ALTIMG 1-s2.0-S0307904X13002151-si99.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/99bdf592806d5c550a1d05b8c75f9c34/si97.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/99bdf592806d5c550a1d05b8c75f9c34/si97.gif si99 si99.gif gif 433 14 20 ALTIMG 1-s2.0-S0307904X13002151-si98.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/d7ebd0adbb6faa779d6a66675492cadb/si98.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/d7ebd0adbb6faa779d6a66675492cadb/si98.gif si98 si98.gif gif 691 16 91 ALTIMG 1-s2.0-S0307904X13002151-si97.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/99bdf592806d5c550a1d05b8c75f9c34/si97.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/99bdf592806d5c550a1d05b8c75f9c34/si97.gif si97 si97.gif gif 433 14 20 ALTIMG 1-s2.0-S0307904X13002151-si96.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/705e590fdd1fd5a6be777dfb6f9d50c7/si96.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/705e590fdd1fd5a6be777dfb6f9d50c7/si96.gif si96 si96.gif gif 901 25 75 ALTIMG 1-s2.0-S0307904X13002151-si95.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/0494dcea6a040593d5f8a19a5e5a1892/si95.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/0494dcea6a040593d5f8a19a5e5a1892/si95.gif si95 si95.gif gif 909 22 77 ALTIMG 1-s2.0-S0307904X13002151-si94.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/112815ed46489b22f8322aaf0a86bb77/si94.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/112815ed46489b22f8322aaf0a86bb77/si94.gif si94 si94.gif gif 1083 20 130 ALTIMG 1-s2.0-S0307904X13002151-si93.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/7f0e993ad7f9fbc4881da5a9952416bb/si93.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/7f0e993ad7f9fbc4881da5a9952416bb/si93.gif si93 si93.gif gif 3639 23 429 ALTIMG 1-s2.0-S0307904X13002151-si92.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/2d18f9fc51c48c3343bb97b1fd0c074b/si92.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/2d18f9fc51c48c3343bb97b1fd0c074b/si92.gif si92 si92.gif gif 721 12 86 ALTIMG 1-s2.0-S0307904X13002151-si91.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/f005c8efe8286fd00273d6a1b44fbed8/si91.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/f005c8efe8286fd00273d6a1b44fbed8/si91.gif si91 si91.gif gif 683 12 85 ALTIMG 1-s2.0-S0307904X13002151-si90.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/7211c365f1df9987c379e83b1a27685c/si90.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/7211c365f1df9987c379e83b1a27685c/si90.gif si90 si90.gif gif 829 21 62 ALTIMG 1-s2.0-S0307904X13002151-si9.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/eec3991794cc1042843e50dbc9486b38/si9.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/eec3991794cc1042843e50dbc9486b38/si9.gif si9 si9.gif gif 537 13 39 ALTIMG 1-s2.0-S0307904X13002151-si86.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/567ed4607c5785a8d6a339fe82eca693/si86.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/567ed4607c5785a8d6a339fe82eca693/si86.gif si86 si86.gif gif 419 14 19 ALTIMG 1-s2.0-S0307904X13002151-si85.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/d007251dcf2a35c92eb6cb51412917ae/si85.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/d007251dcf2a35c92eb6cb51412917ae/si85.gif si85 si85.gif gif 5341 59 369 ALTIMG 1-s2.0-S0307904X13002151-si83.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/99f58010fa8ae267008410abf6415f3d/si83.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/99f58010fa8ae267008410abf6415f3d/si83.gif si83 si83.gif gif 1855 21 288 ALTIMG 1-s2.0-S0307904X13002151-si82.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/f76ed6491ee86b89865c27a1ff6e6287/si82.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/f76ed6491ee86b89865c27a1ff6e6287/si82.gif si82 si82.gif gif 1281 21 174 ALTIMG 1-s2.0-S0307904X13002151-si81.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/0b658922b305e5f1361510112897caba/si81.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/0b658922b305e5f1361510112897caba/si81.gif si81 si81.gif gif 445 15 21 ALTIMG 1-s2.0-S0307904X13002151-si80.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/0b658922b305e5f1361510112897caba/si81.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/0b658922b305e5f1361510112897caba/si81.gif si80 si80.gif gif 445 15 21 ALTIMG 1-s2.0-S0307904X13002151-si8.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/9ef83eb28d754d6822b36d6c1edc92b0/si8.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/9ef83eb28d754d6822b36d6c1edc92b0/si8.gif si8 si8.gif gif 399 17 67 ALTIMG 1-s2.0-S0307904X13002151-si79.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/bbc301f242b76963a448e70ea4820903/si79.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/bbc301f242b76963a448e70ea4820903/si79.gif si79 si79.gif gif 2699 59 369 ALTIMG 1-s2.0-S0307904X13002151-si78.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/54a39aee829c2dc0bc115bf06834ed9a/si78.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/54a39aee829c2dc0bc115bf06834ed9a/si78.gif si78 si78.gif gif 573 20 104 ALTIMG 1-s2.0-S0307904X13002151-si77.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/110004fad76286117dcd0dc50021bee0/si77.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/110004fad76286117dcd0dc50021bee0/si77.gif si77 si77.gif gif 800 18 258 ALTIMG 1-s2.0-S0307904X13002151-si76.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/a1120536be851883a7808a16af57288e/si76.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/a1120536be851883a7808a16af57288e/si76.gif si76 si76.gif gif 577 19 158 ALTIMG 1-s2.0-S0307904X13002151-si75.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/ca726f68fddbedb923a8d41f6f47213e/si75.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/ca726f68fddbedb923a8d41f6f47213e/si75.gif si75 si75.gif gif 472 25 75 ALTIMG 1-s2.0-S0307904X13002151-si74.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/3c5fd83e0fc37704770e0806b62c550f/si74.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/3c5fd83e0fc37704770e0806b62c550f/si74.gif si74 si74.gif gif 476 22 77 ALTIMG 1-s2.0-S0307904X13002151-si71.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/eb8418de09975b05f8c52405f0919808/si71.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/eb8418de09975b05f8c52405f0919808/si71.gif si71 si71.gif gif 651 21 120 ALTIMG 1-s2.0-S0307904X13002151-si70.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/afa684d570f1fe0ff3a42dd6051df3f1/si70.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/afa684d570f1fe0ff3a42dd6051df3f1/si70.gif si70 si70.gif gif 1926 24 535 ALTIMG 1-s2.0-S0307904X13002151-si7.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/2ae4f6a9cce2f28bba461e228a3a35f6/si7.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/2ae4f6a9cce2f28bba461e228a3a35f6/si7.gif si7 si7.gif gif 215 14 15 ALTIMG 1-s2.0-S0307904X13002151-si69.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/441b76234d948f47c480b05188686f8a/si69.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/441b76234d948f47c480b05188686f8a/si69.gif si69 si69.gif gif 2046 30 485 ALTIMG 1-s2.0-S0307904X13002151-si67.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/39f75c5e182b73e35c95fcaeb45c15db/si67.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/39f75c5e182b73e35c95fcaeb45c15db/si67.gif si67 si67.gif gif 619 17 174 ALTIMG 1-s2.0-S0307904X13002151-si65.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/b3881ccbc1a319c5cc8776ac4d720c18/si65.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/b3881ccbc1a319c5cc8776ac4d720c18/si65.gif si65 si65.gif gif 541 18 148 ALTIMG 1-s2.0-S0307904X13002151-si64.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/1bdc635c6a653962d2ec2145006e5b6a/si64.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/1bdc635c6a653962d2ec2145006e5b6a/si64.gif si64 si64.gif gif 242 14 30 ALTIMG 1-s2.0-S0307904X13002151-si63.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/053c3c690e47cae721d3b1d66380f670/si63.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/053c3c690e47cae721d3b1d66380f670/si63.gif si63 si63.gif gif 255 14 30 ALTIMG 1-s2.0-S0307904X13002151-si62.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/764793749c080dcf61d581c16165a735/si62.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/764793749c080dcf61d581c16165a735/si62.gif si62 si62.gif gif 1177 22 321 ALTIMG 1-s2.0-S0307904X13002151-si61.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/0178b53a06c57d287d2144647ada1dd6/si61.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/0178b53a06c57d287d2144647ada1dd6/si61.gif si61 si61.gif gif 795 23 186 ALTIMG 1-s2.0-S0307904X13002151-si60.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/2ae7bc0de80ba181d51e53e06943da01/si60.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/2ae7bc0de80ba181d51e53e06943da01/si60.gif si60 si60.gif gif 257 14 31 ALTIMG 1-s2.0-S0307904X13002151-si59.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/98383c6f9923099312d6d7d50e0b606a/si59.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/98383c6f9923099312d6d7d50e0b606a/si59.gif si59 si59.gif gif 1487 22 445 ALTIMG 1-s2.0-S0307904X13002151-si58.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/3e17bd2f17368f8fe7c6a32ab0870ed0/si58.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/3e17bd2f17368f8fe7c6a32ab0870ed0/si58.gif si58 si58.gif gif 792 23 186 ALTIMG 1-s2.0-S0307904X13002151-si57.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/1bdc635c6a653962d2ec2145006e5b6a/si64.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/1bdc635c6a653962d2ec2145006e5b6a/si64.gif si57 si57.gif gif 242 14 30 ALTIMG 1-s2.0-S0307904X13002151-si56.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/d7a9313d1107121e4c4dde504596e5fc/si56.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/d7a9313d1107121e4c4dde504596e5fc/si56.gif si56 si56.gif gif 1219 23 325 ALTIMG 1-s2.0-S0307904X13002151-si55.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/88b73e180c83dc98d884f811ebc2b58e/si55.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/88b73e180c83dc98d884f811ebc2b58e/si55.gif si55 si55.gif gif 826 23 188 ALTIMG 1-s2.0-S0307904X13002151-si54.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/17bf0a78cd4a0ae0b55518654ab1ec73/si54.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/17bf0a78cd4a0ae0b55518654ab1ec73/si54.gif si54 si54.gif gif 266 14 31 ALTIMG 1-s2.0-S0307904X13002151-si53.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/797a3875a9492a7dc77ca1f242f78de8/si53.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/797a3875a9492a7dc77ca1f242f78de8/si53.gif si53 si53.gif gif 1494 23 449 ALTIMG 1-s2.0-S0307904X13002151-si52.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/a13ae3126a5738031d32b000f4ff8a91/si52.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/a13ae3126a5738031d32b000f4ff8a91/si52.gif si52 si52.gif gif 803 23 188 ALTIMG 1-s2.0-S0307904X13002151-si51.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/053c3c690e47cae721d3b1d66380f670/si63.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/053c3c690e47cae721d3b1d66380f670/si63.gif si51 si51.gif gif 255 14 30 ALTIMG 1-s2.0-S0307904X13002151-si50.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/f9269c24b49cffc9e77a068786f89c24/si50.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/f9269c24b49cffc9e77a068786f89c24/si50.gif si50 si50.gif gif 482 17 99 ALTIMG 1-s2.0-S0307904X13002151-si5.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/b833098a7e0297b0ef3ba843904b110c/si13.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/b833098a7e0297b0ef3ba843904b110c/si13.gif si5 si5.gif gif 215 16 17 ALTIMG 1-s2.0-S0307904X13002151-si49.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/11bca4c4412aa4ab88059ce0451d80a7/si49.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/11bca4c4412aa4ab88059ce0451d80a7/si49.gif si49 si49.gif gif 475 17 100 ALTIMG 1-s2.0-S0307904X13002151-si48.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/570d8fe2ec64d87cb2ada1c54b1a2a5b/si48.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/570d8fe2ec64d87cb2ada1c54b1a2a5b/si48.gif si48 si48.gif gif 1343 19 508 ALTIMG 1-s2.0-S0307904X13002151-si47.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/8a90875e89ad5acb65d59b92aa75f551/si47.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/8a90875e89ad5acb65d59b92aa75f551/si47.gif si47 si47.gif gif 1142 19 427 ALTIMG 1-s2.0-S0307904X13002151-si46.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/196c6351f96d071979221aad31e72dec/si46.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/196c6351f96d071979221aad31e72dec/si46.gif si46 si46.gif gif 289 14 40 ALTIMG 1-s2.0-S0307904X13002151-si45.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/928b46b861c5db8f79d9858a4949c245/si45.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/928b46b861c5db8f79d9858a4949c245/si45.gif si45 si45.gif gif 223 18 16 ALTIMG 1-s2.0-S0307904X13002151-si44.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/cacd2ee8f804491e3be0c2b034c4a281/si33.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/cacd2ee8f804491e3be0c2b034c4a281/si33.gif si44 si44.gif gif 216 18 15 ALTIMG 1-s2.0-S0307904X13002151-si43.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/276ac79d15ecae96d1eede0d5d0a48d5/si43.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/276ac79d15ecae96d1eede0d5d0a48d5/si43.gif si43 si43.gif gif 476 23 83 ALTIMG 1-s2.0-S0307904X13002151-si42.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/70d18d6d3cd1a35eb5f9559ce56a8611/si42.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/70d18d6d3cd1a35eb5f9559ce56a8611/si42.gif si42 si42.gif gif 404 23 57 ALTIMG 1-s2.0-S0307904X13002151-si40.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/baf4d1cba8c717733de2a34a0ecfcc98/si38.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/baf4d1cba8c717733de2a34a0ecfcc98/si38.gif si40 si40.gif gif 382 22 53 ALTIMG 1-s2.0-S0307904X13002151-si4.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/23fa8a441bfe53533a822c3b2999e521/si127.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/23fa8a441bfe53533a822c3b2999e521/si127.gif si4 si4.gif gif 488 17 66 ALTIMG 1-s2.0-S0307904X13002151-si39.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/aac1c1846743d37aea3531ae43d6f877/si39.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/aac1c1846743d37aea3531ae43d6f877/si39.gif si39 si39.gif gif 437 22 80 ALTIMG 1-s2.0-S0307904X13002151-si38.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/baf4d1cba8c717733de2a34a0ecfcc98/si38.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/baf4d1cba8c717733de2a34a0ecfcc98/si38.gif si38 si38.gif gif 382 22 53 ALTIMG 1-s2.0-S0307904X13002151-si37.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/229f39a98bdb6ff92bb49d6dbbca3ccb/si37.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/229f39a98bdb6ff92bb49d6dbbca3ccb/si37.gif si37 si37.gif gif 545 17 132 ALTIMG 1-s2.0-S0307904X13002151-si36.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/d8ea71c8936b2303d516c6060b52b179/si36.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/d8ea71c8936b2303d516c6060b52b179/si36.gif si36 si36.gif gif 219 13 17 ALTIMG 1-s2.0-S0307904X13002151-si34.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/44b7fac5edc46efe758b7463b95bdb35/si34.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/44b7fac5edc46efe758b7463b95bdb35/si34.gif si34 si34.gif gif 308 18 49 ALTIMG 1-s2.0-S0307904X13002151-si33.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/cacd2ee8f804491e3be0c2b034c4a281/si33.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/cacd2ee8f804491e3be0c2b034c4a281/si33.gif si33 si33.gif gif 216 18 15 ALTIMG 1-s2.0-S0307904X13002151-si32.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/8c2c925fbcbaebdaacc1eed4f16c8afc/si32.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/8c2c925fbcbaebdaacc1eed4f16c8afc/si32.gif si32 si32.gif gif 428 20 88 ALTIMG 1-s2.0-S0307904X13002151-si31.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/46835376bb70ff380fcc8438940689fc/si31.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/46835376bb70ff380fcc8438940689fc/si31.gif si31 si31.gif gif 569 21 108 ALTIMG 1-s2.0-S0307904X13002151-si30.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/b833098a7e0297b0ef3ba843904b110c/si13.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/b833098a7e0297b0ef3ba843904b110c/si13.gif si30 si30.gif gif 215 16 17 ALTIMG 1-s2.0-S0307904X13002151-si3.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/23fa8a441bfe53533a822c3b2999e521/si127.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/23fa8a441bfe53533a822c3b2999e521/si127.gif si3 si3.gif gif 488 17 66 ALTIMG 1-s2.0-S0307904X13002151-si28.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/b833098a7e0297b0ef3ba843904b110c/si13.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/b833098a7e0297b0ef3ba843904b110c/si13.gif si28 si28.gif gif 215 16 17 ALTIMG 1-s2.0-S0307904X13002151-si26.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/b833098a7e0297b0ef3ba843904b110c/si13.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/b833098a7e0297b0ef3ba843904b110c/si13.gif si26 si26.gif gif 215 16 17 ALTIMG 1-s2.0-S0307904X13002151-si24.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/c5dec919cb6543a86a80c9f38fef8100/si24.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/c5dec919cb6543a86a80c9f38fef8100/si24.gif si24 si24.gif gif 365 22 45 ALTIMG 1-s2.0-S0307904X13002151-si23.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/b833098a7e0297b0ef3ba843904b110c/si13.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/b833098a7e0297b0ef3ba843904b110c/si13.gif si23 si23.gif gif 215 16 17 ALTIMG 1-s2.0-S0307904X13002151-si22.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/501a0375b9cda2540f607c53e91fb3a0/si22.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/501a0375b9cda2540f607c53e91fb3a0/si22.gif si22 si22.gif gif 233 16 19 ALTIMG 1-s2.0-S0307904X13002151-si21.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/cf5007e15f02aea76358afd58e5b2116/si21.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/cf5007e15f02aea76358afd58e5b2116/si21.gif si21 si21.gif gif 195 13 9 ALTIMG 1-s2.0-S0307904X13002151-si20.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/3d3beae1aba88c189de6a44387b1ac5a/si20.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/3d3beae1aba88c189de6a44387b1ac5a/si20.gif si20 si20.gif gif 421 16 74 ALTIMG 1-s2.0-S0307904X13002151-si2.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/883a369c3f43debc5ef34609e05e9526/si2.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/883a369c3f43debc5ef34609e05e9526/si2.gif si2 si2.gif gif 238 14 20 ALTIMG 1-s2.0-S0307904X13002151-si19.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/99978af3833a35d98b0e292e5e7d4052/si19.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/99978af3833a35d98b0e292e5e7d4052/si19.gif si19 si19.gif gif 847 18 214 ALTIMG 1-s2.0-S0307904X13002151-si18.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/eac83dcc6fc05ca8c90234c2401c1981/si18.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/eac83dcc6fc05ca8c90234c2401c1981/si18.gif si18 si18.gif gif 476 17 123 ALTIMG 1-s2.0-S0307904X13002151-si17.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/15acd97686b137acd39f80fab7022e07/si17.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/15acd97686b137acd39f80fab7022e07/si17.gif si17 si17.gif gif 822 23 177 ALTIMG 1-s2.0-S0307904X13002151-si16.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/b719fa5337f8c294b0568e436a8f9932/si16.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/b719fa5337f8c294b0568e436a8f9932/si16.gif si16 si16.gif gif 817 23 177 ALTIMG 1-s2.0-S0307904X13002151-si15.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/06c4d47c904923feb00fcef0810512c7/si15.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/06c4d47c904923feb00fcef0810512c7/si15.gif si15 si15.gif gif 506 18 101 ALTIMG 1-s2.0-S0307904X13002151-si14.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/de429f7b810a93c854a80027ddb56749/si14.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/de429f7b810a93c854a80027ddb56749/si14.gif si14 si14.gif gif 678 22 160 ALTIMG 1-s2.0-S0307904X13002151-si132.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/23fa8a441bfe53533a822c3b2999e521/si127.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/23fa8a441bfe53533a822c3b2999e521/si127.gif si132 si132.gif gif 488 17 66 ALTIMG 1-s2.0-S0307904X13002151-si131.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/683805eae2189232f040d99ed224cad3/si131.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/683805eae2189232f040d99ed224cad3/si131.gif si131 si131.gif gif 642 17 156 ALTIMG 1-s2.0-S0307904X13002151-si130.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/7100d8f350a5156d3785a50abaca4ec9/si130.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/7100d8f350a5156d3785a50abaca4ec9/si130.gif si130 si130.gif gif 388 16 96 ALTIMG 1-s2.0-S0307904X13002151-si13.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/b833098a7e0297b0ef3ba843904b110c/si13.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/b833098a7e0297b0ef3ba843904b110c/si13.gif si13 si13.gif gif 215 16 17 ALTIMG 1-s2.0-S0307904X13002151-si129.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/f8bc3940096312c383eaad98fb0095e5/si116.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/f8bc3940096312c383eaad98fb0095e5/si116.gif si129 si129.gif gif 448 22 83 ALTIMG 1-s2.0-S0307904X13002151-si128.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/345eff264d3f3bff4350a40bb20fc1f0/si128.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/345eff264d3f3bff4350a40bb20fc1f0/si128.gif si128 si128.gif gif 2272 16 860 ALTIMG 1-s2.0-S0307904X13002151-si127.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/23fa8a441bfe53533a822c3b2999e521/si127.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/23fa8a441bfe53533a822c3b2999e521/si127.gif si127 si127.gif gif 488 17 66 ALTIMG 1-s2.0-S0307904X13002151-si126.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/ecbd15c065d0284c8c65bc420047e1ec/si124.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/ecbd15c065d0284c8c65bc420047e1ec/si124.gif si126 si126.gif gif 392 16 96 ALTIMG 1-s2.0-S0307904X13002151-si125.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/6d2b58ddd3899203bff14bc304554d13/si125.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/6d2b58ddd3899203bff14bc304554d13/si125.gif si125 si125.gif gif 469 22 91 ALTIMG 1-s2.0-S0307904X13002151-si124.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/ecbd15c065d0284c8c65bc420047e1ec/si124.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/ecbd15c065d0284c8c65bc420047e1ec/si124.gif si124 si124.gif gif 392 16 96 ALTIMG 1-s2.0-S0307904X13002151-si123.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/f8bc3940096312c383eaad98fb0095e5/si116.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/f8bc3940096312c383eaad98fb0095e5/si116.gif si123 si123.gif gif 448 22 83 ALTIMG 1-s2.0-S0307904X13002151-si122.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/ac9d970d7987fd95a446248486bbd782/si115.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/ac9d970d7987fd95a446248486bbd782/si115.gif si122 si122.gif gif 318 16 44 ALTIMG 1-s2.0-S0307904X13002151-si121.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/a1337fb9dc1197b1135e807f8308b096/si119.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/a1337fb9dc1197b1135e807f8308b096/si119.gif si121 si121.gif gif 1819 23 422 ALTIMG 1-s2.0-S0307904X13002151-si120.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/2ae4f6a9cce2f28bba461e228a3a35f6/si7.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/2ae4f6a9cce2f28bba461e228a3a35f6/si7.gif si120 si120.gif gif 215 14 15 ALTIMG 1-s2.0-S0307904X13002151-si12.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/f46fd5280852838d65c83cebe8b1b7e4/si12.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/f46fd5280852838d65c83cebe8b1b7e4/si12.gif si12 si12.gif gif 403 23 45 ALTIMG 1-s2.0-S0307904X13002151-si119.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/a1337fb9dc1197b1135e807f8308b096/si119.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/a1337fb9dc1197b1135e807f8308b096/si119.gif si119 si119.gif gif 1819 23 422 ALTIMG 1-s2.0-S0307904X13002151-si118.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/ecbd15c065d0284c8c65bc420047e1ec/si124.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/ecbd15c065d0284c8c65bc420047e1ec/si124.gif si118 si118.gif gif 392 16 96 ALTIMG 1-s2.0-S0307904X13002151-si117.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/6d2b58ddd3899203bff14bc304554d13/si125.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/6d2b58ddd3899203bff14bc304554d13/si125.gif si117 si117.gif gif 469 22 91 ALTIMG 1-s2.0-S0307904X13002151-si116.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/f8bc3940096312c383eaad98fb0095e5/si116.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/f8bc3940096312c383eaad98fb0095e5/si116.gif si116 si116.gif gif 448 22 83 ALTIMG 1-s2.0-S0307904X13002151-si115.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/ac9d970d7987fd95a446248486bbd782/si115.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/ac9d970d7987fd95a446248486bbd782/si115.gif si115 si115.gif gif 318 16 44 ALTIMG 1-s2.0-S0307904X13002151-si114.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/d8ea71c8936b2303d516c6060b52b179/si36.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/d8ea71c8936b2303d516c6060b52b179/si36.gif si114 si114.gif gif 219 13 17 ALTIMG 1-s2.0-S0307904X13002151-si112.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/ecbd15c065d0284c8c65bc420047e1ec/si124.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/ecbd15c065d0284c8c65bc420047e1ec/si124.gif si112 si112.gif gif 392 16 96 ALTIMG 1-s2.0-S0307904X13002151-si111.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/9a1a7f78415cf127d6f2cfeae53064e5/si111.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/9a1a7f78415cf127d6f2cfeae53064e5/si111.gif si111 si111.gif gif 371 23 50 ALTIMG 1-s2.0-S0307904X13002151-si110.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/d47ec61f3d0b566168d8ad6cb73b946d/si110.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/d47ec61f3d0b566168d8ad6cb73b946d/si110.gif si110 si110.gif gif 251 22 16 ALTIMG 1-s2.0-S0307904X13002151-si11.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/b833098a7e0297b0ef3ba843904b110c/si13.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/b833098a7e0297b0ef3ba843904b110c/si13.gif si11 si11.gif gif 215 16 17 ALTIMG 1-s2.0-S0307904X13002151-si109.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/f98d145ff2bf2f4bb9d82ee8523ff287/si109.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/f98d145ff2bf2f4bb9d82ee8523ff287/si109.gif si109 si109.gif gif 1466 18 424 ALTIMG 1-s2.0-S0307904X13002151-si108.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/683805eae2189232f040d99ed224cad3/si131.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/683805eae2189232f040d99ed224cad3/si131.gif si108 si108.gif gif 642 17 156 ALTIMG 1-s2.0-S0307904X13002151-si107.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/ed37c125bdb0db530a26392617259ff9/si107.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/ed37c125bdb0db530a26392617259ff9/si107.gif si107 si107.gif gif 2504 16 731 ALTIMG 1-s2.0-S0307904X13002151-si106.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/9257bf599f57aebdbac7336e8546f10b/si106.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/9257bf599f57aebdbac7336e8546f10b/si106.gif si106 si106.gif gif 811 25 182 ALTIMG 1-s2.0-S0307904X13002151-si105.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/6bbc5a3d9648915a53d785ad3832a56b/si105.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/6bbc5a3d9648915a53d785ad3832a56b/si105.gif si105 si105.gif gif 791 23 178 ALTIMG 1-s2.0-S0307904X13002151-si104.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/cc811d0ee0928f25caacae02d3c8ee6a/si104.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/cc811d0ee0928f25caacae02d3c8ee6a/si104.gif si104 si104.gif gif 2289 16 868 ALTIMG 1-s2.0-S0307904X13002151-si103.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/23fa8a441bfe53533a822c3b2999e521/si127.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/23fa8a441bfe53533a822c3b2999e521/si127.gif si103 si103.gif gif 488 17 66 ALTIMG 1-s2.0-S0307904X13002151-si102.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/3427d6cc244519f939fae9ada68a8dd4/si102.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/3427d6cc244519f939fae9ada68a8dd4/si102.gif si102 si102.gif gif 506 23 92 ALTIMG 1-s2.0-S0307904X13002151-si101.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/82baa0f608114376cd3c305f4ae224cc/si101.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/82baa0f608114376cd3c305f4ae224cc/si101.gif si101 si101.gif gif 512 23 92 ALTIMG 1-s2.0-S0307904X13002151-si100.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/883a369c3f43debc5ef34609e05e9526/si2.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/883a369c3f43debc5ef34609e05e9526/si2.gif si100 si100.gif gif 238 14 20 ALTIMG 1-s2.0-S0307904X13002151-si10.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/e42e8d93bd6558f0262bede555be2c52/si10.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/e42e8d93bd6558f0262bede555be2c52/si10.gif si10 si10.gif gif 297 14 40 ALTIMG 1-s2.0-S0307904X13002151-si1.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X13002151/STRIPIN/image/gif/cfd9fc41a3af2a8c8b70b0bc6a2ea0ce/si1.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X13002151/STRIPIN/image/gif/cfd9fc41a3af2a8c8b70b0bc6a2ea0ce/si1.gif si1 si1.gif gif 236 12 21 ALTIMG APM 9404 S0307-904X(13)00215-1 10.1016/j.apm.2013.03.041 Elsevier Inc. Table 1 Date of Example 1. r 1 2 3 4 5 6 7 \u03c9 r 68 79 43 43 43 26 8 W r 78.1517 74.3738 38.1507 34.7026 32.0273 18.3589 5.4209 Single machine SLK/DIF due window assignment problem with learning effect and deteriorating jobs Ji-Bo Wang a b \u204e Lu Liu a Cheng Wang a a School of Economics and Management, Shenyang Aerospace University, Shenyang 110136, China School of Economics and Management Shenyang Aerospace University Shenyang 110136 China b State Key Laboratory for Manufacturing Systems Engineering, Xi\u2032an Jiaotong University, Xi\u2032an, 710053, china State Key Laboratory for Manufacturing Systems Engineering Xi\u2032an Jiaotong University Xi\u2032an 710053 china \u204e Corresponding author at: School of Economics and Management, Shenyang Aerospace University, Shenyang 110136, China. We study a single-machine scheduling and due window assignment problem, in which job processing times are defined by functions of their starting times (deteriorating effect) and positions in the sequence (learning effect). The problem is to determine the optimal due windows and the processing sequence simultaneously to minimize costs for earliness, tardiness, the window location, window size and makespan. We show that the problem remains polynomially solvable under the proposed model for two popular due window assignment methods: The slack due date assignment method (usually referred to as SLK) and the unrestricted due date assignment method (usually referred to as DIF). Keywords Scheduling Learning effect Deteriorating jobs Due window assignment 1 Introduction In traditional scheduling models, researchers assume that the actual processing times of jobs are constant. However, there are many real-life scheduling situations where the actual processing times of the jobs may be change due to deterioration effect and/or learning effect [1]. Machine scheduling problems with deterioration effect have received increasing attention in recent years. Browne and Yechiali [2] considered a scheduling model in which the processing time of a job is a linear nondecreasing function of its start time (i.e., deteriorating jobs). The deterioration model appears, e.g., in steel production, or electronic assembly systems, where any delay in processing a job will take additional time for accomplishing the job. The reader is referred to Cheng et al. [3,4], Huang and Wang [5], Li et al. [6], Kuo and Yang [7], Wang et al. [8], Yang and Wang [9], Cheng et al. [10], Wang and Wang [11], Zhao and Tang [12], Wang et al. [13], Sun et al. [14], and Wang and Wang [15] for more practical motivations to model job deterioration in such a manner. Extensive surveys of different scheduling models and problems involving deteriorating jobs can be found in Alidaee and Womer [16], Cheng et al. [17], and Gawiejnowicz [18]. On the other hand, in many real-life scheduling situations, workstations improve continuously as a result of performing the same or similar tasks over and over. As a result, the production (processing) time of a given product (job) is shorter if it is scheduled later, this phenomenon is known as a \u201clearning effect\u201d. The reader is referred to Biskup [19,20] and Cheng and Wang [21] for more practical motivations to model job with learning effects in such a manner. A survey on this line of the scheduling problems with learning effects could be found in Biskup [20]. More recent papers which have considered scheduling jobs with learning effects include Lee [22,23], Wang and Wang [24], Bai et al. [25], Shen and Wu [26], Lee et al. [27], and Lee and Chung [28]. However, the phenomenon of a job simultaneously with learning and deterioration effects can be found in many real-life situations [29\u201331]. For example, in steel mills, if the temperature of an ingot, while waiting to enter the rolling machine, drops below a specified level, the ingot must be preheated up to the temperature required for rolling. It may result in additional time for the ingot rolling. On the other hand, the productivity of an operator can be improved through repeating the same operating processes [32]. Thus, there exist both deterioration and learning effects of a job in such a situation. Several studies have investigated this subject under different machine environments, which include Lee [33], Wang and Cheng [34], Wang and Cheng [35], Cheng et al. [36,37], Wang and Guo [38], Wang and Wang [39], Yang [40], Lee and Lai [41], Lee [42], and Lai and Lee [43]. In this paper we study the scheduling of learning effect and deteriorating jobs in the context of the due window assignment problem, i.e., a just-in-time (JIT) production environment (see [44\u201355,12]). In a JIT system with due window, a time interval needs to be determined such that jobs completed within this interval are not penalized. Recently, Wang and Wang [39] considered a single-machine common due window assignment (CON) scheduling problem with learning effect and deteriorating jobs. They showed that the problem remains polynomially solvable. In this paper, we investigate the single machine JIT scheduling problem with learning effect and deteriorating jobs in the context of SLK/DIF due window assignment methods, i.e., the problem is to determine the optimal due windows and the processing sequence simultaneously to minimize costs for earliness, tardiness, the window location, window size and makespan. We show that the SLK and DIF due window assignment scheduling problems with learning effect and deteriorating jobs are solvable in polynomial time, respectively. The rest of this paper is organized as follows. In Section 2 we formulate the model. In Section 3, for the SLK due window assignment method, we provide an O ( n log n ) -time algorithm. In Section 4, we present an O ( n log n ) -time algorithm for the DIF due window assignment method. Some concluding remarks are given in the last section. 2 Problems description There are n independent jobs to be processed on a single machine. All the jobs are available for processing at time zero. The machine can handle one job at a time and preemption is not allowed. As in Wang [30], we assume that the actual processing time of job J j if it is scheduled in position r in a sequence is given by: (1) p j = ( a j + bt ) r a , r = 1 , 2 , \u2026 , n ; j = 1 , 2 , \u2026 , n , where a j is a normal processing time for job J j , a \u2a7d 0 is the learning index, b > 0 is the common deterioration rate for all jobs and t \u2a7e 0 is the starting time for job J j . Let [ d j 1 , d j 2 ] represent the due-window of job J j such that d j 1 \u2a7d d j 2 , j = 1 , 2 , \u2026 , n . For a given schedule \u03c0 , C j = C j ( \u03c0 ) represents the completion time of job J j , E j = max { 0 , d j 1 - C j } is the earliness value of job J j , T j = max { 0 , C j - d j 2 } is the tardiness value of job J j , j = 1 , 2 , \u2026 , n and C max = max { C j | j = 1 , 2 , \u2026 , n } is the maximum completion time (makespan). The objective function consists of five cost components: (i) earliness, (ii) tardiness, (iii) the starting times of the due-windows, (iv) the size of the due-windows, and (v) the makespan. Further, let \u03b1 , \u03b2 , \u03b3 , \u03b4 and \u03b8 be the per time unit penalties for earliness, tardiness, due date, due window size, and makespan, respectively. Let D j denote the due-window size of the job J j . The general objective is to determine d j 1 , d j 2 and a schedule \u03c0 which minimizes (2) Z = \u2211 j = 1 n ( \u03b1 E j + \u03b2 T j + \u03b3 d j 1 + \u03b4 D j ) + \u03b8 C max . 3 SLK due window assignment In this section, we consider the scheduling problem subject to the constraint that the SLK due window assignment method (see [44,49,50]) is employed, i.e., the due-window starting time for the job J j is defined as its processing time plus a job-independent constant: d j 1 = p j + q 1 , the due-window completion time for the job J j is defined as its processing time plus a (larger) job- independent constant: d j 2 = p j + q 2 . Thus due-window of the job J j is [ p j + q 1 , p j + q 2 ] . Note that D j = q 2 - q 1 , i.e., the window size is identical for all the jobs. The general objective is to determine the optimal common flow allowance q 1 , due window size q 2 - q 1 and to find a schedule \u03c0 which minimizes (3) Z = \u2211 j = 1 n ( \u03b1 E j + \u03b2 T j + \u03b3 d j 1 + \u03b4 D j ) + \u03b8 C max = \u2211 j = 1 n ( \u03b1 E j + \u03b2 T j + \u03b3 d j 1 ) + \u03b4 n ( q 2 - q 1 ) + \u03b8 C max . It is clear that there exists an optimal schedule \u03c0 \u2217 without any machine idle time between the starting time of the first job and the completion time of the last job, and the first job in the schedule starts at time zero. To simplify, I will assume that the job order is \u03c0 = ( J 1 , J 2 , \u2026 , J n ) . Lemma 1 If C j \u2a7d d j 1 then C j - 1 \u2a7d d j - 1 1 . Proof For a given schedule \u03c0, If C j \u2a7d d j 1 we have: C j - 1 + p j \u2a7d p j + q 1 \u21d4 C j - 1 \u2a7d q 1 \u21d2 C j - 1 \u2a7d q 1 + p j - 1 \u21d4 C j - 1 \u2a7d d j - 1 1 . \u25a1 Lemma 2 If C j \u2a7e d j 2 then C j + 1 \u2a7e d j + 1 2 . Proof Similar to the proof of Lemma 1. \u25a1 These two lemmas indicate that for any given schedule \u03c0, early jobs are followed by jobs completed within their respective due windows, which are in turn followed by the set of tardy jobs. Lemma 3 For any given schedule \u03c0, the optimal values of q 1 and q 2 are determined by the completion times of the kth and lth jobs ( l \u2a7e k ), i.e., q 1 = p 1 + p 2 + \u22ef + p k , q 2 = p 1 + p 2 + \u22ef + p k + p k + 1 + \u22ef p l . Proof Consider an optimal sequence \u03c0 without this property, i.e., q 1 = p 1 + p 2 + \u22ef + p k + \u25b3 1 , q 2 = p 1 + p 2 + \u22ef + p k + p k + 1 + \u22ef p l + \u25b3 2 , where 0 < \u25b3 1 < p k + 1 , and 0 < \u25b3 2 < p l + 1 . The left end of the due window for job J k + 1 is given by d k + 1 1 = p k + 1 + \u2211 j \u2a7d k p j + \u25b3 1 . Obviously, this job is completed early: C k + 1 = \u2211 j \u2a7d k + 1 p j < d k + 1 1 = p k + 1 + \u2211 j \u2a7d k p j + \u25b3 1 = \u2211 j \u2a7d k + 1 p j + \u25b3 1 . For job J k + 2 is given by d k + 2 1 = p k + 2 + \u2211 j \u2a7d k p j + \u25b3 1 . Obviously, this job is not early: C k + 2 = \u2211 j \u2a7d k + 2 p j > d k + 1 2 = p k + 2 + \u2211 j \u2a7d k p j + \u25b3 1 . Similarly, job J l + 1 is not tardy because d l + 1 2 = p l + 1 + \u2211 j \u2a7d l p j + \u25b3 2 and C l + 1 = \u2211 j \u2a7d l + 1 p j < d l + 1 2 = p l + 1 + \u2211 j \u2a7d l p j + \u25b3 2 = \u2211 j \u2a7d l + 1 p j + \u25b3 2 ; job J l + 2 is tardy because d l + 2 2 = p l + 2 + \u2211 j \u2a7d l p j + \u25b3 2 and C l + 2 = \u2211 j \u2a7d l + 2 p j > d l + 2 2 = p l + 2 + \u2211 j \u2a7d l p j + \u25b3 2 . From Lemmas 1 and 2, all the jobs before the job J k + 1 are early and all the jobs after the job J l + 1 are tardy. We treat each cost component separately. (i) The earliness cost associated with job J j , j = 1 , 2 , \u2026 , k + 1 , is given by \u03b1 \u2211 j = 1 n E j = \u03b1 \u2211 j = 1 k + 1 ( d j 1 - C j ) = \u03b1 [ ( p 1 + q 1 - p 1 ) + ( p 2 + q 1 - p 1 - p 2 ) + \u22ef + ( p k + 1 + q 1 - ( p 1 + p 2 + \u22ef + p k + 1 ) ) ] = \u03b1 \u2211 j = 1 k jp j + \u03b1 ( k + 1 ) \u25b3 1 ; (ii) The tardiness cost associated with job J j , j = l + 2 , l + 3 , \u2026 , n , is given by \u03b2 \u2211 j = 1 n T j = \u03b2 \u2211 j = l + 2 n ( C j - d j 2 ) = \u03b2 \u2211 j = 1 l + 2 p j - ( p l + 2 + q 2 ) + \u22ef + \u2211 j = 1 n p j - ( p n + q 2 ) = \u03b2 \u2211 j = l + 1 n ( n - j ) p j - \u03b2 ( n - l - 1 ) \u25b3 2 , (iii) \u2211 j = 1 n \u03b3 d j 1 = \u03b3 \u2211 j = 1 n ( p j + q 1 ) = \u03b3 ( n + 1 ) \u2211 j = 1 k p j + \u2211 j = k + 1 n p j + n \u03b3 \u25b3 1 ; (iv) \u03b4 n ( q 2 - q 1 ) = \u03b4 n ( \u2211 j = 1 l p j + \u25b3 2 - \u2211 j = 1 k p j - \u25b3 1 ) = \u03b4 n \u2211 j = k + 1 l p j + \u03b4 n ( \u25b3 2 - \u25b3 1 ) ; (v) \u03b8 C max = \u03b8 \u2211 j = 1 n p j . Obviously, it is a simple matter to state exactly which action would decrease the cost: \u25b3 1 = p k + 1 if \u03b1 ( k + 1 ) + n \u03b3 - \u03b4 n < 0 , and 0 otherwise and \u25b3 2 = p l + 1 if \u03b4 n - \u03b2 ( n - l + 1 ) < 0 , and 0 otherwise . \u25a1 Lemma 4 An optimal schedule exists such that k = \u2308 n ( \u03b4 - \u03b3 ) \u03b1 \u2309 and l = \u2308 n ( \u03b2 - \u03b4 ) \u03b2 \u2309 , (where k and l, as defined above, are determined by: q 1 = p 1 + p 2 + \u22ef + p k and q 2 = p 1 + p 2 + \u22ef + p k + p k + 1 + \u22ef p l ). Proof Using the classical small perturbation technique and the simple observations of the proof of Lemma 3, the result can be easily obtained. \u25a1 Remark The significance of Lemma 4 is that the optimal values of k and l do not depend on the sequence. Lemma 5 The optimal total cost can be written as: Z = \u2211 j = 1 n \u03c9 j p [ j ] ,where the positional weight of position j in the schedule is given by \u03c9 j = ( n + 1 ) \u03b3 + \u03b1 j + \u03b8 for j = 1 , 2 , \u2026 , k ; \u03b4 n + \u03b3 + \u03b8 for j = k + 1 , k + 2 , \u2026 , l ; \u03b2 ( n - j ) + \u03b3 + \u03b8 for j = l + 1 , i + 2 , \u2026 , n , where p [ j ] denotes the actual processing time of a job when it is scheduled in position j in a sequence. Proof Let p [ j ] be the actual processing time of a job when it is scheduled in position j in a sequence. By Lemma 3, we can assume that q 1 = p [ 1 ] + p [ 2 ] + \u22ef + p [ k ] and q 2 = p [ 1 ] + p [ 2 ] + \u22ef + p [ k ] + p [ k + 1 ] + \u2026 p [ l ] . Then the objective function can be expressed as Z = \u2211 j = 1 n ( \u03b1 E [ j ] + \u03b2 T [ j ] + \u03b3 d [ j ] 1 ) + \u03b4 n ( q 2 - q 1 ) + \u03b8 C max = \u03b1 \u2211 j = 1 k + 1 ( d [ j ] 1 - C [ j ] ) + \u03b2 \u2211 j = l + 2 n ( C [ j ] - d [ j ] 2 ) + \u03b3 \u2211 j = 1 n d [ j ] 1 + \u03b4 n ( q 2 - q 1 ) + \u03b8 C max = \u03b1 \u2211 j = 1 k jp [ j ] + \u03b2 \u2211 j = l + 1 n ( n - j ) p [ j ] + \u03b3 ( n + 1 ) \u2211 j = 1 k p [ j ] + \u2211 j = k + 1 n p [ j ] + \u03b4 n \u2211 j = k + 1 l p [ j ] + \u03b8 \u2211 j = 1 n p [ j ] = \u2211 j = 1 n \u03c9 j p [ j ] , where \u03c9 j = ( n + 1 ) \u03b3 + \u03b1 j + \u03b8 for j = 1 , 2 , \u2026 , k ; \u03b4 n + \u03b3 + \u03b8 for j = k + 1 , k + 2 , \u2026 , l ; \u03b2 ( n - j ) + \u03b3 + \u03b8 for j = l + 1 , i + 2 , \u2026 , n . \u25a1 Let a [ r ] denote the normal processing time of a job when it is scheduled in position r in a sequence. Then the actual processing times of jobs can be expressed as follows: p [ 1 ] = a [ 1 ] , p [ 2 ] = ( a [ 2 ] + ba [ 1 ] ) 2 a = a [ 2 ] 2 a + b 2 a a [ 1 ] , p [ 3 ] = ( a [ 3 ] + b ( p [ 1 ] + p [ 2 ] ) ) 3 a = a [ 3 ] 3 a + b 3 a ( a [ 2 ] 2 a + a [ 1 ] ( 1 + b 2 a ) ) , p [ 4 ] = a [ 4 ] 4 a + b 4 a ( a [ 3 ] 3 a + a [ 2 ] 2 a ( 1 + b 3 a ) + a [ 1 ] ( 1 + b 2 a ) ( 1 + b 3 a ) ) , \u2026 p [ n ] = a [ n ] n a + bn a ( a [ n - 1 ] ( n - 1 ) a + a [ n - 2 ] ( n - 2 ) a ( 1 + b ( n - 1 ) a ) + \u22ef + a [ 2 ] 2 a \u220f i = 3 n - 1 ( 1 + bi a ) + a [ 1 ] \u220f i = 2 n - 1 ( 1 + bi a ) ) . From Lemma 5, Eq. (3) can be rewritten as Z = \u2211 j = 1 n ( \u03b1 E j + \u03b2 T j + \u03b3 d j 1 ) + \u03b4 n ( q 2 - q 1 ) + \u03b8 C max = \u2211 r = 1 n \u03c9 r p [ r ] = \u03c9 1 a [ 1 ] + \u03c9 2 ( a [ 2 ] 2 a + b 2 a a [ 1 ] ) + \u03c9 3 ( a [ 3 ] 3 a + b 3 a ( a [ 2 ] 2 a + a [ 1 ] ( 1 + b 2 a ) ) ) + \u03c9 4 ( a [ 4 ] 4 a + b 4 a ( a [ 3 ] 3 a + a [ 2 ] 2 a ( 1 + b 3 a ) + a [ 1 ] ( 1 + b 2 a ) ( 1 + b 3 a ) ) ) + \u22ef + \u03c9 n - 1 ( a [ n - 1 ] ( n - 1 ) a + b ( n - 1 ) a ( a [ n - 2 ] ( n - 2 ) a + a [ n - 3 ] ( n - 3 ) a ( 1 + b ( n - 2 ) a ) + \u22ef + a [ 2 ] 2 a \u220f i = 3 n - 2 ( 1 + bi a ) + a [ 1 ] 1 a \u220f i = 2 n - 2 ( 1 + bi a ) ) ) + \u03c9 n ( a [ n ] n a + bn a ( a [ n - 1 ] ( n - 1 ) a + a [ n - 2 ] ( n - 2 ) a ( 1 + b ( n - 1 ) a ) + \u22ef + a [ 2 ] 2 a \u220f i = 3 n - 1 ( 1 + bi a ) + a [ 1 ] 1 a \u220f i = 2 n - 1 ( 1 + bi a ) ) ) = \u03c9 1 + b 2 a \u03c9 2 + b 3 a ( 1 + b 2 a ) \u03c9 3 + \u22ef + bn a \u220f i = 2 n - 1 ( 1 + bi a ) \u03c9 n a [ 1 ] + 2 a \u03c9 2 + b 3 a 2 a \u03c9 3 + b 4 a 2 a ( 1 + b 3 a ) \u03c9 4 + \u22ef + bn a 2 a \u220f i = 3 n - 1 ( 1 + bi a ) \u03c9 n a [ 2 ] + 3 a \u03c9 3 + b 4 a 3 a \u03c9 4 + b 5 a 3 a ( 1 + b 4 a ) \u03c9 5 + \u22ef + bn a 3 a \u220f i = 4 n - 1 ( 1 + bi a ) \u03c9 n a [ 3 ] + \u22ef + ( ( n - 1 ) a \u03c9 n - 1 + bn a ( n - 1 ) a \u03c9 n ) a [ n - 1 ] + n a \u03c9 n a [ n ] = W 1 a [ 1 ] + W 2 a [ 2 ] + \u22ef + W n a [ n ] , where W 1 = \u03c9 1 + b 2 a \u03c9 2 + b 3 a ( 1 + b 2 a ) \u03c9 3 + \u22ef + bn a \u220f i = 2 n - 1 ( 1 + bi a ) \u03c9 n , W 2 = 2 a \u03c9 2 + b 3 a 2 a \u03c9 3 + b 4 a 2 a ( 1 + b 3 a ) \u03c9 4 + \u22ef + bn a 2 a \u220f i = 3 n - 1 ( 1 + bi a ) \u03c9 n , W 3 = 3 a \u03c9 3 + b 4 a 3 a \u03c9 4 + b 5 a 3 a ( 1 + b 4 a ) \u03c9 5 + \u22ef + bn a 3 a \u220f i = 4 n - 1 ( 1 + bi a ) \u03c9 n , \u2026 W n - 1 = ( n - 1 ) a \u03c9 n - 1 + bn a ( n - 1 ) a \u03c9 n , W n = n a \u03c9 n . Finally, we give a lemma, it is useful for the following result. Lemma 6 The sum of products \u2211 j = 1 n x j y j is minimized if sequence x 1 , x 2 , \u2026 , x n is ordered nondecreasingly and sequence y 1 , y 2 , \u2026 , y n is ordered nonincreasingly or vice versa, and it is maximized if the sequences are ordered in the same way. Proof See page 261 in Hardy et al. [56].\u25a1 To minimize Z, the optimal schedule can be obtained by the well-known matching procedure (Lemma 6) of the largest normal processing time to the smallest positional weight, the next larger normal processing time to the next smaller positional weight, etc. Based on the above analysis and Lemma 6, we can obtain that the problem 1 | p j = ( a j + bt ) r a , SLK | \u2211 j = 1 n ( \u03b1 E j + \u03b2 T j + \u03b3 d j 1 + \u03b4 D j ) + \u03b8 C max can be solved by the following algorithm: Algorithm 1 Step 1. By Lemma 4, calculate the optimal position of common flow allowance q 1 = C [ k ] , q 2 = C [ l ] , where k = \u2308 n ( \u03b4 - \u03b3 ) \u03b1 \u2309 and l = \u2308 n ( \u03b2 - \u03b4 ) \u03b2 \u2309 . Calculate the positional weights W r for r = 1 , 2 \u2026 , n . Step 2. Renumber jobs in the nondecreasing order with respect to their normal processing times. Then, assign the job with the longest normal processing time to the position with the smallest value of W r , the job with the second longest normal processing time to the position with the second smallest value of W r , etc. Step 3. Set q 1 = \u2211 r = 1 k p [ r ] and q 2 = \u2211 r = 1 l p [ r ] . Obviously, the total time for Algorithm 1 is O ( n log n ) . In order to illustrate Algorithm 1, we solve the instance as follows: Example 1 Data: n = 7 , a 1 = 3 , a 2 = 4 , a 3 = 6 , a 4 = 9 , a 5 = 14 , a 6 = 18 , a 7 = 20 , \u03b1 = 11 , \u03b2 = 18 , \u03b3 = 5 , \u03b4 = 7 , \u03b8 = 1 , a = - 0.2 , b = 0.05 . According to Algorithm 1, k = \u2308 n ( \u03b4 - \u03b3 ) \u03b1 \u2309 = \u2308 7 ( 7 - 5 ) 11 \u2309 = 2 and l = \u2308 n ( \u03b2 - \u03b4 ) \u03b2 \u2309 = \u2308 7 ( 18 - 7 ) 18 \u2309 = 5 . The input of the positional weights are given in Table 1 . The positional weights are: W 1 = 78.1517 , W 2 = 74.3738 , W 3 = 38.1507 , W 4 = 34.7026 , W 5 = 32.0273 , W 6 = 18.3589 , W 7 = 5.4209 . From Algorithm 1, the optimal schedule is [ J 1 , J 2 , J 3 , J 4 , J 5 , J 6 , J 7 ] . The optimal q 1 = p 1 + p 2 = 6.6128 , q 2 = p 1 + p 2 + p 3 + p 4 + p 5 = 29.7926 and the total cost is 1960.438. 4 DIF due window assignment In this section, we consider the scheduling problem subject to the constraint that the DIF due window assignment method (see [53,54]) is employed, i.e., each job can be assigned a different due window with no restrictions. The general objective is to determine the optimal d j 1 , due window size d j 2 - d j 1 ( j = 1 , 2 , \u2026 , n ) and to find a schedule \u03c0 which minimizes (4) Z = \u2211 j = 1 n ( \u03b1 E j + \u03b2 T j + \u03b3 d j 1 + \u03b4 D j ) + \u03b8 C max . It is clear that there exists an optimal schedule \u03c0 \u2217 without any machine idle time between the starting time of the first job and the completion time of the last job, and the first job in the schedule starts at time zero. The DIF due date assignment method to minimize earliness, tardiness and due date assignment costs was studied by Seidmann et al. [53] and Shabtay and Steiner [54]. By the similar method, we have the following lemmas: Lemma 7 For a given schedule \u03c0, the optimal due window assignment strategy for the DIF due window assignment method is defined as follows: if \u03b3 \u2a7e \u03b2 then set d j 1 = d j 2 = 0 , otherwise set d j 1 = d j 2 = C j for j = 1 , 2 , \u2026 , n . Lemma 8 For the problem 1 | p j = ( a j + bt ) r a , DIF | \u2211 j = 1 n ( \u03b1 E j + \u03b2 T j + \u03b3 d j 1 + \u03b4 D j ) + \u03b8 C max , an optimal schedule can be obtained by sequencing the jobs in a nondecreasing order of a j (the SPT rule). Based on Lemmas 7 and 8, we can obtain that the problem 1 | p j = ( a j + bt ) r a , DIF | \u2211 j = 1 n ( \u03b1 E j + \u03b2 T j + \u03b3 d j 1 + \u03b4 D j ) + \u03b8 C max can be solved by the following algorithm: Algorithm 2 Step 1. Schedule jobs according to the SPT rule. Step 2. If \u03b3 \u2a7e \u03b2 set d j 1 = d j 2 = 0 for j = 1 , 2 , \u2026 , n , otherwise set d j 1 = d j 2 = C j for j = 1 , 2 , \u2026 , n . Obviously, the total time for Algorithm 2 is O ( n log n ) . Now we demonstrate the result of Algorithm 2 in the following example. Example 2 Data: n = 7 , a 1 = 3 , a 2 = 4 , a 3 = 6 , a 4 = 9 , a 5 = 14 , a 6 = 18 , a 7 = 20 , \u03b1 = 11 , \u03b2 = 8 , \u03b3 = 9 , \u03b4 = 5 , \u03b8 = 1 , a = - 0.2 , b = 0.05 . According to Algorithm 2, we have d j 1 = d j 2 = 0 for j = 1 , 2 , \u2026 , 7 , and the optimal schedule is [ J 1 , J 2 , J 3 , J 4 , J 5 , J 6 , J 7 ] . The optimal total cost is 1390.277. 5 Conclusions In this paper we have considered the single machine due window assignment scheduling problem with learning effect and deteriorating jobs. The due window assignment methods used in this problem include equal slack (SLK) and unrestricted (DIF) due window assignment. We proved that the problem remains polynomially solvable in O ( n log n ) time for both of these due window assignment methods. In the future research, it is worth to consider a more general learning and deterioration effect model or extend the results to the case of flow shop problems. Acknowledgments The authors are grateful for two anonymous referees for their helpful comments on earlier version of the article. This research was supported by the National Natural Science Foundation of China under Grant No. 11001181, and the Program for Liaoning Excellent Talents in University (Grant No. LJQ2011014). References [1] M. Pinedo Scheduling Theory, Algorithms and Systems 2002 Prentice Hall New Jersey [2] S. Browne U. Yechiali Scheduling deteriorating jobs on a single processor Oper. Res. 38 1990 495 498 [3] T.C.E. Cheng L. Kang C.T. Ng Due-date assignment and single machine scheduling with deteriorating jobs J. Oper. Res. Soc. 55 2004 198 203 [4] T.C.E. Cheng L. Kang C.T. Ng Single machine due-date scheduling of jobs with decreasing start-time dependent processing times Int. Trans. Oper. Res. 12 2005 355 366 [5] X. Huang M.-Z. Wang Parallel identical machines scheduling with deteriorating jobs and total absolute differences penalties Appl. Math. Model. 35 2011 1349 1353 [6] S. Li C.T. Ng J. Yuan Scheduling deteriorating jobs with CON/SLK due date assignment on a single machine Int. J. Prod. Econ. 131 2011 747 751 [7] W.-H. Kuo D.-L. Yang A note on due-date assignment and single-machine scheduling with deteriorating jobs J. Oper. Res. Soc. 59 2008 857 859 [8] J.-B. Wang J.-J. Wang P. Ji Scheduling jobs with chain precedence constraints and deteriorating jobs J. Oper. Res. Soc. 62 2011 1765 1770 [9] S.-H. Yang J.-B. Wang Minimizing total weighted completion time in a two-machine flow shop scheduling under simple linear deterioration Appl. Math. Comput. 217 2011 4819 4826 [10] T.C.E. Cheng C.J. Hsu Y.C. Huang W.C. Lee Single-machine scheduling with deteriorating jobs and setup times to minimize the maximum tardiness Comput. Oper. Res. 38 2011 1760 1765 [11] J.-B. Wang M.-Z. Wang Single-machine scheduling with nonlinear deterioration Optim. Lett. 6 2012 87 98 [12] C.-L. Zhao H.-Y. Tang A note to due-window assignment and single machine scheduling with deteriorating jobs and a rate-modifying activity Comput. Oper. Res. 39 2012 1300 1303 [13] J.-B. Wang X. Huang Y.-B. Wu P. Ji Group scheduling with independent setup times, ready times and deteriorating job processing times Int. J. Adv. Manuf. Technol. 60 2012 643 649 [14] L.-H. Sun L.-Y. Sun M.-Z. Wang J.-B. Wang Flow shop makespan minimization scheduling with deteriorating jobs under dominating machines Int. J. Prod. Econ. 138 2012 195 200 [15] J.-B. Wang M.-Z. Wang Minimizing makespan in three-machine flow shops with deteriorating jobs Comput. Oper. Res. 40 2013 547 557 [16] B. Alidaee N.K. Womer Scheduling with time dependent processing processing times: review and extensions J. Oper. Res. Soc. 50 1999 711 720 [17] T.C.E. Cheng Q. Ding B.M.T. Lin A concise survey of scheduling with time-dependent processing times Eur. J. Oper. Res. 152 2004 1 13 [18] S. Gawiejnowicz Time-Dependent Scheduling 2008 Springer Berlin [19] D. Biskup Single-machine scheduling with learning considerations Eur. J. Oper. Res. 115 1999 173 178 [20] D. Biskup A state-of-the-art review on scheduling with learning effects Eur. J. Oper. Res. 118 2008 315 329 [21] T.C.E. Cheng G. Wang Single machine scheduling with learning effect considerations Ann. Oper. Res. 98 2000 273 290 [22] W.C. Lee Scheduling with general position-based learning curves Inf. Sci. 181 2011 5515 5522 [23] W.C. Lee A note on single-machine scheduling with general learning effect and past-sequence-dependent setup time Comput. Math. Appl. 62 2011 2095 2100 [24] J.-B. Wang M.-Z. Wang Worst-case analysis for flow shop scheduling problems with an exponential learning effect J. Oper. Res. Soc. 63 2012 130 137 [25] J. Bai M.-Z. Wang J.-B. Wang Single machine scheduling with a general exponential learning effect Appl. Math. Model. 36 2012 829 835 [26] L. Shen Y.-B. Wu Single machine past-sequence-dependent delivery times scheduling with general position-dependent and time-dependent learning effects Appl. Math. Model. 37 2013 5444 5451 [27] W.C. Lee W.C. Yeh M.C. Chuang Uniform parallel-machine scheduling to minimize makespan with general position based learning curves Comput. Ind. Eng. 63 2012 813 818 [28] W.C. Lee Y.H. Chung Permutation flowshop scheduling to minimize the total tardiness with learning effects Int. J. Prod. Econ. 141 2013 327 334 [29] D.A. Nembhard N. Osothsilp Task complexity effects on between-individual learning/forgetting variability Int. J. Ind. Ergon. 29 2002 297 306 [30] J.-B. Wang A note on scheduling problems with learning effect and deteriorating jobs Int. J. Syst. Sci. 37 2006 827 833 [31] J.-B. Wang Single-machine scheduling problems with the effects of learning and deterioration Omega 35 2007 397 402 [32] D.-L. Yang W.-H. Kuo Scheduling with deteriorating jobs and learning effects Appl. Math. Comput. 218 2011 2069 2073 [33] W.-C. Lee A note on deteriorating jobs and learning in single-machine scheduling problems Int. J. Bus. Econ. 3 2004 83 89 [34] J.-B. Wang T.C.E. Cheng Scheduling problems with the effects of deterioration and learning Asia Pac. J. Oper. Res. 24 2007 245 261 [35] X. Wang T.C.E. Cheng Single-machine scheduling with deteriorating jobs and learning effects to minimize the makespan Eur. J. Oper. Res. 178 2007 57 70 [36] T.C.E. Cheng C.C. Wu W.C. Lee Some scheduling problems with deteriorating jobs and learning effects Comput. Ind. Eng. 54 2008 972 982 [37] T.C.E. Cheng C.C. Wu W.C. Lee Scheduling problems with deteriorating jobs and learning effects including proportional setup times Comput. Ind. Eng. 58 2010 326 331 [38] J.-B. Wang Q. Guo A due-date assignment problem with learning effect and deteriorating jobs Appl. Math. Model. 34 2010 309 313 [39] J.-B. Wang C. Wang Single-machine due-window assignment problem with learning effect and deteriorating jobs Appl. Math. Model. 35 2011 4017 4022 [40] S.-J. Yang Single-machine scheduling problems with both start-time dependent learning and position dependent aging effects under deteriorating maintenance consideration Appl. Math. Comput. 217 2011 3321 3329 [41] W.C. Lee P.J. Lai Scheduling problems with general effects of deterioration and learning Inf. Sci. 181 2011 1164 1170 [42] W.C. Lee Single-machine scheduling with past-sequence-dependent setup times and general effects of deterioration and learning Optim. Lett. 2012 10.1007/s11590-012-0481-9 [43] P.J. Lai W.C. Lee Single-machine scheduling with learning and forgetting effects Appl. Math. Model. 37 2013 4509 4516 [44] G.I. Adamopoulos C.P. Pappis Single machine scheduling with flow allowances J. Oper. Res. Soc. 47 1996 1280 1285 [45] K.R. Baker G.D. Scudder Sequencing with earliness and tardiness penalties: a review Oper. Res. 38 1990 22 36 [46] S.D. Liman S.S. Panwalkar S. Thongmee Determination of common due window location in a single machine scheduling problem Eur. J. Oper. Res. 93 1996 68 74 [47] S.D. Liman S.S. Panwalkar S. Thongmee Common due window size and location determination in a single machine scheduling problem J. Oper. Res. Soc. 49 1998 1007 1010 [48] F.J. Kramer C.Y. Lee Common due window scheduling Prod. Oper. Manage. 2 1993 262 275 [49] B. Mor G. Mosheiov Scheduling a maintenance activity and due-window assignment based on common flow allowance Int. J. Prod. Econ. 135 2012 222 230 [50] G. Mosheiov D. Oron Job dependent due-window assignment based on a common flow allowance Found. Comput. Decis. Sci. 35 2010 185 195 [51] G. Mosheiov A. Sarig A due-window assignment problem with position-dependent processing times J. Oper. Res. Soc. 59 2008 997 1003 [52] S.S. Panwalker M.L. Smith A. Seidmann Common due-date assignment to minimize total penalty for the one machine scheduling problem Oper. Res. 30 1982 391 399 [53] A. Seidmann S.S. Panwalkar M.L. Smith Optimal assignment of due dates for a single processor scheduling problem Int. J. Prod. Res. 19 1981 393 399 [54] D. Shabtay G. Steiner The single-machine earliness-tardiness scheduling problem with due date assignment and resource-dependent processing times Ann. Oper. Res. 159 2008 25 40 [55] M.X. Weng J.A. Ventura Scheduling about a large common due-date with tolerance to minimized mean absolute deviation of completion times Naval Res. Logist. 41 1994 843 851 [56] G.H. Hardy J.E. Littlewood G. Polya Inequalities 1967 Cambridge University Press"
    },
    "10.3882/j.issn.1674-2370.2013.02.003": {
        "Title": "Discharge estimation based on machine learning",
        "Date": "April 2013",
        "Text": "serial JL 312434 291210 291830 291881 291887 31 90 Water Science and Engineering WATERSCIENCEENGINEERING 2015-04-18 2015-04-18 2015-04-18T23:48:39 1-s2.0-S1674237015302325 S1674-2370(15)30232-5 S1674237015302325 10.3882/j.issn.1674-2370.2013.02.003 S350 S350.2 HEAD-AND-TAIL 1-s2.0-S1674237013X80019 2015-05-15T07:03:33.915252-04:00 0 0 20130401 20130430 2013 2015-04-19T00:47:57.178032Z rawtext articleinfo articletitlenorm authfirstinitialnorm authfirstsurnamenorm cid cids contenttype copyright crossmark dateloaded dateloadedtxt datesearch datesort dateupdated dco docsubtype doctype doi eid ewtransactionid hubeid indexeddate issfirst issn issnnorm issuelist itemstage itemtransactionid itemweight oauserlicense openaccess openarchive pg pgfirst pglast pii piinorm pubdateend pubdatestart pubdatetxt pubyr sortorder srctitle srctitlenorm srctype ssids alllist content oa subj tomb volfirst volissue volumelist webpdf webpdfpagecount yearnav affil articletitle auth authfirstini authfull authkeywords authlast primabst ref 1674-2370 16742370 false 6 6 2 2 Volume 6, Issue 2 3 145 152 145 152 201304 April 2013 2013-04-01 2013-04-30 2013 article fla Copyright \u00a9 2013 Production and hosting by Elsevier B.V. DISCHARGEESTIMATIONBASEDMACHINELEARNING JIANG Z BEHZAD 2009 7624 7629 M CASTRO 2004 2308 2321 R CLEVELAND 1979 829 836 W CLEVELAND 1988 596 610 W DAI 2010 37 39 L FENG 1996 184 186 G FENG 2004 355 365 H FRENCH 1992 1 31 M LU 2006 47 49 M MITCHELL 2003 T MACHINELEARNING SHI 2007 21 25 K ZHU 2002 M DATAMINING JIANGX2013X145 JIANGX2013X145X152 JIANGX2013X145XZ JIANGX2013X145X152XZ Full 2015-04-16T17:29:16Z FundingBody Hohai University http://creativecommons.org/licenses/by-nc-nd/4.0/ OA-Window item S1674-2370(15)30232-5 S1674237015302325 1-s2.0-S1674237015302325 10.3882/j.issn.1674-2370.2013.02.003 312434 2015-04-18T19:47:57.178032-04:00 2013-04-01 2013-04-30 1-s2.0-S1674237015302325-main.pdf https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1674237015302325/MAIN/application/pdf/87cefdbb0bae839128beb2cfbcc9ab8e/main.pdf https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1674237015302325/MAIN/application/pdf/87cefdbb0bae839128beb2cfbcc9ab8e/main.pdf main.pdf pdf true 410003 MAIN 8 1-s2.0-S1674237015302325-main_1.png https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1674237015302325/PREVIEW/image/png/13c85540dbc2b8f52daa9caa2903645c/main_1.png https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1674237015302325/PREVIEW/image/png/13c85540dbc2b8f52daa9caa2903645c/main_1.png main_1.png png 58607 849 656 IMAGE-WEB-PDF 1 Water Science and Engineering, 2013, 6(2): 145-152 doi:10.3882/j.issn.1674-2370.2013.02.003 http://www.waterjournal.cn e-mail: wse2008@vip.163.com Discharge estimation based on machine learning Zhu JIANG*, Hui-yan WANG, Wen-wu SONG School of Energy and Environment, Xihua University, Chengdu 610039, P. R. China Abstract: To overcome the limitations of the traditional stage-discharge models in describing the dynamic characteristics of a river, a machine learning method of non-parametric regression, the locally weighted regression method was used to estimate discharge. With the purpose of improving the precision and efficiency of river discharge estimation, a novel machine learning method is proposed: the clustering-tree weighted regression method. First, the training instances are clustered. Second, the k-nearest neighbor method is used to cluster new stage samples into the best-fit cluster. Finally, the daily discharge is estimated. In the estimation process, the interference of irrelevant information can be avoided, so that the precision and efficiency of daily discharge estimation are improved. Observed data from the Luding Hydrological Station were used for testing. The simulation results demonstrate that the precision of this method is high. This provides a new effective method for discharge estimation. Key words: stage-discharge relationship; discharge estimation; locally weighted regression; clustering-tree weighted regression; k-nearest neighbor method 1 Introduction The commonly used discharge test technology is complicated and expensive, and cannot be observed continuously. On the other hand, it is relatively easy to observe the average stage continuously. Therefore, discharge is usually calculated on the basis of stage and the stage-discharge relationship. The stage-discharge relationship curve is utilized to describe the relationship between the water stage of a cross-section and the discharge passing through the cross-section. In the process of planning, design, and construction of hydraulic engineering projects, the estimation and prediction of stage and discharge have always been considered an important subject (Lu 2006; Feng and Chen 2004; Feng et al. 1996). The precision of hydrological computation, forecast, and analysis is susceptible to the quality of discharge data. For this reason, the stage-discharge relationship model has always received attention. A given stage or discharge is incompletely reliable due to the influence of fluctuating backwater, flood fluctuations, and other factors. Errors in individual data points may be very large. A common method of seeking a certain pattern in a pile of messy data is to \u00fc\u00fc\u00fc\u00fc\u00fc\u00fc\u00fc\u00fc\u00fc\u00fc\u00fc\u00fc\u00fc This work was supported by the Key Fund Project of the Sichuan Provincial Department of Education (Grant No. 11ZA009), the Fund Project of Sichuan Provincial Key Laboratory of Fluid Machinery (Grant No. SBZDPY-11-5), and the Key Scientific Research Project of Xihua University (Grant No. Z1120413). *Corresponding author (e-mail: HILL5525@163.com) Received Dec. 5, 2011; accepted Jun. 9, 2012 establish relational expressions among them (Dai et al. 2010), which can felicitously reflect the stage-discharge relationships in natural rivers. Scholars have proposed many traditional stage-discharge models, such as the exponential type and polynomial type (French et al. 1992). Propagation of flow becomes more and more complex with the degree of randomness. Although it can be described by deterministic equations in specific conditions, a river is a nonlinear, strongly correlated, and highly complicated dynamic system, due to comprehensive effects of precipitation and human activities (Behzad et al. 2009). Therefore, traditional stage-discharge models may not be suitable for representing modern flow characteristics. In recent years, research on new modeling methods based on new scientific theories has become one of the important aspects of estimation and prediction. As a non-parametric learning method, machine learning does not require a clear assumption to define the complete objective function over the entire sample space. Instead, it can locally approximate each sample through the building of different objective functions (Zhu 2002). Therefore, a machine learning method of non-parametric regression, the locally weighted regression method, is used to establish the relationship between the discharge and stage, and then the discharge can be estimated. In order to improve the precision of estimation, first of all, a novel algorithm is proposed: the clustering-tree weighted regression method. After clustering the training instances, the k-nearest neighbor method is used to cluster new stage samples (for testing) into the best-fit cluster. Following this, the daily discharge is estimated. Finally, the observed data are utilized for comparison between the locally weighted regression method and clustering-tree weighted regression method. 2 Methodology 2.1 Stage-discharge relationships Stage-discharge relationships refer to the empirical relationships between the discharge y passing through a cross-section and the corresponding stage x. Different scholars have proposed different expressions for stage-discharge relationships. In general, the relationships have two types. One is the power law type (French et al. 1992): ya= xb (1) where ais a coefficient, and bis an exponent. The linear relationship between discharge and average stage can be obtained through natural logarithm transformation of Eq. (1): ln y= ln abx ln (2) + The other stage-discharge relational expression has the polynomial form commonly used: yc cxc+ x+\"+ c = 0 + 11 22 pxp (3) where ccc , , ,\", care undetermined coefficients, x(q= 1, 2, \", p) is the value of the 012 pq stage minus a constant, and p is the highest order of the polynomial. The polynomial form has been widely used, because the fitted curve is consistent with hydrological features at most observation stations (Dai et al. 2010). Parameters a, b, and ciin the expressions are generally calculated with the least square method, or some other regression methods. The values of these parameters are greatly affected by the area of the basin, fluctuating backwater, flood fluctuations, and some other complicated factors. Therefore, the real hydrological situation in natural rivers cannot be appropriately reflected by the stage-discharge models using traditional mathematical methods. For these reasons, machine learning is used to establish the non-parametric relationships between the discharge and stage. In this study the discharge was estimated to provide reliable data for hydrological calculation, prediction, and analysis. 2.2 Locally weighted regression Locally weighted regression (LWR) is a non-parametric regression algorithm, first proposed by Cleveland (1979). Cleveland and Devlin (1988) extended it to multi-variable cases. The basic idea of this method is to use weighted least squares to locally fit a polynomial function at each point in the independent variable space, and to use this polynomial function as the estimation of the regression function at this point. The open method rather than a ready-made formula was adopted to calculate the relationships between variables with LWR. The fitted curve can properly present small changes of the relationship between different variables (Cleveland 1979). When we analyze the relationship between discharge and stage, the LWR method can be achieved through the following steps: (1) A space including water stage points is formed. The width of the space is described by z= lm (4) where z is the number of observation parameters participating in the process of the regression, l is the proportion of the number of observation parameters taking part in the regression to the total number of the observation parameters, and m is the number of observational data. (2) The weights of all stage points in the space are defined. The weight of any point is the height of a weight function at this point. The weight function of locally weighted regression has many types. The choice of the weight function does not affect the calculation precision materially, so a common weight function is selected: Wu \u00ad\u00ae 3 )3 u 1 \u00b0 1-u 0 == ()=( (5) \u00b00 Others \u00af ,where u is a weight function variable. The weight for a point ( yx) is iii = ((, i) () wW pxx dx ) (6) where yi is the fitted discharge, xi is the observational stage, x is the estimated stage, and pxx (, i)is the distance from xto xi, that is pxx (, )= xi-x , and ()dx is the distance i from x to the zth point nearest to x. (3) A polynomial is fitted to each point in an independent variable space using the weighted least squares algorithm. (4) The estimated value of discharge is acquired. The process of the LWR method is completed after the four procedures, and the estimated value of discharge can be obtained at last. 2.3 Clustering-tree weighted regression Cluster analysis is a set of methodologies for automatic classification of samples into several groups using a measure of association, so that the samples in the same group are similar, while samples in different groups are quite discrepant from one another (Castro et al. 2004). The essence of the clustering process is an optimization, namely, helping the objective function of the system to reach a minimum value using a rapid algorithm. The clustering process is mainly focused on dividing large numbers of samples into several classes on the basis of similarities; in the meantime, the prediction of a specific sample in an unknown domain is not involved. Therefore, it is not restrained by people\u2019s prior knowledge, and the original information of the data collection can be obtained eventually. The clustering methods mainly include the division method, hierarchical method, density-based method, and grid-based method (Shi et al. 2007). The basic idea of the hierarchical clustering method (Mitchell 2003) is to determine two classes that are most alike by establishing and updating the distance coefficient matrix (or a similar coefficient matrix) gradually, and to merge the two classes into one class. Since the entire process can be expressed as a binary hierarchical tree, the hierarchical clustering method is also a clustering-tree method, with advantages such as clarity in the polymerization process, a high degree of visualization, independence from the initial arrangement of samples, and stability in the clustering results. Nevertheless, it is undeniable that this method also suffers from difficulty in class reconstruction. Aimed at improving the precision and efficiency of discharge estimation, this paper proposes a novel machine learning method, the clustering-tree weighted regression method. The specific process of estimating the stage-discharge relationships using this algorithm can be summarized as follows: Step 1: k-means is used to cluster the observed hydrological data, which are taken as training instances. k-means is the most basic clustering method, which aims to estimate the mean and covariance of a given number of clusters, k, in high-dimensional data. It starts with a random estimation and initial partition, and keeps reassigning the samples to clusters based on the similarity between the samples and clusters, until a convergence criterion is met. The observed hydrological data contain abundant information about the flow status, so they are chosen for clustering. We let Gf represent the clustering of the fth year. Gf consists of n data points: {,rrf1,\", rf} , where ri=1, 2, \", n) is the point ( yx), with yi and , f2 n fi( fifi f xfi representing the observed ith discharge and river stage of the fth year, respectively. k-means is used to find a set of representative points {s1, s2,\", sk} to make the following objective function minimum: kn E =\u00a6\u00a6lij 2 (7) j=1 i=1 where lijis the distance from the point sj to the point rfi , and sj represents the jth cluster center of Gf . Once the objective function is determined, the following tasks can be completed: (a) k cluster centers are randomly selected from n training instances. (b) The nearest cluster center to each point rfi (river stage and discharge) is sought, and then rfi is put in the cluster. (c) The objective function E is computed. If the value of E does not change, the results of the clustering are stable. In that case, the process should proceed to step (e), or else to step (d). (d) The best clustering center is generated by a fixed E, and then the process returns to step (b). (e) The distance coefficient matrix is established and gradually updated, every two nodes with maximum similarity are determined, and then they are merged into a new node until only one node is left. Step 2: The new stage samples are assigned to the most appropriate cluster using the k-nearest neighbor method. The value of k can be determined by several experiments. The minimum classification error rate will be obtained from the k value. The k-nearest neighbor method determines k samples which are the closest to the unknown samples in the multi-dimensional space, and it also judges the category of the unknown instances according to the characteristics of these k samples (Behzad et al. 2009). When a new stage sample is given, the k-nearest neighbor classifier uses the Euclidean distance to search k stage samples closest to the new sample from the clusters. The Euclidean distance between two stage samples xi and xj is defined as follows: dx() i , xj = \u00a6 n (ar ()xi -ar ()xj )2 (8) r =1 where axi is the value of the rth attribute of the stage sample xi . r () Step 3: After each new stage sample is assigned to a cluster, the river discharge is estimated using the LWR method (which is trained with data only from the relevant cluster). 3 Method testing 3.1 Experimental data The Dadu River is the largest tributary of the Minjiang River. It is very important to understand its hydrology in order to fully realize the whole benefit of the Dadu River Basin cascade development. Determination of the stage-discharge model is the first task of hydrological data compilation. The Luding Hydrological Station is one of the national basic stations, and it is located on the main stream of the Dadu River. The daily mean stage and discharge data at the Luding hydrological station from 2007 to 2010 were used, as shown in Fig. 1. The data in the first three years were used as the training samples, and the data in 2010 were used as the testing samples. 3.2 Estimation of discharge for stage-discharge model While using the clustering-tree weighted regression method, we first need to determine k cluster centers. The process of determining the value of k is as follows: First, the hierarchical clustering method is used to get a pedigree chart. Second, the value of k is roughly determined from the chart. Finally, a few values near the k value are tested to select the best one. In this study, the value of k is equal to 4. Four cluster centers were selected from the training samples through simulation experiments, as shown in Fig. 2. Fig. 1 Observed daily stage and discharge data Fig. 2 Four cluster centers The performance of each approach is assessed using the root mean square error (RMSE): m 1 y - y ei oi RMSE = \u00a6 (9) mi=1 yoi where subscripts e and o denote estimated and observed data, respectively. Fig. 3 shows the RMSE values in estimating the daily discharge with the LWR method and the clustering-tree weighted regression method, which demonstrates that the precision of the latter method proposed in this paper is superior to that of the former one. Fig. 3 RMSE values of two methods The estimated results of daily discharge using these two methods are shown in Fig. 4. From the estimated results in Fig. 4(a) and the RMSE values of the LWR method shown in Fig. 3, it can be seen that there is a large deviation between the estimated daily discharge and the observed one when the discharge is low. On the other hand, the estimated results can be improved when the discharge increases. Fig. 4(b) and Fig. 3 show that the clustering-tree weighted regression method can effectively improve the large deviation between the estimated and observed daily discharge under normal climate conditions (e.g., when there are no floods, no heavy rainfall, etc.) and without special water storage requirements. This was achieved by first clustering the hydrological data of the river as the training samples, and then assigning the new stage samples into proper classes with the k-nearest neighbor method. In this way, the interference of other irrelevant information can be avoided, and thus the efficiency and precision of daily discharge estimation can be improved. It can be seen from Fig. 3 that when the discharge was very large, the estimation accuracy of the proposed method was lower than that of the LWR method. This is because the proposed method is based on the cluster. Heavy rainfall rarely occurred, and the training samples included few large discharge values, so the accuracy of the proposed model decreased. Without extreme weather events, the proposed method has practical significance in accurately capturing the hydrological changes of the river. Fig. 4 Estimated discharge with LWR and clustering-tree weighted regression methods 4 Conclusions The movement of water is a complicated process involving a large number of random factors. The traditional stage-discharge models were established on the basis of empirical regression, which is not suitable for complicated river flow characteristics. Both the LWR method and a novel clustering-tree weighted regression method were used to estimate the discharge of the stage-discharge models. The observed data of the Luding Hydrological Station were used to verify these two methods. The RMSE values and predicted results of daily discharge both show that under normal climate conditions the clustering-tree weighted regression method has a higher accuracy than the LWR method, and can accurately capture changing characteristics of dynamic flow. In our future work, other non-parametric techniques that can also be applicable to parametric calibration will be investigated. To further validate the proposed approach in this paper, future tests will be carried out on data collected from different rivers. References Behzad, M., Asghari, K., Eazi, M., and Palhang, M. 2009. Generalization performance of support vector machines and neural networks in runoff modeling. Expert Systems with Applications, 36(4), 7624-7629. [doi:10.1016/j.eswa.2008.09.053] Castro, R. M., Coates, M. J., and Nowak, R. D. 2004. Likelihood based hierarchical clustering. IEEE Transaction on Signal Process, 52(8), 2308-2321. [doi:10.1109/TSP.2004.831124] Cleveland, W. S. 1979. Robust locally weighted regression: An approach to regression analysis by local fitting. Journal of the American Statistical Association, 74(368), 829-836. Cleveland, W. S., and Devlin, S. J. 1988. Locally weighted regression: An approach to regression analysis by local fitting. Journal of the American Statistical Association, 83(403), 596-610. [doi:10.2307/2289282] Dai, L. Q., Dai, H. C., Jiang, D. G., Li, H., and Chen, X. Y. 2010. Calculation of stage-discharge relationship curve based on least square method. Yellow River, 32(9), 37-39. (in Chinese) Feng, G. Z., Wang, S. Y., and Wei, H. Y. 1996. Application of the multivariate autoregressive model to low flow forecast. Journal of Natural Resources, 11(2), 184-186. (in Chinese) Feng, H. Z., and Chen, Y. Y. 2004. A new method for non-linear classify and non-linear regression, II: Application of support vector machine to weather forecast. Journal of Applied Meteorological Science, 15(3), 355-365. (in Chinese) French, M. N., Krajewski, W. F., and Cuykendall, R. R. 1992. Rainfall forecasting in space and time using a neural network. Journal of Hydrology, 137(1-4), 1-31. [doi:10.1016/0022-1694(92)90046-X] Lu, M. 2006. Research on the SVM application of runoff forecast. China Rural Water and Hydropower, (2), 47-49. (in Chinese) Mitchell, T. M. 2003. Machine Learning. Beijing: China Machine Press. (in Chinese) Shi, K. P., Mu, G., Li, T., and L\u00fc, L. 2007. Empirical mode decomposition based clustering-tree method and its application in coherency identification of generating sets. Power System Technology, 31(22), 21-25. (in Chinese) Zhu, M. 2002. Data Mining. Hefei: University of Science and Technology of China Press. (in Chinese) (Edited by Yan LEI) ng samples, and then assigning the new stage samples into proper classes with the k-nearest neighbor method. In this way, the interference of other irrelevant information can be avoided, and thus the efficiency and precision of daily discharge estimation can be improved. It can be seen from Fig. 3 that when the discharge was very large, the estimation accuracy of the proposed method was lower than that of the LWR method. This is because the proposed method is based on the cluster. Heavy rainfall rarely occurred, and the training samples included few large discharge values, so the accuracy of the proposed model decreased. Without extreme weather events, the proposed method has practical significance in accurately capturing the hydrological changes of the river. Fig. 4 Estimated discharge with LWR and clustering-tree weighted regression methods 4 Conclusions The movement of water is a complicated process involving a large number of random factors. The traditional stage-discharge models were established on the basis of empirical regression, which is not suitable for complicated river flow characteristics. Both the LWR method and a novel clustering-tree weighted regression method were used to estimate the discharge of the stage-discharge models. The observed data of the Luding Hydrological Station were used to verify these two methods. The RMSE values and predicted results of daily discharge both show that under normal climate conditions the clustering-tree weighted regression method has a higher accuracy than the LWR method, and can accurately capture changing characteristics of dynamic flow. In our future work, other non-parametric techniques that can also be applicable to parametric calibration will be investigated. To further validate the proposed approach in this paper, future tests will be carried out on data collected from different rivers. References Behzad, M., Asghari, K., Eazi, M., and Palhang, M. 2009. Generalization performance of support vector machines and neural networks in runoff modeling. Expert Systems with Applications, 36(4), 7624-7629. [doi:10.1016/j.eswa.2008.09.053] Castro, R. M., Coates, M. J., and Nowak, R. D. 2004. Likelihood based hierarchical clustering. IEEE Transaction on Signal Process, 52(8), 2308-2321. [doi:10.1109/TSP.2004.831124] Cleveland, W. S. 1979. Robust locally weighted regression: An approach to regression analysis by local fitting. Journal of the American Statistical Association, 74(368), 829-836. Cleveland, W. S., and Devlin, S. J. 1988. Locally weighted regression: An approach to regression analysis by local fitting. Journal of the American Statistical Association, 83(403), 596-610. [doi:10.2307/2289282] Dai, L. Q., Dai, H. C., Jiang, D. G., Li, H., and Chen, X. Y. 2010. Calculation of stage-discharge relationship curve based on least square method. Yellow River, 32(9), 37-39. (in Chinese) Feng, G. Z., Wang, S. Y., and Wei, H. Y. 1996. Application of the multivariate autoregressive model to low flow forecast. Journal of Natural Resources, 11(2), 184-186. (in Chinese) Feng, H. Z., and Chen, Y. Y. 2004. A new method for non-linear classify and non-linear regression, II: Application of support vector machine to weather forecast. Journal of Applied Meteorological Science, 15(3), 355-365. (in Chinese) French, M. N., Krajewski, W. F., and Cuykendall, R. R. 1992. Rainfall forecasting in space and time using a neural network. Journal of Hydrology, 137(1-4), 1-31. [doi:10.1016/0022-1694(92)90046-X] Lu, M. 2006. Research on the SVM application of runoff forecast. China Rural Water and Hydropower, (2), 47-49. (in Chinese) Mitchell, T. M. 2003. Machine Learning. Beijing: China Machine Press. (in Chinese) Shi, K. P., Mu, G., Li, T., and L\u00fc, L. 2007. Empirical mode decomposition based clustering-tree metho WSE 30232 S1674-2370(15)30232-5 10.3882/j.issn.1674-2370.2013.02.003 \u00a9 2013 Hohai University. Production and hosting by Elsevier B.V. This work was supported by the Key Fund Project of the Sichuan Provincial Department of Education (Grant No. 11ZA009), the Fund Project of Sichuan Provincial Key Laboratory of Fluid Machinery (Grant No. SBZDPY-11-5), and the Key Scientific Research Project of Xihua University (Grant No. Z1120413). Discharge estimation based on machine learning Zhu Jiang * Hui-yan Wang Wen-wu Song School of Energy and Environment, Xihua University, Chengdu 610039, P. R. China School of Energy and Environment Xihua University Chengdu 610039 P. R. China * Corresponding author To overcome the limitations of the traditional stage-discharge models in describing the dynamic characteristics of a river, a machine learning method of non-parametric regression, the locally weighted regression method was used to estimate discharge. With the purpose of improving the precision and efficiency of river discharge estimation, a novel machine learning method is proposed: the clustering-tree weighted regression method. First, the training instances are clustered. Second, the k-nearest neighbor method is used to cluster new stage samples into the best-fit cluster. Finally, the daily discharge is estimated. In the estimation process, the interference of irrelevant information can be avoided, so that the precision and efficiency of daily discharge estimation are improved. Observed data from the Luding Hydrological Station were used for testing. The simulation results demonstrate that the precision of this method is high. This provides a new effective method for discharge estimation. Key words stage-discharge relationship discharge estimation locally weighted regression clustering-tree weighted regression k-nearest neighbor method References Behzad et al., 2009 M. Behzad K. Asghari M. Eazi M. Palhang Generalization performance of support vector machines and neural networks in runoff modeling Expert Systems with Applications 36 4 2009 7624 7629 [doi:10.1016/j.eswa.2008.09.053] Castro et al., 2004 R.M. Castro M.J. Coates R.D. Nowak Likelihood based hierarchical clustering IEEE Transaction on Signal Process 52 8 2004 2308 2321 [doi:10.1109/TSP.2004.831124] Cleveland, 1979 W.S. Cleveland Robust locally weighted regression: An approach to regression analysis by local fitting Journal of the American Statistical Association 74 368 1979 829 836 Cleveland and Devlin, 1988 W.S. Cleveland S.J. Devlin Locally weighted regression: An approach to regression analysis by local fitting Journal of the American Statistical Association 83 403 1988 596 610 [doi:10.2307/2289282] Dai et al., 2010 L.Q. Dai H.C. Dai D.G. Jiang H. Li X.Y. Chen Calculation of stage-discharge relationship curve based on least square method Yellow River 32 9 2010 37 39 (in Chinese) Feng et al., 1996 G.Z. Feng S.Y. Wang H.Y. Wei Application of the multivariate autoregressive model to low flow forecast Journal of Natural Resources 11 2 1996 184 186 (in Chinese) Feng and Chen, 2004 H.Z. Feng Y.Y. Chen A new method for non-linear classify and non-linear regression, II: Application of support vector machine to weather forecast Journal of Applied Meteorological Science 15 3 2004 355 365 (in Chinese) French et al., 1992 M.N. French W.F. Krajewski R.R. Cuykendall Rainfall forecasting in space and time using a neural network Journal of Hydrology 137 1-4 1992 1 31 [doi:10.1016/0022-1694(92)90046-X] Lu, 2006 M. Lu Research on the SVM application of runoff forecast China Rural Water and Hydropower 2 2006 47 49 (in Chinese) Mitchell, 2003 T.M. Mitchell Machine Learning 2003 China Machine Press Beijing (in Chinese) Shi et al., 2007 K.P. Shi G. Mu T. Li L. L\u00fc Empirical mode decomposition based clustering-tree method and its application in coherency identification of generating sets Power System Technology 31 22 2007 21 25 (in Chinese) Zhu, 2002 M. Zhu Data Mining 2002 University of Science and Technology of China Press Hefei (in Chinese)"
    },
    "10.1016/j.cmpb.2013.08.004": {
        "Title": "An improved method of early diagnosis of smoking-induced respiratory changes using machine learning algorithms",
        "Date": "December 2013",
        "Text": "serial JL 271322 291210 291791 291871 291901 31 Computer Methods and Programs in Biomedicine COMPUTERMETHODSPROGRAMSINBIOMEDICINE 2013-08-17 2013-08-17 2014-08-29T04:37:22 1-s2.0-S0169260713002800 S0169-2607(13)00280-0 S0169260713002800 10.1016/j.cmpb.2013.08.004 S300 S300.2 FULL-TEXT 1-s2.0-S0169260713X00124 2015-05-14T05:25:39.534626-04:00 0 0 20131201 20131231 2013 2013-08-17T00:00:00Z articleinfo articletitlenorm authfirstinitialnorm authfirstsurnamenorm cid cids contenttype copyright crossmark dateloaded dateloadedtxt datesearch datesort dateupdated dco docsubtype doctype doi eid ewtransactionid fundingbodyid hubeid indexeddate issfirst issn issnnorm issuelist itemstage itemtransactionid itemweight openaccess openarchive pg pgfirst pglast pii piinorm pubdateend pubdatestart pubdatetxt pubyr sectiontitle sortorder sponsoredaccessdate sponsoredaccesstype srctitle srctitlenorm srctype ssids alllist content subj subheadings tomb volfirst volissue volumelist webpdf webpdfpagecount yearnav figure table body affil articletitle auth authfirstini authfull authkeywords authlast primabst ref 0169-2607 01692607 DELAY 2014-10-14 BZG true 112 112 3 3 Volume 112, Issue 3 12 441 454 441 454 201312 December 2013 2013-12-01 2013-12-31 2013 Section I: Methodology article fla Copyright \u00a9 2013 Elsevier Ireland Ltd. IMPROVEDMETHODEARLYDIAGNOSISSMOKINGINDUCEDRESPIRATORYCHANGESUSINGMACHINELEARNINGALGORITHMS AMARAL J 1 Introduction 2 Methods 2.1 Data sets 2.2 Forced oscillation measurements and parameters 2.3 The studied classifiers 2.4 Performance evaluation 2.5 Feature selection 2.6 Design of the experiments 3 Results 3.1 Forced oscillation parameters 3.2 Performance of the studied classifiers 3.2.1 Experiment 1\u2014The use of original FOT parameters without feature selection 3.2.2 Experiment 2\u2014Feature selection on original FOT parameters 3.2.3 Experiment 3\u2014Feature selection on cross products of FOT parameters 3.3 Pursuit for the best features and classifier parameters 4 Discussion 5 Conclusions 6 Future plans References MATHERS 2006 e442 C ENRIGHT 2000 645 652 P KAMINSKY 2001 205 209 A POLKEY 2004 718 719 M CROXTON 2002 838 844 T OOSTVEEN 2003 1026 1041 E BATES 2011 1233 1272 J KACZKA 2011 337 359 D MACLEOD 2001 505 516 D NAVAJAS 2001 555 562 D FARIA 2009 22 A DIMANGO 2006 399 410 A FARIA 2010 1295 1304 A SILVA 2011 2085 2091 K FARIA 2012 A BIOMEDICALENGINEERINGTECHNICALAPPLICATIONSINMEDICINE FORCEDOSCILLATIONTECHNIQUEINDETECTIONSMOKINGINDUCEDRESPIRATORYCHANGES AMARAL 2012 183 193 J AMERICANTHORACICSOCIETYEUROPEANRESPIRATORYSOCIETY 2005 319 338 MELO 2000 2867 2872 P LORINO 1997 150 155 A PESLIN 1981 93 115 R YING 1990 1186 1192 Y KUNCHEVA 2004 L COMBININGPATTERNCLASSIFIERSMETHODSALGORITHMS WEBB 2002 A STATISTICALPATTERNRECOGNITION HAYKIN 1994 S NEURALNETWORKSACOMPREHENSIVEFOUNDATION VAPNIK 2000 V NATURESTATISTICALLEARNINGTHEORY MCCULLAGH 1989 P GENERALIZEDLINEARMODELS ZHANG 2000 451 462 G PEDREIRA 2009 284 290 C GOLDBAUM 2002 162 169 M WITTEN 2005 I DATAMININGPRACTICALMACHINELEARNINGTOOLSTECHNIQUES DIETTERICH 1998 1895 1923 D FAWCETT 2006 861 874 T KOHAVI 1995 1137 1145 R PROCEEDINGS14THINTERNATIONALJOINTCONFERENCEARTIFICIALINTELLIGENCE ASTUDYCROSSVALIDATIONBOOTSTRAPFORACCURACYESTIMATIONMODELSELECTION REFAEILZADEH 2009 P CROSSVALIDATIONENCYCLOPEDIADATABASESYSTEMS DEMSAR 2006 1 30 J GUYON 2003 1157 1182 I HANLEY 1982 29 36 J OBUCHOWSKI 2005 364 372 N PINTEA 2009 49 66 S METZ 1978 283 298 C BRADLEY 1997 1145 1159 P LING 2003 519 524 C PROCEEDINGS18THINTERNATIONALCONFERENCEARTIFICIALINTELLIGENCE AUCASTATISTICALLYCONSISTENTMOREDISCRIMINATINGMEASUREACCURACY HUANG 2005 299 310 J HEIJDEN 2004 F CLASSIFICATIONPARAMETERESTIMATIONSTATEESTIMATIONENGINEERINGAPPROACHUSINGMATLAB GOLDBERG 1989 D GENETICALGORITHMSINSEARCHOPTIMIZATIONMACHINELEARNING MICHALEWICZ 1992 Z GENETICALGORITHMSDATASTRUCTURESEVOLUTIONPROGRAMS LACERDA 2003 111 122 E ILSEOK 2004 1424 1437 O LESSMANN 2006 3063 3069 S PROCEEDINGSINTERNATIONALJOINTCONFERENCENEURALNETWORKS GENETICALGORITHMSFORSUPPORTVECTORMACHINEMODELSELECTION FENG 2007 111 120 T VAFAIE 2010 200 203 H PROCEEDINGSFOURTHINTERNATIONALCONFERENCETOOLSARTIFICIALINTELLIGENCE GENETICALGORITHMSATOOLFORFEATURESELECTIONINMACHINELEARNING ANBARASI 2010 5370 5376 M DELONG 1988 837 845 E SWETS 1988 1285 1293 J AMARALX2013X441 AMARALX2013X441X454 AMARALX2013X441XJ AMARALX2013X441X454XJ Full 2014-10-14T09:16:45Z FundingPartnerOpenArchive Brazilian Government http://www.elsevier.com/open-access/userlicense/1.0/ item S0169-2607(13)00280-0 S0169260713002800 1-s2.0-S0169260713002800 10.1016/j.cmpb.2013.08.004 271322 2014-08-29T02:32:35.030293-04:00 2013-12-01 2013-12-31 DELAY 2014-10-14 BZG 1-s2.0-S0169260713002800-main.pdf https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0169260713002800/MAIN/application/pdf/e70397617d3c061b2a4aebbcb3307a92/main.pdf https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0169260713002800/MAIN/application/pdf/e70397617d3c061b2a4aebbcb3307a92/main.pdf main.pdf pdf true 2289869 MAIN 14 1-s2.0-S0169260713002800-main_1.png https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0169260713002800/PREVIEW/image/png/2c540b5f57e8696f8725b21d69c327ec/main_1.png https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0169260713002800/PREVIEW/image/png/2c540b5f57e8696f8725b21d69c327ec/main_1.png main_1.png png 43804 849 656 IMAGE-WEB-PDF 1 1-s2.0-S0169260713002800-gr6_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0169260713002800/gr6/HIGHRES/image/jpeg/2716b7c5635cc4bccfad65a512c981a3/gr6_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0169260713002800/gr6/HIGHRES/image/jpeg/2716b7c5635cc4bccfad65a512c981a3/gr6_lrg.jpg gr6 gr6_lrg.jpg jpg 602419 1062 1943 IMAGE-HIGH-RES 1-s2.0-S0169260713002800-gr5_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0169260713002800/gr5/HIGHRES/image/jpeg/2af02a4b531ddb32c2d7e28954e561fa/gr5_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0169260713002800/gr5/HIGHRES/image/jpeg/2af02a4b531ddb32c2d7e28954e561fa/gr5_lrg.jpg gr5 gr5_lrg.jpg jpg 533284 1064 1950 IMAGE-HIGH-RES 1-s2.0-S0169260713002800-gr4_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0169260713002800/gr4/HIGHRES/image/jpeg/ae31682d58333eebcec46e885cd30b94/gr4_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0169260713002800/gr4/HIGHRES/image/jpeg/ae31682d58333eebcec46e885cd30b94/gr4_lrg.jpg gr4 gr4_lrg.jpg jpg 487580 2243 1499 IMAGE-HIGH-RES 1-s2.0-S0169260713002800-gr3_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0169260713002800/gr3/HIGHRES/image/jpeg/50788d79dc5fe665ee2940fa0e1fe618/gr3_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0169260713002800/gr3/HIGHRES/image/jpeg/50788d79dc5fe665ee2940fa0e1fe618/gr3_lrg.jpg gr3 gr3_lrg.jpg jpg 621207 1100 1947 IMAGE-HIGH-RES 1-s2.0-S0169260713002800-gr2_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0169260713002800/gr2/HIGHRES/image/jpeg/8cfe03ea68cd3dc24e0ca65dc6b67b1d/gr2_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0169260713002800/gr2/HIGHRES/image/jpeg/8cfe03ea68cd3dc24e0ca65dc6b67b1d/gr2_lrg.jpg gr2 gr2_lrg.jpg jpg 1264376 4208 2621 IMAGE-HIGH-RES 1-s2.0-S0169260713002800-gr1_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0169260713002800/gr1/HIGHRES/image/jpeg/e778b28ec5ad99acf4d2f962a1e4522d/gr1_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0169260713002800/gr1/HIGHRES/image/jpeg/e778b28ec5ad99acf4d2f962a1e4522d/gr1_lrg.jpg gr1 gr1_lrg.jpg jpg 43367 125 2120 IMAGE-HIGH-RES 1-s2.0-S0169260713002800-gr6.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0169260713002800/gr6/DOWNSAMPLED/image/jpeg/08ab4b8212ea222dd906170f2525b319/gr6.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0169260713002800/gr6/DOWNSAMPLED/image/jpeg/08ab4b8212ea222dd906170f2525b319/gr6.jpg gr6 gr6.jpg jpg 69114 300 548 IMAGE-DOWNSAMPLED 1-s2.0-S0169260713002800-gr5.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0169260713002800/gr5/DOWNSAMPLED/image/jpeg/f03e8d2b87e9d0e65c7cde8a0dcf4c81/gr5.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0169260713002800/gr5/DOWNSAMPLED/image/jpeg/f03e8d2b87e9d0e65c7cde8a0dcf4c81/gr5.jpg gr5 gr5.jpg jpg 66978 300 550 IMAGE-DOWNSAMPLED 1-s2.0-S0169260713002800-gr4.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0169260713002800/gr4/DOWNSAMPLED/image/jpeg/1c616db0fa6ac2283a5dc0d11b8d091b/gr4.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0169260713002800/gr4/DOWNSAMPLED/image/jpeg/1c616db0fa6ac2283a5dc0d11b8d091b/gr4.jpg gr4 gr4.jpg jpg 42953 506 338 IMAGE-DOWNSAMPLED 1-s2.0-S0169260713002800-gr3.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0169260713002800/gr3/DOWNSAMPLED/image/jpeg/6c22f78558f63bd02b6574d79a3bb169/gr3.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0169260713002800/gr3/DOWNSAMPLED/image/jpeg/6c22f78558f63bd02b6574d79a3bb169/gr3.jpg gr3 gr3.jpg jpg 70154 311 550 IMAGE-DOWNSAMPLED 1-s2.0-S0169260713002800-gr2.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0169260713002800/gr2/DOWNSAMPLED/image/jpeg/0d3ed6e38cdd3ed8c559e79adef93be2/gr2.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0169260713002800/gr2/DOWNSAMPLED/image/jpeg/0d3ed6e38cdd3ed8c559e79adef93be2/gr2.jpg gr2 gr2.jpg jpg 128779 950 592 IMAGE-DOWNSAMPLED 1-s2.0-S0169260713002800-gr1.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0169260713002800/gr1/DOWNSAMPLED/image/jpeg/b6ad44458da6c3963c17e505647458cd/gr1.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0169260713002800/gr1/DOWNSAMPLED/image/jpeg/b6ad44458da6c3963c17e505647458cd/gr1.jpg gr1 gr1.jpg jpg 10316 35 598 IMAGE-DOWNSAMPLED 1-s2.0-S0169260713002800-gr6.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0169260713002800/gr6/THUMBNAIL/image/gif/9dab3e5660533925727115a7fc2e4164/gr6.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0169260713002800/gr6/THUMBNAIL/image/gif/9dab3e5660533925727115a7fc2e4164/gr6.sml gr6 gr6.sml sml 8342 120 219 IMAGE-THUMBNAIL 1-s2.0-S0169260713002800-gr5.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0169260713002800/gr5/THUMBNAIL/image/gif/f1c44dbdbb62c09d02373a1a003e730b/gr5.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0169260713002800/gr5/THUMBNAIL/image/gif/f1c44dbdbb62c09d02373a1a003e730b/gr5.sml gr5 gr5.sml sml 7602 119 219 IMAGE-THUMBNAIL 1-s2.0-S0169260713002800-gr4.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0169260713002800/gr4/THUMBNAIL/image/gif/7a9733d41786e33e6109041670decff0/gr4.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0169260713002800/gr4/THUMBNAIL/image/gif/7a9733d41786e33e6109041670decff0/gr4.sml gr4 gr4.sml sml 4067 163 109 IMAGE-THUMBNAIL 1-s2.0-S0169260713002800-gr3.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0169260713002800/gr3/THUMBNAIL/image/gif/ada63d493851796321623e99efaf8075/gr3.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0169260713002800/gr3/THUMBNAIL/image/gif/ada63d493851796321623e99efaf8075/gr3.sml gr3 gr3.sml sml 8069 124 219 IMAGE-THUMBNAIL 1-s2.0-S0169260713002800-gr2.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0169260713002800/gr2/THUMBNAIL/image/gif/924013632ae6f8e0810a2074bf2f987f/gr2.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0169260713002800/gr2/THUMBNAIL/image/gif/924013632ae6f8e0810a2074bf2f987f/gr2.sml gr2 gr2.sml sml 4328 164 102 IMAGE-THUMBNAIL 1-s2.0-S0169260713002800-gr1.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0169260713002800/gr1/THUMBNAIL/image/gif/785c896d4b1c65d49c45c2991032566a/gr1.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0169260713002800/gr1/THUMBNAIL/image/gif/785c896d4b1c65d49c45c2991032566a/gr1.sml gr1 gr1.sml sml 676 13 219 IMAGE-THUMBNAIL COMM 3640 S0169-2607(13)00280-0 10.1016/j.cmpb.2013.08.004 Elsevier Ireland Ltd Fig. 1 Chromosome used for searching for best features on the original FOT parameters and SVM parameters. Fig. 2 Respiratory resistance curves (A) and box plot representation (B) as a function of frequency in normal volunteers. Reactance as a function of frequency (C) and box plot representation (D) in the normal group. Similar description for resistance (E), (F) and reactance (G), (H) in the smoking group. The top and the bottom of the box plot represent the 25th- to 75th-percentile values, while the circle represents the mean value and the bar across the box represents the 50th-percentile value. The whiskers outside the box represent the 5th- to 95th-percentile values. Fig. 3 ROC curves for the first experiment. BFP: Best FOT parameter (obtained without use of classifiers); LOGLC: logistic linear classifier; 1-NN: k nearest neighbor (k =1); ANN: artificial neural networks; SVM: support vectors machines. Fig. 4 Comparative analysis of the sensitivities obtained at specificities levels of 75% (A) and 90% (B). Fig. 5 ROC curves for the second experiment. Fig. 6 ROC curves for the third experiment. Table 1 Forced oscillation parameters of the studied groups. Control (n =28) Smokers (n =28) p-value R 0 (cmH2O/L/s) 2.40\u00b10.78 2.97\u00b10.75 0.003 R m (cmH2O/L/s) 2.45\u00b10.68 2.93\u00b10.62 0.009 S (cmH2O/L/s2) 5.42\u00b115.79 \u22124.18\u00b125.67 ns f r (Hz) 10.89\u00b11.72 14.06\u00b14.20 0.005 X m (cmH2O/L/s) 0.55\u00b10.27 0.24\u00b10.41 0.002 C dyn,rs (L/cmH2O) 0.021\u00b10.004 0.017\u00b10.005 0.002 Z rs4Hz (cmH2O/L/s) 3.13\u00b10.76 4.09\u00b11.07 0.0004 R 0: respiratory resistance extrapolated at 0Hz. R m: mean respiratory resistance. S: slope of the linear relationship of resistance versus frequency. f r: resonance frequency. X m: mean respiratory reactance. Crs,dyn: respiratory system dynamic compliance. Z rs4Hz: absolute value of respiratory impedance in 4Hz. ns: non-significant. Values are presented as mean\u00b1SD. Table 2 Results of the experiment 1. The 95% confidence interval is shown in parenthesis bellow each performance metric. The AUC standard error is also shown in parenthesis. Se (%) Sp (%) AUC BFP 70.2 (60.5\u201380) 77.4 (68.4\u201386.3) 0.77 (0.04) (0.69\u20130.84) LOGLC 71.4 (61.8\u201381.1) 70.2 (60.5\u201380.0) 0.78 (0.04) (0.71\u20130.85) 1-NN 77.4 (68.4\u201386.3) 84.5 (76.8\u201392.3) 0.89 (0.03) (0.83\u20130.94) ANN 77.4 (68.4\u201386.3) 73.8 (64.4\u201383.2) 0.79 (0.03) (0.72\u20130.86) SVM 77.4 (68.4\u201386.3) 86.9 (79.7\u201394.1) 0.87 (0.03) (0.81\u20130.92) BFP: best FOT parameter (obtained without use of classifiers). LOGLC: logistic linear classifier. 1-NN: k nearest neighbor (k =1). ANN: artificial neural networks. SVM: support vectors machines. Se: sensitivity; Sp: specificity. AUC: area under the ROC curve. Table 3 Comparison of AUCs\u2014experiment 1. LOGLC KNN ANN SVM BFP 0.015\u00b10.030 0.121\u00b10.039 ** 0.025\u00b10.045 0.103\u00b10.039 ** LOGLC \u2013 0.105\u00b10.037 ** 0.009\u00b10.039 0.087\u00b10.032 ** KNN \u2013 \u2013 \u22120.096\u00b10.035 ** \u22120.018\u00b10.028 ANN \u2013 \u2013 \u2013 0.078\u00b10.034 * BFP: best FOT parameter (obtained without the use of classifiers). LOGLC: logistic linear classifier. 1-NN: k nearest neighbor (k =1). ANN: artificial neural networks. SVM: support vectors machines. * p <0.05. ** p <0.01. Table 4 Results of the experiment 2. Se (%) Sp (%) AUC BFP 70.2 (60.5\u201380) 77.4 (68.4\u201386.3) 0.77(0.04) (0.69\u20130.84) LOGLC 71.4 (61.8\u201381.1) 72.6 (63.1\u201382.2) 0.79(0.03) (0.72\u20130.86) KNN 82.1 (74.0\u201390.3) 79.8 (71.2\u201388.4) 0.87(0.02) (0.82\u20130.93) ANN 72.6 (63.1\u201382.2) 76.2 (67.1\u201385.3) 0.82(0.03) (0.76\u20130.87) SVM 78.6 (69.8\u201387.3) 85.7 (78.2\u201393.2) 0.86(0.03) (0.81\u20130.92) Table 5 comparison of AUCs\u2014experiment 2. LOGLC KNN ANN SVM BFP 0.027\u00b10.027 0.107\u00b10.041 ** 0.043\u00b10.044 0.100\u00b10.040 * LOGLC \u2013 0.080\u00b10.038 * 0.016\u00b10.040 0.073\u00b10.034 * KNN \u2013 \u2013 \u22120.065\u00b10.034 \u22120.007\u00b10.026 ANN \u2013 \u2013 \u2013 0.057\u00b10.028 BFP: best FOT parameter (obtained without use of classifiers). LOGLC: logistic linear classifier. 1-NN: k nearest neighbor (k =1). ANN: artificial neural networks. SVM: support vectors machines. * p <0.05. ** p <0.01. Table 6 Results of the experiment 3. Se (%) Sp (%) AUC Z rs4Hz 70.2 (60.5\u221280) 77.4 (68.4\u221286.3) 0.77(0.04) (0.69\u22120.84) LOGLC 76.2 (67.7\u221285.3) 76.2 (67.1\u221285.3) 0.82(0.03) (0.76\u22120.88) KNN 84.5 (76.8\u221292.3) 85.7 (78.2\u221293.2) 0.91(0.02) (0.86\u22120.95) ANN 78.6 (69.8\u221287.3) 78.6 (69.8\u221287.3) 0.82(0.03) (0.75\u22120.88) SVM 85.7 (78.2\u201393.2) 84.3 (76.8\u221292.3) 0.91(0.02) (0.86\u22120.95) Table 7 Comparison of AUCs\u2014experiment 3. LOGLC KNN ANN SVM BFP 0.058\u00b10.033 0.143\u00b10.036 ** 0.054\u00b10.039 0.142\u00b10.037 ** LOGLC \u2013 0.085\u00b10.034 * 0.004\u00b10.033 0.084\u00b10.036 * KNN \u2013 \u2013 \u20130.089\u00b10.035 * 0.001\u00b10.0196 ANN \u2013 \u2013 \u2013 0.88\u00b10.038 * BFP: best FOT parameter (obtained without use of classifiers). LOGLC: logistic linear classifier. 1-NN: k nearest neighbor (k =1). ANN: artificial neural networks. SVM: support vectors machines. * p <0.05. ** p <0.01. Table 8 Genetic algorithm parameters. Parameter Value Population size 100 Number of generations 50 Crossover rate 0.80 Mutation rate 0.01 Fitness function AUC Table 9 Best parameters and selected features for experiment 1. Selected features Classifiers Parameter Value AUC (f r), (X m), (R 0), (S), (R m), (C rs,dyn), (Z rs4Hz) LOGLC None None 0.78 KNN Number of nearest neighbor 1 0.89 ANN Number of hidden nodes 9 0.79 SVM Regularization parameter(C) 2.38 0.87 Radius (r) 0.30 Table 10 Best parameters and selected features for experiment 2. Selected features Classifiers Parameter Value AUC (X m), (R 0), (S), (R m), (Z rs4Hz) LOGLC None None 0.79 (f r), (X m), (R 0), (R m), (Z rs4Hz) KNN Number of nearest neighbor 1 0.87 (f r), (X m), (R 0), (R m), (Z rs4Hz) ANN Number of hidden nodes 8 0.82 (f r), (X m), (R 0), (S),(R m), (Z rs4Hz) SVM Regularization parameter (C) 13.89 0.86 Radius (r) 0.24 Table 11 Best parameters and selected features for experiment 3. Selected features Classifiers Parameter Value AUC (f r \u00d7 R 0), (f r \u00d7 S), (f r \u00d7 R m), (f r \u00d7 C rs,dyn), (f r \u00d7 Z rs4Hz), (X m \u00d7 R m), (X m \u00d7 C rs,dyn), (R 0 \u00d7 R m), (R m \u00d7 Z rs4Hz), (C rs,dyn \u00d7 C rs,dyn) LOGLC None None 0.82 (f r \u00d7 f r), (f r \u00d7 X m), (f r \u00d7 R m), (f r \u00d7 C rs,dyn), (X m \u00d7 R 0), (X m \u00d7 R m), (R 0 \u00d7 C rs,dyn), (R m \u00d7 R m), (R m \u00d7 C rs,dyn), (C rs,dyn \u00d7 Z rs4Hz) KNN Number of nearest neighbor 1 0.91 (f r \u00d7 f r), (f r \u00d7 X m), (f r \u00d7 R m), (f r \u00d7 C rs,dyn), (X m \u00d7 R 0), (X m \u00d7 R m), (R 0 \u00d7 C rs,dyn), (R m \u00d7 R m), (R m \u00d7 C rs,dyn), (C rs,dyn \u00d7 Z rs4Hz) ANN Number of hidden nodes 2 0.82 (f r \u00d7 f r), (X m \u00d7 X m), (X m \u00d7 R 0), (X m \u00d7 R m), (X m \u00d7 Z rs4Hz), (R m \u00d7 R m), (R m \u00d7 C rs,dyn) SVM Regularization parameter (C) 3.07 0.91 Radius (r) 0.13 Table 12 Comparison of AUCs\u2014best results of all experiments. NN1 SVM1 NN2 NN3 SVM3 Z rs4Hz 0.121\u00b10.039 * 0.103\u00b10.039 * 0.107\u00b10.041 * 0.143\u00b10.036 ** 0.142\u00b10.037 ** NN1 \u2013 0.018\u00b10.028 0.014\u00b10.021 0.022\u00b10.022 0.020\u00b10.026 SVM1 \u2013 \u2013 0.004\u00b10.033 0.040\u00b10.031 0.039\u00b10.032 NN2 \u2013 \u2013 \u2013 0.0357\u00b10.020 0.035\u00b10.026 NN3 \u2013 \u2013 \u2013 \u2013 0.001\u00b10.020 BFP: best FOT parameter (obtained without use of classifiers). NN1: k nearest neighbor (k =1)\u2014experiment 1. SVM1: support vectors machines\u2014experiment 1. NN2: k nearest neighbor (k =1)\u2014experiment 2. NN3: k nearest neighbor (k =1)\u2014experiment 3. SVM3: support vectors machines\u2014experiment 3. * p <0.01. ** p <0.001. An improved method of early diagnosis of smoking-induced respiratory changes using machine learning algorithms Jorge L.M. Amaral a Agnaldo J. Lopes b Jos\u00e9 M. Jansen b Alvaro C.D. Faria c Pedro L. Melo c \u204e a Department of Electronics and Telecommunications Engineering, State University of Rio de Janeiro, Rio de Janeiro, Brazil Department of Electronics and Telecommunications Engineering, State University of Rio de Janeiro Rio de Janeiro Brazil b Pulmonary Function Laboratory, Pedro Ernesto University Hospital, State University of Rio de Janeiro, Rio de Janeiro, Brazil Pulmonary Function Laboratory, Pedro Ernesto University Hospital, State University of Rio de Janeiro Rio de Janeiro Brazil c Biomedical Instrumentation Laboratory, Institute of Biology Roberto Alcantara Gomes and Laboratory of Clinical and Experimental Research in Vascular Biology (BioVasc) State University of Rio de Janeiro, Rio de Janeiro, Brazil Biomedical Instrumentation Laboratory, Institute of Biology Roberto Alcantara Gomes and Laboratory of Clinical and Experimental Research in Vascular Biology (BioVasc) State University of Rio de Janeiro Rio de Janeiro Brazil \u204e Corresponding author. Tel.: +55 21 23340705. The purpose of this study was to develop an automatic classifier to increase the accuracy of the forced oscillation technique (FOT) for diagnosing early respiratory abnormalities in smoking patients. The data consisted of FOT parameters obtained from 56 volunteers, 28 healthy and 28 smokers with low tobacco consumption. Many supervised learning techniques were investigated, including logistic linear classifiers, k nearest neighbor (KNN), neural networks and support vector machines (SVM). To evaluate performance, the ROC curve of the most accurate parameter was established as baseline. To determine the best input features and classifier parameters, we used genetic algorithms and a 10-fold cross-validation using the average area under the ROC curve (AUC). In the first experiment, the original FOT parameters were used as input. We observed a significant improvement in accuracy (KNN=0.89 and SVM=0.87) compared with the baseline (0.77). The second experiment performed a feature selection on the original FOT parameters. This selection did not cause any significant improvement in accuracy, but it was useful in identifying more adequate FOT parameters. In the third experiment, we performed a feature selection on the cross products of the FOT parameters. This selection resulted in a further increase in AUC (KNN=SVM=0.91), which allows for high diagnostic accuracy. In conclusion, machine learning classifiers can help identify early smoking-induced respiratory alterations. The use of FOT cross products and the search for the best features and classifier parameters can markedly improve the performance of machine learning classifiers. Keywords Clinical decision support Early diagnosis Artificial intelligence Forced oscillation technique Smoking Chronic obstructive pulmonary disease 1 Introduction Mortality caused by smoking is one of the few chronic diseases where further increases in prevalence are predicted in the coming decades. According to World Health Organization estimates, tobacco-attributable deaths will rise from 5.4 million in 2005 to 6.4 million in 2015 and 8.3 million in 2030. The number of projected deaths for 2030 ranges from 7.4 to 9.7 million [1]. One of the main causes of this adverse scenario is that the diagnosis of smoking-induced respiratory changes is usually made only in late stages, when respiratory function is already impaired. There is general agreement in the literature that it is necessary to develop new accurate and non-invasive tests of lung function [2\u20134]. In the case of smoking, the National Heart Lung and Blood Institute recently recommended that research into new technologies to improve non-invasive testing of lung function in this disease should be a priority [5]. The experimental method used to implement system identification in the analysis of respiratory mechanics constitutes what is termed the forced oscillation technique (FOT). The FOT is based on the application of a pressure signal during spontaneous breathing, and the resulting pressure and flow changes are analysed to calculate respiratory impedance [6\u201310]. This method is currently the state-of-the-art for the assessment of lung function [7] and has been used for research purposes for many years [3,6\u20139]. The method is simple and requires only passive cooperation, with no forced expiratory manoeuvres. Despite the obvious advantages of the FOT in terms of its non-invasiveness and lack of dependence on patient cooperation, the FOT has not become a standard methodology for the routine assessment of lung function. In the context of a diagnostic framework, although obtaining respiratory impedance values is easy, the interpretation of resistance and reactance curves and the derived parameters measured by the FOT requires training and experience, and it is a difficult task for the untrained pulmonologist. In recent years, strong evidence has emerged regarding the convenience of FOT measurements in several contexts [6\u20138]. The efficacy of many FOT measurements has been demonstrated in terms of the achievement of various clinical goals [6\u20138]. In particular, recent studies from our group provided evidence that measurements of respiratory impedance using the FOT may contribute in the diagnosis of chronic obstructive pulmonary disease (COPD) [11\u201315]. COPD is a disease associated with an abnormal inflammatory response of the lungs to noxious particles or gases, particularly cigarette smoke, the primary risk factor for COPD [16]. To simplify the diagnostic use of the FOT, our group recently developed clinical decision support systems based on machine learning (ML) algorithms that were able to help diagnose COPD using FOT measurements [17,18]. In addition to the development of an automatic classifier, the use of ML algorithms also contributed to improve the diagnostic accuracy of COPD [18]. However, these studies were limited to the diagnosis of late stages of COPD, when medical and social costs are already high [16]. Previous studies have shown that the FOT may contribute to the detection of early respiratory changes due to smoking [11]. These initial studies, however, presented limited diagnostic accuracy and did not include the development of dedicated clinical decision support systems. Based on these promising results and limitations, we hypothesized that the use of ML algorithms associated with FOT measurements would help in the early detection of the effects of smoking on the respiratory system. Such a system would detect early smoking-induced respiratory changes while these pathologic changes are still potentially reversible, which is of utmost importance in the prevention of COPD [16]. There has been no research dedicated to this problem to date. The aims of this study were (1) to evaluate the performance of several ML algorithms to develop an automatic classifier to help diagnose early smoking-induced respiratory changes using forced oscillation measurements; (2) to increase the accuracy of the FOT in detecting early respiratory abnormalities in smoking patients; and (3) to identify the best configuration for the diagnosis of respiratory changes in smoking patients. The remainder of this article is organized as follows. The healthy and smoking patient groups we examined are characterized in Section 2, along with a description of the measurement protocol. This section also presents the evaluated classifiers and describes the methods used for performance evaluation, classifier comparison, feature selection and experimental design. Section 3 presents the results, and Section 4 discusses the results with respect to the search for the best classifier and parameters for detecting early respiratory abnormalities. Finally, Section 5 summarizes the main outcomes of this investigation and proposes future steps in this research topic. 2 Methods 2.1 Data sets We utilized a group of FOT measurements that differed slightly from a previous study regarding the diagnosis of early smoking abnormalities [11]. This study included healthy control subjects with normal spirometry [19] who had never smoked, as well as smoking subjects without COPD [16] and history of asthma [20], who had no cardiovascular, gastrointestinal, renal or neurological symptoms. This group of measurements allowed us to identify the best baseline parameter for accuracy comparisons and evaluate the effects of optimized classifiers in diagnostic accuracy. In the present work, we performed experiments with two data sets. The first dataset consisted of 7 possible input features (FOT parameters) from 168 measurements acquired from 56 volunteers. We found no differences between the biometrical characteristics of healthy individuals and smokers (healthy, n =28, age: 33.1\u00b18.2, weight: 66.1\u00b111.8kg, height: 167.4\u00b18.2cm; smokers, n =28, age: 35.1\u00b19.7 years, weight: 66.1\u00b110.7kg, height: 166.9\u00b17.9cm) [11]. The second data set consisted of 28 input features representing the cross products of the original FOT parameters of the same 168 measurements. 2.2 Forced oscillation measurements and parameters The system used for respiratory impedance analysis was developed in our laboratory and described in detail previously [21]. Measurements were conducted in conformity with the recommendations issued by a task force of the European Respiratory Society [6]. Briefly, the instrument allowed evaluation of total respiratory input impedance (Z rs), which was estimated from signals coming from a pressure transducer (P) and pneumotachograph (V\u2032) placed close to the individual's mouth (Z rs = P/V\u2032). The oscillations applied to the respiratory system were produced by a loudspeaker and directed to the individual's mouth while the individual breathes voluntarily. The forced pseudorandom noise used in this study was composed of 16 harmonics (4\u201332Hz) of the fundamental (2Hz). The peak-to-peak amplitude of this excitation signal was 2cmH2O. During the measurements, the subjects used a nose clip and supported their cheeks and sub-mandible tissues with their hands to reduce the shunt effect [6,7]. Pressure and flow signals were sampled at 1024Hz for 16s. A fast Fourier transform algorithm was applied to adjacent and interpolated 4s data blocks. Impedance data corresponding to coherence values higher than 0.9 were retained for analysis and calculated by averaging three 16s manoeuvres. Linear regression analysis was performed for the real part of the impedance from 4 to 16Hz, which extrapolated the respiratory resistance at 0Hz (R 0) and the slope (S) of the linear relationship of resistance versus frequency. These parameters are related to the total resistance and homogeneity of the respiratory system, respectively [12,22,23]. Mean resistance (R m), primarily sensitive to airway calibre [9], was also calculated. The imaginary part of the impedance was characterized by the mean reactance (X m) and the resonance frequency (f r), which are associated with ventilation homogeneity [24]. The respiratory system dynamic compliance (C rs,dyn) and the absolute value of respiratory impedance in 4Hz (Z rs4Hz) were also evaluated. Z rs4Hz represents the total mechanical load of the respiratory system [6,9], and it is associated with the work required to move air in the respiratory system. 2.3 The studied classifiers In this particular study, the following classification algorithms were evaluated: \u2022 Logistic linear classifier [25,26] \u2022 k nearest neighbor [25] \u2022 Neural networks [27] \u2022 Support vectors machines [28] These algorithms were chosen because they represent a broad variety of classifier algorithms from Lippmann's list of types of classifiers [25]. These algorithms will be briefly described. A complete description of the algorithms can be found in the references. The logistic linear classifier is obtained by logistic regression. The classifier is a member of the family of methods called generalized linear models (\u201cGLM\u201d) [29]. Such models include a linear portion followed by a link function. The linear function of the predictor variables is calculated, and the result of this calculation is passed through the link function. For logistic regression, the linear result is run through a logistic (sigmoid) function. The parameters of the linear function can be determined by maximising the likelihood criterion using a logistic (sigmoid) function. Although it is structurally simple, logistic regression is used extensively in numerous disciplines, including the medical and social science fields. Logistic regression is quick to fit, and the discovered model is easy to implement and quick to recall. It frequently achieves better performance than competing, more complex techniques. The k nearest neighbor (KNN) algorithm is one of the simplest and most elegant classification methods in pattern recognition [25]. KNN is a type of instance-based learning, or lazy learning, which means that in the learning stage, it simply stores a set of labelled instances (training set). When a new query has to be classified, the algorithm finds k numbers of training instances closest to the query point, using a similarity function usually based on Euclidean distance. The classification is performed using majority vote among the classification of the k objects. If k =1, then the object is simply assigned to the class of its nearest neighbor. An artificial neural network (ANN) is a massive parallel system [27] composed of many neurons (simple processing elements) with a function that is determined by the network architecture, synaptic weights (connection strengths) and the processing performed at the neurons. Neural networks are capable of acquiring knowledge through a learning process and storing it in the synaptic weights. One of the most successful neural network architectures is the multilayer perceptron (MLP). MLP has been successfully applied to a variety of pattern recognition problems in industry, business, science [30] and medical diagnosis [30,31]. One of the most important features of a neural network is the ability to generalize what it has learned from the training procedure. This feature allows the network to address noise in the input data and provide correct outputs to new data patterns, i.e., data that were not used to train the network. Support vector machines (SVM) are learning systems based on statistical learning theory [28] and have been successfully used in a variety of classification and regression problems. For a two-class classification problem, the basic form SVM is a linear classifier that performs classification by constructing a hyperplane that optimally separates the classes. The optimal hyperplane is the one that provides the maximal margin. (The margin is defined as the distance from a training sample and the hyperplane). It can be proven that this particular solution has the highest generalization ability. This formulation can be generalized by applying a non-linear mapping of the training set. The data are transformed into a new feature high-dimensional space where the classes are more easily separable and an optimal hyperplane can be found. The radial basis function Kernel is frequently used to accomplish this non-linear mapping and is frequently the first non-linear mapping to consider. Although the decision surface (hyperplane) is linear in the high dimensional space, when it is observed in the original low-dimensional feature space, it is no longer linear, indicating that SVM can also be applied to data that is not linearly separable [32]. 2.4 Performance evaluation The main goal of performance evaluation is to choose the best classifier model and estimate its performance on future examples (termed \u201cgeneralization\u201d) [33,34]. To obtain a performance evaluation, one first has to choose the performance function based on the specific domain of the application. Some of the more commonly used measures are accuracy, sensitivity, specificity, true positive rate, false positive rate, recall, precision and the area under the receiver operating characteristic (ROC) curve (AUC) [35]. In this work, we chose sensitivity (Se), specificity (Sp) and area under the curve (AUC) for the ROC curves because they are often used in medical diagnosis and allow comparison of our results to other recent studies performed by our group [11,13]. After choosing the performance function, one has to define the evaluation structure to estimate performance of the learned model from available data. We want to estimate the performance of an algorithm in unobserved examples to determine the generalization capability of the algorithm. This performance evaluation can be conducted using either hold-out or k-fold cross-validation procedures [33]. We did not use hold-out because it is necessary to split the available datasets into training and test datasets. Hold-out is trained with a training data set, and the performance of the trained classifier is evaluated in the test data set to estimate the generalization accuracy. A drawback with hold-out is that different hold-out sets (different splits) result in different results. Additionally, depending on the size of available data, one can underestimate of the generalization capability [36]. We chose to use k-fold cross validation because it allows a better use of the available dataset. The dataset is partitioned into k equal (or approximately equal) data subsets or folds [37]. For each fold in turn, use that folder for testing and the remaining k \u22121 folders are used for training a classifier. The performance of each learning algorithm on each fold can be tracked. Upon completion, k samples of the performance metric are available and different methodologies, such as averaging, can be used to obtain an aggregate measure of classification accuracy from these samples. It is also possible to use these samples in a statistical hypothesis test to compare two or more machine learning algorithms. The hypothesis test is another key element when one would like to compare two or more machine learning algorithms. In the hypothesis test, we want to test if there is no difference in the performance of two classifiers (null hypothesis) under a certain confidence level (usually 95%). For comparing within one data set, one can use Student's t-test (t-test) or one of its variations [33]. Dietrich [34] notes that the use of a t-test has a risk of Type I errors, i.e., determining a difference where none exists, and suggests the use of 5\u00d72 cross-validation or McNemar's test. For multiple data sets from different domains, Demsar [38] recommends Wilcoxon's signed ranks test, Friedman tests and post hoc tests. The hypothesis test used McNemar's test, following the recommendations of Dietrich [34], and Wilcoxon's signed ranks test on the AUCs of the test folds, as suggested by Demsar [38]. 2.5 Feature selection As a part of the design process of the classifier system, it is customary to perform an input feature selection step. The purpose of this step is to obtain the smallest set of relevant and informative features that can yield satisfactory performance [39]. Other motivations to perform feature selection are related to general data reduction to reduce storage space, increase algorithm speed, gain knowledge on the process that generates the data and allow data visualization (2D or 3D) [39]. Feature selection is also important when one is dealing with a large number of inputs. This case requires estimating a large number of model parameters, which can be difficult in datasets of limited size [31]. We can essentially divide feature selection methods into three groups: filters, wrappers and embedded methods [39]. Filter methods provide a ranked order of the features using a relevant index, such as correlation coefficients or classical statistical tests. Wrappers normally apply an efficient search strategy to find the best features based on the machine learning algorithm performance, such as the classification accuracy. Embedded methods perform feature selection in the process of training and are usually specific to some given learning machines, such as decision trees [39]. We determined the best features for classification using a wrapper strategy. The applied search strategy looked for the feature set that maximized the area under the ROC curve (AUC). The AUC was used as a performance metric because it is often used in medical diagnosis [40\u201343] and provides a better metric than accuracy to compare classifiers [44\u201346]. The AUC allows the use of the probability estimations or \u201cconfidence\u201d of the class prediction provided by the classifiers. This information is completely lost when one uses accuracy, because it does not consider the probability of the prediction; as long as the class with the largest probability estimation is the same as the target, it is regarded as correct [46]. Bradley [44] has compare popular machine learning algorithms using AUC and found it presents some desired properties such as: better sensitivity in ANOVA tests, it is independent of the decision threshold and it invariant to a priori class probability distributions. Huang and Ling [46] have established a formal criteria for comparing two different measures for learning algorithms and they have shown theoretically and empirically that AUCs, in general, are much better measure than the accuracy. Two different search strategies were used as a result of using two different input sets. For the input of the original FOT parameters, we applied an exhaustive search instead of using suboptimal search strategies, such as forward and backward [47], because the number of parameters was small. When the input set was the cross products of the FOT parameters, the search was conducted using genetic algorithms [48,49]. Genetic algorithms provide an adaptive searching mechanism inspired by Darwin's principle of reproduction and survival of the fittest. The individuals (solutions) in a population are represented by chromosomes, and each individual is associated with a fitness value (problem evaluation). The chromosomes are subjected to an evolutionary process that takes several cycles (generations). The basic operations are selection, reproduction, crossover and mutation. Parent selection yields a higher probability of reproduction to the fittest individuals. During crossover some reproduced individuals cross and exchange their genetic characteristics. Mutations may occur in a small percentage and cause a random variation in the genetic material, thus contributing to introduce variety in the population. The evolutionary process guides the genetic algorithm through more promising regions in the search space. Some of the advantages of using genetic algorithms are that it is a global search technique, it can be applied to optimize ill-structured problems, and it does not require a precise mathematical formulation for the problem. Genetic algorithms are robust, applicable to many problems and efficient in that either a sub-optimal or optimal solution may be found within reasonable time and computational effort. 2.6 Design of the experiments We conducted our study with three experiments. In the first experiment, we did not perform any feature selection. We used the dataset of the original FOT parameters. The four classifiers (LOGLC, KNN, ANN and SVM) were implemented with a pattern recognition toolbox (prtools) for Matlab [50]. The LOGLC did not have parameters. In the KNN, k was set 1, so we have the one nearest neighbor classifier (1-NN). In the ANN classifier, the parameter to be search is the number of neurons in the hidden layer. The SVM with a radial basis function kernel had two parameters, the regularization parameter C and the standard deviation of the radial basis function r. The search for the best parameters was performed with a 10-fold cross-validation using the average area under the ROC curve (AUC) in the test folds as a performance index. The strategy used to avoid over-fitting is based on the use of the cross-validation, the choice of classifier complexity and in the training procedures. The logistic linear classifier is a simple linear model, so it is less prone to over-fitting. The artificial neural network is trained with early stopping which a standard training procedure to improve the generalization and thus to avoid over-fitting [27]. In this method, the training procedure is stopped when the performance on validation set (which is different from the training and the test sets) does not improve anymore. In this work, the validation set is an artificially generated set of 1000 samples per class, based on k-nearest neighbor interpolation on the training set. The support vector machine (SVM) training procedure uses regularization. This technique helps to prevent over-fitting by penalizing model complexity. In the SVM, the parameter C controls the amount of regularization. If C is small, then there is a small penalty to increase the margin, hence improving the generalization, at the cost of a few misclassified training points. If C is big, the penalty to increase the margin is higher, so there will be less increase in the generalization. So, in order to maintain a good generalization capability, the search for the appropriate value of C is restricted to a small interval. The k nearest neighbor classifier, with the number of neighbors set to be equal 1, does not have any mechanism in the training procedure to avoid over-fitting. In this case and also for all other classifiers, the use of the k-fold-cross-validation will help to provide an estimate of the generalization error (or other performance measure), which is obtained by averaging the performance measure in the k test folds. It means that the reported result is the average performance of k classifiers trained and tested with k different partitions of the available dataset. This procedure helps to mitigate the over-fitting because it prevents the report of optimistic result obtained from a specific division of the dataset in train and test sets. The ROC curve for Z rs4Hz was used to compare the performance of the classifiers because in a previous study [11], it was considered the best FOT parameter for detecting the early effects of smoking. In the second experiment, we performed a search for a smaller set of the original FOT that would result in better performance. This feature selection in the dataset of original FOT parameters was performed using the wrapper strategy. We searched for the set of input features that would maximize the average AUC. For the LOGLC and 1-NN classifiers, we performed an exhaustive search. For the ANN, we did not perform the feature selection through a search because it takes a long time to build a classifier due to the training procedures. Instead, we used the features selected by others classifiers and only performed the search for the best number of hidden neurons. For the SVM classifier, the search was conducted using genetic algorithms (GA). The use of GA for model and feature selection has been successfully reported in several applications [51\u201356]. In our application, the pursuit for the best parameters (C, r) was conducted together with feature selection. The success of searches using genetic algorithms depends on how the solution is coded in the chromosome and on the fitness function chosen for evaluation of the solution [49]. Because the purpose of the search was to find the best features and parameters for the classifier, the chromosome was divided into two parts: features and parameters. In the former part, each gene indicated if one should use a particular feature or not. If the gene value was equal to 1, the particular feature should be selected; if the gene value was 0, the feature was not selected. The latter chromosome part represented the values of the classifier parameters. Fig. 1 depicts an example of a chromosome for searching for the best features and SVM parameters. Each of the first seven genes represents one of the original FOT parameters. The last two represent the regularization parameter (C) and the standard deviation of the radial basis function (r). The fitness function calculated the average AUC in the test folds of a 10-fold cross-validation. In the third experiment, we performed a search for a smaller set of the cross products of original FOT parameters that would result in better performance. The second dataset, which consisted of 28 input features representing the cross products of the original FOT parameters, was used. In this case, an exhaustive search would be too costly because we would have to perform the 10-fold cross-validation for the (228 \u22122) possible feature input sets. Therefore, in this experiment, the searches for the best features and classifier parameters were performed using Genetic Algorithms. In the three experiments, the comparisons between classifiers were made using McNemar's and Wilcoxon's tests implemented in Matlab 7.4.0 using the Statistics Toolbox 6.0. In addition, the AUCs obtained during the experiments were compared using MedCalc 8.2 (Medicalc Software, Mariakerke, Belgium) with the methodology suggested in Delong et al. [57]. 3 Results 3.1 Forced oscillation parameters Fig. 2 shows the respiratory resistance and reactance as a function of frequency in normal and smoking groups. The smoking patients presented highly significant increases in R 0, R m and f r (p =0.003, p =0.009 and p =0.005, respectively, Table 1 ). S did not show any significant changes, whereas significant decreases were observed in X m (p =0.002) and C rs,dyn (p =0.002). Z rs4Hz was higher in smokers (p =0.0004). 3.2 Performance of the studied classifiers 3.2.1 Experiment 1\u2014The use of original FOT parameters without feature selection Fig. 3 depicts a ROC curve for the best FOT parameter (BFP) and the average ROC curve for each studied classifier. Table 2 shows the sensitivity (Se), specificity (Sp) and area under the curve (AUC) for the ROC curves in Fig. 3. In this table, the optimal Se and Sp points were chosen to balance the highest values of these parameters. Table 3 shows comparisons among the AUCs (difference between AUCs) obtained with the BFP and each studied classifier. For an additional analysis of the ROC, Fig. 4A resumes the Se observed at Sp of 75% (representing a moderate specificity). The 90% specificity level was also described (Fig. 4B) because it theoretically forces the cases presumed to be the most difficult into the disease group by allowing only 10% false positives [38]. McNemar's test, when applied to all pairs of classifiers, indicated that there was a statistically significant difference between LOGLC and 1-NN and LOGLC and SVM. Wilcoxon's test showed statistically significant differences between LOGLC and 1-NN and LOGLC and SVM. We also observed differences between 1-NN and ANN. 3.2.2 Experiment 2\u2014Feature selection on original FOT parameters Fig. 5 depicts the reference ROC curve for the BFP and the average ROC curve for each classifier, and Table 4 describes the associated parameters. Table 5 shows comparisons among the AUCs. Fig. 4 resumes the sensitivities at 75% and 90% specificity for Z rs4Hz, LOGLC, 1-NN, ANN and SVM. McNemar's test revealed a statistically significant difference between LOGLC and 1-NN. The Wilcoxon's test showed difference between LOGLC and 1-NN, LOGLC and SVM. 3.2.3 Experiment 3\u2014Feature selection on cross products of FOT parameters Fig. 6 depicts the baseline ROC curve for the BFP and the average ROC curve for each studied classifier. Table 6 shows the derived parameters, while Table 7 shows comparisons among the AUCs obtained in this experiment. Sensitivities at 75% and 90% specificity for the BFP, LOGLC, 1-NN, ANN and SVM are described in Fig. 4. McNemar's test applied to all pairs of classifiers indicated that there was a statistically significant difference between LOGLC and 1-NN and LOGLC and SVM. Wilcoxon's test showed differences between ANN and SVM and ANN and 1-NN. 3.3 Pursuit for the best features and classifier parameters Table 8 shows the parameters applied in the genetic algorithm to search for the optimal features and parameters. Tables 9\u201311 show the best parameters, the selected features for each classifier and their respective AUCs. Table 12 describes the comparisons of the AUCs obtained with the best results in all of the performed experiments. 4 Discussion Because of the high social and medical costs associated with smoking-induced diseases, early identification and treatment of these patients is important to avoid severe and expensive stages of these diseases [2]. A recent consensus recommended that all smokers, including those who may be at risk for or already have COPD, should be offered the most intensive smoking cessation intervention feasible [16]. This consensus also recommended that patients should be identified as early in the course of the disease as possible, contributing to prevent smoking uptake and maximize cessation [16]. In this study, we designed and evaluated several ML algorithms to develop an automatic classifier to help diagnose early smoking-induced respiratory changes using forced oscillation measurements. We have demonstrated for the first time that such a clinical decision support system may increase the accuracy of the FOT in detecting these early respiratory abnormalities. Notably, the use of feature selection and cross products together with 1-NN and SVM classifiers allowed us to obtain an accurate clinical diagnosis while the smoking-induced pathologic changes are still potentially reversible. The clinical decision support system was developed using a group of smokers with a mean tobacco consumption of 11.2\u00b17.3 pack-years, characterising a sample of smokers with early respiratory changes but only small and non-significant reductions in their spirometric parameters [11]. Their smoking habits resulted in changes in oscillatory mechanics that were consistent with the involved pathophysiology [16]. In accordance with previous results [11\u201313,15,17,18], we observed a significant increase in resistive parameters and a reduction in reactive parameters (Table 1). The first experiment showed that all designed classifiers present better performance than the BFP used as baseline (AUC=0.77) (Figs. 3 and 4, Tables 2 and 3). Considering the comparisons of the sensitivities at 75% and 90% specificity (Fig. 4), it is worth mention that the sensitivities of 1-NN and SVM were higher than that obtained by the BFP. Table 2 shows that 1-NN demonstrated higher AUC (0.89), followed by SVM (0.87). According to the literature, ROC curves with AUCs between 0.50 and 0.70 indicate low diagnostic accuracy, AUCs between 0.70 and 0.90 indicate moderate accuracy, and AUCs between 0.90 and 1.00 indicate high accuracy [58]. Our results indicate that both 1-NN and SVM present AUCs close to the high accuracy range. Table 3 shows statistical differences in the ROC curves of the BFP and the classifiers 1-NN and SVM. It is worth to mention that these statistical differences were in agreement with the McNemar's test and Wilcoxon's test. Compared with the first experiment, the feature selection performed in the second experiment (Figs. 4 and 5, Tables 4 and 5) did not show any significant improvement in the AUC. Regarding the sensitivities, we observed an improvement in only the sensitivity for ANN (Fig. 4A). At 90% specificity, we observed an increase of sensitivity only for SVM (Fig. 4B). Although the feature selection did not help increase the overall performance, it helped identify the most useful FOT parameters. One may argue, in spite of the arguments presented in Section 2.5 to support the use of AUC in the feature selection, another performance measure would have better results. In order to verify this claim, a comparison of the results in the feature selection using AUC and accuracy was made in the experiment 2 for the KNN classifier (k =1). The experiment 2 was chosen, because an exhaustive search is performed, so the difference in the performance could not be caused by the search procedure or due to the choice of classifier parameters (the only parameter k was set to be equal 1). Using AUC for feature selection, the selected FOT parameters were: f r, X m, R 0, R m, Z rs4Hz Using Accuracy for feature selection, the selected FOT parameters were: f r, R 0, R m, C rs,dyn, Z rs4Hz The procedures have chosen a large number of common FOT parameters (f r, R 0, R m, Z rs4Hz) and in both cases the AUC=0.87 and no significant statistical differences were found. Therefore, at least for this experiment, there is no evidence that AUC is a worse choice than accuracy to select features. Table 5 indicates statistical differences in the ROC curves of the BFP and the classifiers 1-NN and SVM, which provide additional support to the results observed in the McNemar's test and Wilcoxon's test. In the third experiment, the feature selection performed on the cross products of the FOT parameters improved the accuracy of all classifiers (Figs. 4 and 6, Tables 6 and 7). In addition, this experiment also helped identify the most useful pairs of FOT parameters. The AUCs for 1-NN and SVM (0.91) were in the high accuracy diagnostic range [58]. In this experiment, all of the studied classifiers presented higher sensitivity values than the BFP (Fig. 4A). At 75% specificity, representing moderate specificity, 1-NN and SVM presented much higher sensitivities (88% and 92%) than the BFP (70%) (Fig. 4B). Once again, there are statistical differences in the ROC curves of the BFP and the classifiers 1-NN and SVM (Table 7), and also an endorsement of the statistical differences found in the McNemar's test and Wilcoxon's test. Tables 9\u201311 show the selected features for each of the studied classifiers. In a recent study [11], Z rs4Hz was the best parameter for detecting early effects of smoking, followed by R 0 and C rs,dyn. The parameters f r and X m were also considered useful. This finding is consistent with the results found in experiments 2 and 3. In experiment 2 (Table 10), the feature selection for 1-NN chose four (Z rs4Hz, R 0, f r, and X m) of the five cited parameters. The feature selection for SVM also chose four (Z rs4Hz, R 0, f r, and X m) of these five parameters. In the third experiment (Table 11), the selected cross products were also consistent with the results identified in [11]. For the LOGLC, all the selected products had at least one of the most useful values. For 1-NN, this situation occurred in nine of ten selected products, and for the SVM, it occurred in six of seven selected products. Table 12 compares the best results of each experiment with the baseline provided by the best FOT parameter (Z rs4Hz). In all experiments, the best classifiers presented better results than the best FOT parameter. There were not statistical differences between the best classifiers. However, it is worth to mention that the last experiment presented the best p-value (p <0.001) in comparison with the BFP. The FOT has a long history in the investigation of smoking-induced respiratory diseases [15]. Although its present use is predominantly in the research domain, the FOT will likely soon enter routine clinical use. One of the main factors that limit its clinical use is that the interpretation of the derived parameters measured by the FOT requires training and experience. By contrast, as noted recently by the GOLD consensus [16], diagnostic simplicity is a key feature for the busy non-specialist clinician. The present work provides evidence that ML algorithms may simplify the use of FOT. Therefore, ML algorithms associated with FOT measurements could be a simple tool in screening early respiratory changes induced by smoking. If this hypothesis is confirmed in a wider number of subjects, this approach may offer the ability to show abnormalities in a phase in which pathological changes are still potentially reversible, helping to prevent the development of COPD. 5 Conclusions We designed and evaluated several classifier systems to develop a clinical decision support system to assist the diagnosis of early respiratory abnormalities in smoking patients. The use of the cross products of the FOT indexes and the search for best features and classifier parameters introduced a significant improvement in the diagnostic accuracy. 1-NN and SVM classifiers were the most robust classifiers, reaching values that allow accurate clinical diagnosis, identifying early respiratory changes with approximately 85% sensitivity and specificity. In addition, the developed system may also be helpful for simplifying the use of the FOT in the routine assessment of lung function. 6 Future plans Future plans include (1) to add to the classification system the ability of identifying the level of airflow obstruction in COPD (mild, moderate, severe or very severe); (2) to contribute to the diagnosis of airway obstruction in asthma; and (3) to improve the understanding and management of COPD and its exacerbations by integrating ML algorithms and home monitoring using FOT and telemedicine services. References [1] C.D. Mathers D. Loncar Projections of global mortality and burden of disease from 2002 to 2030 PLoS Med. 3 11 2006 e442 [2] P.L. Enright R.M. Crapo Controversies in the use of spirometry for early recognition and diagnosis of chronic obstructive pulmonary disease in cigarette smokers Clin. Chest Med. 1 4 2000 645 652 [3] A.D. Kaminsky C.G. Irvin New insights from lung function Curr. Opin. Allergy Clin. Immunol. 1 2001 205 209 [4] M.I. Polkey R. Farr\u00e9 A.T. Dinh-Xuan Respiratory monitoring: revisiting classical physiological principles with new tools Eur. Respir. J. 24 2004 718 719 [5] T.L. Croxton G.G. Weinmann R.M. Senior J.R. Hoidal Future research directions in chronic obstructive pulmonary disease Am. J. Respir. Crit. Care Med. 165 2002 838 844 [6] E. Oostveen D. MacLeod H. Lorino R. Farr\u00e9 Z. Hantos K. Desager F. Marchal The forced oscillation technique in clinical practice: methodology, recommendations and future developments Eur. Respir. J. 22 2003 1026 1041 [7] J.H.T. Bates C.G. Irvin R. Farr\u00e9 Z. Hantos Oscillation mechanics of the respiratory system Compre. Physiol. 1 2011 1233 1272 [8] D.W. Kaczka R.L. Dellac\u00e1 Oscillation mechanics of the respiratory system: applications to lung disease Crit. Rev. Biomed. Eng. 39 4 2011 337 359 [9] D. Macleod M. Birch Respiratory input impedance measurements: forced oscillation methods Med. Biol. Eng. Comput. 39 2001 505 516 [10] D. Navajas R. Farr\u00e9 Forced oscillation technique: from theory to clinical applications Monaldi Arch. Chest Dis. 6 6 2001 555 562 [11] A.C.D. Faria A.J. Lopes J.M. Jansen P.L. Lopes Evaluating the forced oscillation technique in the detection of early smoking-induced respiratory changes Bio. Med. Eng. Online 8 2009 22 [12] A.M.G.T. Di Mango A.J. Lopes J.M. Jansen P.L. Melo Changes in respiratory mechanics with increasing degrees of airway obstruction in COPD: detection by the forced oscillation technique Respir. Med. 100 3 2006 399 410 [13] A.C.D. Faria A.A. Costa A.J. Lopes J.M. Jansen P.L. Melo Forced oscillation technique in the detection of smoking-induced respiratory alterations: diagnostic accuracy and comparison with spirometry Clinics 65 12 2010 1295 1304 [14] K.K.D. Silva A.J. Lopes J.M. Jansen P.L. Melo Within total inspiratory and expiratory impedance in patients with severe chronic obstructive pulmonary disease Clinics 66 12 2011 2085 2091 [15] A.C.D. Faria K.K. Dames da Silva G.M. Costa A.J. Lopes P.L. Melo Forced oscillation technique in the detection of smoking-induced respiratory changes R. Hudak M. Penhaker J. Majernik Biomedical Engineering\u2014Technical Applications in Medicine 2012 InTech Croatia Chapter 13 [16] GOLD\u2014Global initiative for chronic obstructive lung disease, Global Strategy for the Diagnosis, Management and Prevention of Chronic Obstructive Pulmonary Disease In: www.goldcopd.org, Available from: \u3008http://www.goldcopd.org/uploads/users/files/GOLD_Report_2011_Feb21.pdf\u3009, 2001. [17] J.L.M. Amaral, A.C.D. Faria, A.J. Lopes, J.M. Jansen, P.L. Melo, Automatic identification of chronic obstructive pulmonary disease based on forced oscillation measurements and artificial neural networks, in: 32nd Annual International Conference of the IEEE Engineering in Medicine and Biology Society, Buenos Aires, Argentina, 2010. [18] J.L.M Amaral A.C.D. Faria A.J. Lopes J.M. Jansen P.L. Melo Machine learning algorithms and forced oscillation measurements applied to the automatic identification of chronic obstructive pulmonary disease Comput. Methods Programs Biomed. 105 3 2012 183 193 [19] American Thoracic Society/European Respiratory Society Task force: standardization of lung function testing Eur. Respir. J. 26 2005 319 338 [20] WHO\u2014World Health Organization: GINA\u2013Global Initiative for Asthma. 2006. Available from: \u3008http://www.ginasthma.org\u3009. [21] P.L. Melo M.M. Werneck A. Giannella-Neto A new impedance spectrometer for scientific and clinical studies of the respiratory system Rev. Sci. Instrum. 71 2000 2867 2872 [22] A.M. Lorino F. Zerah A. Mariette A. Harf H. Lorino Respiratory resistive impedance in obstructive patients: linear regression analysis vs viscoelastic modeling Eur. Respir. J. 10 1997 150 155 [23] R. Peslin B. Hannhart J. Pino Mechanical impedance of the chest in smokers and non-smokers Bull. Eur. Physiopathol. Respir. 17 1981 93 115 [24] Y. Ying R. Peslin C. Duvivier C. Gallina J. Felicio da Silva Respiratory input and transfer mechanical impedances in patients with chronic obstructive pulmonary disease Eur. Respir. J. 3 1990 1186 1192 [25] L.I. Kuncheva Combining Pattern Classifiers: Methods and Algorithms 2004 Wiley-Interscience New Jersey [26] A.R.R. Webb Statistical Pattern Recognition second ed. 2002 John Wiley & Sons, Ltd New Jersey [27] S. Haykin Neural Networks a Comprehensive Foundation 1994 Macmillan College Publishing Company Englewood Cliffs [28] V.N. Vapnik The Nature of Statistical Learning Theory second ed. 2000 Springer New York [29] P. McCullagh J.A. Nelder Generalized Linear Models second ed. 1989 Chapman and Hall/CRC London [30] G.P. Zhang Neural networks for classification: a survey IEEE Trans. Syst. Man Cybern. Part C: Appl. Rev. 30 2000 451 462 [31] C.E. Pedreira L. Macrini M.G. Land E.S. Costa New decision support tool for treatment intensity choice in childhood acute lymphoblastic leukemia IEEE Trans. Inf. Technol. Biomed. 13 2009 284 290 [32] M.H. Goldbaum P.A. Sample K. Chan J. Williams T.W. Lee E. Blumenthal C.A. Girkin L.M. Zangwill C. Bowd T. Sejnowski R.N. Weinreb Comparing machine learning classifiers for diagnosing glaucoma from standard automated perimetry Invest. Ophthalmol. Visual Sci. 43 1 2002 162 169 [33] I.H. Witten E. Frank Data Mining Practical Machine Learning Tools and Techniques second ed. 2005 Morgan Kaufmann San Francisco [34] D.T. Dietterich Approximate statistical tests for comparing supervised classification learning algorithms Neural Comput. 10 1998 1895 1923 [35] T. Fawcett An introduction to ROC analysis Pattern Recognit. Lett. 7 8 2006 861 874 [36] R. Kohavi A study of cross-validation and bootstrap for accuracy estimation and model selection Proceedings of the 14th International Joint Conference on Artificial Intelligence 1995 1137 1145 [37] P. Refaeilzadeh L. Tang H. Liu Cross Validation, Encyclopedia of Database Systems 2009 Springer New York [38] J. Demsar Statistical comparisons of classifiers over multiple data sets J. Mach. Learn. Res. 7 2006 1 30 [39] I. Guyon A. Elisseeff An introduction to variable and feature selection J. Mach. Learn. Res. 3 2003 1157 1182 [40] J.A. Hanley B.J. McNeil The meaning and use of the area under a receiver operating characteristic (ROC) curve Radiology 143 1982 29 36 [41] N. Obuchowski ROC analysis Am. J. Roentgenol. 184 2 2005 364 372 [42] S. Pintea R. Moldovan The receiver-operating characteristic (ROC) analysis: fundamentals and applications in clinical psychology J. Cogn. Behav. Psychother. 9 1 2009 49 66 [43] C.E. Metz Basic principles of ROC analysis Semin. Nucl. Med. 8 4 1978 283 298 [44] P. Bradley The use of the area under the ROC curve in evaluation of machine learning algorithms Pattern Recognit. 30 7 1997 1145 1159 [45] C.X. Ling J. Huang H. Zhang AUC: a statistically consistent and more discriminating measure than accuracy Proceedings of 18th International Conference on Artificial Intelligence 2003 519 524 [46] J. Huang C.X. Ling Using AUC and accuracy in evaluating learning algorithms IEEE Trans. Knowl. Data Eng. 17 3 2005 299 310 [47] F. Heijden R. Duin R. Ridder D.M.J. Tax Classification, Parameter Estimation and State Estimation: An Engineering Approach Using MATLAB 2004 John Wiley & Sons Ltd New Jersey [48] D.E. Goldberg Genetic Algorithms in Search, Optimization, and Machine Learning 1989 Addison-Wesley Indiana [49] Z. Michalewicz Genetic Algorithms+Data Structures=Evolution Programs 1992 Springer Verlag Berlin [50] R.P.W. Duin, P., Juszczak, P. Paclik., E. Pekalska, D. de Ridder, D.M.J., Tax, S., Verzakov, PRTools4.1, A Matlab Toolbox for Pattern Recognition, Delft University of Technology, Holland, 2007. [51] E.G.M. Lacerda A.C.P.L.F. Carvalho T.B. Ludermir Model selection via genetic algorithms for RBF networks J. Intell. Fuzzy Syst. 13 2 2003 111 122 [52] O. Il-Seok J.S. Lee B.R. Moon Hybrid genetic algorithms for feature selection IEEE Trans. Pattern Anal. Mach. Intell. 26 11 2004 1424 1437 [53] S. Lessmann R. Stahlbock S.F. Crone Genetic algorithms for support vector machine model selection Proceedings International Joint Conference on Neural Networks 2006 3063 3069 [54] T. Feng F. Xuezheng Y. Zhang A.G. Bourgeois A genetic algorithm-based method for feature subset selection Soft Comput. 12 2 2007 111 120 [55] H. Vafaie K. De Jong Genetic algorithms as a tool for feature selection in machine learning Proceedings of Fourth International Conference on Tools with Artificial Intelligence 2010 200 203 [56] M. Anbarasi E. Anupriya N.CH.S.N. Iyengar Enhanced prediction of heart disease with feature subset selection using genetic algorithm Int. J. Eng. Sci. Technol. 2 10 2010 5370 5376 [57] E.R. DeLong D.M. DeLong D.L. Clarke-Pearson Comparing the areas under two or more correlated receiver operating characteristic curves: a nonparametric approach Biometrics 44 1988 837 845 [58] J.A. Swets Measuring the accuracy of diagnostic systems Science 240 1988 1285 1293"
    },
    "10.1016/j.apm.2012.09.072": {
        "Title": "Single machine scheduling with resource allocation and learning effect considering the rate-modifying activity",
        "Date": "1 April 2013",
        "Text": "serial JL 271589 291210 291692 291715 291818 291882 291883 31 Applied Mathematical Modelling APPLIEDMATHEMATICALMODELLING 2012-10-08 2012-10-08 2013-03-15T02:49:15 1-s2.0-S0307904X12006038 S0307-904X(12)00603-8 S0307904X12006038 10.1016/j.apm.2012.09.072 S300 S300.5 FULL-TEXT 1-s2.0-S0307904X13X00022 2017-03-31T22:14:51.790991-04:00 0 0 20130401 2013 2012-10-08T00:00:00Z articleinfo crossmark dco dateupdated tomb dateloaded datesearch indexeddate issuelist volumelist yearnav absattachment articletitlenorm authfirstinitialnorm authfirstsurnamenorm cid cids contenttype copyright dateloadedtxt docsubtype doctype doi eid ewtransactionid hubeid issfirst issn issnnorm itemstage itemtransactionid itemweight openaccess openarchive pg pgfirst pglast pii piinorm pubdatestart pubdatetxt pubyr sectiontitle sortorder srctitle srctitlenorm srctype subheadings volfirst volissue webpdf webpdfpagecount table body mmlmath acknowledge affil articletitle auth authfirstini authfull authkeywords authlast primabst ref alllist content subj ssids 0307-904X 0307904X false 37 37 7 7 Volume 37, Issue 7 63 5371 5380 5371 5380 20130401 1 April 2013 2013-04-01 2013 Research Articles article fla Copyright \u00a9 2012 Elsevier Inc. All rights reserved. SINGLEMACHINESCHEDULINGRESOURCEALLOCATIONLEARNINGEFFECTCONSIDERINGRATEMODIFYINGACTIVITY ZHU Z 1 Introduction 2 Problem formulation 3 Preliminary results 4 Optimal analysis for single-machine scheduling 4.1 Linear resource consumption function case 4.2 Convex resource consumption function case 5 Conclusions Acknowledgment References BISKUP 1999 173 178 D MOSHEIOV 2001 687 693 G LEE 2004 85 93 W BACHMAN 2004 257 264 A CHENG 2008 2476 2487 T KOULAMAS 2010 1142 1143 C MOSHEIOV 2003 665 670 G BISKUP 2008 315 329 D WANG 2010 584 591 J EREN 2009 355 358 T TOKSAR 2009 2394 2417 D CHENG 2010 326 331 T JANIAK 2010 213 217 A WANG 2010 2813 2819 J VICKSON 1980 1155 1167 R JANIAK 1996 284 291 A HOOGEVEEN 2002 181 192 H MONMA 1990 736 748 C KASPI 2004 1481 1489 M SHABTAY 2004 2279 2289 D SHABTAY 2008 25 40 D ZHU 2011 148 157 Z WANG 2010 458 462 D KOULAMAS 2010 479 482 C ZHU 2010 84 87 V SHABTAY 2007 1643 1666 D LEE 2001 119 128 C LEE 2001 493 513 C HE 2005 361 369 Y MOSHEIOV 2006 1053 1057 G GORDON 2009 325 328 V ZHAO 2009 354 357 C MOSHEIOV 2009 2541 2545 G YANG 2010 1510 1514 S ZHAO 2010 C JI 2010 460 463 M LODREE 2010 644 648 E BAGCHI 1989 118 125 U GRAHAM 1979 287 326 R HARDY 1934 G INEQUALITIES BRUCKER 2001 P SCHEDULINGALGORITHMS PAPADIMITRIOU 1982 C COMBINATORIALOPTIMIZATIONALGORITHMSCOMPLEXITY CHOI 2007 645 653 B ZHUX2013X5371 ZHUX2013X5371X5380 ZHUX2013X5371XZ ZHUX2013X5371X5380XZ Full 2017-04-01T00:14:46Z OA-Window ElsevierBranded http://www.elsevier.com/open-access/userlicense/1.0/ item S0307-904X(12)00603-8 S0307904X12006038 1-s2.0-S0307904X12006038 10.1016/j.apm.2012.09.072 271589 2013-03-15T06:43:25.106958-04:00 2013-04-01 1-s2.0-S0307904X12006038-main.pdf https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/MAIN/application/pdf/713b4a202c6b38b933ec0d2876b81962/main.pdf https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/MAIN/application/pdf/713b4a202c6b38b933ec0d2876b81962/main.pdf main.pdf pdf true 223829 MAIN 10 1-s2.0-S0307904X12006038-main_1.png https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/PREVIEW/image/png/5cddd3ec82f50fec1209956909a28a03/main_1.png https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/PREVIEW/image/png/5cddd3ec82f50fec1209956909a28a03/main_1.png main_1.png png 49294 849 656 IMAGE-WEB-PDF 1 1-s2.0-S0307904X12006038-si155.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/de806a4753304ed334587e4a930ce6d3/si155.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/de806a4753304ed334587e4a930ce6d3/si155.gif si155 si155.gif gif 9315 57 462 ALTIMG 1-s2.0-S0307904X12006038-si154.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/f489fe894046fd2f57ccd296b01dcd47/si154.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/f489fe894046fd2f57ccd296b01dcd47/si154.gif si154 si154.gif gif 6987 62 446 ALTIMG 1-s2.0-S0307904X12006038-si153.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/002d72355b018bb20ba12212c0f2f57a/si153.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/002d72355b018bb20ba12212c0f2f57a/si153.gif si153 si153.gif gif 7656 46 549 ALTIMG 1-s2.0-S0307904X12006038-si143.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/06500e80f879be93998c258de938ad0f/si143.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/06500e80f879be93998c258de938ad0f/si143.gif si143 si143.gif gif 10374 82 516 ALTIMG 1-s2.0-S0307904X12006038-si141.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/7b71d2f943185c4a8f9aca7683124c06/si141.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/7b71d2f943185c4a8f9aca7683124c06/si141.gif si141 si141.gif gif 10605 82 522 ALTIMG 1-s2.0-S0307904X12006038-si137.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/2135e70ef348c4184179833a8e986e0a/si137.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/2135e70ef348c4184179833a8e986e0a/si137.gif si137 si137.gif gif 15783 107 725 ALTIMG 1-s2.0-S0307904X12006038-si134.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/d51376f1c84d52928573392b9e862600/si134.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/d51376f1c84d52928573392b9e862600/si134.gif si134 si134.gif gif 15288 107 722 ALTIMG 1-s2.0-S0307904X12006038-si130.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/9decbc7dc656c5f9fbbdacde5b92fe5a/si130.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/9decbc7dc656c5f9fbbdacde5b92fe5a/si130.gif si130 si130.gif gif 13848 111 685 ALTIMG 1-s2.0-S0307904X12006038-si127.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/73bcb5c748c5b184ce23687743f37539/si127.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/73bcb5c748c5b184ce23687743f37539/si127.gif si127 si127.gif gif 9705 50 716 ALTIMG 1-s2.0-S0307904X12006038-si121.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/dcc4b99769cbb7e5b950b86f6fc1132b/si121.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/dcc4b99769cbb7e5b950b86f6fc1132b/si121.gif si121 si121.gif gif 9837 211 357 ALTIMG 1-s2.0-S0307904X12006038-si119.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/564c0cc82bf5522d4167a2018485d9fb/si119.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/564c0cc82bf5522d4167a2018485d9fb/si119.gif si119 si119.gif gif 12366 230 367 ALTIMG 1-s2.0-S0307904X12006038-si118.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/e2bc330815447eb962816e9cf4aef565/si118.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/e2bc330815447eb962816e9cf4aef565/si118.gif si118 si118.gif gif 20181 113 665 ALTIMG 1-s2.0-S0307904X12006038-si114.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/63ed3ee97f23fc5ecb76310030fd72f2/si114.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/63ed3ee97f23fc5ecb76310030fd72f2/si114.gif si114 si114.gif gif 9375 72 414 ALTIMG 1-s2.0-S0307904X12006038-si113.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/cc0f29a2b35f0fa69de3441f9c31039b/si113.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/cc0f29a2b35f0fa69de3441f9c31039b/si113.gif si113 si113.gif gif 10128 50 721 ALTIMG 1-s2.0-S0307904X12006038-si111.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/4b86429f1bff5e3bceae60716db0f775/si111.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/4b86429f1bff5e3bceae60716db0f775/si111.gif si111 si111.gif gif 42525 347 812 ALTIMG 1-s2.0-S0307904X12006038-si96.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/3213c405857b640004c43771c5bbeeaf/si96.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/3213c405857b640004c43771c5bbeeaf/si96.gif si96 si96.gif gif 10479 230 357 ALTIMG 1-s2.0-S0307904X12006038-si93.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/5b7e84d06b575086822c57e498156563/si93.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/5b7e84d06b575086822c57e498156563/si93.gif si93 si93.gif gif 2643 18 347 ALTIMG 1-s2.0-S0307904X12006038-si92.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/a33b1dcabab9bdb3879a20efbfb45504/si92.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/a33b1dcabab9bdb3879a20efbfb45504/si92.gif si92 si92.gif gif 2361 46 199 ALTIMG 1-s2.0-S0307904X12006038-si91.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/fbb9b7864251d7de07a4fdd5917c9af9/si91.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/fbb9b7864251d7de07a4fdd5917c9af9/si91.gif si91 si91.gif gif 2388 43 199 ALTIMG 1-s2.0-S0307904X12006038-si90.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/a355988ac0915db283894ab11fbbd3b1/si90.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/a355988ac0915db283894ab11fbbd3b1/si90.gif si90 si90.gif gif 5271 46 360 ALTIMG 1-s2.0-S0307904X12006038-si89.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/f83b95a291ecf557cb9f639d82fa2f36/si89.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/f83b95a291ecf557cb9f639d82fa2f36/si89.gif si89 si89.gif gif 18444 98 631 ALTIMG 1-s2.0-S0307904X12006038-si83.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/cfbaabbdd889b2b98c312f3f3c9043bb/si83.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/cfbaabbdd889b2b98c312f3f3c9043bb/si83.gif si83 si83.gif gif 8880 72 404 ALTIMG 1-s2.0-S0307904X12006038-si74.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/fc28ec99df061f965b09e8fea3c84e97/si74.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/fc28ec99df061f965b09e8fea3c84e97/si74.gif si74 si74.gif gif 9849 50 717 ALTIMG 1-s2.0-S0307904X12006038-si72.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/eb0045f3df66f71826ee070b94258b37/si72.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/eb0045f3df66f71826ee070b94258b37/si72.gif si72 si72.gif gif 44694 278 916 ALTIMG 1-s2.0-S0307904X12006038-si62.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/ec56e61afbfa45494736d0422bb136b1/si62.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/ec56e61afbfa45494736d0422bb136b1/si62.gif si62 si62.gif gif 8646 52 523 ALTIMG 1-s2.0-S0307904X12006038-si61.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/ff84268d8b65e2a0b14c83d73ff153eb/si61.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/ff84268d8b65e2a0b14c83d73ff153eb/si61.gif si61 si61.gif gif 7293 52 399 ALTIMG 1-s2.0-S0307904X12006038-si60.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/202e1fd32670acaf357012f2f06dcacb/si60.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/202e1fd32670acaf357012f2f06dcacb/si60.gif si60 si60.gif gif 9759 52 661 ALTIMG 1-s2.0-S0307904X12006038-si59.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/e63008f40f37b8956260e42673fa674a/si59.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/e63008f40f37b8956260e42673fa674a/si59.gif si59 si59.gif gif 9225 52 595 ALTIMG 1-s2.0-S0307904X12006038-si58.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/75900b9d05f85ada076b9d3748a27e9e/si58.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/75900b9d05f85ada076b9d3748a27e9e/si58.gif si58 si58.gif gif 6483 52 337 ALTIMG 1-s2.0-S0307904X12006038-si57.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/bc27f11e71f1a17d173d8a6cafdde70f/si57.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/bc27f11e71f1a17d173d8a6cafdde70f/si57.gif si57 si57.gif gif 8238 50 606 ALTIMG 1-s2.0-S0307904X12006038-si56.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/d46fa7402ddec980295543275a0bfc0f/si56.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/d46fa7402ddec980295543275a0bfc0f/si56.gif si56 si56.gif gif 7662 50 567 ALTIMG 1-s2.0-S0307904X12006038-si55.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/11933385037a2739944989ce3e82609f/si55.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/11933385037a2739944989ce3e82609f/si55.gif si55 si55.gif gif 9171 50 743 ALTIMG 1-s2.0-S0307904X12006038-si54.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/e4ee935be393a4ea5e5bd308cbe62bac/si54.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/e4ee935be393a4ea5e5bd308cbe62bac/si54.gif si54 si54.gif gif 8700 50 677 ALTIMG 1-s2.0-S0307904X12006038-si53.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/af801eea3f3a193ad2ca4490cc59a9f7/si53.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/af801eea3f3a193ad2ca4490cc59a9f7/si53.gif si53 si53.gif gif 6057 50 419 ALTIMG 1-s2.0-S0307904X12006038-si51.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/a54aabf5603148517828519e5911c210/si51.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/a54aabf5603148517828519e5911c210/si51.gif si51 si51.gif gif 4581 48 341 ALTIMG 1-s2.0-S0307904X12006038-si50.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/37dbc9fae09c711c3d0ab67996a71af4/si50.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/37dbc9fae09c711c3d0ab67996a71af4/si50.gif si50 si50.gif gif 4305 48 321 ALTIMG 1-s2.0-S0307904X12006038-si49.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/fddc5d4fad2fd4cfc120f64fcbf066b5/si49.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/fddc5d4fad2fd4cfc120f64fcbf066b5/si49.gif si49 si49.gif gif 4146 48 307 ALTIMG 1-s2.0-S0307904X12006038-si48.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/4cc4db3017554d37543931f17f0f5d3c/si48.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/4cc4db3017554d37543931f17f0f5d3c/si48.gif si48 si48.gif gif 3912 21 383 ALTIMG 1-s2.0-S0307904X12006038-si47.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/fbf34a5e15afd439b87c50bde047f927/si47.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/fbf34a5e15afd439b87c50bde047f927/si47.gif si47 si47.gif gif 3732 21 363 ALTIMG 1-s2.0-S0307904X12006038-si46.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/20f7e05d87f4c3b50e84ca201e2e51e7/si46.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/20f7e05d87f4c3b50e84ca201e2e51e7/si46.gif si46 si46.gif gif 3561 21 349 ALTIMG 1-s2.0-S0307904X12006038-si99.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/ad7ac427d22f6d2d9b5e2f3d1c1d705a/si99.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/ad7ac427d22f6d2d9b5e2f3d1c1d705a/si99.gif si99 si99.gif gif 633 17 22 ALTIMG 1-s2.0-S0307904X12006038-si98.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/cccccc4bf2e812c220c91cbe23244ae0/si98.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/cccccc4bf2e812c220c91cbe23244ae0/si98.gif si98 si98.gif gif 612 14 40 ALTIMG 1-s2.0-S0307904X12006038-si97.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/1c3e7605192c5a04b54d3250074c0b68/si42.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/1c3e7605192c5a04b54d3250074c0b68/si42.gif si97 si97.gif gif 4812 20 368 ALTIMG 1-s2.0-S0307904X12006038-si95.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/5d30d5f0a865db2c312c1004c780d23c/si44.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/5d30d5f0a865db2c312c1004c780d23c/si44.gif si95 si95.gif gif 459 14 11 ALTIMG 1-s2.0-S0307904X12006038-si94.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/70faf441b2e839232696caac8f6396bb/si94.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/70faf441b2e839232696caac8f6396bb/si94.gif si94 si94.gif gif 555 13 19 ALTIMG 1-s2.0-S0307904X12006038-si9.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/77428f274f142b59af3d37046674b113/si9.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/77428f274f142b59af3d37046674b113/si9.gif si9 si9.gif gif 696 16 29 ALTIMG 1-s2.0-S0307904X12006038-si88.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/eea9e6e08954cebfaa47fade1c37709f/si88.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/eea9e6e08954cebfaa47fade1c37709f/si88.gif si88 si88.gif gif 1044 16 96 ALTIMG 1-s2.0-S0307904X12006038-si87.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/23b0431fa18308c0140592e550152e83/si87.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/23b0431fa18308c0140592e550152e83/si87.gif si87 si87.gif gif 801 18 49 ALTIMG 1-s2.0-S0307904X12006038-si86.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/a9bfada2d88866f342123b1e81775fa2/si86.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/a9bfada2d88866f342123b1e81775fa2/si86.gif si86 si86.gif gif 717 18 47 ALTIMG 1-s2.0-S0307904X12006038-si85.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/0eef29ec96953b80d8fd506832c6e7a4/si45.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/0eef29ec96953b80d8fd506832c6e7a4/si45.gif si85 si85.gif gif 1071 16 96 ALTIMG 1-s2.0-S0307904X12006038-si84.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/c01952902d37c207c47edd0160cf0b65/si84.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/c01952902d37c207c47edd0160cf0b65/si84.gif si84 si84.gif gif 663 20 19 ALTIMG 1-s2.0-S0307904X12006038-si82.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/857a3bbb8360a867c9d771aa9a9ed901/si82.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/857a3bbb8360a867c9d771aa9a9ed901/si82.gif si82 si82.gif gif 540 16 15 ALTIMG 1-s2.0-S0307904X12006038-si81.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/8e2cc111fe8e3515acb223d4a3f50080/si81.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/8e2cc111fe8e3515acb223d4a3f50080/si81.gif si81 si81.gif gif 1518 18 92 ALTIMG 1-s2.0-S0307904X12006038-si80.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/8e2cc111fe8e3515acb223d4a3f50080/si81.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/8e2cc111fe8e3515acb223d4a3f50080/si81.gif si80 si80.gif gif 1518 18 92 ALTIMG 1-s2.0-S0307904X12006038-si8.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/55d60d6492f9fa6e99517bac65e12e75/si8.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/55d60d6492f9fa6e99517bac65e12e75/si8.gif si8 si8.gif gif 855 17 44 ALTIMG 1-s2.0-S0307904X12006038-si79.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/857a3bbb8360a867c9d771aa9a9ed901/si82.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/857a3bbb8360a867c9d771aa9a9ed901/si82.gif si79 si79.gif gif 540 16 15 ALTIMG 1-s2.0-S0307904X12006038-si78.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/8e2cc111fe8e3515acb223d4a3f50080/si81.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/8e2cc111fe8e3515acb223d4a3f50080/si81.gif si78 si78.gif gif 1518 18 92 ALTIMG 1-s2.0-S0307904X12006038-si77.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/8e2cc111fe8e3515acb223d4a3f50080/si81.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/8e2cc111fe8e3515acb223d4a3f50080/si81.gif si77 si77.gif gif 1518 18 92 ALTIMG 1-s2.0-S0307904X12006038-si76.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/20762b1856a1e665c2acd00ae4173bd7/si76.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/20762b1856a1e665c2acd00ae4173bd7/si76.gif si76 si76.gif gif 531 14 15 ALTIMG 1-s2.0-S0307904X12006038-si75.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/5d30d5f0a865db2c312c1004c780d23c/si44.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/5d30d5f0a865db2c312c1004c780d23c/si44.gif si75 si75.gif gif 459 14 11 ALTIMG 1-s2.0-S0307904X12006038-si73.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/6f54482c6cbeb184326d8db494c627ed/si73.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/6f54482c6cbeb184326d8db494c627ed/si73.gif si73 si73.gif gif 3228 19 316 ALTIMG 1-s2.0-S0307904X12006038-si71.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/0ae967bce7f874e2fa5848cdbfe8b767/si71.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/0ae967bce7f874e2fa5848cdbfe8b767/si71.gif si71 si71.gif gif 4941 21 367 ALTIMG 1-s2.0-S0307904X12006038-si70.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/157dd89c1f4bb83a775893d5a4fd364d/si43.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/157dd89c1f4bb83a775893d5a4fd364d/si43.gif si70 si70.gif gif 4998 21 375 ALTIMG 1-s2.0-S0307904X12006038-si7.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/00bca9ce50813a75158c5631586350e0/si7.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/00bca9ce50813a75158c5631586350e0/si7.gif si7 si7.gif gif 1359 19 117 ALTIMG 1-s2.0-S0307904X12006038-si69.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/0ae967bce7f874e2fa5848cdbfe8b767/si71.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/0ae967bce7f874e2fa5848cdbfe8b767/si71.gif si69 si69.gif gif 4941 21 367 ALTIMG 1-s2.0-S0307904X12006038-si68.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/975c87b624ff1e79842c010e06c9aa57/si68.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/975c87b624ff1e79842c010e06c9aa57/si68.gif si68 si68.gif gif 1143 18 58 ALTIMG 1-s2.0-S0307904X12006038-si67.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/649b9584c61099980b53fcb53f2971e0/si64.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/649b9584c61099980b53fcb53f2971e0/si64.gif si67 si67.gif gif 504 12 13 ALTIMG 1-s2.0-S0307904X12006038-si66.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/917de19ce9ea921eed724f620febecd4/si63.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/917de19ce9ea921eed724f620febecd4/si63.gif si66 si66.gif gif 480 11 13 ALTIMG 1-s2.0-S0307904X12006038-si65.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/0e5827238bdf6b81a9349a517503b093/si65.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/0e5827238bdf6b81a9349a517503b093/si65.gif si65 si65.gif gif 1035 16 94 ALTIMG 1-s2.0-S0307904X12006038-si64.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/649b9584c61099980b53fcb53f2971e0/si64.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/649b9584c61099980b53fcb53f2971e0/si64.gif si64 si64.gif gif 504 12 13 ALTIMG 1-s2.0-S0307904X12006038-si63.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/917de19ce9ea921eed724f620febecd4/si63.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/917de19ce9ea921eed724f620febecd4/si63.gif si63 si63.gif gif 480 11 13 ALTIMG 1-s2.0-S0307904X12006038-si6.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/e32ebe52efe052c0b829f889254b1562/si6.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/e32ebe52efe052c0b829f889254b1562/si6.gif si6 si6.gif gif 3036 23 246 ALTIMG 1-s2.0-S0307904X12006038-si52.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/09c632dfaea18ec460f8bca28b192afa/si52.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/09c632dfaea18ec460f8bca28b192afa/si52.gif si52 si52.gif gif 921 18 54 ALTIMG 1-s2.0-S0307904X12006038-si5.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/e99e08c15c31775fed87fbe0217f2c44/si5.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/e99e08c15c31775fed87fbe0217f2c44/si5.gif si5 si5.gif gif 1350 17 62 ALTIMG 1-s2.0-S0307904X12006038-si45.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/0eef29ec96953b80d8fd506832c6e7a4/si45.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/0eef29ec96953b80d8fd506832c6e7a4/si45.gif si45 si45.gif gif 1071 16 96 ALTIMG 1-s2.0-S0307904X12006038-si44.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/5d30d5f0a865db2c312c1004c780d23c/si44.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/5d30d5f0a865db2c312c1004c780d23c/si44.gif si44 si44.gif gif 459 14 11 ALTIMG 1-s2.0-S0307904X12006038-si43.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/157dd89c1f4bb83a775893d5a4fd364d/si43.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/157dd89c1f4bb83a775893d5a4fd364d/si43.gif si43 si43.gif gif 4998 21 375 ALTIMG 1-s2.0-S0307904X12006038-si42.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/1c3e7605192c5a04b54d3250074c0b68/si42.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/1c3e7605192c5a04b54d3250074c0b68/si42.gif si42 si42.gif gif 4812 20 368 ALTIMG 1-s2.0-S0307904X12006038-si41.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/c1b35b2c0755cec02c8b880e2fadc3ee/si41.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/c1b35b2c0755cec02c8b880e2fadc3ee/si41.gif si41 si41.gif gif 591 16 17 ALTIMG 1-s2.0-S0307904X12006038-si40.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/89db07dd8524790f290f3a643bd5cdc7/si40.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/89db07dd8524790f290f3a643bd5cdc7/si40.gif si40 si40.gif gif 237 16 17 ALTIMG 1-s2.0-S0307904X12006038-si4.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/0399545c7caf2e19d0854213e84e2d1b/si4.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/0399545c7caf2e19d0854213e84e2d1b/si4.gif si4 si4.gif gif 224 15 17 ALTIMG 1-s2.0-S0307904X12006038-si39.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/318db2d3c851d61bfa318dd487e14074/si39.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/318db2d3c851d61bfa318dd487e14074/si39.gif si39 si39.gif gif 420 16 72 ALTIMG 1-s2.0-S0307904X12006038-si38.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/e78eeea302f52bbd9630ea7138ec7d0e/si38.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/e78eeea302f52bbd9630ea7138ec7d0e/si38.gif si38 si38.gif gif 463 21 91 ALTIMG 1-s2.0-S0307904X12006038-si37.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/5ccb96c17b78ab718ee6f16c24024942/si37.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/5ccb96c17b78ab718ee6f16c24024942/si37.gif si37 si37.gif gif 941 21 210 ALTIMG 1-s2.0-S0307904X12006038-si36.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/ce7f698c7ffc5551973bad7cf30b6f0b/si36.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/ce7f698c7ffc5551973bad7cf30b6f0b/si36.gif si36 si36.gif gif 881 21 198 ALTIMG 1-s2.0-S0307904X12006038-si35.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/2d65dc9a7863017f35e930e45db5cf90/si35.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/2d65dc9a7863017f35e930e45db5cf90/si35.gif si35 si35.gif gif 873 21 202 ALTIMG 1-s2.0-S0307904X12006038-si34.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/958aafe987511f70f2f5fb2d1fe3289f/si34.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/958aafe987511f70f2f5fb2d1fe3289f/si34.gif si34 si34.gif gif 857 18 214 ALTIMG 1-s2.0-S0307904X12006038-si33.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/1a78b6ef4f98836921968c047e754c23/si33.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/1a78b6ef4f98836921968c047e754c23/si33.gif si33 si33.gif gif 1582 21 358 ALTIMG 1-s2.0-S0307904X12006038-si32.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/c0eb9b2fe1584424cd5b0b5e9ef98a19/si32.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/c0eb9b2fe1584424cd5b0b5e9ef98a19/si32.gif si32 si32.gif gif 1518 20 352 ALTIMG 1-s2.0-S0307904X12006038-si31.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/d507959728ece18f6f21e19f559bf014/si31.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/d507959728ece18f6f21e19f559bf014/si31.gif si31 si31.gif gif 506 18 95 ALTIMG 1-s2.0-S0307904X12006038-si30.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/94dbc90ba8b83101b5be16447fc03bed/si30.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/94dbc90ba8b83101b5be16447fc03bed/si30.gif si30 si30.gif gif 681 33 104 ALTIMG 1-s2.0-S0307904X12006038-si3.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/2a0ff347116e9847970e73476cb6ef66/si3.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/2a0ff347116e9847970e73476cb6ef66/si3.gif si3 si3.gif gif 379 18 68 ALTIMG 1-s2.0-S0307904X12006038-si29.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/8f925e3158230bd834bf31c7bb8de4a9/si29.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/8f925e3158230bd834bf31c7bb8de4a9/si29.gif si29 si29.gif gif 635 33 94 ALTIMG 1-s2.0-S0307904X12006038-si28.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/359cbcc654dde2cfdb0c338fbb45a01c/si28.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/359cbcc654dde2cfdb0c338fbb45a01c/si28.gif si28 si28.gif gif 770 28 147 ALTIMG 1-s2.0-S0307904X12006038-si27.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/26cc22d6277f691c6737390706e41095/si27.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/26cc22d6277f691c6737390706e41095/si27.gif si27 si27.gif gif 271 16 35 ALTIMG 1-s2.0-S0307904X12006038-si26.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/6c1bda7f175d1a8d27c128b1ba2460be/si26.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/6c1bda7f175d1a8d27c128b1ba2460be/si26.gif si26 si26.gif gif 224 18 15 ALTIMG 1-s2.0-S0307904X12006038-si25.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/17d74949dfe57bb2d5a87dd98708f2d8/si25.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/17d74949dfe57bb2d5a87dd98708f2d8/si25.gif si25 si25.gif gif 212 14 15 ALTIMG 1-s2.0-S0307904X12006038-si24.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/3da056f08f54969ef3334a0c5bdbb980/si24.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/3da056f08f54969ef3334a0c5bdbb980/si24.gif si24 si24.gif gif 418 18 73 ALTIMG 1-s2.0-S0307904X12006038-si23.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/fb3a9c40cf898873f145674b44a9279e/si23.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/fb3a9c40cf898873f145674b44a9279e/si23.gif si23 si23.gif gif 225 14 16 ALTIMG 1-s2.0-S0307904X12006038-si22.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/c8976b234e113bdd09027c893a4edb67/si22.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/c8976b234e113bdd09027c893a4edb67/si22.gif si22 si22.gif gif 687 22 140 ALTIMG 1-s2.0-S0307904X12006038-si21.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/ef2baa5d9a1b01e5375f26f7c3e7cbc4/si21.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/ef2baa5d9a1b01e5375f26f7c3e7cbc4/si21.gif si21 si21.gif gif 625 22 125 ALTIMG 1-s2.0-S0307904X12006038-si20.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/f0cc79c75d55ae20f6943eb1fce6d088/si156.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/f0cc79c75d55ae20f6943eb1fce6d088/si156.gif si20 si20.gif gif 188 14 11 ALTIMG 1-s2.0-S0307904X12006038-si2.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/68694718793b1fc87e29ca896cad51ce/si173.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/68694718793b1fc87e29ca896cad51ce/si173.gif si2 true si2.gif gif 524 18 68 ALTIMG 1-s2.0-S0307904X12006038-si19.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/f0cc79c75d55ae20f6943eb1fce6d088/si156.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/f0cc79c75d55ae20f6943eb1fce6d088/si156.gif si19 si19.gif gif 188 14 11 ALTIMG 1-s2.0-S0307904X12006038-si18.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/7e25d488a4e5f43072368a599ade9bb2/si117.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/7e25d488a4e5f43072368a599ade9bb2/si117.gif si18 si18.gif gif 383 16 96 ALTIMG 1-s2.0-S0307904X12006038-si179.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/68694718793b1fc87e29ca896cad51ce/si173.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/68694718793b1fc87e29ca896cad51ce/si173.gif si179 si179.gif gif 524 18 68 ALTIMG 1-s2.0-S0307904X12006038-si178.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/dc18a51c1e4ddb399c362b9ac37f08e7/si132.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/dc18a51c1e4ddb399c362b9ac37f08e7/si132.gif si178 si178.gif gif 357 18 38 ALTIMG 1-s2.0-S0307904X12006038-si177.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/61948cfa9f214e7fdfd54cfe6242fc9f/si177.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/61948cfa9f214e7fdfd54cfe6242fc9f/si177.gif si177 si177.gif gif 485 17 62 ALTIMG 1-s2.0-S0307904X12006038-si176.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/5b4e443f6740189425706b29e5fe2515/si106.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/5b4e443f6740189425706b29e5fe2515/si106.gif si176 si176.gif gif 354 18 38 ALTIMG 1-s2.0-S0307904X12006038-si175.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/68694718793b1fc87e29ca896cad51ce/si173.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/68694718793b1fc87e29ca896cad51ce/si173.gif si175 si175.gif gif 524 18 68 ALTIMG 1-s2.0-S0307904X12006038-si174.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/641a67a6be13214298b7c2a3c6fadbf9/si136.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/641a67a6be13214298b7c2a3c6fadbf9/si136.gif si174 si174.gif gif 1701 21 375 ALTIMG 1-s2.0-S0307904X12006038-si173.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/68694718793b1fc87e29ca896cad51ce/si173.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/68694718793b1fc87e29ca896cad51ce/si173.gif si173 si173.gif gif 524 18 68 ALTIMG 1-s2.0-S0307904X12006038-si172.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/a0d824dffb5756eabe60cc8a4120068a/si172.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/a0d824dffb5756eabe60cc8a4120068a/si172.gif si172 si172.gif gif 1639 20 368 ALTIMG 1-s2.0-S0307904X12006038-si171.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/afd5ad625681211bdc493f4f77b3d2b9/si171.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/afd5ad625681211bdc493f4f77b3d2b9/si171.gif si171 si171.gif gif 327 16 67 ALTIMG 1-s2.0-S0307904X12006038-si170.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/f0cc79c75d55ae20f6943eb1fce6d088/si156.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/f0cc79c75d55ae20f6943eb1fce6d088/si156.gif si170 si170.gif gif 188 14 11 ALTIMG 1-s2.0-S0307904X12006038-si17.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/a8dca0a0d59eb4325e3f2e878f773fe2/si17.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/a8dca0a0d59eb4325e3f2e878f773fe2/si17.gif si17 si17.gif gif 237 17 21 ALTIMG 1-s2.0-S0307904X12006038-si169.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/61948cfa9f214e7fdfd54cfe6242fc9f/si177.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/61948cfa9f214e7fdfd54cfe6242fc9f/si177.gif si169 si169.gif gif 485 17 62 ALTIMG 1-s2.0-S0307904X12006038-si168.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/2e56cdd583b324588cd2a09b58bf72ed/si168.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/2e56cdd583b324588cd2a09b58bf72ed/si168.gif si168 si168.gif gif 518 18 80 ALTIMG 1-s2.0-S0307904X12006038-si167.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/f0cc79c75d55ae20f6943eb1fce6d088/si156.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/f0cc79c75d55ae20f6943eb1fce6d088/si156.gif si167 si167.gif gif 188 14 11 ALTIMG 1-s2.0-S0307904X12006038-si166.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/68694718793b1fc87e29ca896cad51ce/si173.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/68694718793b1fc87e29ca896cad51ce/si173.gif si166 si166.gif gif 524 18 68 ALTIMG 1-s2.0-S0307904X12006038-si165.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/475169577f555ca8f62e55f33550e3db/si157.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/475169577f555ca8f62e55f33550e3db/si157.gif si165 si165.gif gif 1682 21 367 ALTIMG 1-s2.0-S0307904X12006038-si164.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/9f7c7b27f30cd354201ede99395c9f9e/si104.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/9f7c7b27f30cd354201ede99395c9f9e/si104.gif si164 si164.gif gif 206 16 11 ALTIMG 1-s2.0-S0307904X12006038-si163.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/d8ea71c8936b2303d516c6060b52b179/si163.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/d8ea71c8936b2303d516c6060b52b179/si163.gif si163 si163.gif gif 219 13 17 ALTIMG 1-s2.0-S0307904X12006038-si162.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/05cab242a3f566f6abdf29ab9892dca3/si162.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/05cab242a3f566f6abdf29ab9892dca3/si162.gif si162 si162.gif gif 290 14 42 ALTIMG 1-s2.0-S0307904X12006038-si161.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/4cd1e6d39420e16881718af848a6b8dc/si161.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/4cd1e6d39420e16881718af848a6b8dc/si161.gif si161 si161.gif gif 311 14 71 ALTIMG 1-s2.0-S0307904X12006038-si160.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/431dc1b32c11798c082bc94f56abb5fe/si160.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/431dc1b32c11798c082bc94f56abb5fe/si160.gif si160 si160.gif gif 238 16 18 ALTIMG 1-s2.0-S0307904X12006038-si159.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/9ed477256ff70ba37376765805ae8a52/si159.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/9ed477256ff70ba37376765805ae8a52/si159.gif si159 si159.gif gif 229 16 18 ALTIMG 1-s2.0-S0307904X12006038-si158.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/b7c1a3e015b28c9e3d6a017bc30d0514/si158.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/b7c1a3e015b28c9e3d6a017bc30d0514/si158.gif si158 si158.gif gif 239 14 40 ALTIMG 1-s2.0-S0307904X12006038-si16.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/194f21752ca747d30330079d07e29e42/si16.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/194f21752ca747d30330079d07e29e42/si16.gif si16 si16.gif gif 628 19 151 ALTIMG 1-s2.0-S0307904X12006038-si157.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/475169577f555ca8f62e55f33550e3db/si157.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/475169577f555ca8f62e55f33550e3db/si157.gif si157 si157.gif gif 1682 21 367 ALTIMG 1-s2.0-S0307904X12006038-si156.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/f0cc79c75d55ae20f6943eb1fce6d088/si156.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/f0cc79c75d55ae20f6943eb1fce6d088/si156.gif si156 si156.gif gif 188 14 11 ALTIMG 1-s2.0-S0307904X12006038-si152.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/8ebff0178a3576a2f3bcee4685b9a1fd/si152.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/8ebff0178a3576a2f3bcee4685b9a1fd/si152.gif si152 si152.gif gif 339 17 39 ALTIMG 1-s2.0-S0307904X12006038-si151.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/9fd661620db61c60106b7946e0f0cd87/si151.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/9fd661620db61c60106b7946e0f0cd87/si151.gif si151 si151.gif gif 391 17 48 ALTIMG 1-s2.0-S0307904X12006038-si150.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/6590aaf8ac63e68785632690b9cb0ee6/si150.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/6590aaf8ac63e68785632690b9cb0ee6/si150.gif si150 si150.gif gif 1220 36 195 ALTIMG 1-s2.0-S0307904X12006038-si15.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/0399545c7caf2e19d0854213e84e2d1b/si4.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/0399545c7caf2e19d0854213e84e2d1b/si4.gif si15 si15.gif gif 224 15 17 ALTIMG 1-s2.0-S0307904X12006038-si149.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/b212b30441b2d6f31c73f46d726d604b/si146.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/b212b30441b2d6f31c73f46d726d604b/si146.gif si149 si149.gif gif 517 26 70 ALTIMG 1-s2.0-S0307904X12006038-si148.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/25e8d99229270e0b37d937dac1d05bf6/si148.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/25e8d99229270e0b37d937dac1d05bf6/si148.gif si148 si148.gif gif 2926 55 621 ALTIMG 1-s2.0-S0307904X12006038-si147.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/e8d1f9c6cbb8194ac0349db7be9a7156/si147.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/e8d1f9c6cbb8194ac0349db7be9a7156/si147.gif si147 si147.gif gif 1057 35 170 ALTIMG 1-s2.0-S0307904X12006038-si146.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/b212b30441b2d6f31c73f46d726d604b/si146.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/b212b30441b2d6f31c73f46d726d604b/si146.gif si146 si146.gif gif 517 26 70 ALTIMG 1-s2.0-S0307904X12006038-si145.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/d6e9ff45207d1db1994419884babba81/si145.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/d6e9ff45207d1db1994419884babba81/si145.gif si145 si145.gif gif 2659 55 529 ALTIMG 1-s2.0-S0307904X12006038-si144.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/ac31a843eaf0e77f46cee5ec8a881cf3/si144.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/ac31a843eaf0e77f46cee5ec8a881cf3/si144.gif si144 si144.gif gif 378 17 50 ALTIMG 1-s2.0-S0307904X12006038-si142.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/1a78b6ef4f98836921968c047e754c23/si33.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/1a78b6ef4f98836921968c047e754c23/si33.gif si142 si142.gif gif 1582 21 358 ALTIMG 1-s2.0-S0307904X12006038-si140.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/c0eb9b2fe1584424cd5b0b5e9ef98a19/si32.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/c0eb9b2fe1584424cd5b0b5e9ef98a19/si32.gif si140 si140.gif gif 1518 20 352 ALTIMG 1-s2.0-S0307904X12006038-si14.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/5232cc9c39c45c3b4953b30e303a7851/si14.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/5232cc9c39c45c3b4953b30e303a7851/si14.gif si14 si14.gif gif 512 17 132 ALTIMG 1-s2.0-S0307904X12006038-si139.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/afb025d505d038b5217742118a9dd529/si139.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/afb025d505d038b5217742118a9dd529/si139.gif si139 si139.gif gif 199 10 12 ALTIMG 1-s2.0-S0307904X12006038-si138.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/139b0ec0afd88b38a2979a3a6d38f9d8/si138.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/139b0ec0afd88b38a2979a3a6d38f9d8/si138.gif si138 si138.gif gif 952 20 222 ALTIMG 1-s2.0-S0307904X12006038-si136.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/641a67a6be13214298b7c2a3c6fadbf9/si136.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/641a67a6be13214298b7c2a3c6fadbf9/si136.gif si136 si136.gif gif 1701 21 375 ALTIMG 1-s2.0-S0307904X12006038-si135.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/3610628e2f4dbe20c9ff8f4da4e1987c/si135.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/3610628e2f4dbe20c9ff8f4da4e1987c/si135.gif si135 si135.gif gif 1111 19 316 ALTIMG 1-s2.0-S0307904X12006038-si133.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/475169577f555ca8f62e55f33550e3db/si157.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/475169577f555ca8f62e55f33550e3db/si157.gif si133 si133.gif gif 1682 21 367 ALTIMG 1-s2.0-S0307904X12006038-si132.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/dc18a51c1e4ddb399c362b9ac37f08e7/si132.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/dc18a51c1e4ddb399c362b9ac37f08e7/si132.gif si132 si132.gif gif 357 18 38 ALTIMG 1-s2.0-S0307904X12006038-si131.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/c25cb13e27cfa4a10a1c30d98d3af3fb/si131.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/c25cb13e27cfa4a10a1c30d98d3af3fb/si131.gif si131 si131.gif gif 498 18 81 ALTIMG 1-s2.0-S0307904X12006038-si13.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/47c03bb9821c6f76be61b9b2c0e5ebed/si13.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/47c03bb9821c6f76be61b9b2c0e5ebed/si13.gif si13 si13.gif gif 287 13 39 ALTIMG 1-s2.0-S0307904X12006038-si129.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/a4f074345871721545bca8e007b7930a/si129.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/a4f074345871721545bca8e007b7930a/si129.gif si129 si129.gif gif 753 17 221 ALTIMG 1-s2.0-S0307904X12006038-si128.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/3610628e2f4dbe20c9ff8f4da4e1987c/si135.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/3610628e2f4dbe20c9ff8f4da4e1987c/si135.gif si128 si128.gif gif 1111 19 316 ALTIMG 1-s2.0-S0307904X12006038-si126.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/a4f074345871721545bca8e007b7930a/si129.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/a4f074345871721545bca8e007b7930a/si129.gif si126 si126.gif gif 753 17 221 ALTIMG 1-s2.0-S0307904X12006038-si125.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/dc18a51c1e4ddb399c362b9ac37f08e7/si132.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/dc18a51c1e4ddb399c362b9ac37f08e7/si132.gif si125 si125.gif gif 357 18 38 ALTIMG 1-s2.0-S0307904X12006038-si124.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/641a67a6be13214298b7c2a3c6fadbf9/si136.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/641a67a6be13214298b7c2a3c6fadbf9/si136.gif si124 si124.gif gif 1701 21 375 ALTIMG 1-s2.0-S0307904X12006038-si123.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/dc18a51c1e4ddb399c362b9ac37f08e7/si132.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/dc18a51c1e4ddb399c362b9ac37f08e7/si132.gif si123 si123.gif gif 357 18 38 ALTIMG 1-s2.0-S0307904X12006038-si122.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/641a67a6be13214298b7c2a3c6fadbf9/si136.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/641a67a6be13214298b7c2a3c6fadbf9/si136.gif si122 si122.gif gif 1701 21 375 ALTIMG 1-s2.0-S0307904X12006038-si120.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/f0cc79c75d55ae20f6943eb1fce6d088/si156.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/f0cc79c75d55ae20f6943eb1fce6d088/si156.gif si120 si120.gif gif 188 14 11 ALTIMG 1-s2.0-S0307904X12006038-si12.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/ecbd15c065d0284c8c65bc420047e1ec/si12.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/ecbd15c065d0284c8c65bc420047e1ec/si12.gif si12 si12.gif gif 392 16 96 ALTIMG 1-s2.0-S0307904X12006038-si117.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/7e25d488a4e5f43072368a599ade9bb2/si117.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/7e25d488a4e5f43072368a599ade9bb2/si117.gif si117 si117.gif gif 383 16 96 ALTIMG 1-s2.0-S0307904X12006038-si116.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/225570d2b3f314736cd2f057f4354d93/si116.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/225570d2b3f314736cd2f057f4354d93/si116.gif si116 si116.gif gif 302 18 49 ALTIMG 1-s2.0-S0307904X12006038-si115.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/dd09c6ac4c084d42856906c3dac96eeb/si115.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/dd09c6ac4c084d42856906c3dac96eeb/si115.gif si115 si115.gif gif 274 18 47 ALTIMG 1-s2.0-S0307904X12006038-si112.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/139b0ec0afd88b38a2979a3a6d38f9d8/si138.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/139b0ec0afd88b38a2979a3a6d38f9d8/si138.gif si112 si112.gif gif 952 20 222 ALTIMG 1-s2.0-S0307904X12006038-si110.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/641a67a6be13214298b7c2a3c6fadbf9/si136.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/641a67a6be13214298b7c2a3c6fadbf9/si136.gif si110 si110.gif gif 1701 21 375 ALTIMG 1-s2.0-S0307904X12006038-si11.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/157359628594dd19b06ae0924351306f/si11.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/157359628594dd19b06ae0924351306f/si11.gif si11 si11.gif gif 604 25 97 ALTIMG 1-s2.0-S0307904X12006038-si109.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/a1e97b4c25a8bf801846c08562822ea1/si109.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/a1e97b4c25a8bf801846c08562822ea1/si109.gif si109 si109.gif gif 508 18 67 ALTIMG 1-s2.0-S0307904X12006038-si108.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/475169577f555ca8f62e55f33550e3db/si157.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/475169577f555ca8f62e55f33550e3db/si157.gif si108 si108.gif gif 1682 21 367 ALTIMG 1-s2.0-S0307904X12006038-si107.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/dc18a51c1e4ddb399c362b9ac37f08e7/si132.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/dc18a51c1e4ddb399c362b9ac37f08e7/si132.gif si107 si107.gif gif 357 18 38 ALTIMG 1-s2.0-S0307904X12006038-si106.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/5b4e443f6740189425706b29e5fe2515/si106.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/5b4e443f6740189425706b29e5fe2515/si106.gif si106 si106.gif gif 354 18 38 ALTIMG 1-s2.0-S0307904X12006038-si105.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/4761502850fc6f3ef4f27f5c0f35de82/si105.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/4761502850fc6f3ef4f27f5c0f35de82/si105.gif si105 si105.gif gif 249 21 18 ALTIMG 1-s2.0-S0307904X12006038-si104.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/9f7c7b27f30cd354201ede99395c9f9e/si104.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/9f7c7b27f30cd354201ede99395c9f9e/si104.gif si104 si104.gif gif 206 16 11 ALTIMG 1-s2.0-S0307904X12006038-si103.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/d8ea71c8936b2303d516c6060b52b179/si163.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/d8ea71c8936b2303d516c6060b52b179/si163.gif si103 si103.gif gif 219 13 17 ALTIMG 1-s2.0-S0307904X12006038-si102.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/05cab242a3f566f6abdf29ab9892dca3/si162.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/05cab242a3f566f6abdf29ab9892dca3/si162.gif si102 si102.gif gif 290 14 42 ALTIMG 1-s2.0-S0307904X12006038-si101.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/4cd1e6d39420e16881718af848a6b8dc/si161.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/4cd1e6d39420e16881718af848a6b8dc/si161.gif si101 si101.gif gif 311 14 71 ALTIMG 1-s2.0-S0307904X12006038-si100.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/09fa194213d5728afae93e79c70e786e/si100.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/09fa194213d5728afae93e79c70e786e/si100.gif si100 si100.gif gif 217 14 15 ALTIMG 1-s2.0-S0307904X12006038-si10.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/ad841a180ef14ae2f047bc4ee790b74b/si10.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/ad841a180ef14ae2f047bc4ee790b74b/si10.gif si10 si10.gif gif 276 16 29 ALTIMG 1-s2.0-S0307904X12006038-si1.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0307904X12006038/STRIPIN/image/gif/dc18a51c1e4ddb399c362b9ac37f08e7/si132.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0307904X12006038/STRIPIN/image/gif/dc18a51c1e4ddb399c362b9ac37f08e7/si132.gif si1 true si1.gif gif 357 18 38 ALTIMG APM 9146 S0307-904X(12)00603-8 10.1016/j.apm.2012.09.072 Elsevier Inc. Single machine scheduling with resource allocation and learning effect considering the rate-modifying activity Zhanguo Zhu a b e \u204e Feng Chu c Linyan Sun b Ming Liu d a College of Economics & Management, Nanjing Agricultural University, Nanjing 210095, PR China b School of Management, State Key Laboratory for Mechanical Manufacturing Systems Engineering, The Key Lab of the Ministry of Education for Process Control and Efficiency Engineering, Xi\u2019an Jiaotong University, Xi\u2019an, Shaanxi Province 710049, PR China c Laboratoire d\u2019informatique, Biologie Int\u00e9grative et Syst\u00e8mes Complexes (IBISC), EA 4526, Universit\u00e9 d\u2019Evry Val d\u2019Essonne, 91020 Evry Cedex, France d School of Economics & Management, Tongji University, Shanghai 200092, PR China e Universit\u00e9 de technologie de Troyes, Institut Charles Delaunay, FRE CNRS 2848, Laboratoire d\u2019optimisation des syst\u00e8mes industriels (LOSI), 12 rue Marie Curie \u2013 BP 2060, 10010 Troyes Cedex, France \u204e Corresponding author at: College of Economics & Management, Nanjing Agricultural University, Nanjing 210095, PR China. This paper addresses a single machine scheduling problem in which the actual job processing times are determined by resource allocation function, its position in a sequence and a rate-modifying activity simultaneously. We discuss two objective functions with two resource allocation functions under the consideration of a rate-modifying activity. We show that the problems are solvable in O ( n 4 ) time for a linear resource allocation function and are solvable in O ( n 2 logn ) time for a convex resource allocation function. Keywords Scheduling Rate-modifying activity Resource allocation Learning effect 1 Introduction In realistic scheduling system, job processing times are usually affected by many practical settings. Learning effect of workers, different amount of resources allocated to jobs and when to schedule the rate-modifying activity may change the production rate due to which job processing times are variable. Research involving human activities in production environment has received much attention in recent years and learning effect in the context of scheduling is one of the most important issues. The workers or processors obtain experience leading to the improvement of efficiency because of repeating similar or identical tasks. Such phenomenon is called learning effect. Biskup [1] was the first to discuss scheduling problems in a learning environment. He proposed an actual processing time formulation based on job scheduled positions which reflects the learning phenomenon and showed that the scheduling problems of minimizing the deviation from a common due date and minimizing the sum of flow times remain polynomially solvable. The well-known learning model can be expressed as follows: the actual processing time of job j if it is scheduled in position r in the sequence is p jr = p j r a , where p j is the normal job processing time of job j and a is the negative learning index. Mosheiov [2] proposed polynomial-time solutions still exist for the makespan minimization problem, multi-criteria single-machine problems and the minimum flow-time problem on parallel identical machines with similar learning effect setting to Biskup [1]. Lee and Wu [3] studied two-machine flowshop with a learning effect problem for the objective of minimizing total completion time. Bachman and Janiak [4] considered scheduling jobs with position-dependent processing times in which they proved the makespan minimization problem is strong NP-hard for two different models of learning effect. They proposed Earliest Ready Date algorithms and showed that the makespan minimization problem with job ready times and maximum lateness minimization problems are equivalent. Cheng et al. [5] discussed some scheduling problems with learning effects in which the actual processing time of a job is dependent on the total normal processing times of the jobs already processed and of the jobs scheduled position. Koulamas [6] showed that the makespan minimization problem with job-dependent learning effects by Mosheiov and Sidney [7] can be solved in O ( nlogn ) time under some respective assumptions. Other recent related studies are Biskub [8], Wang [9], Eren [10], Toksar and G\u00fcner [11], Cheng et al. [12], Janiak and Rudek [13], Wang et al. [14], and so on. In scheduling problems, the schedulers usually allocate finite amount of resource to a job to control its actual processing time. Many researchers focus on these kind of problems which are called scheduling problems with controllable processing problem since Vickson [15] initiated this field. Two different resource allocation functions were usually utilized in previous research. One is a linear function of the amount of resource associated to each job and the actual processing time under this setting can be defined as: p j A ( u j ) = p j - b j u j , 0 \u2a7d u j \u2a7d u \u00af j < p j b j , where j = 1 , 2 , \u2026 , n , p j is the nominal processing time of job j, b j > 0 is the compression rate of job j , u j is the amount of resource allocated to job j , u \u00af j is the maximal amount of resource that can be allocated to job j. Janiak and Kovalyov [16] considered single machine scheduling problem in which each job has a deadline and a controllable processing time based on linear resource allocation function. Two cases based on whether the resource is continuously divisible or discrete are considered. Hoogeveen and Woeginger [17] studied sequencing problems with controllable processing time and showed several polynomial time results for the maximum job cost criterion and an NP-hardness result for the total weighted job completion time criterion. The other is a convex function of the amount of resource allocated to each job and the controllable job processing time can be written as: p j A ( u j ) = ( p j u j ) k , for j = 1 , 2 , \u2026 , n , where k > 0 is a constant. Monma et al. [18] were among the pioneers that utilized this convex function in resource allocation problem. Kaspi and Shabtay [19] studied a scheduling problem with convex resource allocation function and job release dates for minimizing the makespan. They provided two polynomial time algorithms for two different cases of release dates. Shabtay and Kaspi [20] studied a single scheduling to minimize the total weighted flow time with convex resource function. They proposed an exact dynamic programming algorithm for small or medium size problem and heuristic algorithms for large-scale problems. Shabtay and Steiner [21], Zhu et al. [22], Wang et al. [23] and Koulamas et al. [24] analyzed scheduling problems with these two resource allocation functions in their work. Zhu et al. [25] investigated two single-machine scheduling problems with limited resource and deteriorating jobs. They presented polynomial solutions for two objectives under different limits. For details on scheduling problems with controllable processing times, see the most recent survey by Shabtay and Steiner [26]. Different from the common assumption of classic maintenance in scheduling, a rate-modifying activity improves the production rate of a machine by changing the processing times of jobs following the activity. Lee and Leon [27] first investigated scheduling with the rate-modifying activity based on the practical phenomenon in electronic industry. However, relatively limited literature has involved this field although it is very important in practical industry. Lee and Lin [28] discussed scheduling problems with maintenance and repair rate-modifying activities. In their work, they assumed that machine break down is random, studied two types of processing cases, and provided some interesting results for several expected objective functions. He et al. [29] studied scheduling problem under consideration of a restricted rate-modifying activity. They analyzed the computational complexity and proposed pseudo-polynomial time optimal or fully polynomial time approximation algorithm for two objective functions. Mosheiov and Oron [30] and Gordon and Tarasevich [31] discussed scheduling problems with a rate-modifying activity in the context of a common due-date. Zhao et al. [32] investigated two-parallel machines scheduling with rate-modifying activities and proposed efficient algorithms for two objective functions. Mosheiov and Sarig [33], Yang et al. [34] and Zhao and Tang [35] considered a rate-modifying activity in scheduling with a common due-window under different environment settings. Ji and Cheng [36] studied a scheduling problem with multiple rate-modifying activities. They allowed each machine to have multiple different rate-modifying activities and also introduced job-dependent learning effect into the problem. They provided polynomial solutions for the objective to minimize the total completion time. Lodree and Geiger [37] integrated time-dependent processing times and rate-modifying activity into the scheduling problem together. They pointed out that the specific position of the rate-modifying activity was in the middle of the task sequence. However, to the best of our knowledge, all the existing literature has studied the settings mentioned above independently except that Wang et al. [23] first combined the effects of learning and resource allocation together. In this paper, we extend their model to include an additional rate-modifying activity which makes the problem under study more reasonable and realistic. The rest of this paper is organized as follows. In Section 2 the problem formulation is presented. Some preliminary results for further analysis are provided in Section 3. Our optimal analysis for both objective functions with learning effect and rate-modifying activity is presented in Section 4. The last section concludes this paper. 2 Problem formulation The problem under the consideration of rate-modifying activity, learning effect, and resource allocation concurrently is described as follows. There are given a set J = ( J 1 , J 2 , \u2026 , J n ) of independent jobs to be processed on a single machine. Each job j is non-preemptive and available for processing at time 0. Associated with every job j there is a normal processing time p j . For any sequence \u03c0 = ( J [ 1 ] , J [ 2 ] , \u2026 , J [ n ] ) , J [ r ] denotes the job scheduled in position r, where r = 1 , 2 , \u2026 , n . In addition, there is a rate-modifying activity the duration of which is t on the single machine and no jobs are processed during the carrying out of the rate-modifying activity. Suppose the rate-modifying activity is in position i 1 if it is scheduled just after the completion of job in position i 1 . The processing times of jobs scheduled after the rate-modifying activity will be changed. In this paper we discuss two different resource allocation functions including the linear and the convex function. For the linear one, we assume the actual processing time of job j is p j A = p j ( r ) a - b j u j if it is scheduled in position r before the rat-modifying activity, otherwise, p j A = \u03b1 j p j ( r ) a - b j u j . \u03b1 j is the modifying rate, where 0 < \u03b1 j \u2a7d 1 . a is a learning index, u j denotes the amount of resource that can be allocated to job j, and b j is the compression rate of job j. For a job j , u j satisfies 0 \u2a7d u j \u2a7d u \u00af j < \u03b1 j p j ( n ) a b j . For the convex one, we assume the actual processing time of job j is p j A = p j ( r ) a u j k if it is scheduled in position r before the rate-modifying activity, otherwise, p j A = \u03b1 j p j ( r ) a u j k . For any sequence \u03c0 , C j = C j ( \u03c0 ) denotes the completion time of job j. As in Wang et al. [23], two cost functions discussed in this problem are f ( \u03c0 , u ) = \u03b2 1 C max + \u03b2 2 TC + \u03b2 3 TADC + \u03b2 4 \u2211 j = 1 n G j u j and g ( \u03c0 , u ) = \u03b2 1 C max + \u03b2 2 TW + \u03b2 3 TADW + \u03b2 4 \u2211 j = 1 n G j u j , where C max = max { C j | j = 1 , 2 , \u2026 , n } , TC = \u2211 j = 1 n C j , TW = \u2211 j = 1 n W j , TADC = \u2211 h = 1 n \u2211 j = h n | C h - C j | and TADW = \u2211 h = 1 n \u2211 j = h n | W h - W j | denote the makespan, the total completion times, total waiting times, the total absolute differences in completion times, and the total absolute differences in waiting times. W j = C j - p j A denotes the waiting time of job j. The definitions of TADC and TADW refer to Bagchi [38]. \u03b2 1 , \u03b2 2 , \u03b2 3 and \u03b2 4 are positive parameters decided by the decision-makers. G j is the unit time cost incurred by the resource allocation to job j. Following the three-field notation of Graham et al. [39], we denote our problems as 1 | RALE , RM | \u03b2 1 C max + \u03b2 2 TC + \u03b2 3 TADC + \u03b2 4 \u2211 j = 1 n G j u j and 1 | RALE , RM | \u03b2 1 C max + \u03b2 2 TW + \u03b2 3 TADW + \u03b2 4 \u2211 j = 1 n G j u j , where RALE means \u201cresource allocation and learning effect\u201d and RM means \u201crate-modifying activity\u201d. 3 Preliminary results In this section, we show some preliminary works for our further analysis of this problem. Based on the above notations and allowing to perform a rate-modifying activity in position i 1 , the completion time of each job j, for j = 1 , 2 , \u2026 , n can be presented in the following: For the linear case: C [ j ] = C [ j - 1 ] + ( p [ j ] ( j ) a - b [ j ] u [ j ] ) , j = 1 , 2 , \u2026 , i 1 , C [ j ] = C [ j - 1 ] + t + ( \u03b1 [ j ] p [ j ] ( j ) a - b [ j ] u [ j ] ) , j = i 1 + 1 , C [ j ] = C [ j - 1 ] + ( \u03b1 [ j ] p [ j ] ( j ) a - b [ j ] u [ j ] ) , j = i 1 + 2 , \u2026 , n . For the convex case: C [ j ] = C [ j - 1 ] + p [ j ] ( j ) a u [ j ] k , j = 1 , 2 , \u2026 , i 1 , C [ j ] = C [ j - 1 ] + t + \u03b1 [ j ] p [ j ] ( j ) a u [ j ] k , j = i 1 + 1 , C [ j ] = C [ j - 1 ] + \u03b1 [ j ] p [ j ] ( j ) a u [ j ] k , j = i 1 + 2 , \u2026 , n , where C [ 0 ] = 0 . The total completion time, the makespan, the total absolute differences in completion times, the total waiting time, and the total absolute differences in waiting times can be expressed as: For the linear case: C max = \u2211 j = 1 i 1 ( p [ j ] ( j ) a - b [ j ] u [ j ] ) + t + \u2211 j = i 1 + 1 n ( \u03b1 [ j ] p [ j ] ( j ) a - b [ j ] u [ j ] ) , TC = \u2211 j = 1 n C j = \u2211 j = 1 i 1 ( n - j + 1 ) ( p [ j ] ( j ) a - b [ j ] u [ j ] ) + \u2211 j = i 1 + 1 n ( n - j + 1 ) ( \u03b1 [ j ] p [ j ] ( j ) a - b [ j ] u [ j ] ) + ( n - i 1 ) t , TADC = \u2211 j = 1 i 1 ( j - 1 ) ( n - j + 1 ) ( p [ j ] ( j ) a - b [ j ] u [ j ] ) + \u2211 j = i 1 + 1 n ( j - 1 ) ( n - j + 1 ) ( \u03b1 [ j ] p [ j ] ( j ) a - b [ j ] u [ j ] ) + i 1 ( n - i 1 ) t , TW = \u2211 j = 1 i 1 ( n - j ) ( p [ j ] ( j ) a - b [ j ] u [ j ] ) + \u2211 j = i 1 + 1 n ( n - j ) ( \u03b1 [ j ] p [ j ] ( j ) a - b [ j ] u [ j ] ) + ( n - i 1 ) t ) , TADW = \u2211 j = 1 i 1 j ( n - j ) ( p [ j ] ( j ) a - b [ j ] u [ j ] ) + \u2211 j = i 1 + 1 n j ( n - j ) ( \u03b1 [ j ] p [ j ] ( j ) a - b [ j ] u [ j ] ) + i 1 ( n - i 1 ) t . For the convex case: C max = \u2211 j = 1 i 1 p [ j ] ( j ) a u [ j ] k + t + \u2211 j = i 1 + 1 n \u03b1 [ j ] p [ j ] ( j ) a u [ j ] k , TC = \u2211 j = 1 n C j = \u2211 j = 1 i 1 ( n - j + 1 ) p [ j ] ( j ) a u [ j ] k + \u2211 j = i 1 + 1 n ( n - j + 1 ) \u03b1 [ j ] p [ j ] ( j ) a u [ j ] k + ( n - i 1 ) t , TADC = \u2211 j = 1 i 1 ( j - 1 ) ( n - j + 1 ) p [ j ] ( j ) a u [ j ] k + \u2211 j = i 1 + 1 n ( j - 1 ) ( n - j + 1 ) \u03b1 [ j ] p [ j ] ( j ) a u [ j ] k + i 1 ( n - i 1 ) t , TW = \u2211 j = 1 i 1 ( n - j ) p [ j ] ( j ) a u [ j ] k + \u2211 j = i 1 + 1 n ( n - j ) \u03b1 [ j ] p [ j ] ( j ) a u [ j ] k , TADW = \u2211 j = 1 i 1 j ( n - j ) p [ j ] ( j ) a u [ j ] k + \u2211 j = i 1 + 1 n j ( n - j ) \u03b1 [ j ] p [ j ] ( j ) a u [ j ] k + i 1 ( n - i 1 ) t . Besides, a useful lemma that can be applied in Section 4 to solve the problem is as follows. Lemma 1 There are two vectors X and Y, the elements of which are x i and y i , respectively for i = 1 , 2 , \u2026 , n . If x i and y i are sorted in opposite order, \u2211 i = 1 n x i y i is the minimal value. Proof See the proof in page 261 by Hardy et al. [40].\u25a1 4 Optimal analysis for single-machine scheduling In this section, we present optimal analysis for single machine scheduling problem with resource consumption functions and performing a rate-modifying activity. We discuss two total cost functions for each kind of resource consumption function. As in Section 2, we denote the problems under them as 1 | RALE , RM | \u03b2 1 C max + \u03b2 2 TC + \u03b2 3 TADC + \u03b2 4 \u2211 j = 1 n G j u j and 1 | RALE , RM | \u03b2 1 C max + \u03b2 2 TW + \u03b2 3 TADW + \u03b2 4 \u2211 j = 1 n G j u j , respectively. The decisions to be made for each case of above problems include three parts: the resource assignment, the job sequencing and the position schedule of the rate-modifying activity. 4.1 Linear resource consumption function case In this subsection, we provide the optimal solutions for the problems under study with the linear resource consumption function. For the 1 | RALE , RM | \u03b2 1 C max + \u03b2 2 TC + \u03b2 3 TADC + \u03b2 4 \u2211 j = 1 n G j u j problem, considering the preliminary results, its cost function can be represented as: f ( \u03c0 , u ) = \u03b2 1 C max + \u03b2 2 TC + \u03b2 3 TADC + \u03b2 4 \u2211 j = 1 n G j u j = \u03b2 1 \u2211 j = 1 i 1 ( p [ j ] ( j ) a - b [ j ] u [ j ] ) + t + \u2211 j = i 1 + 1 n ( \u03b1 [ j ] p [ j ] ( j ) a - b [ j ] u [ j ] ) + \u03b2 2 \u2211 j = 1 i 1 ( n - j + 1 ) ( p [ j ] ( j ) a - b [ j ] u [ j ] ) + \u2211 j = i 1 + 1 n ( n - j + 1 ) ( \u03b1 [ j ] p [ j ] ( j ) a - b [ j ] u [ j ] ) + ( n - i 1 ) t + \u03b2 3 \u2211 j = 1 i 1 ( j - 1 ) ( n - j + 1 ) ( p [ j ] ( j ) a - b [ j ] u [ j ] ) + \u2211 j = i 1 + 1 n ( j - 1 ) ( n - j + 1 ) ( \u03b1 [ j ] p [ j ] ( j ) a - b [ j ] u [ j ] ) + i 1 ( n - i 1 ) t + \u03b2 4 \u2211 j = 1 n G j u j = \u2211 j = 1 i 1 ( \u03b2 1 + ( n - j + 1 ) \u03b2 2 + ( j - 1 ) ( n - j + 1 ) \u03b2 3 ) ( p [ j ] ( j ) a - b [ j ] u [ j ] ) + \u2211 j = i 1 + 1 n ( \u03b2 1 + ( n - j + 1 ) \u03b2 2 + ( j - 1 ) ( n - j + 1 ) \u03b2 3 ) ( \u03b1 [ j ] p [ j ] ( j ) a - b [ j ] u [ j ] ) + ( \u03b2 1 + \u03b2 2 ( n - i 1 ) + \u03b2 3 i 1 ( n - i 1 ) ) t + \u03b2 4 \u2211 j = 1 n G [ j ] u [ j ] . Let w j = \u03b2 1 + ( n - j + 1 ) \u03b2 2 + ( j - 1 ) ( n - j + 1 ) \u03b2 3 , (1) f ( \u03c0 , u ) = \u2211 j = 1 i 1 w j p [ j ] ( j ) a + \u2211 j = i 1 + 1 n w j \u03b1 [ j ] p [ j ] ( j ) a + \u2211 j = 1 n ( \u03b2 4 G [ j ] - w j b [ j ] ) u [ j ] + ( \u03b2 1 + \u03b2 2 ( n - i 1 ) + \u03b2 3 i 1 ( n - i 1 ) ) t . We discuss the determination of the resource allocation of each job j first. From above analysis, for given position of i 1 and job sequence, the amount ( u j ) of resource allocated to each job j depends on the coefficient \u03b2 4 G [ j ] - w j b [ j ] . If \u03b2 4 G [ j ] - w j b [ j ] is negative, considering the objective minimizing the cost function, the optimal amount of resource allocated should be u \u00af j , the upper bound of the amount of the resource. Similarly, if the coefficient \u03b2 4 G [ j ] - w j b [ j ] is positive, the optimal amount of resource allocated to job j should be 0. If \u03b2 4 G [ j ] - w j b [ j ] is equal to 0, any value between 0 and u \u00af j does not affect the cost function. So for any job j of a given sequence, the optimal resource allocation is expressed in the following. u [ j ] \u2217 = u \u00af [ j ] , if \u03b2 4 G [ j ] - w r b [ j ] < 0 , ( 2 ) u [ j ] \u2208 [ 0 , u \u00af [ j ] ] , if \u03b2 4 G [ j ] - w r b [ j ] = 0 , ( 3 ) 0 , if \u03b2 4 G [ j ] - w r b [ j ] > 0 . ( 4 ) u [ j ] \u2217 denotes the optimal amount of the resource allocated to job j, for j = 1 , 2 , \u2026 , n . Then we show the job sequence decision method. Set x jr = 1 if job j is scheduled in position r, otherwise x jr = 0 , where r = 1 , 2 , \u2026 , n . Let B jr = w r p j ( r ) a , if \u03b2 4 G [ j ] - w r b [ j ] \u2a7e 0 , r = 1 , \u2026 , i 1 , ( 5 ) w r p j ( r ) a + ( \u03b2 4 G [ j ] - w r b [ j ] ) u \u00af j , if \u03b2 4 G [ j ] - w r b [ j ] < 0 , r = 1 , \u2026 , i 1 , ( 6 ) w r \u03b1 j p j ( r ) a , if \u03b2 4 G [ j ] - w r b [ j ] \u2a7e 0 , r = i 1 + 1 , \u2026 , n , ( 7 ) w r \u03b1 j p j ( r ) a + ( \u03b2 4 G [ j ] - w r b [ j ] ) u \u00af j , if \u03b2 4 G [ j ] - w r b [ j ] < 0 , r = i 1 + 1 , \u2026 , n . ( 8 ) We can formulate the problem as the following binary integer programming problem: min \u2211 j = 1 n \u2211 r = 1 n B jr x jr + ( \u03b2 1 + \u03b2 2 ( n - i 1 ) + \u03b2 3 i 1 ( n - i 1 ) ) t subject to \u2211 r = 1 n x jr = 1 , j = 1 , 2 , \u2026 , n , \u2211 j = 1 n x jr = 1 , r = 1 , 2 , \u2026 , n , x jr = 1 or 0 , j = 1 , 2 , \u2026 , n , r = 1 , 2 , \u2026 , n . The first set of constraints guarantees each job is scheduled once and the second set of constraints guarantees each position is taken by only one job. The third set of constraints means x jr is a binary variable. For given position i 1 , the above problem is equivalent to minimize the following assignment problem. ( AP ) min \u2211 j = 1 n \u2211 r = 1 n B jr x jr subject to \u2211 r = 1 n x jr = 1 , j = 1 , 2 , \u2026 , n , \u2211 j = 1 n x jr = 1 , r = 1 , 2 , \u2026 , n , x jr = 1 or 0 , j = 1 , 2 , \u2026 , n , r = 1 , 2 , \u2026 , n . From above analysis, we propose the following polynomial time algorithm to solve optimally the 1 | RALE , RM | \u03b2 1 C max + \u03b2 2 TC + \u03b2 3 TADC + \u03b2 4 \u2211 j = 1 n G j u j problem. Algorithm 1. Step 1: Set i 1 = 1 . Step 2: Calculate the weight B jr with (5)\u2013(8). Step 3: Solve the assignment problem (AP) to obtain the local optimal sequence ( \u03c0 \u2032 ) and the total cost. Step 4: i 1 = i 1 + 1 . If i 1 \u2a7d n , then go to Step 2. Otherwise go to Step 5. Step 5: The global optimal sequence is the one with the minimum total cost, we denote the optimal sequence as \u03c0 \u2217 and the optimal position of rate-modifying activity as i 1 \u2217 . Step 6: Calculate the optimal resources by (2)\u2013(4) and calculate the actual processing time p j A to obtain the objective value. As we all know that this classical assignment problem can be solved with O ( n 3 ) (see [41,42], other related studies adopted this result include [1,36,43], etc.). Furthermore, to obtain the global schedule, since the position of rate-modifying activity is variable and may be 1, 2,\u2026, n, the complexity of the studied problem under linear resource function is O ( n 4 ) and the following theorem holds. Theorem 1 The 1 | RALE , RM | \u03b2 1 C max + \u03b2 2 TC + \u03b2 3 TADC + \u03b2 4 \u2211 j = 1 n G j u j problem under linear resource function can be solved in O ( n 4 ) time . Then we analyze the 1 | RALE , RM | \u03b2 1 C max + \u03b2 2 TW + \u03b2 3 TADW + \u03b2 4 \u2211 j = 1 n G j u j problem. The cost function can be represented as: g ( \u03c0 , u ) = \u03b2 1 C max + \u03b2 2 TW + \u03b2 3 TADW + \u03b2 4 \u2211 j = 1 n G j u j = \u03b2 1 \u2211 j = 1 i 1 ( p [ j ] ( j ) a - b [ j ] u [ j ] ) + t + \u2211 j = i 1 + 1 n ( \u03b1 [ j ] p [ j ] ( j ) a - b [ j ] u [ j ] ) + \u03b2 2 \u2211 j = 1 i 1 ( n - j ) ( p [ j ] ( j ) a - b [ j ] u [ j ] ) + \u2211 j = i 1 + 1 n ( n - j ) ( \u03b1 [ j ] p [ j ] ( j ) a - b [ j ] u [ j ] ) + ( n - i 1 ) t + \u03b2 3 \u2211 j = 1 i 1 j ( n - j ) ( p [ j ] ( j ) a - b [ j ] u [ j ] ) + \u2211 j = i 1 + 1 n j ( n - j ) ( \u03b1 [ j ] p [ j ] ( j ) a - b [ j ] u [ j ] ) + i 1 ( n - i 1 ) t + \u03b2 4 \u2211 j = 1 n G j u j = \u2211 j = 1 i 1 ( \u03b2 1 + ( n - j ) \u03b2 2 + j ( n - j ) \u03b2 3 ) ( p [ j ] ( j ) a - b [ j ] u [ j ] ) + \u2211 j = i 1 + 1 n ( \u03b2 1 + ( n - j ) \u03b2 2 + j ( n - j ) \u03b2 3 ) ( \u03b1 [ j ] p [ j ] ( j ) a - b [ j ] u [ j ] ) + ( \u03b2 1 + \u03b2 2 ( n - i 1 ) + \u03b2 3 i 1 ( n - i 1 ) ) t + \u03b2 4 \u2211 j = 1 n G [ j ] u [ j ] , Let \u03c6 j = \u03b2 1 + ( n - j ) \u03b2 2 + j ( n - j ) \u03b2 3 , (9) g ( \u03c0 , u ) = \u2211 j = 1 i 1 \u03c6 j p [ j ] ( j ) a + \u2211 j = i 1 + 1 n \u03c6 j \u03b1 [ j ] p [ j ] ( j ) a + \u2211 j = 1 n ( \u03b2 4 G [ j ] - \u03c6 j b [ j ] ) u [ j ] + ( \u03b2 1 + \u03b2 2 ( n - i 1 ) + \u03b2 3 i 1 ( n - i 1 ) ) t . Similar to the above analysis, the optimal resource allocation can be obtained from the following formulation. u [ j ] \u2217 = u \u00af [ j ] , if \u03b2 4 G [ j ] - \u03c6 r b [ j ] < 0 , ( 10 ) u [ j ] \u2208 [ 0 , u \u00af [ j ] ] , if \u03b2 4 G [ j ] - \u03c6 r b [ j ] = 0 , ( 11 ) 0 , if \u03b2 4 G [ j ] - \u03c6 r b [ j ] > 0 . ( 12 ) Set x jr = 1 if job j is scheduled in position r, otherwise x jr = 0 , where r = 1 , 2 , \u2026 , n . H jr = \u03c6 r p j ( r ) a , if \u03b2 4 G [ j ] - \u03c6 r b [ j ] \u2a7e 0 , r = 1 , \u2026 , i 1 , ( 13 ) \u03c6 r p j ( r ) a + ( \u03b2 4 G [ j ] - \u03c6 r b [ j ] ) u \u00af j , if \u03b2 4 G [ j ] - \u03c6 r b [ j ] < 0 , r = 1 , \u2026 , i 1 , ( 14 ) \u03c6 r \u03b1 j p j ( r ) a , if \u03b2 4 G [ j ] - \u03c6 r b [ j ] \u2a7e 0 , r = i 1 + 1 , \u2026 , n , ( 15 ) \u03c6 r \u03b1 j p j ( r ) a + ( \u03b2 4 G [ j ] - \u03c6 r b [ j ] ) u \u00af j , if \u03b2 4 G [ j ] - \u03c6 r b [ j ] < 0 , r = i 1 + 1 , \u2026 , n . ( 16 ) We can formulate the problem as the following binary integer programming problem: min \u2211 j = 1 n \u2211 r = 1 n H jr x jr + ( \u03b2 1 + \u03b2 2 ( n - i 1 ) + \u03b2 3 i 1 ( n - i 1 ) ) t subject to \u2211 r = 1 n x jr = 1 , j = 1 , 2 , \u2026 , n , \u2211 j = 1 n x jr = 1 , r = 1 , 2 , \u2026 , n , x jr = 1 or 0 , j = 1 , 2 , \u2026 , n , r = 1 , 2 , \u2026 , n . For given i 1 , the above problem can be transferred to minimize the following assignment problem. min \u2211 j = 1 n \u2211 r = 1 n H jr x jr subject to \u2211 r = 1 n x jr = 1 , j = 1 , 2 , \u2026 , n , \u2211 j = 1 n x jr = 1 , r = 1 , 2 , \u2026 , n , x jr = 1 or 0 , j = 1 , 2 , \u2026 , n , r = 1 , 2 , \u2026 , n . The algorithm for the 1 | RALE , RM | \u03b2 1 C max + \u03b2 2 TW + \u03b2 3 TADW + \u03b2 4 \u2211 j = 1 n G j u j problem is similar to the Algorithm 1, and its complexity is O ( n 4 ) . Theorem 2 The 1 | RALE , RM | \u03b2 1 C max + \u03b2 2 TW + \u03b2 3 TADW + \u03b2 4 \u2211 j = 1 n G j u j problem under linear resource function can be solved in O ( n 4 ) time. Special case: Now we discuss the following special case: we assume \u03b2 1 = \u03b2 3 = \u03b2 4 = G j = a = b j = 0 . As above analysis, its cost function can be represented as f ( \u03c0 , u ) = \u2211 j = 1 i 1 w j p [ j ] ( j ) a + \u2211 j = i 1 + 1 n w j \u03b1 [ j ] p [ j ] ( j ) a + \u2211 j = 1 n ( \u03b2 4 G [ j ] - w j b [ j ] ) u [ j ] + ( \u03b2 1 + \u03b2 2 ( n - i 1 ) + \u03b2 3 i 1 ( n - i 1 ) ) t , where w j = \u03b2 1 + ( n - j + 1 ) \u03b2 2 + ( j - 1 ) ( n - j + 1 ) \u03b2 3 . Considering the assumption that \u03b2 1 = \u03b2 3 = \u03b2 4 = G j = a = b j = 0 , w j = ( n - j + 1 ) \u03b2 2 , and f ( \u03c0 , u ) = \u03b2 2 \u2211 j = 1 i 1 ( n - j + 1 ) p [ j ] + \u03b2 2 \u2211 j = i 1 + 1 n ( n - j + 1 ) \u03b1 [ j ] p [ j ] + \u03b2 2 ( n - i 1 ) = \u03b2 2 \u2211 j = 1 i 1 ( n - j + 1 ) p [ j ] + \u2211 j = i 1 + 1 n ( n - j + 1 ) \u03b1 [ j ] p [ j ] + ( n - i 1 ) . It is easy find that this special case is just equivalent to one of Lee and Leon [27]\u2019s case of 1 / rm / \u2211 C j (please refer to page 122\u2013123 in their paper for details), the complexity is also O ( n 4 ) . 4.2 Convex resource consumption function case In this part, we provide the optimal solutions for the problems under study with the convex resource consumption function. For the 1 | RALE , RM | \u03b2 1 C max + \u03b2 2 TC + \u03b2 3 TADC + \u03b2 4 \u2211 j = 1 n G j u j problem, the: f ( \u03c0 , u ) = \u03b2 1 C max + \u03b2 2 TC + \u03b2 3 TADC + \u03b2 4 \u2211 j = 1 n G j u j = \u2211 j = 1 i 1 w j p [ j ] ( j ) a u [ j ] k + \u2211 j = i 1 + 1 n w j \u03b1 [ j ] p [ j ] ( j ) a u [ j ] k + \u2211 j = 1 n ( \u03b2 4 G [ j ] ) u [ j ] + ( \u03b2 1 + \u03b2 2 ( n - i 1 ) + \u03b2 3 i 1 ( n - i 1 ) ) t , where w j = \u03b2 1 + ( n - j + 1 ) \u03b2 2 + ( j - 1 ) ( n - j + 1 ) \u03b2 3 . For the 1 | RALE , RM | \u03b2 1 C max + \u03b2 2 TW + \u03b2 3 TADW + \u03b2 4 \u2211 j = 1 n G j u j problem, the cost function is expressed as: g ( \u03c0 , u ) = \u03b2 1 C max + \u03b2 2 TW + \u03b2 3 TADW + \u03b2 4 \u2211 j = 1 n G j u j = \u2211 j = 1 i 1 \u03c6 j p [ j ] ( j ) a u [ j ] k + \u2211 j = i 1 + 1 n \u03c6 j \u03b1 [ j ] p [ j ] ( j ) a u [ j ] k + \u2211 j = 1 n ( \u03b2 4 G [ j ] ) u [ j ] + ( \u03b2 1 + \u03b2 2 ( n - i 1 ) + \u03b2 3 i 1 ( n - i 1 ) ) t , where \u03c6 j = \u03b2 1 + ( n - j ) \u03b2 2 + j ( n - j ) \u03b2 3 . Following the analysis process of the linear case, we calculate the optimal resource allocation which is a function of a sequence of jobs first. Lemma 2 For any specified sequence \u03c0 , there exists an optimal resource allocation for the cost function f ( \u03c0 , u ) = \u03b2 1 C max + \u03b2 2 TC + \u03b2 3 TADC + \u03b2 4 \u2211 j = 1 n G j u j , which is: u [ j ] \u2217 = kw j \u03b2 4 G [ j ] 1 k + 1 p [ j ] ( j ) a k k + 1 , j = 1 , 2 , \u2026 , i 1 , ( 17 ) kw j \u03b2 4 G [ j ] 1 k + 1 p [ j ] ( j ) a k k + 1 \u03b1 [ j ] k k + 1 , j = i 1 + 1 , i 1 + 2 , \u2026 , n . ( 18 ) For the cost function g ( \u03c0 , u ) = \u03b2 1 C max + \u03b2 2 TW + \u03b2 3 TADW + \u03b2 4 \u2211 j = 1 n G j u j which is: u [ j ] \u2217 = k \u03c6 j \u03b2 4 G [ j ] 1 k + 1 ( p [ j ] ( j ) a ) k k + 1 , j = 1 , 2 , \u2026 , i 1 , ( 19 ) k \u03c6 j \u03b2 4 G [ j ] 1 k + 1 ( p [ j ] ( j ) a ) k k + 1 \u03b1 [ j ] k k + 1 , j = i 1 + 1 , i 1 + 2 , \u2026 , n . ( 20 ) Proof For the first cost function f ( \u03c0 , u ) , When j = 1 , 2 , \u2026 , i 1 , \u2202 f ( \u03c0 , u ) \u2202 u [ j ] = \u2202 w j p [ j ] ( j ) a u [ j ] k + \u03b2 4 G [ j ] u [ j ] \u2202 u [ j ] = \u03b2 4 G [ j ] - kw j ( p [ j ] ( j ) a ) k 1 u [ j ] k + 1 , Let \u2202 f ( \u03c0 , u ) \u2202 u [ j ] = 0 , we obtain u j \u2217 = kw j \u03b2 4 G [ j ] 1 k + 1 ( p [ j ] ( j ) a ) k k + 1 . When j = i 1 + 1 , i 1 + 2 , \u2026 , n , \u2202 f ( \u03c0 , u ) \u2202 u [ j ] = \u2202 w j \u03b1 [ j ] p [ j ] ( j ) a u [ j ] k + \u03b2 4 G [ j ] u [ j ] \u2202 u [ j ] = \u03b2 4 G [ j ] - kw j ( \u03b1 [ j ] p [ j ] ( j ) a ) k 1 u [ j ] k + 1 , Let \u2202 f ( \u03c0 , u ) \u2202 u [ j ] = 0 , we obtain u j \u2217 = kw j \u03b2 4 G [ j ] 1 k + 1 ( p [ j ] ( j ) a ) k k + 1 \u03b1 [ j ] k k + 1 . The proof for the second cost function g ( \u03c0 , u ) is similar.\u25a1 Substituting the optimal u \u2217 ( \u03c0 ) to both of the cost functions, we get the following new expression: (21) f \u02c6 ( \u03c0 , u \u2217 ( \u03c0 ) ) = k - k k + 1 + k 1 k + 1 ( \u03b2 4 ) k k + 1 \u2211 j = 1 n \u03c1 [ j ] \u03bc j + ( \u03b2 1 + \u03b2 2 ( n - i 1 ) + \u03b2 3 i 1 ( n - i 1 ) ) t , where, \u03c1 [ j ] = ( G [ j ] p [ j ] ) k k + 1 , j = 1 , 2 , \u2026 , i 1 , ( 22 ) ( \u03b1 [ j ] G [ j ] p [ j ] ) k k + 1 , j = i 1 + 1 , i 1 + 2 , \u2026 , n . ( 23 ) \u03bc j = ( w j ( j ) ak ) 1 k + 1 , for the first cost function, ( 24 ) ( \u03c6 j ( j ) ak ) 1 k + 1 , for the second cost function . ( 25 ) For any given position of rate-modifying activity i 1 , to minimize the problem expressed as in 21 is equivalent to minimizing the matching problem stated in Lemma 1. So based on the consideration of the rate-modifying activity and Lemma 1, we propose Algorithm 2 for The 1 | RALE , RM | \u03b2 1 C max + \u03b2 2 TC + \u03b2 3 TADC + \u03b2 4 \u2211 j = 1 n G j u j problem. Algorithm 2. Step 1: Set i 1 = 1 . Step 2: Calculate \u03c1 j and \u03bc j with (22)\u2013(24). Step 3: Obtain the local optimal job sequence with Lemma 1 and the total cost. Step 4: i 1 = i 1 + 1 . If i 1 \u2a7d n , then go to Step 2. Otherwise go to step 5. Step 5: The global optimal sequence is the one with the minimum total cost, we denote the optimal sequence as \u03c0 \u2217 and the optimal position of rate-modifying activity as i 1 \u2217 . Step 6: Calculate the optimal resources by (17) and (18) calculate the actual processing time to obtain the objective value. Theorem 3 The 1 | RALE , RM | \u03b2 1 C max + \u03b2 2 TC + \u03b2 3 TADC + \u03b2 4 \u2211 j = 1 n G j u j problem under convex resource function can be solved in O ( n 2 logn ) time. Proof For given position of rate-modifying activity i 1 , the problem with function f ( \u03c0 , u ( \u03c0 ) \u2217 ) can be solved within O ( nlogn ) by Lemma 2. In addition, the position i 1 may be 1 , 2 , \u2026 , n , so the overall complexity of Algorithm 2 for 1 | RALE , RM | \u03b2 1 C max + \u03b2 2 TC + \u03b2 3 TADC + \u03b2 4 \u2211 j = 1 n G j u j is O ( n 2 logn ) .\u25a1 Theorem 4 The 1 | RALE , RM | \u03b2 1 C max + \u03b2 2 TW + \u03b2 3 TADW + \u03b2 4 \u2211 j = 1 n G j u j problem under convex resource function can be solved in O ( n 2 logn ) time. Proof The proof and the algorithm are similar to Theorem 3 and algorithm 2, respectively.\u25a1 5 Conclusions The resource allocation, learning effect and the option for performing a rate-modifying activity have been investigated independently in recent years. The single machine scheduling problem with learning effect and resource allocation has been proved that it can be solved in O ( n 3 ) and O ( nlogn ) for different resource allocation functions in the literature. In this paper we extend the setting by allowing to perform a rate-modifying activity. We prove that the problem can be solved in O ( n 4 ) and O ( n 2 logn ) for different resource allocation function respectively. In future work, we will incorporate more realistic settings such as multiple rate-modifying activities, due-window assignment, and so on into the scheduling system. Acknowledgment This research was partially supported by the National Science Foundation of China under Grants 71201085, and 71101106. References [1] D. Biskup Single-machine scheduling with learning considerations Eur. J. Oper. Res. 115 1999 173 178 [2] G. Mosheiov Scheduling problems with learning effect Eur. J. Oper. Res. 132 2001 687 693 [3] W.-C. Lee C.-C. Wu Minimizing total completion time in a two-machine flowshop with a learning effect Int. J. Prod. Econ. 88 2004 85 93 [4] A. Bachman A. Janiak Scheduling jobs with position-dependent processing times J. Oper. Res. Soc. 55 2004 257 264 [5] T.C.E. Cheng C.-C. Wu W.-C. Lee Some scheduling problems with sum-of-processing-times-based and job-position-based learning effects Inform. Sci. 178 2008 2476 2487 [6] C. Koulamas A note on single-machine scheduling with job-dependent learning effects Eur. J. Oper. Res. 207 2010 1142 1143 [7] G. Mosheiov J.B. Sidney Scheduling with general job-dependent learning curves Eur. J. Oper. Res. 147 2003 665 670 [8] D. Biskup A state-of-the-art review on scheduling with learning effects Eur. J. Oper. Res. 188 2008 315 329 [9] J.-B. Wang Single-machine scheduling with past-sequence-dependent setup times and time-dependent learning effect Comput. Ind. Eng. 55 2010 584 591 [10] T. Eren Minmizing the total weighted completion time on a single machine scheduling with release dates and a learning effect Appl. Math. Comput. 208 2009 355 358 [11] D. Toksar E. G\u00fcner Parallel machine earliness/tardiness scheduling problem under the effects of position based learning and linear/nonlinear deterioration Comput. Oper. Res. 36 2009 2394 2417 [12] T.C.E. Cheng W.-C. Lee C.-C. Wu Scheduling problems with deteriorating jobs and learning effects including proportional setup times Comput. Ind. Eng. 58 2010 326 331 [13] A. Janiak R. Rudek A note on a makespan minimization problem with a multi-ability learning effect Omega 38 2010 213 217 [14] J.-B. Wang L.H. Sun L.Y. Sun Single machine scheduling with exponential sum-of-logarithm-processing-times based learning effect Appl. Math. Model. 34 2010 2813 2819 [15] R.G. Vickson Choosing the job sequence and processing times to minimize total processing plus flow cost on a single machine Operat. Res. 28 1980 1155 1167 [16] A. Janiak M.Y. Kovalyov Single machine scheduling subjective to deadlines and resource dependent processing times Eur. J. Oper. Res. 94 1996 284 291 [17] H. Hoogeveen G.J. Woeginger Some comments on sequencing with controllable processing times Computing 68 2002 181 192 [18] C.L. Monma A. Schrijver M.J. Todd V.K. Wei Convex resource allocation problems on directed acyclic graphs: duality, complexity, special cases and extensions Math. Operat. Res. 15 1990 736 748 [19] M. Kaspi D. Shabtay Convex resource allocation for minimizing the makespan in a single machine with job release dates Comput. Operat. Res. 31 2004 1481 1489 [20] D. Shabtay M. Kaspi Minimizing the total weighted flow time in a single machine with controllable processing times Comput. Operat. Res. 31 2004 2279 2289 [21] D. Shabtay G. Steiner The single-machine earliness-tardiness scheduling problem with due date assignment and resource-dependent processing times Ann. Oper. Res. 159 2008 25 40 [22] Z. Zhu L. Sun F. Chu M. Liu Single-machine group scheduling with resource allocation and learning effect Comput. Ind. Eng. 60 2011 148 157 [23] D. Wang M.-Z. Wang J.-B. Wang Single-machine scheduling with learning effect and resource-dependent processing times Comput. Ind. Eng. 59 2010 458 462 [24] C. Koulamas S. Gupta G.J. Kyparisis A unified analysis for the single-machine scheduling problem with controllable and non-controllable variable job processing times Eur. J. Oper. Res. 205 2010 479 482 [25] V.C.Y. Zhu L.Y. Sun L.H. Sun X.H. Li Single machine scheduling time-dependent jobs with resource-dependent ready times Comput. Ind. Eng. 58 2010 84 87 [26] D. Shabtay G. Steiner A survey of scheduling with controllable processing times Discrete Appl. Math. 155 2007 1643 1666 [27] C.-L. Lee V.-J. Leon Machine scheduling with a rate modifying activity Eur. J. Oper. Res. 129 2001 119 128 [28] C.-Y. Lee C.-S. Lin Single-machine scheduling with maintenance and repair rate-modifying activity Eur. J. Oper. Res. 135 2001 493 513 [29] Y. He M. Ji T.C.E. Cheng Single machine scheduling with a restricted rate-modifying activity Naval Res. Log. 52 2005 361 369 [30] G. Mosheiov D. Oron Due-date assignment and maintenance activity scheduling problem Math. Comput. Model. 44 2006 1053 1057 [31] V.S. Gordon A.A. Tarasevich A note: common due date assignment for a single machine scheduling with the rate-modifying activity Comput. Oper. Res. 36 2009 325 328 [32] C.L. Zhao H.Y. Tang C.D. Cheng Two-parallel machines scheduling with rate-modifying activities to minimize total completion time Eur. J. Oper. Res. 198 2009 354 357 [33] G. Mosheiov A. Sarig Scheduling a maintenance activity and due-window assignment on a single machine Comput. Oper. Res. 36 2009 2541 2545 [34] S.-J. Yang D.-L. Yang T.C.E. Cheng Single-machine due-window assignment and scheduling with job-dependent aging effects and deteriorating maintenance Comput. Oper. Res. 37 2010 1510 1514 [35] C.L. Zhao H.Y. Tang A note to due-window assignment and single machine scheduling with deteriorating jobs and a rate-modifying activity Comput. Oper. Res. 2010 online [36] M. Ji T.C.E. Cheng Scheduling with job-dependent learning effects and multiple rate-modifying activities Inform. Process. Lett. 110 2010 460 463 [37] E.J. Lodree Jr. C.D. Geiger A note on the optimal sequence position for a rate-modifying activity under simple linear deterioration Eur. J. Oper. Res. 201 2010 644 648 [38] U. Bagchi Simultaneous minimization of mean and variation of flow time and waiting time in single machine systems Oper. Res. 37 1989 118 125 [39] R.L. Graham E.L. Lawler J.K. Lenstra A.R. Kan Optimization and approximation in deterministic sequencing and scheduling: a survey Ann. Discrete Math. 5 1979 287 326 [40] G.H. Hardy J.E. Littlewood G. Polya Inequalities 1934 Cambridge University Press London [41] P. Brucker Scheduling Algorithms third ed. 2001 Springer Berlin [42] C.H. Papadimitriou K. Steiglitz Combinatorial Optimization: Algorithms and Complexity 1982 Prentice-Hall NewJersey [43] B.-C. Choi S.-H. Yoon S.-J. Chung Single machine scheduling problem with controllable processing times and resource dependent release times Eur. J. Oper. Res. 181 2007 645 653"
    },
    "10.1016/j.procs.2013.09.295": {
        "Title": "A Comparative Analysis of Data Privacy and Utility Parameter Adjustment, Using Machine Learning Classification as a Gauge",
        "Date": "2013",
        "Text": "serial JL 280203 291210 291871 31 90 Procedia Computer Science PROCEDIACOMPUTERSCIENCE 2013-11-14 2013-11-14 2014-11-04T06:36:18 1-s2.0-S1877050913010958 S1877-0509(13)01095-8 S1877050913010958 10.1016/j.procs.2013.09.295 S300 S300.6 HEAD-AND-TAIL 1-s2.0-S1877050913X00080 2021-10-14T13:14:58.733356Z 0 0 20130101 20131231 2013 2013-11-14T00:00:00Z rawtext articleinfo articletitlenorm authfirstinitialnorm authfirstsurnamenorm cid cids confeditor contenttype copyright crossmark dateloaded dateloadedtxt datesearch datesort dateupdated dco docsubtype doctype doi eid ewtransactionid hubeid indexeddate issn issnnorm itemstage itemtransactionid itemweight oauserlicense openaccess openarchive pg pgfirst pglast pii piinorm pubdateend pubdatestart pubdatetxt pubyr sortorder srctitle srctitlenorm srctype ssids alllist content oa subj suppl tomb vol volfirst volissue volumelist webpdf webpdfpagecount yearnav affil articletitle auth authfirstini authfull authkeywords authlast primabst ref 1877-0509 18770509 false 20 20 C Volume 20 68 414 419 414 419 2013 2013 2013-01-01 2013-12-31 2013 Complex Adaptive Systems Cihan H. Dagli article fla Copyright \u00a9 2013 The Authors. Published by Elsevier B.V. ACOMPARATIVEANALYSISDATAPRIVACYUTILITYPARAMETERADJUSTMENTUSINGMACHINELEARNINGCLASSIFICATIONAGAUGE MIVULE K MIVULE 2012 176 181 K RASTOGI 2007 531 542 V SRAMKA 2010 27 M WONG 2007 543 554 R MEYERSON 2004 223 228 A PARK 2007 67 78 H KRAUSE 2010 633 662 A WANG 2005 Y GHOSH 2008 A BRENNER 2010 71 80 H RASTOGI 2007 531 542 V LI 2009 517 526 T KATOS 2011 123 139 V DAYARATHNA 2011 194 206 R SPIEKERMANN 2012 S FRIEDEWALD 2010 61 67 M MATTHEWS 2011 1 29 G TIAN 2012 H PRIVACYPRESERVINGDATAMININGTHROUGHDATAPUBLISHINGKNOWLEDGEMODELSHARINGDISSERTATION MORTON 2012 429 436 S BAYARDO 2005 217 228 R IYENGAR 2002 279 288 V DUNHAMB 2003 58 60 M DATAMININGINTRODUCTORYADVANCEDTOPICSUPPERSADDLERIVER OGANIAN 2001 345 353 A MIVULE 2012 65 71 K BACHE 2013 K MIVULEX2013X414 MIVULEX2013X414X419 MIVULEX2013X414XK MIVULEX2013X414X419XK Full 2013-10-07T08:08:58Z http://creativecommons.org/licenses/by-nc-nd/3.0/ OA-Window ElsevierWaived 0 item S1877-0509(13)01095-8 S1877050913010958 1-s2.0-S1877050913010958 10.1016/j.procs.2013.09.295 280203 2014-11-04T06:27:53.631023-05:00 2013-01-01 2013-12-31 1-s2.0-S1877050913010958-main.pdf https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1877050913010958/MAIN/application/pdf/3d7a7667a0de5fc8d12a37388320afc4/main.pdf https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1877050913010958/MAIN/application/pdf/3d7a7667a0de5fc8d12a37388320afc4/main.pdf main.pdf pdf true 1745591 MAIN 6 1-s2.0-S1877050913010958-main_1.png https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1877050913010958/PREVIEW/image/png/70323cb0f91302a5f8d85e7a89e3fa1c/main_1.png https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1877050913010958/PREVIEW/image/png/70323cb0f91302a5f8d85e7a89e3fa1c/main_1.png main_1.png png 63570 849 656 IMAGE-WEB-PDF 1 Procedia Computer Science 20 ( 2013 ) 414 \u00e2\u20ac\u201c 419 1877-0509 2013 The Authors. Published by Elsevier B.V. Selection and peer-review under responsibility of Missouri University of Science and Technology doi: 10.1016/j.procs.2013.09.295 ScienceDirect Available online at www.sciencedirect.com Complex Adaptive Systems, Publication 3 Cihan H. Dagli, Editor in Chief Conference Organized by Missouri University of Science and Technology 2013- Baltimore, MD A Comparative Analysis of Data Privacy and Utility Parameter Adjustment, Using Machine Learning Classification as a Gauge Kato Mivule a and Claude Turner b a* ab Bowie State University, 14000 Jericho Park Road, Bowie, MD, 20715 Abstract During the data privacy process, the utility of datasets diminishes as sensitive information such as personal identifiable information (PII) is removed, transformed, or distorted to achieve confidentiality. The intractability of attaining an equilibrium between data privacy and utility needs is well documented, requiring trade-offs, and further complicated by the fact that making such trade-offs also remains problematic. Given such complexity, in this paper, we endeavor to empirically investigate what parameters could be fine-tuned to achieve an acceptable level of data privacy and utility during the data privacy process, while making reasonable trade-offs. Therefore, we present the comparative classification error gauge (Comparative x-CEG) approach, a data utility quantification concept that employs machine learning classification techniques to gauge data utility based on the classification error. In this approach, privatized datasets are passed through a series of classifiers, each of which returns a classification error, and the classifier with the lowest classification error is chosen; if the classification error is lower or equal to a set threshold then better utility might be achieved, otherwise, adjustment to the data privacy parameters are made to the chosen classifier. The process repeats x times until the desired threshold is reached. The goal is to generate empirical results after a range of parameter adjustments in the data privacy process, from which a threshold level might be chosen to make trade-offs. Our preliminary results show that given a range of empirical results, it might be possible to choose a tradeoff point and publish privacy compliant data with an acceptable level of utility. Keywords: Data privacy; utility; machine learning classifiers; comparative data analysis 1. Introduction During the privacy preserving process, the utility of a dataset a measure of how useful a privatized dataset is to the user of that dataset diminishes as sensitive data such as PII is removed, transformed, or distorted to achieve confidentiality [1, 2, 3]. Yet, finding equilibrium between privacy and utility needs remains intractable, necessitating trade-offs [4, 5, 6]. For example, by using the suppression of data that is removing or deleting sensitive attributes before publication of data, privacy might be guaranteed to an extent that the PII and other sensitive data is removed. * Corresponding author. Tel.: 443-333-6169 E-mail address: mivulek0220@students.bowiestate.edu 2013 The Authors. Published by Elsevier B.V. Selection and peer-review under responsibility of Missouri University of Science and Technology Open access under CC BY-NC-ND license. Open access under CC BY-NC-ND license. 415 Kato Mivule and Claude Turner / Procedia Computer Science 20 ( 2013 ) 414 \u00e2\u20ac\u201c 419 However, a researcher using such a published dataset might find it difficult to fully account for some categorical entries despite confidentiality guarantees provided to that privatized dataset. In another example involving numerical data, employing high noise perturbation levels to provide privacy for sensitive numerical data might render the privatized dataset useless to a researcher as too much noise distorts the original traits of the data. Given such intricacy, in this paper, we attempt to empirically explore what parameters could be adjusted to attain an adequate level of data privacy and utility during the data privacy process, while making practical trade-offs. We present the comparative classification error gauge (Comparative x-CEG) approach, a data utility quantification model that uses machine learning classification techniques to gauge data utility based on the classification error. The remaining part of this paper is ordered as follows. Section 2 discusses background and related work. Section 3 presents our methodology and experiment. In section 4, we present preliminary results. Finally, in section 5, provides concluding remarks. 2. Background and Related Work The task of achieving a satisfactory level of data utility while preserving privacy is a well-documented NP-hard problem that would necessitate trade-offs [7, 8]. Additionally, the problem is further complicated by the fact that attaining such trade-offs also remains intractable. Researchers have observed that the problem of preserving confidentiality while publishing useful statistical data is extensive and that the trade-off between the privacy and the utility of any anonymization technique, would largely depend on the level of background knowledge about a particular dataset, with higher levels indicating that it would be impossible to achieve any such trade-offs [9, 10, 11]. Li and Li (2009) indicated in their study that it is not promising to equate privacy and utility as datasets get distorted when they are privatized, leading to a decline of utility [12]. Even with the latest state of the art data privacy algorithms like differential privacy, confidentiality is guaranteed but at a major loss of data utility [13]. As Dwork (2006) concisely put it [14], utility; perfect utility can b . In other words, the more confidential data is made to be, the more likely that the privatized data will be become useless and decline in utility. The privacy definition problem: On the other hand, there happens to be no specific standard metric to define privacy, as Katos, Stowell, and Bedner (2011) observed, that privacy is a human and socially driven characteristic comprised of human traits such as acuities and sentiments [15]. Dayarathna (2011) stated that to wholly comprehend the notion of data privacy, an all-inclusive methodology to outlining data privacy should include the legal, technical, and ethical facets [16]. This point is additionally exemplified by Spiekermann (2012) who noted that one of the difficulties in designing and engineering data privacy is that the idea of privacy is fuzzy, frequently confused with data security, and as a result, very problematic to implement [17]. Adding to this point, Friedewald, Wright, Gutwirth, and Mordini (2010), in their research on the legal aspects of data privacy stated that since privacy is an evolving and shifting complex multi-layered notion, being described and treasured otherwise by various people; and that empirical studies are needed to assess how different people define and value privacy [18]. As Mathews and Harel (2011) observed, the human element remains a key factor and as such data privacy is intrinsically tied to fuzziness and evolutions of how individuals view privacy, and the same applies to data utility; that is, what information about themselves that individuals determine as fit to share with others [19]. Therefore, it becomes problematic to create a generalized data privacy and utility solution; however, different individuals and entities will have different data privacy needs and thus tailored data privacy solutions. Given the complexities of defining privacy, quantifying data utility is likewise problematic. However, various methods have been employed to enumerate data utility by basically quantifying the statistical differences between the original and privatized datasets, such as, the relative query error metric, research value metric, discernibility data metric, classification error metric, the Shannon entropy, and the information loss metric (mean square error) [ 20, 21, 22, 23, 24, 25]. However, in this paper, we suggest using the machine learning as a gauge, by using the classification error to adjust data privacy parameters until a desired threshold is attained. 2.1. Essential Terms While a number of data privacy algorithms exist, in this paper, the subsequent methods are used. Noise addition: is a data privacy algorithm in which random numbers selected from a normal distribution with zero mean and a standard deviation are added to data for obfuscation, and is expressed by [26, 27]: 416 Kato Mivule and Claude Turner / Procedia Computer Science 20 ( 2013 ) 414 \u00e2\u20ac\u201c 419 (1) X is the original numerical data and is the set of random numbers (noise) with a distribution that is added to X, and Z is the privatized dataset [26, 27]. Multiplicative noise: random numbers whose mean \u00ce\u00bc= 1 and a small variance are produced, and then multiplied to the original data, generating confidential data, expressed as follows: [27, 28]: (2) Where is the original data; is the random numbers with mean \u00ce\u00bc= 1 and a small variance ; is the confidential data after multiplying and [27, 28]. Logarithmic noise: makes a logarithmic modification of the original data as shown below [26, 28]: (3) Random values are then produced and added to the data that underwent a logarithmic alteration . Lastly, the confidential data, , is generated as given in Equation (4) [26, 28]: (4) Note that the original data is represented by ; is the logarithmic altered data values; and is the confidential data. 3. Methodology The Comparative x-CEG approach: We present the Comparative Classification Error Gauge (x-CEG) approach. This approach is motivated by a need to investigate how a dataset that is subjected to various data privacy algorithms performs under different machine classifiers. Empirical results from this process are then gathered and a comparative analysis is performed to determine the best classifier. In the comparative x-CEG approach, a data privacy algorithm is applied on a dataset, where are the various data privacy procedures, as shown in Fig 1. The privatized datasets is generated, where are the new privatized datasets with each corresponding to . The privatized datasets are passed through a series of machine learning classifiers, where is the different machine learning classifiers. Statistical properties of the privatized datasets, after applying the various data privacy algorithms are quantified. The classification error from each classifier is then measured and the classifier with the lowest classification error is chosen. If the classification error of that chosen classifier is lower or equal to a set threshold, then better utility might be achieved; otherwise, an adjustment of the data privacy parameters of and or the machine learning parameters of the chosen classifier. , is made. The results are resent to the classifier and a measure of the classification error is done again. The procedure replicates until a desired classification error using the chosen classifier is achieved, indicating a better utility for the user of that privatized dataset. The advantages of this approach is that multiple checks for utility using various classifiers is achieved but also a more in-depth comparative analysis is done and as such a knowledge of which machine learning classifier works best on which dataset. Secondly, since a large dataset of empirical data is generated, choosing a reasonable threshold (trade-off) point becomes feasible. 4. Experiment This section presents the experiment setup and preliminary results to be used. The Iris Fisher multivariate dataset from the UCI repository [29], with both numeric and categorical data was used. One hundred and fifty data points were used as the original dataset. The dataset consisted of numeric attributes: sepal length, sepal width, petal length, and petal width. It also included one categorical attribute with three classes, Iris-Setosa, Iris-Versicolor, and Iris- Virginica. Three data privacy algorithms were applied on the original data set; namely, noise addition, logarithmic noise, and multiplicative noise. The comparative x-CEG algorithm was applied, using KNN, Neural Nets, Decision Trees, AdaBoost, and Na\u00c3\u00afve Bayes classification methods. MATLAB and RapidMiner were employed as tools in this experiment. The original Iris dataset with 150 records was imported into MATLAB and then vertically partitioned with the first partition containing the continuous data and the second partition containing categorical data of class labels. Data privacy algorithms were applied on the continuous portion of the data, and the categorical 417 Kato Mivule and Claude Turner / Procedia Computer Science 20 ( 2013 ) 414 \u00e2\u20ac\u201c 419 portion was used in classification of the data. The datasets were then set to RapidMiner, and a series of machine learning classification techniques was applied on both the original Iris data and the various privatized Iris datasets, allowing for an implementation of the Comparative x-CEG concept. Fig. 1. The Comparative x-CEG procedure 4.1. Results Fig. 2. (a) The comparative x-CEG classification error results; (b) The suggested tradeoff point (threshold) at 0.2 classification error 418 Kato Mivule and Claude Turner / Procedia Computer Science 20 ( 2013 ) 414 \u00e2\u20ac\u201c 419 Fig. 3. Statistical distribution for the original data and privatized data using noise addition, logarithmic, and multiplicative privacy 4.2. Discussion As shown in Fig. 2. (a)., using the original Iris dataset as a benchmark, the lowest classification error was 0.04 for the original data using KNN, with 0.06 for AdaBoost Ensemble for the highest classification error. For a normal original Iris dataset without privacy, classification error is less than 1 percent. However, after applying noise addition privacy method, the classification error is at average 0.3, approximately 30 percent misclassification with the non-adjusted mean and variance. Still, after adjusting noise addition parameters, with the mean set to 0 and variance at 0.1, the classification error drops on average to 0.04, similar to the original dataset. While such close results might be appealing on a data utility basis, the privacy of such a dataset is significantly diminished as the dataset becomes similar to the original. Additionally, the classification error for both logarithmic and multiplicative noise is on average 0.4, approximately 40 per cent misclassification. On the privacy basis, both logarithmic and multiplicative noise provides better privacy. And, as shown in Fig. 3, in the scatter plots, it is very difficult to separate or cluster data after applying logarithmic and multiplicative noise. However, the utility of such datasets is not appealing when approximately 40 percent of the data is misclassified. As illustrated in Fig. 2. (b)., after generating empirical data, a preferred threshold or trade-off point classification error is set at 0.2, approximately 20 percent misclassification. However, this could be lower, depending on user privacy and utility needs. 5. Conclusion Employing the Comparative x-CEG methodology by adjusting data privacy parameters could generate adequate empirical data to assist in selecting a trade-off point for preferred data privacy and utility levels. However, more rigorous empirical studies are needed to further test this hypothesis. Furthermore, finding the optimal balance between privacy and utility needs remains an intractable problem, and, as such, for future work, we seek to study optimal trade-off points based on larger empirical datasets, and on a case by case basis. Also, we plan to conduct analytical and empirical work comparing various data privacy algorithms not covered in this study. 419 Kato Mivule and Claude Turner / Procedia Computer Science 20 ( 2013 ) 414 \u00e2\u20ac\u201c 419 References 1. K. Mivule, C. Turner, and S.- Computer Science, 2012, vol. 12, pp. 176 181. 2. rence 542. 3. M. Sramka, R. Safavi-naini, J. -oriented Framework for Measuring Privacy and Utility in Data 4. R. C.-W. Wong, A. W.-C. Fu, K. Wan 33rd international conference on Very large data bases, pp. 543 554, 2007. 5. - of the twenty third ACM SIGMOD- SIGACT-SIGART symposium on Principles of database systems PODS 04, 2004, pp. 223 228. 6. - conference on Management of data SIGMOD 07, 2007, pp. 67 78. 7. - vol. 39, pp. 633 662, 2010. 8. Y. W. Y. Wang and X. W. X. Wu, Approximate inverse frequent itemset mining: privacy, complexity, and approximation. 2005. 9. - annual ACM symposium on Symposium on theory of computing STOC 09, p. 351, 2008. 10. 80, 2010. 11. between , pp. 531 542, 2007. 12. ACM SIGKDD, 9, pp. 517 526, 2009. 13. -utility tradeoff for multi-dimensional Privacy in Statistical Databases, Vol. 6344., Josep Domingo-Ferrer and Emmanouil Magkos, Eds. Springer, 2011, pp. 187 199. 14. eneel, V. Sassone, and I. Wegener, Eds. Springer, 2006, pp. 1 12. 15. Computer Science Volume 6514, 2011, pp. 123 139. 16. JICLT, vol. 6, no. 4, pp. 194 206, 2011. 17. 18. acy, data protection and emerging sciences and technologies: towards a 67, Mar. 2010. 19. hods for statistical disclosure limitation and methods for assessing 29, 2011. 20. - Dissertation, The University of Texas at San Antonio, 2012. 21. ACM SIGHIT symposium on International health informatics - 436. 22. R. J. Bayardo and R. - 228, 2005. 23. , 288, 2002. 24. M. H. Dunham(b), Data Mining, Introductory and Advanced Topics. Upper Saddle River, New Jersey: Prentice Hall, 2003, pp. 58 60. 25. A. Oganian and J. Domingo- Journal of the United Nations Economic Commission for Europe, vol. 4, no. 18, pp. 345 353., 2001. 26. Research Methods, American Statistical Association,, 1986, vol. Jay Kim, A, no. 3, pp. 370 374. 27. 71, 2012. 28. -01, Statistical Research 29. - and Computer Science., Irvine, CA, 2013. er, after applying noise addition privacy method, the classification error is at average 0.3, approximately 30 percent misclassification with the non-adjusted mean and variance. Still, after adjusting noise addition parameters, with the mean set to 0 and variance at 0.1, the classification error drops on average to 0.04, similar to the original dataset. While such close results might be appealing on a data utility basis, the privacy of such a dataset is significantly diminished as the dataset becomes similar to the original. Additionally, the classification error for both logarithmic and multiplicative noise is on average 0.4, approximately 40 per cent misclassification. On the privacy basis, both logarithmic and multiplicative noise provides better privacy. And, as shown in Fig. 3, in the scatter plots, it is very difficult to separate or cluster data after applying logarithmic and multiplicative noise. However, the utility of such datasets is not appealing when approximately 40 percent of the data is misclassified. As illustrated in Fig. 2. (b)., after generating empirical data, a preferred threshold or trade-off point classification error is set at 0.2, approximately 20 percent misclassification. However, this could be lower, depending on user privacy and utility needs. 5. Conclusion Employing the Comparative x-CEG methodology by adjusting data privacy parameters could generate adequate empirical data to assist in selecting a trade-off point for preferred data privacy and utility levels. However, more rigorous empirical studies are needed to further test this hypothesis. Furthermore, finding the optimal balance between privacy and utility needs remains an intractable problem, and, as such, for future work, we seek to study optimal trade-off points based on larger empirical datasets, and on a case by case basis. Also, we plan to conduct analytical and empirical work comparing various data privacy algorithms not covered in this study. 419 Kato Mivule and Claude Turner / Procedia Computer Science 20 ( 2013 ) 414 \u00e2\u20ac\u201c 419 References 1. K. Mivule, C. Turner, and S.- Computer Science, 2012, vol. 12, pp. 176 181. 2. rence 542. 3. M. Sramka, R. Safavi-naini, J. -oriented Framework for Measuring Privacy and Utility in Data 4. R. C.-W. Wong, A. PROCS 2701 S1877-0509(13)01095-8 10.1016/j.procs.2013.09.295 The Authors \u2606 Selection and peer-review under responsibility of Missouri University of Science and Technology. A Comparative Analysis of Data Privacy and Utility Parameter Adjustment, Using Machine Learning Classification as a Gauge Kato Mivule \u204e Claude Turner Bowie State University, 14000 Jericho Park Road, Bowie, MD, 20715 \u204e Corresponding author. Tel.: +443 333 6169. During the data privacy process, the utility of datasets diminishes as sensitive information such as personal identifiable information (PII) is removed, transformed, or distorted to achieve confidentiality. The intractability of attaining an equilibrium between data privacy and utility needs is well documented, requiring trade-offs, and further complicated by the fact that making such trade-offs also remains problematic. Given such complexity, in this paper, we endeavor to empirically investigate what parameters could be fine-tuned to achieve an acceptable level of data privacy and utility during the data privacy process, while making reasonable trade-offs. Therefore, we present the comparative classification error gauge (Comparative x-CEG) approach, a data utility quantification concept that employs machine learning classification techniques to gauge data utility based on the classification error. In this approach, privatized datasets are passed through a series of classifiers, each of which returns a classification error, and the classifier with the lowest classification error is chosen; if the classification error is lower or equal to a set threshold then better utility might be achieved, otherwise, adjustment to the data privacy parameters are made to the chosen classifier. The process repeats x times until the desired threshold is reached. The goal is to generate empirical results after a range of parameter adjustments in the data privacy process, from which a threshold level might be chosen to make trade-offs. Our preliminary results show that given a range of empirical results, it might be possible to choose a tradeoff point and publish privacy compliant data with an acceptable level of utility. Keywords Data privacy utility machine learning classifiers comparative data analysis References [1] K. Mivule C. Turner S.-Y. Ji Towards A Differential Privacy and Utility Preserving Machine Learning Classifier in Procedia Computer Science 12 2012 176 181 [2] V. Rastogi D. Suciu S. Hong The Boundary Between Privacy and Utility in Data Publishing in 33rd international conference on Very large data bases (VLDB\u2019 07) 2007 531 542 [3] M. Sramka R. Safavi-naini J. Denzinger M. Askari A Practice-oriented Framework for Measuring Privacy and Utility in Data Sanitization Systems Categories and Subject Descriptors in In Proceedings of the 2010 EDBT/ICDT Workshops 2010 27 [4] R.C.-W. Wong A.W.-C. Fu K. Wang J. Pei Minimality Attack in Privacy Preserving Data Publishing Proceedings of the 33rd international conference on Very large data bases 2007 543 554 [5] A. Meyerson R. Williams On the complexity of optimal K-anonymity in Proceedings of the twenty third ACM SIGMOD- SIGACT-SIGART symposium on Principles of database systems PODS 04 2004 223 228 [6] H. Park K. Shim Approximate algorithms for K-anonymity in Proceedings of the 2007 ACM SIGMOD international conference on Management of data SIGMOD 07 2007 67 78 [7] A. Krause E. Horvitz A Utility-Theoretic Approach to Privacy in Online Services Journal of Artificial Intelligence Research 39 2010 633 662 [8] Y.W.Y. Wang X.W.X. Wu Approximate inverse frequent itemset mining: privacy, complexity, and approximation. 2005 [9] A. Ghosh T. Roughgarden M. Sundararajan Universally Utility-Maximizing Privacy Mechanisms Proceedings of the 41st annual ACM symposium on Symposium on theory of computing STOC 09 351 2008 [10] H. Brenner K. Nissim Impossibility of Differentially Private Universally Optimal Mechanisms FOCS, no. 860 2010 71 80 [11] V. Rastogi D. Suciu S. Hong The Boundary between Privacy and Utility in Data Publishing VLDB\u2019 07 2007 531 542 [12] T. Li N. Li On the tradeoff between privacy and utility in data publishing ACM SIGKDD KDD\u2019 09 2009 517 526 [13] S. Fienberg, A. Rinaldo, and X. Yang, \u201cDifferential privacy and the risk-utility tradeoff for multi-dimensional contingency tables\u201d in Privacy in Statistical Databases, Vol. 6344., Josep Domingo-Ferrer and Emmanouil Magkos, Eds. Springer, 2011, pp. 187-199. [14] C. Dwork, \u201cDifferential Privacy\u201d in Automata languages and programming, vol. 4052, no. d, M. Bugliesi, B. Preneel, V. Sassone, and Wegener, Eds. Springer, 2006, pp. 1-12. [15] V. Katos F. Stowell P. Bednar Data Privacy Management and Autonomous Spontaneous Security in Lecture Notes in Computer Science 6514 2011 123 139 [16] R. Dayarathna Taxonomy for Information Privacy Metrics JICLT 6 4 2011 194 206 [17] S. Spiekermann The challenges of privacy by design Communications of the ACM 55 7 38, Jul 2012 [18] M. Friedewald D. Wright S. Gutwirth E. Mordini Privacy, data protection and emerging sciences and technologies: towards a common framework, Innovation: The European Journal of Social Science Research 23 1 Mar 2010 61 67 [19] G.J. Matthews O. Harel Data confidentiality: A review of methods for statistical disclosure limitation and methods for assessing privacy Statistics Surveys 5 2011 1 29 [20] H. Tian Privacy-preserving data mining through data publishing and knowledge model sharing, Dissertation 2012 The University of Texas at San Antonio [21] S. Morton M. Mahoui P.J. Gibson Data anonymization using an improved utility measurement in Proceedings of the 2nd ACM SIGHIT symposium on International health informatics - IHI\u2019 12 2012 429 436 [22] R.J. Bayardo R. Agrawal Data Privacy through Optimal k-Anonymization in 21st ICDE\u2019 05 2005 217 228 [23] V.S. Iyengar Transforming data to satisfy privacy constraints ACM SIGKDD KDD\u2019 02 2002 279 288 [24] M.H. Dunham(b) Data Mining, Introductory and Advanced Topics. Upper Saddle River 2003 Prentice Hall New Jersey 58 60 [25] A. Oganian J. Domingo-ferrer On the complexity of optimal microaggregation for statistical disclosure control Statistical Journal of the United Nations Economic Commission for Europe 4 18 2001 345 353 [26] J. Kim, \u201cA Method For Limiting Disclosure in Microdata Based Random Noise and Transformation\u201d in Proceedings of the Survey Research Methods, American Statistical Association,, 1986, vol. Jay Kim, A, no. 3, pp. 370-374. [27] K. Mivule Utilizing Noise Addition for Data Privacy, an Overview, in IKE 2012 2012 65 71 [28] J. J. Kim and W. E. Winkler, \u201cMultiplicative Noise for Masking Continuous Data, Research Report Series, Statistics #2003-01, Statistical Research Division\u201d Washington, D.C., 2003. [29] K. Bache M. Lichman Iris Fisher Dataset - UCI Machine Learning Repository. University of California, School of Information and Computer Science., Irvine, CA 2013"
    },
    "10.1016/j.procir.2013.05.033": {
        "Title": "Quality Prediction in Interlinked Manufacturing Processes based on Supervised & Unsupervised Machine Learning",
        "Date": "2013",
        "Text": "serial JL 282173 291210 291885 31 90 Procedia CIRP PROCEDIACIRP 2013-06-24 2013-06-24 2014-11-04T06:36:18 1-s2.0-S2212827113002400 S2212-8271(13)00240-0 S2212827113002400 10.1016/j.procir.2013.05.033 S300 S300.3 HEAD-AND-TAIL 1-s2.0-S2212827113X00046 2021-10-18T13:09:52.337333Z 0 0 20130101 20131231 2013 2013-06-24T00:00:00Z rawtext articleinfo articletitlenorm authfirstinitialnorm authfirstsurnamenorm cid cids confeditor contenttype copyright crossmark dateloaded dateloadedtxt datesearch datesort dateupdated dco docsubtype doctype doi eid ewtransactionid hubeid indexeddate issn issnnorm itemstage itemtransactionid itemweight oauserlicense openaccess openarchive pg pgfirst pglast pii piinorm pubdateend pubdatestart pubdatetxt pubyr sortorder srctitle srctitlenorm srctype ssids alllist content oa subj suppl tomb vol volfirst volissue volumelist webpdf webpdfpagecount yearnav affil articletitle auth authfirstini authfull authkeywords authlast primabst ref 2212-8271 22128271 false 7 7 C Volume 7 33 193 198 193 198 2013 2013 2013-01-01 2013-12-31 2013 Forty Sixth CIRP Conference on Manufacturing Systems 2013 Pedro F. Cunha article fla Copyright \u00a9 2013 The Authors. Published by Elsevier B.V. QUALITYPREDICTIONININTERLINKEDMANUFACTURINGPROCESSESBASEDSUPERVISEDUNSUPERVISEDMACHINELEARNING LIEBER D LIEBERX2013X193 LIEBERX2013X193X198 LIEBERX2013X193XD LIEBERX2013X193X198XD Full 2013-07-16T12:28:15Z http://creativecommons.org/licenses/by-nc-nd/3.0/ OA-Window ElsevierWaived 0 item S2212-8271(13)00240-0 S2212827113002400 1-s2.0-S2212827113002400 10.1016/j.procir.2013.05.033 282173 2014-11-04T07:22:29.796987-05:00 2013-01-01 2013-12-31 1-s2.0-S2212827113002400-main.pdf https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S2212827113002400/MAIN/application/pdf/51ce09c6ac84d2b7979632a5edbf6c7c/main.pdf https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2212827113002400/MAIN/application/pdf/51ce09c6ac84d2b7979632a5edbf6c7c/main.pdf main.pdf pdf true 814183 MAIN 6 1-s2.0-S2212827113002400-main_1.png https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2212827113002400/PREVIEW/image/png/0768789a0d8a006219f21aa5da9b82a4/main_1.png https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S2212827113002400/PREVIEW/image/png/0768789a0d8a006219f21aa5da9b82a4/main_1.png main_1.png png 47859 849 656 IMAGE-WEB-PDF 1 Procedia CIRP 7 ( 2013 ) 193 \u00e2\u20ac\u201c 198 2212-8271 2013 The Authors. Published by Elsevier B.V. Selection and peer-review under responsibility of Professor Pedro Filipe do Carmo Cunha doi: 10.1016/j.procir.2013.05.033 Forty Sixth CIRP Conference on Manufacturing Systems 2013 Quality Prediction in Interlinked Manufacturing Processes based on Supervised & Unsupervised Machine Learning Daniel Lieber a *, Marco Stolpe b , Benedikt Konrad a , Jochen Deuse a , Katharina Morik b a Institute of Production Systems, TU Dortmund, Leonhard-Euler-Str. 5, 44227 Dortmund, Germany b Chair of Artificial Intelligence, TU Dortmund, 44221 Dortmund, Germany * Corresponding author. Tel.: +49-231-755-2796; fax: +49-231-755-2649. E-mail address: daniel.lieber@tu-dortmund.de. Abstract In the context of a rolling mill case study, this paper presents a methodical framework based on data mining for predicting the physical quality of intermediate products in interlinked manufacturing processes. In the first part, implemented data preprocessing and feature extraction components of the Inline Quality Prediction System are introduced. The second part shows how the combination of supervised and unsupervised data mining methods can be applied to identify most striking operational patterns, promising quality-related features and production parameters. The results indicate how sustainable and energy-efficient interlinked manufacturing processes can be achieved by the application of data mining. \u00c2\u00a9 2013 The Authors. Published by Elsevier B.V. Selection and/or peer-review under responsibility of Professor Pedro Filipe do Carmo Cunha Keywords: Inline Quality Prediction; Data Preprocessing; Feature Subset Selection; Data Mining; Supervised Machine Learning; Sustainability; Ressource- and Energy-Efficiency 1. Introduction Steel industry production is characterized by highly resource-consuming, complex and automated interlinked manufacturing processes. Technological and temporal restrictions limit physical product quality inspections to the final process step. Hence, undetected quality deviations passing through the entire value chain have severe impact on internal failure costs due to increasing rejection and reworking. In this respect, recently Alwood and Cullen [1] presented remarkable research results summarizing that in 2008 60% (334 million tons) of world-wide re-melted steel scrap (574 mill. tons) never reached final products but was scrapped in advance. In contrast to 30% (98 mill. tons) accruing from steelmaking and casting processes, 70% (236 mill. tons) of production-related scrap can be associated with waste products resulting at later stages due to offcuts, surplus and defects. New solutions for continuous quality monitoring are therefore needed and investigated in the context of a hot rolling mill case study, provided by a leading German steel company (see Fig. 1). In this context, nowadays internal material defects cannot be monitored by external state-of-the-art sensors. Therefore, the goal is to identify quality deviations as early as possible and in real-time by data mining on distributed sensor measurements along the process chain. More specifically, since final product quality depends on how it was processed, value series of sensor measurements recorded at each processing step might contain quality-related patterns. Given also quality labels generated from ultrasonic tests, supervised learning may derive prediction models which can predict the quality related physical properties of a Fig. 1. Hot rolling mill process chain and recorded series data [5] FIFO FIFO FIFO FIFO Continuous Casting (Steel Bar) Rotary Hearth Furnace Breaking Down Roll Finishing Stand 1 Finishing Stand 2 Separation Facility Ultrasonic Tests Separated Steel Rods Zone/position Exposure time/zone Exposure time Zone temp. Computed material temp. (top, bottom, core) Armature current Rotation speed Rolling temperature Roll adjustment Grooves Rolling torque, force & speed Cooling Draught # rods per Order # rods OK # rods defect Type, position, extension & frequency of defect Amount of scrapped material Available online at www.sciencedirect.com 2013 The Authors. Published by Elsevier B.V. lection and peer-r view under responsibility of Professo Pedro Filipe do Carmo Cunha Open access under CC BY-NC-ND license. Open access under CC BY-NC-ND license. 194 Daniel Lieber et al. / Procedia CIRP 7 ( 2013 ) 193 \u00e2\u20ac\u201c 198 product already at intermediate production steps. Early detection of defects will save production resources and lead to more sustainable and energy-efficient interlinked manufacturing processes. Previous publications have discussed the general challenges of distributed data mining on sensor data of interlinked processes [2] and the problem of deriving appropriate quality labels [3, 4]. Moreover, in [5] the implementation of a data acquisition and storage system was described and first prediction results on data recorded at the rotary hearth furnace were presented. As now value series data from all processing units is available, there are three key contributions of this paper: First, an approach for automatically preprocessing value series data, extracting features and compiling them into a table format which is suitable for many supervised and unsupervised data mining algorithms is presented. Second, it is shown that by combining supervised and unsupervised data mining methods striking patterns in rolling mill process data can be identified, e.g. operational modes. Third, first results on predicting the final quality of steel bars and a selection of promising features for quality prediction are presented. The remainder of this paper is arranged as follows: In the next section, related work regarding the state of the art of data mining in manufacturing is presented. Section 3 gives a general overview of the Inline Quality Prediction (IQP) System realized as automated processes in the open source data mining software RapidMiner [6]. Subsequently, section 4 introduces implemented system components focusing on data preprocessing and feature extraction. Followed by an overview of data mining tasks and algorithms in section 5, section 6 provides results of several analysis steps conducted on the preprocessed data. Finally, we conclude and discuss forthcoming work in section 7. 2. Data Mining in Manufacturing Processes Literature reviews such as Choudhary et al. [7] illustrate the diversity of data mining techniques used in industrial manufacturing applications, like process characterization, reporting, fault diagnostics, product development, production scheduling as well as preventive maintenance, defect prediction and decision support systems. However, contrary to the increasing interest in manufacturing related knowledge discovery activities, data miner surveys by Rexer Analytics [8] or KDnuggets [9] annually show that production related data mining projects in manufacturing are still underrepresented in comparison to more well- established fields, e.g. consumer-analytics, fraud- detection or banking. Focusing particularly on the steel industry, related work can be found by Peters et al. [10] who are conducting research on data mining techniques with focus on cause analyses, e.g. surface defects of flat steel products. In contrast to Peters et al., the intention of the project presented in this paper is to develop universal distributed data mining techniques for real-time inline quality prediction focusing on detecting internal material defects that nowadays cannot be monitored by external state-of-the-art sensors. 3. Inline Quality Prediction (IQP) System A final goal of the hot rolling mill case study is the design of a distributed Inline Quality Prediction (IQP) system that integrates and automates all necessary data mining steps, analyzing and classifying process patterns in real-time. Fig. 2 shows common data mining steps that are defined and summarized in the Cross Industry Standard Process for Data Mining (CRISP-DM) [11] and the widespread methodology of Knowledge Discovery in Databases (KDD) [12]. While the mining problem and the data acquisition component of the system were already discussed in previous work, the next section describes the general design of components for preprocessing and extracting features from value series, transforming them into a format that is suitable for many well-known data mining algorithms. The modular design is easily extensible and has been implemented as automated processes in RapidMiner. Future goals are already respected, like the distributed deployment of all preprocessing and feature extraction processes across real production units. 4. Data Preprocessing Different types of sensor measurements like rolling force, speed and temperature (see Fig. 1) are transmitted in separate signal channels. For each steel bar, the value series of all recorded channels must be individually preprocessed. Fig. 3 shows the general steps for preprocessing on the upper right. Data Understanding Data Selection Business Understanding Data Mining Problem Interpretation Data Aquisition/Storage Data Collection Visualization Evaluation Deployment Reporting ... Decision Support Modeling Model Selection Data Postprocess. Data Preprocessing Attribute Selection Transformation Data Cleansing Fig. 2. Life cycle of a data mining project 195 Daniel Lieber et al. / Procedia CIRP 7 ( 2013 ) 193 \u00e2\u20ac\u201c 198 The steps are realized as a master process that executes different types of sub-processes (global and local cleansing, global and local feature extractions, etc.) for each bar and signal channel. These automatically call more generic procedures for preprocessing, like filtering, outlier cleansing or normalization (Table 1). These procedures can be reused by different processes of the system, providing specific parameters like thresholds depending on the particular channel. Table 1. Excerpt of available preprocessing procedures Generic Preprocessing Procedures Outlier smoothing based on thresholds Data cleansing by filtering Rounding Normalization Segmentation Fig. 3 shows an example series consisting of rolling force measurements, recorded during the processing of a single steel bar. Global cleansing involves removing irrelevant values where the steel bar was not processed. Since the sensors measure continuously, such intervals would be hard to detect by an automated process without knowledge about the domain. The cleansing therefore relies on the meaning of values in other channels. For instance, a roll position above a certain threshold indicates no processing, allowing to remove values from the same interval in other channels. Similarly, the segmentation of series into meaningful intervals, like individual rolling steps, is easy visually, but sometimes hard to automate. Although methods for the automatic segmentation exist [13], it is much more reliable and faster to count rolling steps with a sensor and use that information for the splitting. Table 2. Excerpt of available feature extraction procedures Feature Extraction Procedures Time-related statistics (length of the series or of segments) Value statistics (min./max. values, sum, mean, median, std.deviation) Statistics on differences between following values (min., max., etc.) Statistics on differences between start and end values (min., max., etc.) Measures for the deviation between target and actual values Frequency statistics and counts (histograms, number of segments) Global features (G) are extracted from the whole series right after global cleansing, while local features (L) are extracted from individual segments after a local preprocessing step (LP). Table 2 shows an excerpt of the types of features that can be calculated from series values. In a postprocessing step (FP), extracted features from segments may be aggregated further by the same methods. At the end, features extracted from each channel for each steel bar are collected in a single data table (see the lower part of Fig. 3), together with quality OK NOK generated from ultrasonic test records [4]. The resulting table, in this case consisting of 470 rows and 2,170 extracted features, can be analyzed by different data mining algorithms introduced in the next section. The reasoning behind extracting aggregated statistics like the median or standard deviation is that if there were quality-related issues already on a large scale, the costly extraction of features describing fine-grained differences can be avoided. Moreover, knowledge on global patterns may support the identification of local ones. Channel 1 bar_id 12345 Meta-Info ... ... Global Features (G) length max mean 330 0.410 0.161 ... ... Local Features (L) length _seg max _seg mean _seg 44 0.379 0.356 ... ... Aggregated Features (A) ... ... ... ... ... ... ... ... ... ... ... ... Channel m differenz_mean_ seg(i)_seg(i+1) stddev_differenz_ mean mean_diff_ mean_process Global Preprocessing (GP) Local Preprocessing (LP) Feature Postprocessing (FP) ... Resulting Feature Set -0.022 0.091 0.011 ... ... ... ... ... ... ... ... ... ... ... ... ... ... ...... ... ... 54321 ... 342 0.425 0.163 ... 68 0.394 0.366 ... ... ... ... ... ...-0.009 0.089 0.013 LP GP FP LP LP LP LP LP LP LP bar_id n channel m A A Total number of features p For each steel bar For each channel Extract global features Determine segments Local cleansing Extract local features For each segment Aggregate local features Generate dataset of all extracted features D a t a P r e p r o c e s i n g Global cleansing 1 2 3 1 2 3 GP / LP / FP 1 2 3 Fig. 3. Resulting data table including meta data and features extracted from value series data of channels 1 to m 196 Daniel Lieber et al. / Procedia CIRP 7 ( 2013 ) 193 \u00e2\u20ac\u201c 198 5. Modeling In the following, an overview of basic data mining tasks and algorithms is given and the methods used in the experimental section are introduced. 5.1. Unsupervised Learning and Clustering Unsupervised methods, like visualization, clustering, outlier detection or dimension reduction are often used as a first step in data mining for getting an impression of patterns and relationships in complex data sets. Clustering algorithms divide a set of observations into groups (clusters) such that observations inside clusters are more similar to each other than to those in other clusters. Thus, clustering can provide a first insight into similarity relationships. The feature values that were extracted according to section 4 are all numeric and can be interpreted as points in a metric space. Given a set of observations represented by data points in a p-dimensional Euclidean space, i.e. , , the dissimilarity between two observations and can, for instance, be measured by the Euclidean distance. The k-Means algorithm [14] computes a partitioning of into a user-specified number of clusters, with the goal of minimizing the average Euclidean distance between the points in each cluster. Initially, it assigns all data points randomly to clusters. Then, in alternating steps, it calculates the mean vector of each cluster and (re)assigns each data point to the cluster whose mean is closest, until the means do not change anymore. The algorithm should be started several times, since it can only find a locally optimal clustering. The Self Organizing Map (SOM) [15] achieves a clustering and a dimensionality reduction by mapping input vectors from a higher dimensional continuous space to a fixed number of points (neurons) on a lower dimensional grid. Since similar input vectors are also lying close to each other on the grid, similarity relationships between high-dimensional input vectors can easily be visualized on a two dimensional map. 5.2. Supervised Methods and Classification Supervised methods are used if some observations can already be labeled according to a known target concept and a rule or function (also called model) for this assignment should be learned from the data. Given distinct class labels, the Na\u00c3\u00afve Bayes [16] classifier predicts the class of a given observation based on the prior probability of the class and , the likelihood of the feature values given the class : is a normalization constant and can be ignored for classification. The probabilities and are estimated from the set of labeled observations. Predicted is usually the class with the highest estimated probability. Although the method assumes the often not given independence of features it has achieved sufficient prediction accuracy in many practical applications. Decision trees [17] classify observations by sorting them into axis parallel rectangular regions of the input space. The method recursively determines features whose values can be used for sorting observations into regions that contain as many points of the same class as possible. The actual classification is then performed by tests on the chosen features and their values, along a path from the root to the leaves of the tree. The nearest neighbor method (k-NN) [18] stores a set of labeled observations. New observations are classified by majority vote of the k nearest neighbors. The support vector machine (SVM) [19] determines the support vectors of a hyperplane which separates the observations of two classes with maximum margin. Providing a kernel function that measures the similarity of observations in a higher dimensional feature space allows for a non-linear separation of observations in the original input space. 5.3. Feature Selection Often only a subset of features is relevant. In the case of distance based methods, noisy or highly correlated features can even disturb learning. If the selection of features is not already embedded in an algorithm, filter or wrapper approaches may be used for automatically determining a subset of relevant features [20]. While filters select features based on simple criteria, the wrapper approach evaluates generated subsets of features by training and applying a prediction model. In Section 6, an evolutionary wrapper approach is used for the selection of subsets. Starting with a population of random feature subsets, the algorithm successively combines and mutates the fittest individuals over several generations and returns the best found subset. 5.4. Evaluation One possible measure for the accuracy of a model is the percentage of correctly classified observations. Maximizing the accuracy on the training set will usually underestimate the true error, which is the expected error also on unseen observations. A better estimation is the accuracy on an independent hold-out set not shown to the learning algorithm. If only few labeled observations are available, a standard procedure for estimating the accuracy is the n-fold cross-validation [21]. The training set is divided randomly into equally sized subsets and each subset is used once as a hold-out set. The total accuracy is then the average of the accuracies on these hold-out subsets. 197 Daniel Lieber et al. / Procedia CIRP 7 ( 2013 ) 193 \u00e2\u20ac\u201c 198 6. Data Analysis and Results For an analysis of the data set described in section 4, some of the extracted features are excluded. The block roll temperature is removed due to an unreliable sensor. Features on individual segments are not included since it is unclear how to compare different numbers of rolling steps in distance calculations. Therefore, only global and aggregated features are kept, resulting in 218 features describing each of the 470 processes. 6.1. Quality Prediction and Important Features The feature vectors of the 470 processes (indicated by points) are mapped to different parts of a 40x30 SOM (see Fig. 4) for getting a first impression of the data. The color of a point represents the final quality (red for and blue for of the resulting steel bar. Here, quality deviations are known to be porosities related to processing in the rolling mill. Processes that are similar according to their feature values are lying close to each other on the map. The distance between two points is additionally weighted as indicated by the shading, where lighter shades can be interpreted like hills on a geographical map. Dark areas surrounded by very light borders therefore indicate separate clusters of similar processes. In many cases, processes leading to a low final product quality are lying very close to those leading to a high quality (see e.g. the zoomed area in Fig. 4). A visual inspection of corresponding plots verifies that such series look almost identical on a large scale and that differences can rather be found in fine-grained details. For assessing how well both classes can be separated quantitatively, the prediction accuracy of the supervised classification methods introduced in section 5 was estimated by a 10-fold cross-validation. Parameter settings and manually chosen subsets of features were varied in the experiments. Since k-NN looked most promising, an exhaustive evolutionary feature selection with k=7 over 50 generations was conducted and could achieve a prediction accuracy of 80.21%. The top 13 selected features are believed to be quality-relevant by domain experts and include the heating time in the hearth furnace, rolling force, speed and temperature. Because seven of the features regard statistics which measure differences within or between rolling steps, future work on improving prediction performance should focus on a more detailed description of these deviations. Another promising result stems from focusing only on the correct prediction of high quality steel bars. Even though blue and red points are lying close together, the SOM in Fig. 4 also contains large continuous areas of processes resulting in high quality. If process parameters would stay in these ranges, avoiding those with higher probability for errors, it might already improve the process and reduce the amount of produced scrap metal. 6.2. Detection of Distinct Operational Modes Asking what processes look most similar to each other reveals a high similarity between processes resulting in the same end dimension. Instead of plotting the quality, Fig. 5 shows the different end dimensions plotted in different colors on the SOM. Here, processes resulting in the same end dimension form large clusters, i.e. continuous separated areas of the same color. Further, Fig. 6 shows the distribution of end dimensions in each of ten clusters as determined by the k-Means algorithm. Many of the clusters include only Fig. 4. Quality levels of steel bars plotted on a 40x30 SOM OK NOK 1V 2V 3V 4V 5V 6V 7V 8V 3V 18 2V 10 6V 62 5V; 2 7V 9 3V 18 4V 24 5V 21 5V 108 6V 12 6V 11 5V 16 3V 36 4V 17 2V 45 8V; 2 3V 39 1V 18 3V; 1 4V; 1 0 123456789 Cluster_ID A m o u n t o f E x a m p l e s p e r c l u s t e r d i v i d e d i n f i n a l d i m e n s i o n s 0 20 40 60 80 100 120 198 Daniel Lieber et al. / Procedia CIRP 7 ( 2013 ) 193 \u00e2\u20ac\u201c 198 one or two end dimensions that are similar. A decision tree (see e.g. Fig. 7) trained solely on the features of the first finishing roll could decide on the end dimension with an accuracy of 90%, while k-NN (k=11) achieved about 97%, indicating a high correlation between end dimensions and processes. Most important for deciding is the position of the roll (channel 501) which makes sense, since it determines the height of the end product. Experts have verified that the mapping between large scale process behavior and the end dimension produced, detected by means of automated data mining methods, reflects the real modes of operation in the rolling mill. 7. Conclusion Data mining on features of a rolling mill process is able to detect meaningful and striking operational patterns previously only known to domain experts. The result is an improvement on previous work [4] where, only based on static features from the rotary hearth furnace, no such patterns could be detected. The clustering of aggregated sensor measurements now allows for a quantitative description of deviations from the intended operational modes, enabling e.g. automated process monitoring. Moreover, first prediction results indicate only a low correlation between modes and the quality of the end product, verifying the correctness of operation on a large scale. The description of distinct modes could further give valuable hints for the detection of quality-related patterns that are independent from the final product An exhaustive evolutionary feature selection indicates promising features for quality prediction, including heating times in the furnace and deviations of rolling force, speed and temperature within and between consecutive rolling steps. Future work will show if the extraction of more fine-grained deviations can lead to an improvement in prediction performance. Moreover, focusing only on the correct prediction of high-quality steel bars may help with learning a model for more safe and reliable process parameter ranges. Acknowledgements. This work has been supported by the DFG, Collaborative Research Center 876, project B3, http://sfb876.tu-dortmund.de/. References [1] Alwood, J.M., Cullen, J.M., 2012. Sustainable Materials - With Both Eyes Open. UIT Cambridge, Cambridge, p. 51-54. [2] Stolpe, M., Morik, K., Konrad, B., Lieber, D., Deuse, J., 2011. Next Generation Data Mining Summit 2011. Athens, Greece. [3] Stolpe, M., Morik, K., 2011. Learning from Label Proportions by ECML PKDD 2011 Gunopulos, D. and others, Part III, Vol. 6913, Springer, Berlin, Heidelberg, pp. 349-364. [4] Konrad, B., Lieber, D., Deuse, J., 2012. Striving for Zero Defect Production: Intelligent Manufacturing Control through Data Mining in Continuous Robust Manufacturing Control Vol. 1, No. 1, Springer, Heidelberg, pp. tba. [5] Lieber, D., Konrad, B., Deuse, J., Stolpe, M., Morik, K., 2012. Sustainable Manufacturing Processes through Real-Time Quality Leveraging Technology for a Sustainable World Dornfeld, D.A., Linke, B., Springer, Heidelberg, pp. 393-398. [6] Mierswa, I., Wurst, M., Klinkenberg, R., Scholz, M., Euler, T., 2006. YALE: Rapid Prototyping for Complex Data Mining Tasks, . of the 12th ACM SIGKDD int. conf. on Knowledge Discovery and Data M Gunopulos, D., Eliassi-Rad, T., ACM, New York, pp. 935-940. [7] Choudhary, A.K., Harding, J.A., Tiwari, M.K., 2009. Data Mining in Manufacturing: A Review Based on the Kind of Knowledge, Journal of Intelligent Manufacturing, Springer, Vol. 20, pp. 501- 525. [8] Rexer Analytics, http://www.rexeranalytics.com, 2012. [9] KDnuggets, http://www.kdnuggets.com/polls, 2012. [10] Peters, H., Ebel, A., Holzknecht, N., Link, N., Hackmann, J., Heckenthaler, T., L\u00c3\u00bccking, F., Pander, M., 2012. Industrial data mining in the steel industry, Stahl und Eisen, 132(2), pp. 29-37. [11] Nisbet, R., Elder, J., Miner, G., 2009. Handbook of Statistical Analysis and Data Mining Applications, Elsevier, San Diego, p. 39. [12] Fayyad, U., Piatetski-Shapiro, G., Smyth, P., 1996. From Data Mining to Knowledge Discovery in Databases, AI Magazine, Vol. 17, No. 3, pp. 37-54. [13] Rakthanmanon, T., Keogh, E.J., Lonardi, S., Evans, S., 2012. MDL-based time series clustering, Knowl Inf Sys, Vol. 33, pp. 371-399. [14] MacQueen, J., 1967. Some methods for classification and analysis of multivariate observations, Symp. Math. Stat. & Prob., pp. 281- 297. [15] Kohonen, T., 2001. Self-Organizing Maps, Springer, 3rd ed. [16] John, G.H., Langley, P., 1995. Estimating continuous distributions in Bayesian classifiers, in Proc. of the 11th Conf. on Uncertainty in Artificial Intelligence Morgan Kaufmann, San Francisco, pp. 338-345. [17] Quinlan, J.R., 1986. Induction of decision trees, Machine Learning, Vol. 1, No. 1, pp. 81-106. [18] Aha, D., 1992. Tolerating noisy, irrelevant, and novel attributes in instance-based learning algorithms, International Journal of Man- Machine Studies, Vol. 36, No. 2, pp. 267-287. [20] Vapnik, V., 1999. The nature of statistical learning theory, Springer, New York, 2nd ed. [21] Pudil, P., Novovicov\u00c3\u00a1, J., 1998. Novel Methods for feature Subset Extraction, Construction and Selection A Data Mining Perspective Kluwer, Dortdrecht, pp. 101- 116. [22] Hastie, T., Tibshirani, R., Friedman, J., 2009. The Elements of Statistical Learning: Data Mining, Inference, and Prediction, Springer, 2nd ed. 501_mean_mean_process 501_length 501_min 501_mean 505_max 2V 8V 5V 3V 503_sum_mean_differenz_mean_process > 0,4582 0,4582 6V 7V 4V 1V 501_mean_mean_process 0,1455 > 0,2133 > 0,2078 0,2078 > 0,7943 0,7943 0,4195> 0,4195 > 0,3160 0,31600,2133 > 0,1455 Fig. 7. Decision tree for in the furnace and deviations of rolling force, speed and temperature within and between consecutive rolling steps. Future work will show if the extraction of more fine-grained deviations can lead to an improvement in prediction performance. Moreover, focusing only on the correct prediction of high-quality steel bars may help with learning a model for more safe and reliable process parameter ranges. Acknowledgements. This work has been supported by the DFG, Collaborative Research Center 876, project B3, http://sfb876.tu-dortmund.de/. References [1] Alwood, J.M., Cullen, J.M., 2012. Sustainable Materials - With Both Eyes Open. UIT Cambridge, Cambridge, p. 51-54. [2] Stolpe, M., Morik, K., Konrad, B., Lieber, D., Deuse, J., 2011. Next Generation Data Mining Summit 2011. Athens, Greece. [3] Stolpe, M., Morik, K., 2011. Learning from Label Proportions by ECML PKDD 2011 Gunopulos, D. and others, Part III, Vol. 6913, Springer, Berlin, Heidelberg, pp. 349-364. [4] Konrad, B., Lieber, D., Deuse, J., 2012. Striving for Zero Defect Production: Intelligent Manufacturing Control through Data Mining in Continuous Robust Manufacturing Control Vol. 1, No. 1, Springer, Heidelberg, pp. tba. [5] Lieber, D., Konrad, B., Deuse, J., Stolpe, M., Morik, K., 2012. Sustainable Manufacturing Processes through Real-Time Quality Leveraging Technology for a Sustainable World Dornfeld, D.A., Linke, B., Springer, Heidelberg, pp. 393-398. [6] Mierswa, I., Wurst, M., Klinkenberg, R., Scholz, M., Euler, T., 2006. YALE: Rapid Prototyping for Complex Data Mining Tasks, . of the 12th ACM SIGKDD int. conf. on Knowledge Discovery and Data M Gunopulos, D., Eliassi-Rad, T., ACM, New York, pp. 935-940. [7] Choudhary, A.K., Harding, J.A., Tiwari, M.K., 2009. Data Mining in Manufacturing: A Review Based on the Kind of Knowledge, Journal of Intelligent Manufacturing, Springer, Vol. 20, pp. 501- 525. [8] Rexer Analytics, http://www.rexeranalytics.com, 2012. [9] KDnuggets, http://www.kdnuggets.com/polls, 2012. [10] Peters, H., Ebel, A., Holzknecht, N., Link, N., Hackmann, J., Heckenthaler, T., L\u00c3\u00bccking, F., Pander, M., 2012. Industrial data mining in the steel industry, Stahl und Eisen, 132(2), pp. 29-37. [11] Nisbet, R., Elder, J., Miner, G., 2009. Handbook of Statistical Analysis and Data Mining Applications, Elsevier, San Diego, p. 39. [12] Fayyad, U., Piatetski-Shapiro, G., Smyth, P., 1996. From Data Mining to Knowledge Discovery in Databases, AI Magazine, Vol. 17, No. 3, pp. 37-54. [13] Rakthanmanon, T., Keogh, E.J., Lonardi, S., Evans, S., 2012. MDL-based time series clustering, Knowl Inf Sys, Vol. 33, pp. 371-399. [14] MacQueen, J., 1967. Some methods for classification and analysis of multivariate observations, Symp. Math. Stat. & Prob., pp. 281- 297. [15] Kohonen, T., 2001. Self-Organizing Maps, Springer, 3rd ed. [16] John, G.H., Langley, P., 1995. Estimating continuous distributions in Bayesian classifiers, in Proc. of the 11th Conf. on Uncertainty in Artificial Intelligence Morgan Kaufmann, San Francisco, pp. 338-345. [17] Quinlan, J.R., 1986. Induction of decision trees, Machine Learning, Vol. 1, No. 1, pp. 81-106. [18] Aha, D., 1992. Tolerating noisy, irrelevant, and novel attributes in instance-based learning algorithms, International Journal of Man- Machine Studies, Vol. 36, No. 2, pp. 267-287. [20] Vapnik, V., 1999. The nature of statistical learning theory, Springer, New York, 2nd ed. [21] Pudil, P., Novovicov\u00c3\u00a1, J., 1998. Novel Methods for feature Subset Extraction, Construction and Selection A Data Mining Perspective Kluwer, Dortdrecht, pp. 101- 116. [22] Hastie, T., Tibshirani, R., Friedman, J., 2009. The Elements of Statistical Learning: PROCIR 498 S2212-8271(13)00240-0 10.1016/j.procir.2013.05.033 The Authors \u2606 Selection and peer-review under responsibility of Professor Pedro Filipe do Carmo Cunha. Quality Prediction in Interlinked Manufacturing Processes based on Supervised & Unsupervised Machine Learning Daniel Lieber a \u204e Marco Stolpe b Benedikt Konrad a Jochen Deuse a Katharina Morik b a Institute of Production Systems, TU Dortmund, Leonhard-Euler-Str. 5, 44227 Dortmund, Germany b Chair of Artificial Intelligence, TU Dortmund, 44221 Dortmund, Germany \u204e Corresponding author. Tel.: +49 231 755 2796; fax: +49 231 755 2649. In the context of a rolling mill case study, this paper presents a methodical framework based on data mining for predicting the physical quality of intermediate products in interlinked manufacturing processes. In the first part, implemented data preprocessing and feature extraction components of the Inline Quality Prediction System are introduced. The second part shows how the combination of supervised and unsupervised data mining methods can be applied to identify most striking operational patterns, promising quality-related features and production parameters. The results indicate how sustainable and energy-efficient interlinked manufacturing processes can be achieved by the application of data mining. Keywords Inline Quality Prediction Data Preprocessing Feature Subset Selection Data Mining Supervised Machine Learning Sustainability Ressource- and Energy-Efficiency References [1] Alwood, J.M., Cullen, J.M., 2012. Sustainable Materials - With Both Eyes Open. UIT Cambridge, Cambridge, p. 51-54. [2] Stolpe, M., Morik, K., Konrad, B., Lieber, D., Deuse, J., 2011. Next Generation Data Mining Summit 2011. Athens, Greece. [3] Stolpe, M., Morik, K., 2011. Learning from Label Proportions by Optimizing Cluster Model Selection, in \u201cECML PKDD 2011, Gunopulos, D. and others, Part III, Vol. 6913, Springer, Berlin, Heidelberg, pp. 349-364. [4] Konrad, B., Lieber, D., Deuse, J., 2012. Striving for Zero Defect Production: Intelligent Manufacturing Control through Data Mining in Continuous Rolling Mill Processes, in Robust Manufacturing Control\u201d K. Windt, Vol. 1, No. 1, Springer, Heidelberg, pp. tba. [5] Lieber, D., Konrad, B., Deuse, J., Stolpe, M., Morik, K., 2012. Sustainable Manufacturing Processes through Real-Time Quality Prediction, in \u201eLeveraging Technology for a Sustainable World, Dornfeld, D.A., Linke, B., Springer, Heidelberg, pp. 393-398. [6] Mierswa, I., Wurst, M., Klinkenberg, R., Scholz, M., Euler, T., 2006. YALE: Rapid Prototyping for Complex Data Mining Tasks, in \u201eKDD\u030106: Proc. of the 12th ACM SIGKDD int. conf. on Knowledge Discovery and Data Mining\u201c, Ungar, L., Craven, M., Gunopulos, D., Eliassi-Rad, T., ACM, New York, pp. 935-940. [7] Choudhary, A.K., Harding, J.A., Tiwari, M.K., 2009. Data Mining. in Manufacturing: A Review Based on the Kind of Knowledge, Journal of Intelligent Manufacturing, Springer, Vol. 20, pp. 501-525. [8] Rexer Analytics, http://www.rexeranalytics.com, 2012. [9] KDnuggets, http://www.kdnuggets.com/polls, 2012. [10] Peters, H., Ebel, A., Holzknecht, N., Link, N., Hackmann, J., Heckenthaler, T., L\u00fccking, F., Pander, M., 2012. Industrial data mining in the steel industry, Stahl und Eisen, 132(2), pp. 29-37. [11] Nisbet, R., Elder, J., Miner, G., 2009. Handbook of Statistical Analysis and Data Mining Applications, Elsevier, San Diego, p. 39. [12] Fayyad, U., Piatetski-Shapiro, G., Smyth, P., 1996. From Data Mining to Knowledge Discovery in Databases, AI Magazine, Vol. 17, No. 3, pp. 37-54. [13] Rakthanmanon, T., Keogh, E.J., Lonardi, S., Evans, S., 2012. MDL-based time series clustering, Knowl Inf Sys, Vol. 33, pp. 371-399. [14] MacQueen, J., 1967. Some methods for classification and analysis of multivariate observations, Symp. Math. Stat. & Prob., pp. 281-297. [15] Kohonen, T., 2001. Self-Organizing Maps, Springer, 3rd ed. [16] John, G.H., Langley, P., 1995. Estimating continuous distributions in Bayesian classifiers, in Proc. of the 11th Conf. on Uncertainty in Artificial Intelligence\u201d, Morgan Kaufmann, San Francisco, pp. 338-345. [17] Quinlan, J.R., 1986. Induction of decision trees, Machine Learning, Vol. 1, No. 1, pp. 81-106. [18] Aha, D., 1992. Tolerating noisy, irrelevant, and novel attributes in instance-based learning algorithms, International Journal of Man-Machine Studies, Vol. 36, No. 2, pp. 267-287. [19] Vapnik, V., 1999. The nature of statistical learning theory, Springer, New York, 2nd ed. [20] Pudil, P., Novovicov\u00e1, J., 1998. Novel Methods for feature Subset Selection with Respect to Problem Knowledge, in \u201cFeature Extraction, Construction and Selection \u2013 A Data Mining Perspective\u201d H. Liu, H. Motoda, Kluwer, Dortdrecht, pp. 101-116. [21] Hastie, T., Tibshirani, R., Friedman, J., 2009. The Elements of Statistical Learning: Data Mining, Inference, and Prediction, Springer, 2nd ed."
    },
    "10.1016/j.jbi.2013.09.007": {
        "Title": "TEMPTING system: A hybrid method of rule and machine learning for temporal relation extraction in patient discharge summaries",
        "Date": "December 2013",
        "Text": "serial JL 272371 291210 291682 291870 291901 31 80 Journal of Biomedical Informatics JOURNALBIOMEDICALINFORMATICS 2013-09-20 2013-09-20 2021-03-30T19:55:41 1-s2.0-S1532046413001482 S1532-0464(13)00148-2 S1532046413001482 10.1016/j.jbi.2013.09.007 S300 S300.2 FULL-TEXT 1-s2.0-S1532046413X00097 2021-03-30T21:27:42.623139Z 0 0 20131201 20131231 2013 2013-09-20T00:00:00Z absattachment articleinfo articletitlenorm authfirstinitialnorm authfirstsurnamenorm cid cids confeditor contenttype copyright crossmark dateloaded dateloadedtxt datesearch datesort dateupdated dco docsubtype doctype doi eid ewtransactionid hubeid indexeddate issn issnnorm itemstage itemtransactionid itemweight oauserlicense openaccess openarchive pg pgfirst pglast pii piinorm pubdateend pubdatestart pubdatetxt pubyr sectiontitle sortorder srctitle srctitlenorm srctype ssids alllist content oa subj subheadings suppl tomb vol volfirst volissue volumelist webpdf webpdfpagecount yearnav figure table body mmlmath acknowledge affil articletitle auth authfirstini authfull authkeywords authlast footnotes highlightsabst primabst ref specialabst 1532-0464 15320464 true 46 46 S Volume 46, Supplement 8 S54 S62 S54 S62 201312 December 2013 2013-12-01 2013-12-31 2013 Supplement: 2012 i2b2 NLP Challenge on Temporal Relations in Clinical Data \u00d6zlem Uzuner a Amber Stubbs b a Department of Information Studies, SUNY Albany, Albany, NY 12222, USA b Department of Information Studies, SUNY Albany, Albany, NY 12222, USA Original Research article fla Copyright \u00a9 2013 Elsevier Inc. All rights reserved. TEMPTINGSYSTEMAHYBRIDMETHODRULEMACHINELEARNINGFORTEMPORALRELATIONEXTRACTIONINPATIENTDISCHARGESUMMARIES CHANG Y 1 Introduction 2 Material and methods 2.1 Multi-stage rule-based temporal relation extraction system 2.1.1 Stage 1: intra-sentence TLINK extraction 2.1.2 Stage 2: Inter-sentence TLINK extraction 2.1.2.1 Co-reference resolution 2.1.2.2 Timeline-dependent linking 2.1.3 Stage 3: Clinical note-section-based TLINK extraction 2.2 Maximum entropy-based temporal relation extraction system 2.3 TLINK integration algorithm 3 Results 4 Discussion 5 Related work 6 Concluding remarks Acknowledgments References ALLEN 1984 123 154 J BERGER 1996 39 71 A GROUIN 2013 820 827 C LAPATA 2006 85 117 M PUSTEJOVSKY 2005 123 164 J TANG 2013 828 835 B TSAI 2006 S11 R CHANGX2013XS54 CHANGX2013XS54XS62 CHANGX2013XS54XY CHANGX2013XS54XS62XY Full 2014-12-01T00:02:24Z ElsevierBranded http://www.elsevier.com/open-access/userlicense/1.0/ OA-Window 2021-03-18T10:35:55.237Z http://vtw.elsevier.com/data/voc/AddOnTypes/50.7/nlp S1532046413001482 National Heart, Lung and Blood Institute NHLBI National Heart, Lung, and Blood Institute http://data.elsevier.com/vocabulary/SciValFunders/100000050 http://sws.geonames.org/6252001/ National Library of Medicine NLM U.S. National Library of Medicine http://data.elsevier.com/vocabulary/SciValFunders/100000092 http://sws.geonames.org/6252001/ National Science Council of Taiwan NSC 101-2319-B-010-002 NSC-102-2218-E-038-001 TMU101-AE1-B55 NSC 102-2319-B-010-002 NSC National Science Council http://data.elsevier.com/vocabulary/SciValFunders/501100001868 http://sws.geonames.org/1668284/ NIH NLM Informatics for Integrating Biology 2U54LM008748 i2b2 NLM NLM U.S. National Library of Medicine http://data.elsevier.com/vocabulary/SciValFunders/100000092 http://sws.geonames.org/6252001/ Taipei Medical University TMU Taipei Medical University http://data.elsevier.com/vocabulary/SciValFunders/501100004700 http://sws.geonames.org/1668284/ NHLBI 1R13LM01141101 NHLBI National Heart, Lung, and Blood Institute http://data.elsevier.com/vocabulary/SciValFunders/100000050 http://sws.geonames.org/6252001/ NIH NIH National Institutes of Health http://data.elsevier.com/vocabulary/SciValFunders/100000002 http://sws.geonames.org/6252001/ This research was supported by Informatics for Integrating Biology and the Bedside (i2b2), award number 2U54LM008748 from the NIH/National Library of Medicine (NLM); by the National Heart, Lung and Blood Institute (NHLBI); and by award number 1R13LM01141101 from the NIH NLM. The content is solely the responsibility of the authors and does not necessarily reflect the official views of the NLM, NHLBI, or the National Institutes of Health. The study was conducted under the \u201cIII Innovative and Prospective Technologies Project\u201d of the Institute for Information Industry, which is subsidized by the Ministry of Economic Affairs of the Republic of China. Moreover, this research was also supported by the National Science Council of Taiwan under Grant NSC 101-2319-B-010-002, NSC 102-2319-B-010-002, and NSC-102-2218-E-038-001, the research Grant TMU101-AE1-B55 of Taipei Medical University. item S1532-0464(13)00148-2 S1532046413001482 1-s2.0-S1532046413001482 10.1016/j.jbi.2013.09.007 272371 2021-03-30T21:27:42.623139Z 2013-12-01 2013-12-31 1-s2.0-S1532046413001482-main.pdf https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001482/MAIN/application/pdf/604343926cf5fe055544ddcb6be10871/main.pdf main.pdf pdf true 1512496 MAIN 9 1-s2.0-S1532046413001482-main_1.png https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001482/PREVIEW/image/png/9490347c6b53b8496c89fa914b866a15/main_1.png main_1.png png 63701 849 656 IMAGE-WEB-PDF 1 1-s2.0-S1532046413001482-fx1.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001482/fx1/DOWNSAMPLED/image/jpeg/13c84dc58cb966703797b9b1ea368ec2/fx1.jpg fx1 true fx1.jpg jpg 22269 199 271 IMAGE-DOWNSAMPLED 1-s2.0-S1532046413001482-gr1.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001482/gr1/DOWNSAMPLED/image/jpeg/a8c996cae250512fea38f4bd9c300f95/gr1.jpg gr1 gr1.jpg jpg 63044 421 578 IMAGE-DOWNSAMPLED 1-s2.0-S1532046413001482-gr2.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001482/gr2/DOWNSAMPLED/image/jpeg/844f4d5f557b6193536c4b524cd6f52f/gr2.jpg gr2 gr2.jpg jpg 11391 72 533 IMAGE-DOWNSAMPLED 1-s2.0-S1532046413001482-gr3.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001482/gr3/DOWNSAMPLED/image/jpeg/7b3f6f4d25c0a8d05a768cd01113e270/gr3.jpg gr3 gr3.jpg jpg 22579 183 488 IMAGE-DOWNSAMPLED 1-s2.0-S1532046413001482-gr4.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001482/gr4/DOWNSAMPLED/image/jpeg/3f0b5734b68cbb72ce97381fed02a9ea/gr4.jpg gr4 gr4.jpg jpg 37529 284 489 IMAGE-DOWNSAMPLED 1-s2.0-S1532046413001482-gr5.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001482/gr5/DOWNSAMPLED/image/jpeg/0ef4da7b0c861bc06f84ccfbd2e56342/gr5.jpg gr5 gr5.jpg jpg 35208 348 489 IMAGE-DOWNSAMPLED 1-s2.0-S1532046413001482-gr6.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001482/gr6/DOWNSAMPLED/image/jpeg/950eab001f4a8f3e28d620408a148d88/gr6.jpg gr6 gr6.jpg jpg 36089 308 489 IMAGE-DOWNSAMPLED 1-s2.0-S1532046413001482-gr7.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001482/gr7/DOWNSAMPLED/image/jpeg/3823fcd0281fbdeca84f6c94430a0c5a/gr7.jpg gr7 gr7.jpg jpg 12970 205 350 IMAGE-DOWNSAMPLED 1-s2.0-S1532046413001482-fx1.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001482/fx1/THUMBNAIL/image/gif/5592d17855a4804651f7f967e67c00e6/fx1.sml fx1 true fx1.sml sml 12159 161 219 IMAGE-THUMBNAIL 1-s2.0-S1532046413001482-gr1.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001482/gr1/THUMBNAIL/image/gif/a49150536bb9652a755693f1113e877c/gr1.sml gr1 gr1.sml sml 9142 160 219 IMAGE-THUMBNAIL 1-s2.0-S1532046413001482-gr2.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001482/gr2/THUMBNAIL/image/gif/97805fabf2be73525fc9d2292f77f5f4/gr2.sml gr2 gr2.sml sml 2388 30 219 IMAGE-THUMBNAIL 1-s2.0-S1532046413001482-gr3.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001482/gr3/THUMBNAIL/image/gif/9bbd4cf2e783fa1bd2c1216361647c1b/gr3.sml gr3 gr3.sml sml 4988 82 219 IMAGE-THUMBNAIL 1-s2.0-S1532046413001482-gr4.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001482/gr4/THUMBNAIL/image/gif/1c2019746ba5b7c26e2bca078e2089ec/gr4.sml gr4 gr4.sml sml 7027 127 219 IMAGE-THUMBNAIL 1-s2.0-S1532046413001482-gr5.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001482/gr5/THUMBNAIL/image/gif/5383d0014d1440774397ae8b6e617675/gr5.sml gr5 gr5.sml sml 7089 156 219 IMAGE-THUMBNAIL 1-s2.0-S1532046413001482-gr6.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001482/gr6/THUMBNAIL/image/gif/e36cd6c61c56d45f8f24578dee96b8cd/gr6.sml gr6 gr6.sml sml 6811 138 219 IMAGE-THUMBNAIL 1-s2.0-S1532046413001482-gr7.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001482/gr7/THUMBNAIL/image/gif/d22aca7c98c5acbe2520eda75117f3bb/gr7.sml gr7 gr7.sml sml 5232 128 219 IMAGE-THUMBNAIL 1-s2.0-S1532046413001482-fx1_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001482/fx1/HIGHRES/image/jpeg/dead9bca67ebef508c414a5daca8f5e4/fx1_lrg.jpg fx1 true fx1_lrg.jpg jpg 93741 531 722 IMAGE-HIGH-RES 1-s2.0-S1532046413001482-gr1_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001482/gr1/HIGHRES/image/jpeg/89b11e9b705eefb509dbba9261dea00b/gr1_lrg.jpg gr1 gr1_lrg.jpg jpg 213001 1119 1535 IMAGE-HIGH-RES 1-s2.0-S1532046413001482-gr2_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001482/gr2/HIGHRES/image/jpeg/f68ebb11bb09ca7dbd9809edb634d85c/gr2_lrg.jpg gr2 gr2_lrg.jpg jpg 85253 319 2362 IMAGE-HIGH-RES 1-s2.0-S1532046413001482-gr3_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001482/gr3/HIGHRES/image/jpeg/0f61bfeb4428b888482117c98fa9847f/gr3_lrg.jpg gr3 gr3_lrg.jpg jpg 90898 527 1402 IMAGE-HIGH-RES 1-s2.0-S1532046413001482-gr4_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001482/gr4/HIGHRES/image/jpeg/3b3a7d321689b6ad460595ce45091bed/gr4_lrg.jpg gr4 gr4_lrg.jpg jpg 356681 1257 2165 IMAGE-HIGH-RES 1-s2.0-S1532046413001482-gr5_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001482/gr5/HIGHRES/image/jpeg/3f1427155224c86679803be8a241519a/gr5_lrg.jpg gr5 gr5_lrg.jpg jpg 124983 924 1299 IMAGE-HIGH-RES 1-s2.0-S1532046413001482-gr6_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001482/gr6/HIGHRES/image/jpeg/5b0b9b6adaccec7f85d48fa40d0b673a/gr6_lrg.jpg gr6 gr6_lrg.jpg jpg 347245 1365 2165 IMAGE-HIGH-RES 1-s2.0-S1532046413001482-gr7_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001482/gr7/HIGHRES/image/jpeg/94b4da7d3a8bb71fbcf2e975ec1fe63d/gr7_lrg.jpg gr7 gr7_lrg.jpg jpg 39666 546 931 IMAGE-HIGH-RES 1-s2.0-S1532046413001482-si1.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001482/STRIPIN/image/gif/e01715e39f704b44b99b23f5209f0f85/si1.gif si1 si1.gif gif 130 5 11 ALTIMG 1-s2.0-S1532046413001482-si10.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001482/STRIPIN/image/gif/6e72ed259a800a7c03f37d0e66278518/si10.gif si10 si10.gif gif 3725 50 403 ALTIMG 1-s2.0-S1532046413001482-si11.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001482/STRIPIN/image/gif/f28ce9ec97c4809bad8a6d51fb1e68e9/si11.gif si11 si11.gif gif 3820 50 410 ALTIMG 1-s2.0-S1532046413001482-si12.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001482/STRIPIN/image/gif/0e95ae48e3a6206e786c6b4738835318/si12.gif si12 si12.gif gif 6715 98 417 ALTIMG 1-s2.0-S1532046413001482-si13.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001482/STRIPIN/image/gif/6772caa1b52736d0a1d9567dc1a0fb01/si13.gif si13 si13.gif gif 2519 20 518 ALTIMG 1-s2.0-S1532046413001482-si14.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001482/STRIPIN/image/gif/d1d4f2c11122d5ba21a0b622cda1685b/si14.gif si14 si14.gif gif 2036 53 319 ALTIMG 1-s2.0-S1532046413001482-si15.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001482/STRIPIN/image/gif/6d70aa3dc87a28dd279333176897309e/si15.gif si15 si15.gif gif 2368 53 418 ALTIMG 1-s2.0-S1532046413001482-si16.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001482/STRIPIN/image/gif/0fdf73cdb146f70e86fad5dddca5667e/si16.gif si16 si16.gif gif 1303 24 278 ALTIMG 1-s2.0-S1532046413001482-si2.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001482/STRIPIN/image/gif/872a87851695f2d39885716d32316365/si2.gif si2 si2.gif gif 178 10 17 ALTIMG 1-s2.0-S1532046413001482-si3.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001482/STRIPIN/image/gif/7a4a111d5cf25ad865763375e09da3aa/si3.gif si3 si3.gif gif 314 14 47 ALTIMG 1-s2.0-S1532046413001482-si4.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001482/STRIPIN/image/gif/cb33480536764ba887654fa9e7d817c9/si4.gif si4 si4.gif gif 2080 20 421 ALTIMG 1-s2.0-S1532046413001482-si5.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001482/STRIPIN/image/gif/ea20962c648a68abe02097a290a94210/si5.gif si5 si5.gif gif 2893 49 424 ALTIMG 1-s2.0-S1532046413001482-si6.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001482/STRIPIN/image/gif/aa099876742ff293ef9a399a17705808/si6.gif si6 si6.gif gif 1782 20 350 ALTIMG 1-s2.0-S1532046413001482-si7.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001482/STRIPIN/image/gif/3bcf5824710fdbcb0fd7dc9b2ee182a3/si7.gif si7 si7.gif gif 4263 78 495 ALTIMG 1-s2.0-S1532046413001482-si8.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001482/STRIPIN/image/gif/134140939ddc60425d0c20b37a8a5677/si8.gif si8 si8.gif gif 3053 48 486 ALTIMG 1-s2.0-S1532046413001482-si9.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001482/STRIPIN/image/gif/e7a6c4647a4b573ba983a606b25975e2/si9.gif si9 si9.gif gif 2977 48 465 ALTIMG YJBIN 2062 S1532-0464(13)00148-2 10.1016/j.jbi.2013.09.007 Elsevier Inc. Fig. 1 The system architecture. Fig. 2 An example of intra-sentence TLINK extraction. Fig. 3 The timeline of the five parts in a discharge summary. Fig. 4 An example of clinical note section-based TLINK extraction (DocID: 801.xml). Fig. 5 System architecture of maximum entropy-based temporal relation extraction system. Fig. 6 The TLINK integration algorithm. Statements behind the symbol \u201c#\u201d are comments. Fig. 7 The distribution of each TLINK type in the training and test datasets. Table 1 Keywords used to determine the clinical note sections of a discharge summary. Keyword Clinical note section type Admission Admission Discharge Discharge \u201cprocedure\u201d, \u201cdaily\u201d, \u201chospital\u201d Hospital Course \u201cpresent\u201d, \u201cidentifying\u201d, \u201chistory\u201d Clinical History \u201cadditional\u201d Other Table 2 The lexical features used in the machine learning-based system. Feature function Description Example First type (ft) The entity type of e 1 ft(p 1)=EVENT Last type (lt) The entity type of e 2 lt(p 1)=TIMEX3 Middle entities (me) The number of entities between the given candidate TLINK pair me(p 2)=1 Distance (dis) The number of tokens between the given candidate TLINK pair dis(p 2)=9 Density (den) The probability of a TLINK pair establishing a TLINK decreases as the distance and the number of entities between them increases. The density feature is the same as to the inverse of the dis product to me. The logarithms and Laplace smoothing are used to avoid overflow and zero probability respectively den =1.301 den ( e i , e j ) = - log ( 1 ( dis ( e i , e j ) + 1 ) \u00d7 ( me ( e i , e j ) + 1 ) ) Table 3 Comparison of the performance of the machine learning-based system and each stage of the rule-based system on the training set. Components Precision (%) Recall (%) F-measure (%) MRTSstage1 42.04 30.47 35.33 MRTSstage2 55.43 9.46 16.16 MRTSstage3 78.87 9.87 17.54 METS 51.73 24.27 33.03 Table 4 Performance comparison of different configurations. Configuration Precision (%) Recall (%) F-measure (%) (1) MRTSstage1 42.04 30.47 35.33 (2) MRTSstage1+2 43.77 46.66 45.17 (3) MRTSstage1+2+3 54.87 49.44 52.01 (4) MRTSstage1+2+3 +METS 55.96 55.07 55.51 Baselinerandom 27.98 18.02 21.92 Table 5 Overall results derived by the compared methods on the test dataset. Components Precision (%) Recall (%) F-measure (%) Run1 (MRTSstage1+2) 57.58 50.94 54.05 Run2 (MRTSstage1+2+3) 55.07 55.55 55.31 Run3 (MRTSstage1+2+3 +METS) 56.70 55.86 56.28 Baselinerandom 25.42 17.81 20.95 Table 6 Performance comparison on the training set for METSone-stage and METStwo-stage. Components Precision (%) Recall (%) F-measure (%) METSone-stage 38.98 40.22 39.59 METS 51.73 24.27 33.03 METSone-stage +MRTS 49.84 59.25 53.57 METS+MRTS 55.96 55.07 55.51 TEMPTING system: A hybrid method of rule and machine learning for temporal relation extraction in patient discharge summaries Yung-Chun Chang a b Hong-Jie Dai c \u204e Johnny Chi-Yang Wu a Jian-Ming Chen a Richard Tzong-Han Tsai d Wen-Lian Hsu a a Institute of Information Science, Academia Sinica, Nankang, Taipei, Taiwan, ROC Institute of Information Science Academia Sinica Nankang Taipei Taiwan, ROC b Department of Information Management, National Taiwan University, Taipei, Taiwan, ROC Department of Information Management National Taiwan University Taipei Taiwan, ROC c Graduate Institute of Biomedical Informatics, College of Medical Science and Technology, Taipei Medical University, Taipei, Taiwan, ROC Graduate Institute of Biomedical Informatics College of Medical Science and Technology Taipei Medical University Taipei Taiwan, ROC d Department of Computer Science and Information Engineering, National Central University, Taoyuan, Taiwan, ROC Department of Computer Science and Information Engineering National Central University Taoyuan Taiwan, ROC \u204e Corresponding authors. Fax: +886 2 2739 2914 (H.-J. Dai). Graphical abstract Patient discharge summaries provide detailed medical information about individuals who have been hospitalized. To make a precise and legitimate assessment of the abundant data, a proper time layout of the sequence of relevant events should be compiled and used to drive a patient-specific timeline, which could further assist medical personnel in making clinical decisions. The process of identifying the chronological order of entities is called temporal relation extraction. In this paper, we propose a hybrid method to identify appropriate temporal links between a pair of entities. The method combines two approaches: one is rule-based and the other is based on the maximum entropy model. We develop an integration algorithm to fuse the results of the two approaches. All rules and the integration algorithm are formally stated so that one can easily reproduce the system and results. To optimize the system\u2019s configuration, we used the 2012 i2b2 challenge TLINK track dataset and applied threefold cross validation to the training set. Then, we evaluated its performance on the training and test datasets. The experiment results show that the proposed TEMPTING (TEMPoral relaTion extractING) system (ranked seventh) achieved an F-score of 0.563, which was at least 30% better than that of the baseline system, which randomly selects TLINK candidates from all pairs and assigns the TLINK types. The TEMPTING system using the hybrid method also outperformed the stage-based TEMPTING system. Its F-scores were 3.51% and 0.97% better than those of the stage-based system on the training set and test set, respectively. Keywords Temporal relation extraction Natural language processing Text mining Hybrid method Maximum entropy 1 Introduction Event and temporal information extraction from plain text is an essential task in natural language processing (NLP) research; and it has been used for many NLP applications, such as document summarization and question answering [4]. Document summarization must identify the key events in one or more stories to yield the best summary with the least extraneous information. Question answering must be able to answer queries about dates, the duration of events, and even relative times in the form of natural language or a set query type. The possible domains for temporal information extraction are numerous and varied, but it is especially useful for processing patient records in the medical domain. Such records contain valuable temporal data that is usually in the form of free text. Information about the sequence of events in patient records plays an essential role in clinical research because it can help solve diverse problems; for example, finding the correlations between treatments and outcomes or extracting information about adverse drug reactions. However, the knowledge that certain items are correlated may be worthless without knowing their temporal order. For example, if researchers are interested in the efficacy of the medicine vancomycin, realizing that the symptom of a disease changes after a patient takes vancomycin may be insufficient without learning that the change only occurs after three days of treatment. To improve the temporal extraction of patient information in the clinical domain, the Sixth Informatics for Integrating Biology and the Bedside (i2b2) NLP challenge [27] was held in 2012. The challenge involved automatically determining the temporal relations between events described in de-identified patient discharge summaries. Based on the TLINK, EVENT and TIMEX3 tags defined in TimeBank [17], 1 TimeBank is a hand-annotated corpus that conforms to the TimeML specification [18], which is an ISO standard for the annotation of events and temporal expressions, as well as anchoring and ordering the relations between them. In TimeBank, the TLINK tag represents the temporal relationship between events (the EVENT tag) or between an EVENT and a time expression (the TIMEX3 tag). 1 the challenge released a dataset annotated by Partners HealthCare and Beth Israel Deaconess Medical Center [22], and proposed three tracks: (1) EVENT/TIMEX3 track: recognize event and time expressions; (2) TLINK track: based on the given EVENT and TIMEX3 tags, identify their temporal relations; (3) End-to-End track: perform the above two tasks on raw discharge summaries. In the framework of the TLINK track, the actions, situations and descriptions in a discharge summary that are related to the patient\u2019s timeline are annotated with the EVENT tag. Phrases in the summary that provide time-relevant knowledge are annotated with the TIMEX3 tags. Temporal links or TLINKs indicate the relations between pairs of EVENTs and TIMEX3s; and the attribute \u201ctype\u201d of a TLINK indicates how temporal objects are related to each other. A TLINK track system must establish a TLINK link between the involved entities. It must also state their attribute type explicitly; that is, indicate if they are: \u201cbefore\u201d, \u201cafter\u201d, \u201cincludes\u201d, \u201cis included\u201d, \u201cholds\u201d, \u201csimultaneous\u201d, \u201cimmediately after\u201d, \u201cimmediately before\u201d, \u201cbegins\u201d, \u201cends\u201d, and so on. Compared to general relation extraction tasks, identifying temporal relations in patient discharge summaries is more strenuous, and has motivated a great deal of NLP research in recent years [12,19,23]. Continuing with the vancomycin example above, the recognition of temporal phrases (e.g. after \u2026 three days) and event entities (e.g. vancomycin) are clearly prerequisites for understanding and interpreting the statement. However, the further temporal knowledge and inferences are more important and must be derived. First, the temporal aspects of the properties of entities must be properly assigned. Second, event descriptions involving entities and their time stamps must be extracted. Finally, the temporal order of the involved entities has to be inferred. In this paper, we focus on the TLINK track and propose a hybrid TEMPoral relaTion extractING (TEMPTING) system that combines rule-based and machine learning approaches to capture the above knowledge and inferences. Temporal relation extraction rules and the pseudocode for integrating the rule-based and machine learning results are formally described. To the best of our knowledge, many leading systems in i2b2 [6,24] do not consider some of the proposed rules or state them formally. 2 Material and methods Our objective is to extract temporally related entity pairs ei and ej , and their temporal relation, r, from a text as a TLINK tuple [ei , r, ej ]. Fig. 1 shows the system architecture of TEMPTING, which is comprised of two key subsystems: the multi-stage rule-based temporal relation extraction system (the rule-based system) and the maximum entropy-based temporal relation extraction system (the machine learning-based system). For each discharge summary dk in D ={d 1,\u2026, dl }, all entities E ={e 1, e 2,\u2026, em } in dk are first paired to form the candidate TLINK pair set P ={p 1,\u2026, pn }, where p =\u3008ei , ej \u3009 is a TLINK pair constructed by the entities ei and ej . The candidate pair set P is then processed by both subsystems and the TLINKs they extract are fused by a TLINK integration algorithm to generate the final results. In the rule-based system, we group several heuristic rules into three different stages to determine the type r of each p in P. Depending on the setting of the TLINK track, the type should be one of the following values: {\u201cBEFORE\u201d, \u201cOVERLAP\u201d and \u201cAFTER\u201d}. First, we apply the intra-sentence rules to extract the TLINKs in a sentence. Then, we exploit the inter-sentence extraction rules along with the co-reference and timeline concept to extract cross-sentence TLINKs. Finally, TLINKs are retrieved according to the clinical note sections, which are different portions of clinical notes that contain rich information about the patient during different stages, such as admission, treatment and discharge. These can be used to determine the TLINK types that each EVENT/TIMEX3 belongs to. In the Results section, we will show the performance of the proposed rules based on the combination of different stages. In the machine learning-based system, an additional phase, TLINK detection, is implemented to filter out EVENT/TIMEX3 pairs that do not possess a TLINK. A supervised learning-based TLINK type classifier then predicts the type r of p. For each p, the feature extraction component extracts representative text features that are used by the TLINK detector/classifier. In the following subsections, we describe our two temporal relation extraction systems and the rules/features developed for the TLINK track. 2.1 Multi-stage rule-based temporal relation extraction system The rule-based system is implemented as a series of rule-based models that exploit a number of linguistic rules to capture various temporal relation patterns. One or several deterministic rules represent a processing stage in the system. In the following subsections, we use four symbols to represent each rule: constants, variables, functions, and predicates. Constants represent objects in a discharge summary, such as a time entity \u201cper day\u201d or an event entity \u201clevofloxacin\u201d. Variables (e.g., i, j) range over the objects. Constants and variables may belong to specific types. Predicates represent the relationships between objects, or the attributes of objects. We use logical connectives and quantifiers to construct the rules recursively from constants or variables. The Boolean operations of logical conjunction, disjunction and negation are denoted by \u201c\u2227\u201d, \u201c\u2228\u201d, and \u201c \u00ac \u201d respectively; and the symbol \u201c \u21d2 \u201d means \u201cimplies\u201d. For instance, A \u21d2 B means that if A is true, then B is also true; however, if A is false, nothing is said about B. Parentheses may be used to enforce the precedence. 2.1.1 Stage 1: intra-sentence TLINK extraction This stage determines the default TLINK types of the TLINK pairs found in the same sentence. Fig. 2 shows an example where two OVERLAP TLINKs should be extracted from the sentence. One is constructed by two EVENT entities, e 1 and e 2; and the other is comprised of e 2 and the time expression (TIMEX3) entity t 1. Note that we use different variable symbols to represent different types of entities. For EVENT entities, the variable eti is used; and the ti symbol is used for TIMEX3 entities. In the training set of the i2b2 TLINK track, we observed that the probability of two EVENT entities in the same sentence having a TLINK type of OVERLAP is 61.8%. Therefore, in the first stage, we developed the following rule to assign the OVERLAP link between two event entities found in the same sentence. R . 1 . 1 isTheSameSentence ( et i , et j ) \u21d2 TLINK OVERLAP ( et i , et j ) Furthermore, based on our analysis on the training set, we believe there is a high probability that an EVENT entity will establish an OVERLAP TLINK with the nearest co-occurring TIMEX3 in the same sentence. Accordingly, the following rule is used to construct the OVERLAP link between an EVENT entity and its nearest TIMEX3 entity. R . 1 . 2 isTheSameSentence ( e i , t j ) \u2227 isTheNearestTime ( t j , e i ) \u21d2 TLINK OVERLAP ( e i , t j ) 2.1.2 Stage 2: Inter-sentence TLINK extraction To discover the relationships between time expressions or events across sentences, we employ two strategies in this stage. The first uses the co-reference resolution model developed in our previous work [8] to uncover EVENTs that literally imply the same concept. The second exploits timeline-dependent information to determine the type of the TLINK between the EVENT and TIMEX3 entities. 2.1.2.1 Co-reference resolution Co-reference resolution involves determining whether two noun phrases are used to refer to the same thing. We used the co-reference resolution method developed for the co-reference resolution track in the 2011 i2b2/VA/Cincinnati Challenge to determine the co-referential relationship between entities. The following rule captures the idea that if two EVENTs are co-reference pairs, a TLINK with type attribute \u201cOVERLAP\u201d should be established between them because they should indicate the same incident. R . 2 . 1 isCoreference ( e i , e j ) \u21d2 TLINK OVERLAP ( e i , e j ) 2.1.2.2 Timeline-dependent linking To discover the relationships between time expressions or events across sentences, we developed a timeline-dependent algorithm that is implemented in two steps. First, all time expressions in a discharge summary are collected and denoted as T ={t 1, t 2,\u2026 to }. Second, the TLINK types among the collected expressions are determined based on their descriptions. Unfortunately, a wide variety of phrases and expressions can be used to state temporal information. For example, December 25, 2010 can be expressed in different ways, such as 2010-12-25, 12/25/2010, and 25/12/2010. Different temporal phrases that refer to the same event must be normalized so that they can be processed easily. In this work, the normalization information provided with the TLINK track dataset was used. For example, the normalized format for a calendar date is [YYYY]-[MM]-[DD]; and in the sentence \u201cThe patient was brought to the operating room on 03/30/1999\u201d the normalized time expression for \u201c03/30/1999\u201d is 1999-03-30. After using common sense rules to compare the normalized temporal description, the TLINK type is assigned to any ti and tj in T. For instance, the TLINK tuple [ti ,\u201cAFTER\u201d, tj ] is generated if ti \u2019s normalized value is after tj \u2019s value, and the \u201cOVERLAP\u201d type is assigned if their values are the same. After constructing the timeline for all t in T, the algorithm looks for the set of overlapping tuples. A set consists of entities whose temporal type is OVERLAP with their corresponding time expressions in T, e.g., R.1.2 may represent an overlapping tuple {\u3008et 1,\u201cOVERLAP\u201d, t 1\u3009, \u3008et 3,\u201cOVERLAP\u201d, t 2\u3009}. Using the constructed timeline, the algorithm then applies the following rule to determine the missing TLINK types among entities in the overlapping tuple. R . 2 . 2 [ TLINK OVERLAP ( e i , t k ) \u2228 TLINK BEFORE ( e i , t k ) ] \u2227 [ TLINK OVERLAP ( e j , t l ) \u2228 TLINK AFTER ( e j , t l ) ] \u2227 TLINK BEFORE ( t k , t l ) \u21d2 TLINK BEFORE ( e i , e j ) The above rule states that (1) if an entity ei occurs on tk or before tk , (2) the occurrence time of another entity ej is tl (or after tl ), and (3) tl is after tk , then the TLINK tuple \u3008ei ,\u201cBEFORE\u201d, ej \u3009 should be generated. We also use the following rule, which is based on a similar principle. R . 2 . 3 TLINK OVERLAP ( e i , t k ) \u2227 TLINK OVERLAP ( e j , t l ) \u2227 TLINK OVERLAP ( t k , t l ) \u21d2 TLINK OVERLAP ( e i , e j ) When it is known that an entity ei overlaps with the time tk , and the occurrence time of another entity ej is tl , with the additional knowledge that tk and tl overlap, R.2.3 establishes a TLINK tuple \u3008ei ,\u201cOVERLAP\u201d, ej \u3009. R . 2 . 4 TLINK BEFORE ( e i , t k ) \u2227 TLINK AFTER ( e j , t l ) \u2227 TLINK OVERLAP ( t k , t l ) \u21d2 TLINK AFTER ( e j , e i ) Based on the timeline concept and the logic shown on the left-hand side of R.2.4 it is reasonable to conclude that entity ei occurred before entity ej because of the overlap between tk and tl . Hence, a TLINK tuple \u3008ej ,\u201cAFTER\u201d, ei \u3009 is derived. 2.1.3 Stage 3: Clinical note-section-based TLINK extraction In this stage, we use several rules to determine the type of TLINKs between the time expressions of \u201cadmission date\u201d or \u201cdischarge date\u201d, and the entities found in certain clinical note sections of a discharge summary. We divide a discharge summary into five parts: clinical history, admission, course of treatment, discharge, and other clinical note sections. Fig. 3 shows the timeline of the five parts. We assign the section time of the admission note-section as the date of admission. In addition, the clinical history note-section, which usually contains information about the patient\u2019s physical status as well as his/her psychological, social, and sexual statuses, is set as the time before the admission date. The section times of the course of treatment, discharge and other note-sections are defined in a similar manner. The clinical note section-based timeline information can be used to determine the TLINK types of the entities in the different note-sections. We illustrate the concept in Fig. 4 . In this summary, it is obvious that the admission date t 1 is \u201c05/09/2000\u201d, and the discharge date t 2 is \u201c05/30/2000\u201d because they are listed in the \u201cADMISSION DATE\u201d and \u201cDISCHARGE DATE\u201d note-sections, respectively. Therefore, the occurrence times of entities found in the \u201cHISTORY OF PRESENT ILLNESS\u201d note-section should be BEFORE t 1 and t 2, because this note-section details the illness history of the patient. Similarly, the occurrence times of entities in the \u201cCOURSE of TREATMENT\u201d note-section, should be \u201cAFTER t 1, but BEFORE t 2\u201d. One of the key steps in this stage is to determine the clinical note sections of the discharge summary. Clinical records are usually in a consistent format. For example, a discharge summary is divided into different clinical note sections with each section title printed in upper case letters with a colon at the end [13]. We exploit this property and employ a string matching method to recognize the corresponding sections. Table 1 shows the keywords used and the corresponding clinical note sections. Based on the clinical note sections in a discharge summary and the timeline information, we delineate the following rules. For example, R.3.1 sets the occurrence times of all EVENT entities in the course of treatment note-section as \u201cAFTER\u201d and \u201cBEFORE\u201d the admission date and the discharge date respectively. R . 3 . 1 isHospitalCourseSection ( s i ) \u2227 isInSection ( et i , s i ) \u21d2 TLINK AFTER ( et i , t admission ) \u2227 TLINK BEFORE ( et i , t discharge ) R . 3 . 2 isHospitalCourseSection ( s i ) \u2227 isInSection ( et i , s i ) \u21d2 TLINK BEFORE ( et i , t admission ) \u2227 TLINK BEFORE ( et i , t discharge ) R . 3 . 3 isAdmissionSection ( s i ) \u2227 isInSection ( et i , s i ) \u21d2 TLINK OVERLAP ( et i , t admission ) \u2227 TLINK BEFORE ( et i , t discharge ) isDischargeSection ( s i ) \u2227 isInSection ( et i , s i ) \u21d2 TLINK AFTER ( et i , t admission ) \u2227 TLINK OVERLAP ( et i , t discharge ) R . 3 . 4 isOtherSection ( s i ) \u2227 isInSection ( et i , s i ) \u21d2 TLINK AFTER ( et i , t discharge ) 2.2 Maximum entropy-based temporal relation extraction system Fig. 5 shows the flow chart of the proposed supervised learning temporal relation extraction system, which is comprised of two key subsystems: the TLINK detector and the TLINK type classifier. In contrast to the rule-based system described in Section 2.1, which treats all pairs in the candidate TLINK pair set P ={p 1,\u2026, pn } as possible candidates, the proposed system first filters the set with the TLINK detector. For each pair p\u2032 in the filtered pair set P\u2032, the TLINK type classifier predicts its type to complete the TLINK tuple. For example, in the sentence \u201cA peripheral intravenous line was started on Labor Day in the a.m. No respiratory distress was noted\u2026\u201d from 101.xml in the training dataset, three candidate TLINK pairs {\u3008et 24, t 7\u3009, \u3008et 24, et 221\u3009, \u3008et 221, t 7\u3009} are generated, where et24, t7, and et221 represent \u201cA peripheral intravenous line\u201d, \u201cLabor Day\u201d, and \u201cdistress\u201d respectively. After TLINK detection, only two TLINK pairs {\u3008e 24, t 7\u3009, \u3008e 221, t 7\u3009} remain. Finally, the TLINK type classifier infers the TLINK types, and generates the TLINK tuples {[e 24,\u201cAFTER\u201d, t 7], [e221,\u201cOVERLAP\u201d, t 7]}. In this work, we formulate the TLINK detection and TLINK type classification tasks as binary and multi-class classification problems, respectively. Furthermore, we utilize the maximum entropy classification method [2] to construct a logistic regression-based statistical model for each task. Let TP denote a candidate TLINK pair. The maximum entropy method classifies a candidate TLINK pair in terms of the following conditional probability: (1) P ( TP | cp l ) = 1 Z ( cp l ) exp \u2211 j w j \u2217 f j ( TP , cp l ) (2) Z ( cp l ) = exp \u2211 j w j \u2217 f j ( TP , cp l ) + \u2211 k w k \u2217 f k ( \u00ac TP , cp l ) , where fj is a feature function and wj is its weight. A feature function indicates a specific condition between TP and cpl ; and Z(cpl ) is a smoothing factor that is used to normalize P(TP|cpl ) within the range [0,1]. Given a training dataset, the weights of the feature functions can be derived by the conditional maximum likelihood estimation method. The learned weights are then used by Eq. (1) for the TLINK detection and TLINK type classification tasks. Usually, the syntactic information between two entities is important for constructing a TLINK in a sentence. We utilize the subsets of lexical features proposed in [3,5,7] for TLINK detection and TLINK type prediction. Table 2 shows some of the lexical features. In the table, we use the candidate TLINK pairs, p 1 =\u3008e 24, t 7\u3009=\u3008\u201cA peripheral intravenous line\u201d,\u201cLabor Day\u201d\u3009, and p 2 =\u3008e 24, e 221\u3009 shown in Fig. 5 as an example to explain the developed features. 2.3 TLINK integration algorithm Fig. 6 shows the proposed TLINK integration algorithm, which is designed to favor the TLINK tuples generated by the rule-based system over those of the machine learning-based system because cross validation indicates that the former system outperformed the latter on the training set. We discuss the performance of both systems in the next section. In the first loop, the algorithm checks the tuples generated by the machine learning-based system to determine whether the entity pair \u3008el , em \u3009 in the tuple also exists in the tuple set RMRTS generated by the rule-based system. If the pair is found in RMRTS , but with a different TLINK type, the algorithm will accept the TLINK type determined by the machine learning-based method. The algorithm will only accept the rule-based system\u2019s TLINK type when the system updates the TLINK type value after Stage 1 (see Section 2.1.1). We designed the algorithm in this way because the precision of Stages 2 and 3 in the rule-based system (see Sections 2.1.2 and 2.1.3) are better than those of the machine learning-based system (see Table 3 in the Results and Discussion section). In addition, if the entity pair is not involved in any tuples generated by the rule-based system, the tuple containing the pair will be accepted and added to the final tuple set. In the second loop, the algorithm checks for the remaining tuple set of the rule-based system, which was not added to the final tuple set. From the perspective of the machine learning-based system, the tuples in the remaining tuple set should be filtered out by the TLINK detector. However, because we prefer to accept the results of the rule-based system, the algorithm only rejects the entity pair \u3008el , em \u3009 whose TLINK detector score is less than the threshold \u03c4. In this work, we set the value of \u03c4 at 0.3. 3 Results We used the training set released by the i2b2 TLINK track as our dataset to develop the rules used by the rule-based system (MRTS). For the machine learning-based system (METS), we performed threefold cross validation on the same dataset to select efficient features for TLINK detection and TLINK type classification in the sequential forward feature selection method [26]. We also performed threefold cross validation on the proposed stage-based system and the ME-based system to compare their performance. Then, we averaged the results of the three runs to obtain the global performance. Table 3 shows the performance of each stage of MRTS and METS using the official evaluation script provided by the i2b2 TLINK track. The evaluation metrics are the Precision, Recall, and F-measure. The first three rows show the performance of the stages of MRTS. It is noteworthy that Stage 3 achieves the highest precision, which demonstrates the capability of the proposed clinical note section-based TLINK extraction method. The precision of METS is lower than that in MRTS-Stage 2 and Stage 3, but it is better than the score of MRTS-Stage 1. Accordingly, our TLINK integration algorithm only accepts the TLINK type determined by METS if its type remains the same after Stage 1 of MRTS (indicated by the third IF in Fig. 6). The results in the fourth row show that, the performance of METS was not significantly better than that of MRTS. This is probably due to the low inter-annotator agreement (kappa value: 0.3 reported by the organizers [27]) and the inability of syntactic features alone to discriminate between temporal relations. To achieve better results, supplementary context information and semantic features should also be considered. Table 4 compares the results derived by different configurations on the training set. The first configuration only uses the rules defined in MRTS-Stage 1. Based on the results of MRTSstage1, the second configuration integrates the rules in MRTS-Stage 2 to modify the generated TLINK types. MRTSstage1+2+3 includes all the stages developed for MRTS. Finally, the MRTSstage1+2+3 +METS configuration uses the proposed TLINK integration algorithm to fuse all the TLINK tuples generated by MRTS and METS. In addition, as a baseline for the evaluation, we use a naive method (Baselinerandom), which randomly selects TLINK candidates from all pairs and assigns the TLINK types. Comparison of MRTSstage1 with MRTSstage1+2+3 shows that the proposed stages improve the overall performance of temporal relation extraction, and they clearly outperform the baseline method. Incorporating Stage 2 into MRTS improves the F-score by 9.84%. The full MRTS system achieves an F-score of 52.01% on the cross validation dataset. The final hybrid system, which uses the TLINK integration algorithm to incorporate the results of METS with MRTS, improves the F-score by 20.18%. Finally, Table 5 shows the average scores of the three runs we submitted for the i2b2 TLINK test dataset. In line with our observation in the training set, the hybrid system (Run 3) achieves the best performance, which demonstrates that the proposed TLINK integration algorithm is robust. The TEMPTING system also outperforms the baseline, which applies a random method on the test dataset. 4 Discussion Compared to general relation extraction tasks, identifying temporal relations in discharge summaries requires temporal knowledge and inference. To assess the effectiveness of the proposed rules for different TLINK types, we preserve the TLINK type that we want to evaluate for each discharge summary, and select rules based on their target TLINK types for evaluating the individual TLINK type performance on the training and test sets. For instance, we remove TLINK types AFTER and OVERLAP from the dataset, and only use rules related to the BEFORE link (denoted as MRTSBEFORE) when we evaluate the BEFORE TLINK. The results show that the TEMPTING system achieves the best performance on the OVERLAP TLINKs, and the worst performance on the TLINK type AFTER. The reason that the AFTER TLINK is much harder than others is that the distribution of AFTER TLINKs in the i2b2 dataset is much less than that of the others, as shown in Fig. 7 . The phenomenon prevents us from devising useful rules and learning meaningful feature weights; hence the recognition task is more complicated. Furthermore, after carefully examining the cases with incorrect AFTER TLINKs, we found that the developed rules based on the identified clinical note sections and their timeline information of MRTSAFTER are incapable of discriminating between EVENT entities. For instance, R.3.1 sets the occurrence time of all EVENT entities in the course of treatment note-section as \u201cAFTER\u201d the admission date due to the difficulty in identifying the clinical note sections, leading to the unsatisfactory performance by MRTSAFTER. Our analysis of the test dataset shows that the TEMPTING system can achieve approximately 76.0% accuracy in identifying the TLINK between EVENT and TIMEX3 entities. Specifically, the accuracy are 90.5% for \u201cBEFORE\u201d, 71.4% for \u201cOVERLAP\u201d, and 66.7% for \u201cAFTER\u201d. However, the system\u2019s performance in recognizing the TLINK between EVENT and SECTIME is poor with only 20% accuracy on average. In our system, the development of this type of TLINK is based solely on the clinical note section that the EVENT belongs to. Because the chronological relations between note-sections are not closely examined, some of the TLINKs are incorrect. In addition, through the intense discussion of the TLINK track of the i2b2 2012 challenge Google group, the cognition of existing TLINKs varied among the annotators and participants. Disagreements between the annotators caused some complications, especially when applying the machine learning approach. Similarly, determining the cases where two EVENTs/TIMEX3s should be linked with a TLINK is also a challenging task, and may result in lost or redundant TLINKs. Based on the above analysis, we should prioritize improving the performance of detecting TLINKs between EVENT and SECTIME in the future and improve the efficiency of TEMPTING in retrieving TLINKs. In addition, our results show that MRTSBEFORE achieves a high precision, but a low recall. Our analysis of the experimental data shows that BEFORE links are usually constructed by an EVENT entity and a TIMEX3 entity; hence, the rule that sets the occurrence time of all EVENT entities in the clinical history note-section to \u201cBEFORE\u201d the admission date and the discharge date (see R.3.1, R.3.2, and R.3.3) yields a very high detection precision because the clinical history note-section is much easier to identify by using the proposed keywords (see Table 1). However, because our clinical note section identification method based on string matching has difficulty determining the corresponding note-sections, its recall is low. For the machine learning-based system comprised of two subsystems, i.e., the TLINK detector and the TLINK type classifier, we conducted an additional experiment to verify the usability of the TLINK detector. The results are shown in Table 6 . The first configuration (denoted as METSone-stage) excludes the TLINK detector, but the second configuration adds it in MRTSstage1 (denoted as METS). In MRTSstage1+2+3 and MRTSstage1+2+3 +METS, based on the results of MRTSstage1 and MRTSstage1+2, we use the TLINK integration algorithm to fuse all TLINK tuples generated by the rule-based system. By comparing different configurations, we find that adding the TLINK detector improves the precision at the expense of the recall. Although adding the TLINK detector yields the lowest F-score, it improves the precision and F-score when we use the fusion algorithm to combine the outputs of the rule-based and machine learning-based systems through the fusing algorithm, while it still maintained a satisfied recall. Based on the results, we conclude that the TLINK detection step must be executed before predicting TLINK types. 5 Related work Regardless of the specific details of target temporal relations, most researchers have approached the problem in a rule-based manner or a pattern-based manner. Many existing temporal relation extraction systems link events directly to associated timestamps [9,21,16], This is a simple and practical approach, but it is used at the expense of the recall because many events do not have an associated timestamp. The principle behind rule-based methods is to design a number of rules for classifying the types of temporal relations as shown by our rule-based system. In most works, these manually defined rules are based on Allen\u2019s interval algebra [1], which is a calculus developed for temporal reasoning. One usage of these rules is to enlarge the training set [14], and another is to ascertain the predicted temporal relations [21,25]. Pattern-based methods extract some generic lexical syntactic patterns for the co-occurrence of events. Extraction of such patterns can be performed manually or automatically. The major drawback of extracting patterns manually is that it tends to result in a high recall but a low precision, as shown by our results in Tables 3 and 4. Several heuristics that are similar to our hybrid method have been proposed to resolve the low precision problem [5,25]. Our maximum entropy-based system is an example of a machine learning-based approach that attempts to learn a classifier from an annotated corpus, and tries to improve the classification accuracy by feature engineering. Another example is Mani et al.\u2019s ME classifier [14], which assigns each pair of events to one of the six relations in an augmented TimeBank corpus. The classifier relies on perfect features that were hand-tagged in the corpus, namely, the tense, aspect, modality, polarity and event class. Pairwise agreement on grammatical tenses and aspect were also included. Lapata and Lascarides [11], whose learner is based on syntax and clausal ordering features, trained an event classifier for inter-sentence events and built a corpus by saving sentences that contained two events, one of which is triggered by a key time word (e.g. after or before). There was a large variation in the machine learning methods explored by the i2b2 TLINK track participants, ranging from maximum entropy, Bayesian, and support vector machine methods to conditional random field approaches. For example, Roberts et al. [20] proposed two supervised methods. The first uses conditional random fields to find relevant word sequences; and the second uses support vector machines to perform binary and multi-class classification. Their official results reported an overall temporal link detection F-score of 55.94%. Cherry et al. [6] proposed several features, such as syntactic, semantic, and structural features, and developed a temporal reasoning module to further infer the temporal relations between entities. Some participants also incorporated heuristics and rule-based components into their systems. For example, Tang et al. [24] used heuristics to select candidate entity pairs for assigning TLINKs. Nikfarjam et al. [15] also combined machine learning and a graph driven approach to extract TLINKs. The graph-based approach creates a temporal graph of a sentence based on parse tree dependencies of the simplified sentences, along with some additional frequent patterns. Some teams divided the tasks into more specific sub-tasks to improve the performance [10,28]. Other hybrid systems in the 2012 i2b2 TLINK track used simple rules to merge the TLINK results of multiple classifiers, e.g., by removing contradictory sentence-across TLINKS from the same sentences [24]. By contrast, we developed a fusion algorithm that integrates the results of two systems based on their performance on the dataset. The best configuration of our hybrid system achieved an F-score of 0.56, which ranked in the seventh place out of the top 10 teams. 6 Concluding remarks Temporal information is crucial in electronic medical records and related clinical manuscripts. Hence, discovering the temporal relationships between entities in patient\u2019s medical data may help medical personnel make clinical decisions, as well as facilitate data modeling and biomedical research. Most of the approaches used in the 2012 i2b2 TLINK track were hybrid methods that combined supervised, unsupervised, and rule-based methods to extract temporal relations. In this paper, we describe several rules and present an algorithm that integrates the results of rule-based and supervised learning systems. Our experiment results demonstrate the efficacy of the proposed approach. Nevertheless, we believe our system could be improved by incorporating of additional linguistic and domain knowledge. In the future, we will employ more sophisticated features to strengthen the system. We will also investigate advanced machine learning algorithms, such as Markov logic network [29], which can extract temporal relation tuples accurately. Our objective is to further enhance the performance of temporal representation and reasoning in medical natural language processing. Acknowledgments This research was supported by Informatics for Integrating Biology and the Bedside (i2b2), award number 2U54LM008748 from the NIH/National Library of Medicine (NLM); by the National Heart, Lung and Blood Institute (NHLBI); and by award number1R13LM01141101 from the NIH NLM. The content is solely the responsibility of the authors and does not necessarily reflect the official views of the NLM, NHLBI, or the National Institutes of Health. The study was conducted under the \u201cIII Innovative and Prospective Technologies Project\u201d of the Institute for Information Industry, which is subsidized by the Ministry of Economic Affairs of the Republic of China. Moreover, this research was also supported by the National Science Council of Taiwan under Grant NSC 101-2319-B-010-002, NSC 102-2319-B-010-002, and NSC-102-2218-E-038-001, the research Grant TMU101-AE1-B55 of Taipei Medical University. References [1] J. Allen Towards a general theory of action and time J Artif Intell 23 2 1984 123 154 [2] A.L. Berger S.A.D. Pietra V.J.D. Pietra A maximum entropy approach to natural language processing Comput Linguist 22 1 1996 39 71 [3] Bethard S, Martin JH. CU-TMP: temporal relation classification using syntactic and semantic features. In: Proceedings of the 4th international workshop on semantic evaluations. Prague, Czech Republic: Association for Computational Linguistics; 2007. p. 129\u201332. [4] Boguraev B, Ando RK. Timeml-compliant text analysis for temporal reasoning. In: Proceedings of the 19th international joint conference on artificial intelligence; 2005. p. 997\u20131003. [5] Chang YC, Chuang PH, Chen CC, Hsu WL. FISER: an effective method for detecting interactions between topic persons. In: Proceedings of the 8th Asia information retrieval societies conference; 2012. p. 267\u201377. [6] Cherry C, Zhu X, Martin J, et al. A la Recherche du Temps Perdu\u2014extracting temporal relations from medical text in the 2012 i2b2 NLP challenge. J Am Med Inform Assoc. doi: http://dx.doi.org/10.1136/amiajnl-2013-001624 [published online first: 23.03.13]. [7] Chklovski T, Pantel P. Global path-based refinement of noisy graphs applied to verb semantics. In: Proceeding of international joint conference on natural language processing; 2005. p. 792\u2013803. [8] Dai HJ, Chen CY, Wu CY, Lai PT, Tsai RT, Hsu WL. Coreference resolution of medical concepts in discharge summaries by exploiting contextual information. J Am Med Inform Assoc; 2012 May 3. [9] Filatova E, Hovy E. Assigning time-stamps to event-clauses. In: Proceedings of the workshop on temporal and spatial information processing, vol. 13; 2001. p. 88\u201395. [10] C. Grouin N. Grabar T. Hamon Eventual situations for timeline extraction from clinical reports J Am Med Inform Assoc 20 5 2013 820 827 10.1136/amiajnl-2013-001627 [11] M. Lapata A. Lascarides Learning sentence-internal temporal relations J AI Res 27 2006 85 117 [12] Ling X, Weld DS. Temporal information extraction. In: Proceedings of association for the advancement of artificial intelligence; 2010. p. 1385\u201390. [13] Long W. Extracting diagnoses from discharge summaries. In: Proceedings of the AMIA Annu Symp. American Medical Informatics Association; 2005. p. 470\u20134. [14] Mani I, Verhagen M, Wellner B, Lee CM, Pustejovsky J. Machine learning of temporal relations. In: Proceedings of the 21st international conference on computational linguistics and the 44th annual meeting of the association for computational linguistics; 2006. p. 753\u201360. [15] Nikfarjam A, Emadzadeh E, Sutton N, Gonzalez G. Temporal relationship extraction from clinical-notes using SVM and graph reasoning. In: Proceedings of 2012 i2b2 shared-tasks and workshop on challenges in natural language processing for clinical data; 2012. [16] Pasca, M. Answering definition questions via temporally-anchored text snippets. In: Proceedings of international joint conference on natural language processing; 2008. p. 411\u20137. [17] Pustejovsky J, Hanks P, Sauri R, et al. The TimeBank corpus. In: Proceedings of corpus linguistics. UK: Lancaster University; 2003. p. 647\u201356. [18] Pustejovsky J, Castano J, Ingria R, et al. TimeML: Robust specification of event and temporal expressions in text. In: Proceedings of the fifth international workshop on computational semantics (IWCS-5); 2003. [19] J. Pustejovsky R. Knippen J. Littman R. Saur\u00ed Temporal and event information in natural language text Lang Resour Eval 39 2 2005 123 164 [20] Roberts K, Rink B, Harabagiu SM. UTD: hybrid methods for temporal relation identification in clinical text. In: Proceedings of 2012 i2b2 shared-tasks and workshop on challenges in natural language processing for clinical data; 2012. [21] Schilder F, Habel C. From temporal expressions to temporal information: semantic tagging of news messages. In: Proceedings of the workshop on temporal and spatial information processing, vol. 13; 2001. p. 65\u201372. [22] Sun W, Rumshisky A, Uzuner O, Szolovits P, Pustejovsky J. 2012 i2b2 Temporal relations challenge annotation guidelines; 2012. [23] Verhagen M, Saur\u00ed R, Caselli T, Pustejovsky J. SemEval-2010 task 13: TempEval-2. In: Proceedings of the 5th international workshop on semantic evaluation; 2010. p. 57\u201362. [24] B. Tang Y. Wu M. Jiang A hybrid system for temporal information extraction from clinical text J Am Med Inform Assoc 20 5 2013 828 835 10.1136/amiajnl-2013-001635 [25] Torisawa K. Acquiring inference rules with temporal constraints by using japanese coordinated sentences and noun-verb co-occurrences. In: Proceedings of the main conference on human language technology conference of the North American chapter of the association of computational linguistics; 2006. p. 57\u201364. [26] R.T.H. Tsai C.L. Sung H.J. Dai H.C. Hung T.Y. Sung W.L. Hsu NERBio: using selected word conjunctions, term normalization, and global patterns to improve biomedical named entity recognition BMC Bioinformatics 7 Suppl. 5 2006 S11 [27] Weiyi S, Anna R, Ozlem U. Evaluating temporal relations in clinical text: 2012 i2b2 Challenge. J Am Med Inform Assoc. doi: http://dx.doi.org/10.1136/amiajnl-2013-001628 [published online first: 05.04.13]. [28] Xu Y, Wang Y, Liu T, et al. An end-to-end system to identify temporal relation in discharge summaries: 2012 i2b2 challenge. J Am Med Inform Assoc doi: http://dx.doi.org/10.1136/amiajnl-2012-001607 [published online first: 06.03.13]. [29] Yoshikawa K, Riedel S, Asahara M, Matsumoto Y. Jointly identifying temporal relations with Markov logic. In: Proceedings of the joint conference of the 47th annual meeting of the ACL and the 4th international joint conference on natural language processing of the AFNLP, vol. 1; 2009. p. 405\u201313."
    },
    "10.1016/j.nicl.2013.06.016": {
        "Title": "Left ear advantage in speech-related dichotic listening is not specific to auditory processing disorder in children: A machine-learning fMRI and DTI study",
        "Date": "2013",
        "Text": "serial JL 282794 291210 291703 291730 291738 291803 291834 291905 31 90 NeuroImage: Clinical NEUROIMAGECLINICAL 2013-07-02 2013-07-02 2014-08-05T00:53:03 1-s2.0-S2213158213000843 S2213-1582(13)00084-3 S2213158213000843 10.1016/j.nicl.2013.06.016 S300 S300.4 FULL-TEXT 1-s2.0-S2213158213X00026 2021-01-12T13:19:13.900523Z 0 0 20130101 20131231 2013 2013-07-02T00:00:00Z articleinfo articletitlenorm authfirstinitialnorm authfirstsurnamenorm cid cids contenttype copyright crossmark dateloaded dateloadedtxt datesearch datesort dateupdated dco docsubtype doctype doi eid ewtransactionid fundingbodyid hubeid indexeddate issn issnnorm itemstage itemtransactionid itemweight oauserlicense openaccess openarchive pg pgfirst pglast pii piinorm pubdateend pubdatestart pubdatetxt pubyr sectiontitle sortorder sponsoredaccesstype srctitle srctitlenorm srctype subheadings suppl tomb volfirst volissue volumelist webpdf webpdfpagecount yearnav figure table body acknowledge affil articletitle auth authfirstini authfull authkeywords authlast highlightsabst primabst ref alllist content oa subj ssids 2213-1582 22131582 UNLIMITED NONE true 3 3 C Volume 3 4 8 17 8 17 2013 2013 2013-01-01 2013-12-31 2013 Regular Articles article fla Copyright \u00a9 2013 The Authors. Published by Elsevier Inc. LEFTEARADVANTAGEINSPEECHRELATEDDICHOTICLISTENINGNOTSPECIFICAUDITORYPROCESSINGDISORDERINCHILDRENAMACHINELEARNINGFMRIDTISTUDY SCHMITHORST V 1 Introduction 2 Materials and methods 2.1 Participants 2.2 Audiological testing 2.3 fMRI scans 2.4 DTI scans 2.5 First-level analyses 2.6 ML analyses 2.7 Post-hoc tractography analysis 2.8 Post-hoc fMRI analyses to investigate possible effects of participant motion 3 Results 4 Discussion 4.1 DTI classifier 4.2 fMRI classifier 4.3 Implications for clinical practice 4.4 The etiology of ear advantage 4.5 Relation of LEA to other measures of auditory processing 4.6 Limitations 5 Conclusion Acknowledgment References ASHAAMERICANSPEECHLANGUAGEHEARINGASSOCIATION ASHTARI 2007 501 510 M ASTAFIEV 2003 4689 4699 S BEHRENS 2003 1077 1088 T BETHMANN 2007 145 157 A BRANCUCCI 2004 2329 2336 A BROADBENT 1958 D PERCEPTIONCOMMUNICATION BRYDEN 1988 1 43 M HANDBOOKDICHOTICLISTENINGTHEORYMETHODSRESEARCH OVERVIEWDICHOTICLISTENINGPROCEDURERELATIONCEREBRALORGANIZATION BUDDE 2009 2805 2813 M CACACE 2005 112 123 A CHERMAK 1997 G CENTRALAUDITORYPROCESSINGDISORDERSNEWPERSPECTIVES CORBETTA 1998 761 773 M DEBONIS 2008 4 18 D DELLAPENNA 2007 2303 2311 S DRAMSDAHL 2011 406 410 M DUBOIS 2008 14 27 J EICHELE 2005 405 412 T EMANUEL 2002 93 117 D EMANUEL 2011 48 60 D FERNANDES 2006 106 114 M FONTOURA 2008 34 39 D FOUNDAS 2006 79 86 A GIEDD 1999 861 863 J HALE 2006 896 904 T HAYNES 2006 523 534 J HENRY 1979 335 338 R HENRY 1983 915 918 R HICKOK 2007 393 402 G HUBLET 1976 3 8 C HUGDAHL 1995 K BRAINASYMMETRY DICHOTICLISTENINGPROBINGTEMPORALLOBEFUNCTIONALINTEGRITY HUGDAHL 2002 441 476 K ASYMMETRICALBRAIN DICHOTICLISTENINGINSTUDYAUDITORYLATERALITY HUGDAHL 2005 119 133 K HUGDAHL 1986 417 432 K HUGDAHL 1997 667 675 K HUGDAHL 1997 1494 1500 K HUNDGEORGIADIS 2002 166 176 M JANCKE 2002 736 743 L JANCKE 2001 349 363 L JERGER 2000 467 474 J JOACHIMS 1999 T MAKINGLARGESCALESVMLEARNINGPRACTICALADVANCESINKERNELMETHODSSUPPORTVECTORLEARNING KATZ 2005 124 127 J KEITH 1984 R AUDITIONINCHILDRENMETHODSSTUDY DICHOTICLISTENINGINCHILDREN KEITH 2009 R SCAN3FORCHILDRENTESTSFORAUDITORYPROCESSINGDISORDER KIM 2006 626 632 J KIMURA 1961 166 171 D KIMURA 1964 355 358 D KIMURA 1967 163 168 D KIMURA 1973 70 78 D KINOSHITA 1999 348 354 Y KINSBOURNE 1970 193 201 M KINSBOURNE 1973 239 255 M ATTENTIONPERFORMANCEIV CONTROLATTENTIONBYINTERACTIONBETWEENCEREBRALHEMISPHERES KINSBOURNE 1975 81 97 M ATTENTIONPERFORMANCEV MECHANISMHEMISPHERICCONTROLLATERALGRADIENTATTENTION KINSBOURNE 1980 221 224 M KLUENDER 1999 503 511 K KNECHT 2000 2512 2518 S KODAKA 1997 291 298 Y KRIEGESKORTE 2009 363 373 N KRIEGESKORTE 2008 1126 1141 N LIBERMAN 2000 187 196 A LIPSCHUTZ 2002 643 656 B LORING 1990 831 838 D LUO 2008 11615 11621 F MA 2007 3722 3730 X MA 2008 1127 1134 X MAZZIOTTA 1995 89 101 J METWALLI 2010 156 164 N MONCRIEFF 2011 316 322 D MOORE 2010 e382 e390 D MORAIS 1975 127 139 J MORAIS 1973 107 111 J MORAIS 1975 253 262 J MUSIEK 2010 F AMERICANACADEMYAUDIOLOGYCLINICALPRACTICEGUIDELINESDIAGNOSISTREATMENTMANAGEMENTCHILDRENADULTSCENTRALAUDITORYPROCESSINGDISORDER NAISMITH 2009 589 594 R NEWMAN 2007 C CLINICALOTOLOGY DIAGNOSTICAUDIOLOGY NORMAN 2006 424 430 K OBLESER 2008 8116 8123 J OIE 2013 M OTOOLE 2007 1735 1752 A PEREIRA 2009 S199 S209 F SCHMITHORST 2004 399 402 V SCHMITHORST 2006 1366 1379 V SCHMITHORST 2005 139 147 V SCHMITHORST 2007 1060 1074 V SCHMITHORST 2011 156 167 V SCHONWIESNER 2005 1521 1528 M SIDTIS 1988 161 184 J HANDBOOKDICHOTICLISTENINGTHEORYMETHODSRESEARCH DICHOTICLISTENINGAFTERCOMMISSUROTOMY SPARKS 1968 3 16 R SPRINGER 1975 341 346 S SPRINGER 1978 305 312 S STRAUSS 1987 747 753 E SUGA 2002 9 18 N SZAFLARSKI 2006 796 807 J TAKAHASHI 2000 881 885 M TALAIRACH 1988 J COPLANARSTEREOTAXICATLASHUMANBRAIN TAYLOR 2008 1397 1406 P THEVENAZ 1998 27 41 P THOMSEN 2004 211 218 T TZOURIO 1997 63 77 N VANDENNOORT 2008 902 911 M VANETTINGERVEENSTRA 2010 3481 3488 H VANNEST 2009 971 976 J VAPNIK 1995 V NATURESTATISTICALLEARNINGTHEORY VAPNIK 1997 V NEURALINFORMATIONPROCESSINGSYSTEMS SUPPORTVECTORMETHODFORFUNCTIONAPPROXIMATIONREGRESSIONESTIMATIONSIGNALPROCESSING VOYER 2011 245 255 D WARDAK 2006 4228 4235 C WESTERHAUSEN 2008 1044 1054 R WESTERHAUSEN 2006 272 279 R WESTERHAUSEN 2009 1322 1329 R WESTERHAUSEN 2009 183 189 R WILSON 2004 701 702 S WORSLEY 2002 1 15 K XIAO 2002 57 63 Z ZAIDEL 1983 95 151 E CEREBRALHEMISPHEREASYMMETRYMETHODTHEORYAPPLICATION DISCONNECTIONSYNDROMEAMODELFORLATERALITYEFFECTSINNORMALBRAIN ZATORRE 1989 1207 1219 R ZATORRE 1999 544 554 R SCHMITHORSTX2013X8 SCHMITHORSTX2013X8X17 SCHMITHORSTX2013X8XV SCHMITHORSTX2013X8X17XV Full 2013-07-16T21:32:41Z ElsevierWaived http://creativecommons.org/licenses/by-nc-nd/3.0/ item S2213-1582(13)00084-3 S2213158213000843 1-s2.0-S2213158213000843 10.1016/j.nicl.2013.06.016 282794 2021-01-12T13:19:13.900523Z 2013-01-01 2013-12-31 UNLIMITED NONE 1-s2.0-S2213158213000843-main.pdf https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S2213158213000843/MAIN/application/pdf/7b359d052eab1f7f910d1090cbf2b137/main.pdf https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2213158213000843/MAIN/application/pdf/7b359d052eab1f7f910d1090cbf2b137/main.pdf main.pdf pdf true 746839 MAIN 10 1-s2.0-S2213158213000843-main_1.png https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2213158213000843/PREVIEW/image/png/4e8a4230fc93da1ca18db3e26491f2b9/main_1.png https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S2213158213000843/PREVIEW/image/png/4e8a4230fc93da1ca18db3e26491f2b9/main_1.png main_1.png png 64150 849 656 IMAGE-WEB-PDF 1 1-s2.0-S2213158213000843-gr5.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S2213158213000843/gr5/DOWNSAMPLED/image/jpeg/a0cb144c42966b8cdd162f2711a4ec9c/gr5.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2213158213000843/gr5/DOWNSAMPLED/image/jpeg/a0cb144c42966b8cdd162f2711a4ec9c/gr5.jpg gr5 gr5.jpg jpg 22509 230 491 IMAGE-DOWNSAMPLED 1-s2.0-S2213158213000843-gr4.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S2213158213000843/gr4/DOWNSAMPLED/image/jpeg/302bcff73cebea1b6e18b2f935f6171a/gr4.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2213158213000843/gr4/DOWNSAMPLED/image/jpeg/302bcff73cebea1b6e18b2f935f6171a/gr4.jpg gr4 gr4.jpg jpg 17226 272 384 IMAGE-DOWNSAMPLED 1-s2.0-S2213158213000843-gr3.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S2213158213000843/gr3/DOWNSAMPLED/image/jpeg/3009b9dc11b26d89b57a7f8e37fe05a2/gr3.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2213158213000843/gr3/DOWNSAMPLED/image/jpeg/3009b9dc11b26d89b57a7f8e37fe05a2/gr3.jpg gr3 gr3.jpg jpg 48969 347 378 IMAGE-DOWNSAMPLED 1-s2.0-S2213158213000843-gr2.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S2213158213000843/gr2/DOWNSAMPLED/image/jpeg/28b94e2fd62268e86085535c2bb99df2/gr2.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2213158213000843/gr2/DOWNSAMPLED/image/jpeg/28b94e2fd62268e86085535c2bb99df2/gr2.jpg gr2 gr2.jpg jpg 16229 280 383 IMAGE-DOWNSAMPLED 1-s2.0-S2213158213000843-gr1.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S2213158213000843/gr1/DOWNSAMPLED/image/jpeg/7efd8435091c4e44b0258031f319b687/gr1.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2213158213000843/gr1/DOWNSAMPLED/image/jpeg/7efd8435091c4e44b0258031f319b687/gr1.jpg gr1 gr1.jpg jpg 36049 483 380 IMAGE-DOWNSAMPLED 1-s2.0-S2213158213000843-gr5.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S2213158213000843/gr5/THUMBNAIL/image/gif/95b4fb59f040d98ea31066c3365b39fb/gr5.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2213158213000843/gr5/THUMBNAIL/image/gif/95b4fb59f040d98ea31066c3365b39fb/gr5.sml gr5 gr5.sml sml 8580 103 219 IMAGE-THUMBNAIL 1-s2.0-S2213158213000843-gr4.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S2213158213000843/gr4/THUMBNAIL/image/gif/871dc01a4d9640d70e3ffc3ca33897aa/gr4.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2213158213000843/gr4/THUMBNAIL/image/gif/871dc01a4d9640d70e3ffc3ca33897aa/gr4.sml gr4 gr4.sml sml 3786 155 219 IMAGE-THUMBNAIL 1-s2.0-S2213158213000843-gr3.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S2213158213000843/gr3/THUMBNAIL/image/gif/2aab1366b9b5c2a8370c9843fe3ca694/gr3.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2213158213000843/gr3/THUMBNAIL/image/gif/2aab1366b9b5c2a8370c9843fe3ca694/gr3.sml gr3 gr3.sml sml 11383 163 178 IMAGE-THUMBNAIL 1-s2.0-S2213158213000843-gr2.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S2213158213000843/gr2/THUMBNAIL/image/gif/bd8389e4074bb6a5c42f00ca5d61c2f8/gr2.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2213158213000843/gr2/THUMBNAIL/image/gif/bd8389e4074bb6a5c42f00ca5d61c2f8/gr2.sml gr2 gr2.sml sml 3739 160 219 IMAGE-THUMBNAIL 1-s2.0-S2213158213000843-gr1.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S2213158213000843/gr1/THUMBNAIL/image/gif/c78d4bb42f186e68476a235aa5304741/gr1.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2213158213000843/gr1/THUMBNAIL/image/gif/c78d4bb42f186e68476a235aa5304741/gr1.sml gr1 gr1.sml sml 8950 164 129 IMAGE-THUMBNAIL YNICL 124 S2213-1582(13)00084-3 10.1016/j.nicl.2013.06.016 The Authors \u00a9 2013. Published by The Author. All rights reserved. Fig. 1 Region found to predict LEA or REA during a speech-related dichotic listening task in children for the functional contrast of listening to words presented dichotically vs. words presented diotically (images in radiologic orientation; slice locations: Z=+41mm to Z=+56mm, Talairach coordinate system.). Fig. 2 Functional activation (Z-scores, mean\u00b1s.d.) for the contrast of diotic listening vs. dichotic listening, for the region of the left frontal eye fields (shown in Fig. 1), for children with LEA vs. children with REA. Fig. 3 Region found to predict LEA or REA during a speech-related dichotic listening task in children for axial diffusivity (images in radiologic orientation; slice locations: Z=\u22124 mm to Z=+6mm, MNI coordinate system.). Fig. 4 Axial diffusivity (10\u22123 mm2/s; mean\u00b1s.d.) for the region shown in Fig. 3 for children with LEA vs. children with REA. Fig. 5 Probabilistic tractography results using the region in Fig. 3 as the starting seed, thresholded from a minimum of 1% of streamlines passing through each voxel, showing the relevant tracts to be the auditory radiations (left) and corticospinal tract (right) (slice locations: Coronal slice, Y=\u221225.5mm; sagittal slice, X=\u221222.5mm, MNI coordinate system). Table 1 Demographic and behavioral data on children classified as left-ear advantage (LEA) and right-ear advantage (REA) whose data was included in the fMRI study. REA LEA p #M, #F 10M, 2F 10M, 2F 1.00 Age (months) 133.6\u00b124.3 129.9\u00b123.4 0.71 # words identified in right ear (SCAN3 Competing words free recall) 17.3\u00b11.7 12.2\u00b11.8 <.001 # words identified in left ear (SCAN3 Competing words free recall) 14.2\u00b12.0 16.8\u00b12.2 <0.01 Sqrt. # of retained frames 10.2\u00b11.0 9.5\u00b11.5 0.20 Table 2 Demographic and behavioral data on children classified as left-ear advantage (LEA) and right-ear advantage (REA) whose data was included in the DTI study. REA LEA p #M, #F 12M, 2F 8M, 2F 0.71 Age (months) 131.1\u00b127.0 131.3\u00b125.0 0.98 # words identified in right ear (SCAN3 competing words free recall) 17.7\u00b11.1 12.0\u00b11.7 <.001 # words identified in left ear (SCAN3 competing words free recall) 14.1\u00b12.0 16.7\u00b12.3 <.01 Table 3 Performance (as age-normed percentile rank) on four subtests of the SCAN3 test for auditory processing disorders: Auditory Figure Ground, Filtered Words, Competing Words-Directed Ear and Competing Sentences, for all children with a LEA. Participant # Auditory Figure Ground Filtered Words Competing Words-Directed Ear Competing Sentences 1 9 37 63 37 2 5 63 37 37 3 50 50 84 37 4 75 84 50 63 5 25 50 84 50 6 25 75 75 16 7 25 75 63 63 8 25 75 50 63 9 91 91 75 50 10 50 50 63 37 11 50 75 5 2 12 37 91 75 50 Table 4 Region (from Fig. 1) found to predict left-ear advantage (LEA) or right-ear advantage (REA) for the functional contrast of listening to words presented dichotically vs. words presented diotically. Region X, Y, Z (mm Talairach) # Voxels Left middle/superior frontal gyrus (BA 8) \u221216, 33, 45 61 Table 5 Region (from Fig. 2) found to predict left-ear advantage (LEA) or right-ear advantage (REA) from axial diffusivity (AD). Region X, Y, Z (mm MNI) # Voxels Left internal capsule (sublenticular region) \u221232, \u221231, 3 58 Table 6 Performance of the classifiers used to predict LEA or REA during a speech-related dichotic listening task in children. Classifier Accuracy (%) Accuracy (95% confidence limit) p REA accuracy (%) LEA accuracy (%) fMRI (dichotic vs. diotic) 87.5 67.6\u201395.3 <0.001 83.3 91.2 DTI (AD) 87.5 67.6\u201395.3 <0.001 85.7 90.0 Left ear advantage in speech-related dichotic listening is not specific to auditory processing disorder in children: A machine-learning fMRI and DTI study Vincent J. Schmithorst a \u204e Rola Farah b Robert W. Keith b a Pediatric Neuroimaging Research Consortium, Dept. of Radiology, Cincinnati Children's Hospital Medical Center, Cincinnati, OH, United States Pediatric Neuroimaging Research Consortium Dept. of Radiology Cincinnati Children's Hospital Medical Center Cincinnati OH United States b Department of Communication Sciences and Disorders, College of Allied Health Sciences, University of Cincinnati, Cincinnati, OH, United States Department of Communication Sciences and Disorders College of Allied Health Sciences University of Cincinnati Cincinnati OH United States \u204e Corresponding author at: Department of Radiology, Children's Hospital of Pittsburgh of UPMC, 4401 Penn Ave., Pittsburgh, PA 15224, United States. Tel.: +1 412 692 3212; fax: +1 412 692 6312. Dichotic listening (DL) tests are among the most frequently included in batteries for the diagnosis of auditory processing disorders (APD) in children. A finding of atypical left ear advantage (LEA) for speech-related stimuli is often taken by clinical audiologists as an indicator for APD. However, the precise etiology of ear advantage in DL tests has been a source of debate for decades. It is uncertain whether a finding of LEA is truly indicative of a sensory processing deficit such as APD, or whether attentional or other supramodal factors may also influence ear advantage. Multivariate machine learning was used on diffusion tensor imaging (DTI) and functional MRI (fMRI) data from a cohort of children ages 7\u201314 referred for APD testing with LEA, and typical controls with right-ear advantage (REA). LEA was predicted by: increased axial diffusivity in the left internal capsule (sublenticular region), and decreased functional activation in the left frontal eye fields (BA 8) during words presented diotically as compared to words presented dichotically, compared to children with right-ear advantage (REA). These results indicate that both sensory and attentional deficits may be predictive of LEA, and thus a finding of LEA, while possibly due to sensory factors, is not a specific indicator of APD as it may stem from a supramodal etiology. Keywords Diffusion Magnetic Resonance Imaging Functional Magnetic Resonance Imaging Attention Dichotic listening tests Functional laterality Auditory processing disorder 1 Introduction Auditory processing disorder (APD) is a deficit in the neural processing of auditory stimuli (Asha. American Speech-Language-Hearing Association, 2005), distinct from higher-order cognitive function, which is estimated to affect 2\u20133% of school-aged children (Chermak and Musiek, 1997). Children diagnosed with APD have normal peripheral hearing but manifest deficits in one or more areas of higher-order auditory perception. The disorder is highly heterogeneous in nature, with a long list of behavioral indications (Asha. American Speech-Language-Hearing Association, 2005), such as difficulty understanding spoken language in noisy backgrounds or competing messages; difficulty following complex auditory directions or commands; difficulty in sound localization and lateralization; and difficulty in auditory discrimination. Thus, there is a wide variety of tests used in diagnostic procedures for APD (Emanuel, 2002; Emanuel et al., 2011; Jerger and Musiek, 2000). Behavioral findings from a study of over 1000 children in the U.K. suggest that many children referred for APD testing may in fact suffer a cognitive and/or attention deficit rather than a sensory processing deficit (Moore et al., 2010). Thus, a key difficulty in APD diagnosis is differential diagnosis of APD as opposed to other supramodal influences such as attention, memory, cognition, and ability to follow directions (Cacace and Mcfarland, 2005; Katz and Tillery, 2005). Dichotic listening (DL) tests are among the most frequently included and important tests used when diagnosing APD in children (Emanuel, 2002; Emanuel et al., 2011). In DL tasks, two different auditory stimuli are presented simultaneously to the right and left ears and the listener is required to report what was heard. Most individuals report speech-related stimuli presented to their right ear with greater accuracy compared to their left ear in the \u201cfree recall\u201d condition (individuals report stimuli in either order), a phenomenon known as the right-ear advantage (REA). The REA has been a robust finding (Hugdahl, 2002; Hugdahl and Hammar, 1997), since it was first described in the 1960s. However, not every individual demonstrates a REA; somewhere around 15\u201320% of right-handed individuals exhibit either no ear advantage (NEA) or a left-ear advantage (LEA) (Bryden, 1988). Moncrieff (2011) also reports that the prevalence of LEA in typically achieving children is approximately 20%. Many clinical audiologists consider ear advantage (EA) scores to be indicators of hemispheric dominance for language as well as neurologically-based auditory processing, language, and learning disorders (Keith, 1984). The common interpretation among clinical audiologists is that a REA for verbal stimuli indicates left hemisphere dominance for language. A LEA for verbal stimuli, on the other hand, is considered to indicate mixed or reversed dominance for language: a finding that is common among children with phonologic, reading, language and learning disorders (Hugdahl, 2005; Kimura, 1961; Newman and Sandridge, 2007). The rationale for the inclusion of DL tests in test batteries is that abnormal findings can result from the presence of APD (Asha. American Speech-Language-Hearing Association, 2005; Debonis and Moncrieff, 2008). Thus, a finding of LEA may indicate a sensory deficit which is thought to be associated with right-hemisphere language dominance. However, both the etiologies of right-hemisphere language dominance and of EA are unknown, lending doubt to this interpretation. Attentional or other supramodal influences may be responsible, or partly responsible, for EA, right-hemisphere dominance, or both. The association between LEA and right-hemispheric dominance is also uncertain. This construct is based on evidence of loci of language function obtained from multiple studies (Kimura, 1961). However, the prevalence of NEA/LEA is significantly greater than the prevalence of right-hemisphere lateralization for language processing in right-handed individuals. The prevalence of right-hemisphere lateralization is estimated at only between 1 and 5% (Knecht et al., 2000; Loring et al., 1990). Also, validation studies in normal adults and epileptic patients of speech-related DL (e.g. Bethmann et al., 2007; Fernandes et al., 2006; Fontoura et al., 2008; Hugdahl et al., 1997; Hund-Georgiadis et al., 2002; Strauss et al., 1987; Van Ettinger-Veenstra et al., 2010; Zatorre, 1989) confirmed the REA as predictive of left-hemisphere dominance, but not LEA as predictive of right-hemisphere dominance. Moreover, the interpretation of LEA made by clinical audiologists (e.g. that of indicating mixed or reversed language dominance and a possible sensory deficit) has never been tested using techniques of evoked potentials or imaging studies. American Academy of Audiology (Musiek et al., 2010) recognized the need for brain imaging and other electrophysiologic research to ascertain the status of the central auditory nervous system in children and adults. In this study we investigate whether functional MRI (fMRI) and diffusion tensor MRI (DTI) data can be used to predict whether a given individual will show a REA or a LEA. Toward this end, we use multivariate machine learning (ML) techniques (Haynes and Rees, 2006; Norman et al., 2006; O'toole et al., 2007; Pereira et al., 2009). These techniques represent a novel method for analyzing neuroimaging data which provide several advantages over standard analyses. While standard analyses (e.g. Worsley et al., 2002) are mass-univariate, multivariate analyses may show greater sensitivity (Pereira et al., 2009) to detect significantly different patterns of activation or structural differences between groups, when these differences are spread out over several regions. Mass-univariate analyses must implement a procedure for multiple statistical comparisons across regions, and while several regions may individually fail to meet a given threshold (corrected for multiple comparisons), the data combined over those regions may in fact meet that threshold. 2 Materials and methods 2.1 Participants The LEA study cohort consisted of right-handed children 7\u201314years old (N=13) who were recruited from the auditory processing disorders (APD) clinic at Cincinnati Children's Hospital Medical Center (CCHMC). All children were native English speakers with no diagnosed cognitive or neurological pathologies or hearing loss. These children had been referred for APD assessment due to listening and hearing complaints despite normal peripheral hearing, and were administered the SCAN3 APD test battery (Keith, 2009). Children with a LEA were identified from results of the competing words free recall subtest of the SCAN3 battery. Parents reported complaints such as difficulty understanding speech in background noise, following oral instructions, and rapid speech. These children often had difficulty following directions and difficulty localizing the source of the signal/speech, and frequently requested speakers to repeat oral information. However, parents reported no concerns or symptoms in regard to cognitive or neurological pathology; thus, in accordance with standard clinical practice, no specific cognitive or neurological evaluation was conducted. None of the participants received a diagnosis of APD after administration of the test battery (which was a chance occurrence, as APD diagnosis was not used as an inclusion or exclusion criterion). Typically developing children (N=20) were recruited as controls from the Cincinnati area via flyer and word of mouth. All of these children had a typical right ear advantage (REA) on the competing words free recall subtest of the SCAN3 test battery. The Institutional Review Boards at CCHMC and the University of Cincinnati approved all experiments. Informed consent from one parent and assent from each child were obtained before testing. Demographic information is reported in Tables 1 and 2 for those children for whom usable fMRI and DTI data were successfully obtained, respectively. All children were right handed based on a questionnaire filled out by parents that included a question \u201cis your child right/left handed/inconsistent\u201d. They were asked to base their response according to which hand the child used for writing, throwing, striking a match, scissors, toothbrush, spoon, knife, and a computer mouse. There were 2 children identified from the chart review who were reported as being left handed by their parents so they were not invited to participate in the study. 2.2 Audiological testing Peripheral hearing sensitivity for both ears was verified via standard pure tone audiometry and immittance testing in a sound proof booth. All children had pure-tone thresholds of 15dB HL or better at octave frequencies ranging from 250Hz to 8000Hz, and Type-A tympanograms. There was no significant difference in pure tone average (PTA) for either ear (p>0.5, unpaired T-test). Following peripheral auditory testing, the Dichotic Competing Words (CW) subtest of the SCAN3 battery (Keith, 2009), typically used to test children for APD, was administered to all children. Two different monosyllabic words were presented to both ears simultaneously and the children were instructed to repeat both words in any order, called the \u201cfree recall\u201d response mode. The test included 20 word pairs presented dichotically. The word pairs were aligned for onset and offset to eliminate any cue for the first word heard. The EA score was calculated as the mathematical difference between the right ear (RE) and left ear (LE) raw score. A positive value is considered a REA and a negative value a LEA. The EA scores were compared to age-matched normative data. All children in the LEA group had an atypical LEA with prevalence of 10% or less compared to the normative data. As part of their APD assessment, additional subtests of the SCAN3 test battery including Auditory Figure Ground, Filtered Words, Competing Words-Directed Ear and Competing Sentences had been administered to the children with LEA prior to recruitment in the study. For the Auditory Figure Ground (AFG) subtest, test stimuli consist of 20 monaural words presented in multi-talker speech background noise at an SNR of +8dB; the stimuli are presented at intensity of 8dB greater than the background noise. For the Filtered Words (FW) subtest, the test stimuli consist of one syllable words that have been low-pass filtered at 750Hz with a roll-off of 30dB per octave. Twenty words are administered to each ear. The Competing Words-Directed Ear (CW-DE) subtest includes monosyllabic word pairs presented to both ears simultaneously. The child is instructed to repeat both words in a prescribed order: repeating from the right ear first for the first 15 word pairs then repeating from the left ear first for the second 15 word pairs. The Competing Sentences subtest consists of sentence pairs presented dichotically in a focused attention mode of administration. In this mode, the child is instructed to repeat only the stimuli presented to the right ear for the first 10 sentence pairs followed by repeating only the stimuli presented to the left ear for the second 10 sentence pairs. Normative data is available for all subtests of the SCAN3 according to the child's age. 2.3 fMRI scans All scans were acquired on a Philips 3T Achieva system. The event-related fMRI paradigm was similar to that used in a previously published study (Van Den Noort et al., 2008). The paradigm consisted of word pairs taken from the CW paradigm. 20 word pairs were presented dichotically. Silent gradient intervals were used for the word presentations (Schmithorst and Holland, 2004); this method allows the presentation of stimuli without any background scanner noise. This technique has been shown to provide similar or better activation than using continuous scanning (Vannest et al., 2009). The children responded orally by repeating back the heard words. For the control task, the two words were presented diotically, one after the other. Diotic presentation was selected as a control task in order to control for cognitive processes related to receptive language, expressive language, working memory, and sublexical auditory processing. A 6-second scanning period (in which three image volumes are acquired) followed a 5-second stimulus presentation period. fMRI\u2013EPI scan parameters were: TR/TE=2000/38ms, matrix=64\u00d764, FOV=24cm\u00d724cm, SENSE factor=2, slice thickness=5mm, 25 slices acquired covering the whole brain. The stimuli were presented using Presentation software (Neurobehavioral Systems Inc., Albany, CA) and the order of presentation was randomized at runtime. One scan run was obtained with 40 trials (20 dichotic, 20 diotic) with 11s per trial (5second stimulus presentation, 6second scanning period) for a total acquisition time of 7min 20s. In-scanner performance was monitored via an MRI-compatible microphone. 2.4 DTI scans The 15-direction standard Philips EPI-DTI sequence was used with the following parameters: FOV=22.4cm\u00d722.4cm, matrix=112\u00d7112, slice thickness=2mm, 60 slices were acquired for 2mm isotropic resolution over the whole brain, b value=1000s/mm2, SENSE factor=2. 2.5 First-level analyses The fMRI scans were motion-corrected using an affine transformation and a pyramid iterative algorithm (Thevenaz et al., 1998) (scans were not smoothed prior to analysis as a \u201csearchlight\u201d procedure (described below) is to be used.). The motion correction was performed separately for the sets of 1st, 2nd, and 3rd scans after the silent period. The motion correction was performed repeatedly for each set of reference images. The remainder of the 1st level analysis for fMRI was performed using in-house routines written in IDL (ENVI, Boulder, CO). The optimal motion correction results (e.g. which set of reference of images were chosen) were selected using the maximum number of frames meeting a cost function threshold selected via visual inspection (Szaflarski et al., 2006). The entire dataset was discarded if there were not at least 47 retained frames. This happened for 9 participants, leaving a total of 24 participants with usable data. A General Linear Model (GLM) was performed separately on the 1st, 2nd, and 3rd scans after the silent period with manner of presentation (diotic vs. dichotic) the variable of interest, and linear and quadratic terms to account for scanner drift as covariates of no interest. Results were combined into a single Z-score map of functional activation and transformed into stereotactic (Talairach) space (Talairach and Tournoux, 1988) at 3.75mm\u00d73.75mm by 5mm resolution. The DTI scans were pre-processed in a similar manner as that described in Schmithorst et al. (2005). Scans were visually inspected for gross motion artifacts and slice drop-outs due to motion during the diffusion sensitizing gradients. This resulted in datasets being discarded from 9 participants, leaving a total of 24 participants with usable data (21 participants had usable data for both DTI and fMRI). Fractional anisotropy (FA), mean diffusivity (MD), axial diffusivity (AD), and radial diffusivity (RD) maps were computed from the tensor components. These maps were transformed into standard Montreal Neurological Institute (MNI) space using the following procedure (routines written in SPM8, Wellcome Institute of Cognitive Neurology, London, UK). The T1-weighted anatomical images were segmented into gray, white, and CSF images using the segmentation procedure in SPM8. The FA maps were co-registered to the white matter maps using a 6-parameter rigid-body transformation, and this transformation was applied to the other DTI parameter maps. The white matter maps for each child were normalized to the white matter template (using the non-linear normalization routine). This transformation was then applied to the DTI parameter maps. Only voxels with FA>0.25 and white matter probability>0.9 were retained for further analysis. 2.6 ML analyses ML analyses were performed using in-house code written in IDL (ENVI, Boulder, CO). The ML analyses were performed using a searchlight approach with a 5\u00d75\u00d75 cube and a Support Vector Machine (SVM) classifier (Vapnik, 1995). The searchlight cube was chosen to be similar in magnitude to spatial filters typically used for voxelwise fMRI and DTI analyses (e.g. Schmithorst and Holland, 2006; Schmithorst et al., 2005, 2007, 2011). The SVMLight program (Joachims, 1999) was used when there was more than one independent variable; in-house code was written in IDL for the special case of one independent variable. The ML analyses only included voxels where each participant had a usable data point (e.g. in the brain for fMRI, in white matter with FA>0.25 and WM probability>0.9 for DTI). The classifier accuracy in distinguishing LEA children from REA children was estimated using leave-one-subject-out cross-validation. To avoid biasing the classification accuracy estimator (Pereira et al., 2009), the following steps were performed only on the training data for each cross-validation run. For each voxel, the mean value (Z-score map for fMRI; FA, RD, MD, or AD for DTI) was determined for the 5\u00d75\u00d75 cube centered on the voxel (the mean value, rather than a weighted average found via e.g. Gaussian filtering, was chosen due to its superior SNR). Feature selection: Feature selection was performed by ranking all voxels in the brain. The metric used was accuracy on an SVM classifier (using data from a single voxel only) estimated using leave-one-subject-out cross-validation (since these steps involve only the training data for each cross-validation run in which one participant is left out, each training run for estimation of classifier accuracy using leave-one-subject-out cross-validation will therefore include data from N-2 participants.). The voxels were ranked according to the performance of the classifier, and only data from the top-ranked voxels were retained for further analysis. The number of voxels to retain was chosen a priori as between 1 and 10. Classification: An SVM classifier was trained for each set (e.g. from 1 to 10) of retained voxels, and the number of voxels to retain was determined based on which classifier performed the best. The voxels to retain and the parameters for the classifier were stored and then used to classify the test subject. One of the children was scanned twice, on different days. Both datasets were retained for analysis, since having more training data available is always optimal for ML. When the doubly-scanned participant was the test subject for the cross-validation, however, the other scan from the participant was removed from the training set to avoid bias. In order to estimate accuracy from cross-validation, the doubly-scanned participant was counted as being correctly classified if he/she was correctly classified both times, incorrectly classified if he/she was incorrectly classified both times, and assigned a value of 0.5 if one of the datasets resulted in a correct classification while the other resulted in an incorrect classification. For those classifiers shown to be better than chance level, the classifiers were re-trained using the entire dataset using the above procedure. Classifier maps (incorporating all voxels included in the classifier and 5\u00d75\u00d75 cubes centered on them) were constructed to display the relevant voxels (e.g. where the searchlight was located). For each region, ROIs were drawn and the fMRI or DTI values for each class (REA vs. LEA) were obtained. Data values were averaged from both sets of the doubly-scanned participant. Post-hoc analyses were performed on the resulting data to further investigate the significance of the regions included in the classifiers (relevant regions may incorporate less than 125voxels due to the part of the searchlight cube being outside the region of usable data. Also, we note that in this study we are classifying individual subjects and the training data is independent from the test data, unlike applications such as classification of cognitive states from neuroimaging data, where the training and test data are correlated. Thus, the null distribution is equivalent to that obtained from chance classification and it is not necessary to use permutation testing to derive the null distribution.). 2.7 Post-hoc tractography analysis To investigate the DTI results further, the white matter parcellation map (ICBM DTI-81 Atlas) (Mazziotta et al., 1995) was used to classify the relevant white matter region. Additionally, probabilistic tractography (Behrens et al., 2003) was performed, using the voxels relevant for classification from the DTI results as the starting seed points. The probabilistic tractography was performed using routines in FSL (fMRIB, Oxford, UK). The streamlines were transformed back into MNI space and then averaged across participants. 2.8 Post-hoc fMRI analyses to investigate possible effects of participant motion Differences in participant motion between the LEA and REA children could conceivably affect the results. Thus, an additional analysis was conducted on the average activation in the ROI. A GLM was performed with functional activation as the independent variable and side of ear advantage, participant motion (parameterized by the square root of the number of retained frames), and their interaction as dependent variables. 3 Results Based on the classification, there were significant differences in (out-of-scanner) performance in the left and right ears of the competing words free recall test between the groups; however, there were no significant differences in age, sex or motion inside the scanner between the groups for either the fMRI or the DTI study (Tables 1 and 2). As all the control participants demonstrated a REA, it was not necessary to exclude any participant based on the dichotic testing results. Performance on the other subtests of the SCAN3 test battery, administered to all children with LEA, is given in Table 3 as age-normed percentile scores (scores were converted into Z-scores for further statistical analysis). There was no significant difference from normal for Auditory Figure Ground (T(11)=\u22121.41, ns), Competing Sentences (T(11)=\u22121.44, ns) or Competing Words Directed Ear (T(11)=1.21, ns). However, there was a significant difference from normal for the Filtered Words subtest (T(11)=3.39, p<0.01). For the fMRI task, there were highly significant within-subject correlations between the in-scanner performance during the dichotic condition and the results of the DL test performed outside the scanner (the same words were used for both tests, although the in-scanner presentation order was randomized.). For the number correct in the right ear, overall correlation was R=0.96 (p<0.001); in children with right-ear advantage, correlation was R=0.97 (p<0.001); in children with left-ear advantage, correlation was R=0.82 (p<0.005). For the number correct in the left ear, overall correlation was R=0.95 (p<0.001); in children with right-ear advantage, correlation was R=0.94 (p<0.001); in children with left-ear advantage, correlation was R=0.94 (p<0.001) (due to the difference in correlation coefficients (R=0.94 vs. R=0.82) between in-scanner and out-of-scanner performance in the LEA group between the left and right ears, we tested for an in-scanner performance\u00d7side interaction on out-of-scanner performance; the result was not significant (T(20)=0.23, p>0.5).) For the ear advantage (# correct right\u2212# correct left), overall correlation was R=0.99 (p<0.001); for the children with right-ear advantage, correlation was R=0.86 (p<0.001); for the children with left-ear advantage, correlation was R=0.96 (p<0.001). Root mean square (rms) differences in scores between the two test administrations were also computed: rms differences for the right ear, left ear, and difference were 0.94, 0.96, and 0.68, respectively. No child displayed a difference in the side of ear advantage between the two tests. A systematic difference between the two test administrations was reached at a trend level for the right ear (T(23)=2.055, p=0.051) and the left ear (T(23)=1.74, p=0.095), with children performing better on average in the scanner, likely due to a training effect. However, these effects canceled each other out in the computation of ear difference scores, where no significant effect was seen (T(23)=0.29, p>0.5). All children performed very well in the diotic condition, with each child correctly identifying at least 34 out of the 40 words presented. No difference was seen between REA and LEA children (p>0.5, unpaired T-test). A classifier of LEA vs. REA was successfully trained for the fMRI data. The accuracy of the classifier was 87.5% (95% confidence interval 67.6%\u201395.3%). The accuracy is significantly different from chance (p<0.001). The relevant region (Fig. 1 ; Table 4 ) is the left middle/superior frontal gyrus in the region of the frontal eye fields (BA 8). Post-hoc analysis (Fig. 2 ) revealed greater activation for children with REA during the diotic presentation in the left frontal eye fields (p<1e\u22124, one-sample T-test) as compared to the dichotic presentation; however, no difference was found in children with LEA (p>0.5, one-sample T-test). Analyzing possible effects of participant motion, the GLM revealed a significant main effect of EA side (T(20)=5.24, p<1e\u22124) but no significant main effect of motion (T(20)=0.9, p>0.5); there was a trend towards an interaction (T(20)=\u22121.7, p<0.1). Removing the effects of motion via stepwise regression for both groups still resulted in a highly significant difference between groups (p<1e\u22124, unpaired T-test). These results allow us to conclude that our results are not unacceptably biased by participant motion. From the DTI data, no classifier of LEA vs. REA was successfully trained for FA, MD, or RD. However, a classifier was successfully trained for the AD data. The accuracy of the classifier was 87.5% (95% confidence interval 67.6%\u201395.3%). The accuracy is significantly different from chance (p<0.001). The relevant region (Fig. 3 ; Table 5 ) is in the left internal capsule. This region was classified as the retrolenticular part using the DTI atlas; however, the atlas does not distinguish between the retrolenticular and sublenticular parts. Post-hoc analysis (Fig. 4 ) revealed greater AD for children with LEA compared to those with REA (p<0.005, unpaired T-test). This region also had greater MD in children with LEA (p<0.01, unpaired T-test), but no significant difference in FA (p>0.5, unpaired T-test) or RD (p>0.5, unpaired T-test). AD was correlated with MD (R=0.56, p<0.01) and FA (R=0.55, p<0.01) but not RD (R=\u22120.19, p>0.35). For convenience the results of both classifiers are summarized in Table 6 . The tractography results revealed the most probable connections to be to the posterior part of the thalamus and the auditory cortex (Fig. 5 , left), indicating the relevant white matter tract as the auditory radiations, and showing the region in Fig. 4 to be the sublenticular, and not the retrolenticular, part of the internal capsule. However, the tractography results also show connections though the corticospinal tract (Fig. 5, right). 4 Discussion There are some neuroimaging and electrophysiology studies in the literature that investigate dichotic listening (Eichele et al., 2005; Jancke and Shah, 2002; Jancke et al., 2001; Thomsen et al., 2004; Westerhausen et al., 2006, 2009a). Schmithorst et al. (2011) published a DTI study that investigated the structural correlates of some tests used to diagnose APD in normal children. However, this is the first study, to our knowledge, which uses machine-learning techniques to predict results of one of the tests, i.e. the competing words free recall subtest. Machine-learning techniques are much more powerful than standard statistical analyses for ascertaining the clinical value of diagnostic tests as they relate to a given pathology. While standard statistical analyses are only capable of informing the investigator that the average result of a given test or tests (to a given degree of statistical significance) differs dependent on pathology, machine-learning techniques inform on the sensitivity and specificity of a specific test battery. 4.1 DTI classifier LEA was found to be predicted by increased AD in the posterior limb of the internal capsule, including projections to the auditory cortex (indicating the sublenticular portion). The AD values did not significantly correlate with RD. Increased MD, but no significant difference in RD or FA, was found in children with LEA (despite this difference in MD, we were unable to successfully train a classifier using MD. A region that meets a nominal (uncorrected) threshold for significant between-group differences will not necessarily be detected when attempting to train a classifier, due to the fact that the whole brain is searched each training run. In fact, the region may not even be found with a conventional voxelwise GLM analysis, due to the necessity to correct for multiple comparisons. Additionally, the mathematics of an SVM classifier is different from a GLM.). Physiological interpretation of DTI parameters is open to debate, and there are a number of possible explanations for differences in AD. One interpretation is that increased AD indicates a pattern of reduced tortuosity in the fiber anatomy and/or increased axonal fiber organization (Dubois et al., 2008). This result has been shown histologically in rat experiments (Takahashi et al., 2000) and increased AD (without any change in RD) has been shown developmentally in adolescent older vs. younger males (Ashtari et al., 2007). Also, many studies have shown changes in AD resulting from axonal or neuronal injury or degeneration; however, the direction of the change varies depending on the specific pathology. Increased AD was found as a result of neurodegeneration in patients with amyotrophic lateral sclerosis (Metwalli et al., 2010). However, axonal injury in a mouse model of multiple sclerosis was found to result in decreased AD (Budde et al., 2009; Kim et al., 2006). Yet another possibility is that increased AD results from decreased neurofibrils (such as microtubules and neurofilaments) and loss of glial cells (Kinoshita et al., 1999) in response to intoxication with methylmercury chloride (MMC). To make matters more complicated yet, patients with optic neuritis displayed an initial decrease of AD, followed by an increase over baseline 1year after onset (Naismith et al., 2009). Future research needs to be performed to better understand the etiology of differences in AD. Nevertheless, we find the explanations of axonal injury, decreased neurofibrils, or neurodegeneration unlikely for our study, given that the axonal injury and decreased neurofibrils were found in mice exposed to toxins, and our study cohort consisted of normal children without obvious neuropathology. Therefore, we consider reduced tortuosity and increased organization as the most likely explanation for the increased AD. Increased organization (as reflected by increased AD) is consistent with enhanced efferent connectivity. Cortical feedback (through the corticofugal pathway) is known to alter the representation of auditory information at the subcortical level of processing (Luo et al., 2008; Ma and Suga, 2007, 2008; Suga et al., 2002; Xiao and Suga, 2002) in animal models. This feedback is both excitatory and inhibitory (Luo et al., 2008). Thus, children with LEA may be exhibiting increased inhibition of the signal from the right ear due to increased connectivity in the efferent auditory pathway. This may be possibly the result of inefficiencies in the gray matter pruning process, which begins around the younger age range of our study (Giedd et al., 1999). However, we cannot rule out the DTI results being due to impaired afferent connectivity, as DTI is unable to resolve the directionality of the connectivity difference (e.g. thalamo-cortical vs. cortico-thalamic). Thalamo-cortical projections appear to be related to multimodal and polysensory integration (Kriegeskorte, 2009; Kriegeskorte et al., 2008). If impaired afferent connectivity is the reason for the increase in AD, the causal direction of the relationship between LEA and deficits in multimodal integration is at present unclear. The tractography results also indicate connections to the motor/premotor regions. This may be an artifact, due to our large effective voxel size (e.g. from the 5\u00d75\u00d75searchlight region used) encompassing part of the posterior limb of the internal capsule. However, it may also be the case that LEA is associated with differences in connectivity to premotor regions, as they have been hypothesized to be implicated in speech processing via articulatory representations (Hickok and Poeppel, 2007; Kluender and Lotto, 1999; Liberman and Whalen, 2000; Wilson et al., 2004). 4.2 fMRI classifier Children with REA activate the left frontal eye fields (BA 8) to a greater extent under the diotic than under the dichotic condition, while no difference was found in children with LEA. These results are consistent with previously published studies suggesting that attentional factors may play an important role in side of ear advantage. Frontal eye field activation has been noted in several neuroimaging studies involving auditory attention (Lipschutz et al., 2002; Tzourio et al., 1997; Zatorre et al., 1999) and dichotic listening (Thomsen et al., 2004). The frontal eye fields play an important role in attentional explanations of the REA (Kinsbourne, 1970, 1973, 1975, 1980). In this model, greater activation of the left hemisphere to language stimuli extends to the lateral-orienting frontal eye fields, biasing attention contralaterally towards the right side of space (Astafiev et al., 2003; Corbetta et al., 1998; Kodaka et al., 1997; Taylor et al., 2008; Wardak et al., 2006). This results in a right-sided advantage for the detection of sensory stimuli including visual, somatosensory, and auditory. In the children with REA, this right-sided attentional bias (as reflected by frontal eye field activation) is greater in the absence of dichotic competition, as is expected as there is no distractor on the contralateral side. Our findings that side of ear advantage may be related to attentional differences are also consistent with previously published studies investigating laterality and dichotic listening performance in individuals with attention deficit hyperactivity disorder (ADHD). Normal controls, but not adults with ADHD, displayed a REA for word recognition (Hale et al., 2006); the interaction was statistically significant, despite the small sample size (22 controls vs. 22 adults with ADHD). ADHD participants also displayed worse performance for words presented to the right ear compared to controls. Interestingly, individuals with ADHD also displayed better performance overall during dichotic listening involving the presentation of emotional stimuli, and also better performance in the left ear, leading the authors to posit greater right hemisphere and lower left hemisphere contribution in individuals with ADHD. Children with ADHD displayed a REA during a version of dichotic listening when they were instructed to focus attention on the left ear (Oie et al., in press); similar results were also found in adults (Dramsdahl et al., 2011), again indicating a link between spatial attention and ADHD. 4.3 Implications for clinical practice Side of ear advantage was found to be strongly predicted by differences in activation in the frontal eye fields related to the mode of presentation (diotic vs. dichotic). These results are consistent with LEA being the result of differences in directional biases of attention, as persons with an attentional deficit may focus their listening attention differently than typical listeners, resulting in a left ear advantage (LEA) on free recall dichotic listening tests. However, our results are also consistent with a neuroanatomical underpinning to LEA at the sensory level. Differences in connectivity in the area of the auditory radiations in the left hemisphere (connecting the medial geniculate to auditory cortex) were also shown to predict a finding of LEA as accurately as functional activation differences in the frontal eye fields. Whether this is due to excess efferent, inhibitory connections (as we find more likely) or due to impaired afferent, ascending connections are unknown at this time. Such a deficit is likely associated with impaired speech comprehension, as it inhibits the flow of information into the left auditory cortex and subsequently into language processing areas in the left hemisphere. Therefore, although previous investigations indicate that LEA is sensitive to sensory deficits, we find that it cannot be taken as a specific indicator for modality specific APD. Our results also support the concern of Moore et al. (2010) that many children referred for APD testing may in fact have a cognitive/attention rather than an auditory perceptual deficit, underscoring the importance of dissociating supramodal influences in APD diagnostic test batteries. In addition to attention and cognition, other examples of supramodal influence include memory, ability to follow instructions, motivation, etc. While none of the study participants with a LEA received a diagnosis of APD, and they performed on average at near-normal or above-normal levels on the other SCAN3 subtests (not involving dichotic listening), they were referred for APD testing with complaints regarding speech perception. The between-test differences in performance are not surprising: large differences in patterns of correlations between brain connectivity and task performance on individual tests used for APD diagnosis, including degraded speech, have previously been found (Schmithorst et al., 2011). Our results also support previous studies (e.g. Bethmann et al., 2007; Hugdahl et al., 1997) showing that a finding of LEA is not predictive for atypical right-hemispheric language dominance, as we have identified two mechanisms by which LEA could also arise in a child with normal left-hemisphere dominance. 4.4 The etiology of ear advantage Additionally, our results can inform the ongoing debate over the etiology of ear advantage, for which there is currently no consensus. In the structural model of DL (Kimura, 1964, 1967, 1973), the (weaker) ipsilateral connections in the ascending auditory pathway are suppressed (via some sort of \u201cocclusion\u201d mechanism) at some point in the auditory pathway during presentation of dichotic stimuli. Each hemisphere then exclusively receives input from the contralateral ear. Input from the left ear must therefore traverse interhemispherically from the right auditory cortex across the corpus callosum before it can be processed in the language areas of the left hemisphere. Therefore stimuli presented to the right ear have a more direct connection to the language areas, without the need for a \u201ccallosal relay\u201d (Westerhausen and Hugdahl, 2008; Zaidel, 1983) resulting in delay and/or attenuation of auditory information for stimuli presented to the left ear. In the attentional model (Kinsbourne, 1970, 1973), the processing of language stimuli in the left hemisphere biases subsequent attention towards the contralateral (right) hemispace. This model is based on a \u201cfilter\u201d theory of selective attention (Broadbent, 1958), in which due to limited capacity for information processing in a given channel, only a proportion of sensory input is accepted for subsequent processing, the remainder being rejected. Since the right-ear message is mainly projected towards an already-activated left hemisphere, the attentional system is biased towards accepting the message presented in the right ear, and rejecting that presented in the left ear. Evidence in support of the structural model comes from commisurotomized patients who can recognize monaural stimuli but completely fail to recognize stimuli presented to the left ear during a dichotic presentation (Sidtis, 1988; Sparks and Geschwind, 1968; Springer and Gazzaniga, 1975; Springer et al., 1978). The structural model finds additional support from magnetoencephalography (MEG) studies (Brancucci et al., 2004; Della Penna et al., 2007) that show inhibition of the ipsilateral auditory pathway for dichotic stimuli with similar fundamental frequencies and for dichotic stimuli with different intensities. However, one of the most important findings favoring the attentional model is that change in lateralization occurs when listeners are instructed to direct attention to either the left or the right ear (Foundas et al., 2006; Hugdahl, 1995; Hugdahl and Andersson, 1986). Additionally, the REA has also been shown to be a right side of space advantage, in several experiments which either used loudspeakers instead of earphones (Hublet et al., 1976; Morais, 1975; Morais and Bertelson, 1973), or simulated the position of sounds by altering amplitude and/or phase (Morais and Bertelson, 1975). Also supporting the attentional model are studies showing a REA even for monaural stimulation (Henry, 1979, 1983), undercutting the assumption in the structural model that an occlusion mechanism is necessary to elicit a REA. These two models (structural vs. attentional/supramodal), however, are not mutually exclusive. A recent study (Westerhausen et al., 2009b) demonstrated interactions between top-down (e.g. free-report vs. focused attention) and bottom-up (interaural intensity difference) factors for ear advantage, suggesting that attentional and sensory components are not independent, but interacting. Our results, in which EA was found to be predicted both by attentional factors and by neuranatomical differences below the level of the auditory cortex, lend support to this framework. It should be pointed out, however, that our results are confounded by the fact that the LEA children were referred for APD testing whereas the REA children were not. 4.5 Relation of LEA to other measures of auditory processing While children with LEA did not show a significant difference from normal on either Auditory Figure Ground (speech in noise) or Competing Sentences, they did perform significantly better than normal on low-pass Filtered Words. For this task, it is likely that participants are using spectral information (normally processed in the right hemisphere) to aid with lexical decision (Obleser et al., 2008; Schonwiesner et al., 2005), and children with LEA may have a more direct input into the right hemisphere, as information does not need to traverse interhemispherically across the corpus callosum if the main input is from the left ear. In normal children, structural connectivity across the corpus callosum has been associated with performance on the Filtered Words test (Schmithorst et al., 2011). However, further research will be necessary on this topic. 4.6 Limitations The study is subject to some limitations. The study population was biased towards males, which might limit its generalizability; however, sex differences are not consistently reported in DL (Bryden, 1988), and while a recent meta-analysis (Voyer, 2011) found some evidence of greater laterality in males, the effect size was rather small (d=0.054). Additionally, this study utilized the free-recall version of dichotic listening, in which the listener reports back the two words heard in any order. Further research will investigate whether performance on directed-ear versions of dichotic listening tests may also be predicted via neuroimaging data. In this study lateralization was taken as a dichotomous variable; however, it can also be parameterized as a continuous variable and predicted using a different type of classifier such as Support Vector Regression (Vapnik et al., 1997). A possible limitation is the selection of the control group from a community population. A more matched control group would have consisted of children with REA referred for APD testing due to complaints regarding speech perception but not eventually diagnosed with APD. The choice of control population to use involves a tradeoff of information obtained about the precise neuroanatomical and neurofunctional correlates of EA versus information available about the clinical relevance of DL testing for APD in children referred for APD testing. If (hypothetically) attentional factors would accurately predict LEA in children referred for APD testing versus REA in children referred for APD testing, we would be able to draw the same conclusion as we have in the current study. However, a much stronger conclusion would have been available from a (hypothetical) failure to predict LEA from attentional factors: in our current study design, we would have been able to conclude that a finding of LEA is specific to a sensory processing deficit and hence of more significant clinical value for APD diagnosis. As the main focus of this study was to investigate the clinical relevance of EA for APD diagnosis, we chose to use a community-based sample for our control population. 5 Conclusion In children referred for APD testing, LEA during a dichotic listening task involving speech-related stimuli was found to be predicted by greater axial diffusivity in the sublenticular part of the left internal capsule; and lesser functional activation in the left frontal eye fields during diotic speech-related presentations relative to dichotic presentations. Results show that LEA may be predicted by attentional or other supramodal differences as well as sensory deficits and therefore not specific to APD. Acknowledgment The authors thank Tom Mitchell, Ph.D., for the helpful discussion regarding the implementation of ML. References Asha. American Speech-Language-Hearing Association, 2005 Asha. American Speech-Language-Hearing Association (Central) Auditory processing disorders [technical report] Available from www.asha.org/policy 2005 Ashtari et al., 2007 M. Ashtari K.L. Cervellione K.M. Hasan J. Wu C. Mcilree H. Kester B.A. Ardekani D. Roofeh P.R. Szeszko S. Kumra White matter development during late adolescence in healthy males: a cross-sectional diffusion tensor imaging study NeuroImage 35 2007 501 510 Astafiev et al., 2003 S.V. Astafiev G.L. Shulman C.M. Stanley A.Z. Snyder D.C. Van Essen M. Corbetta Functional organization of human intraparietal and frontal cortex for attending, looking, and pointing Journal of Neuroscience 23 2003 4689 4699 Behrens et al., 2003 T.E. Behrens M.W. Woolrich M. Jenkinson H. Johansen-Berg R.G. Nunes S. Clare P.M. Matthews J.M. Brady S.M. Smith Characterization and propagation of uncertainty in diffusion-weighted MR imaging Magnetic Resonance in Medicine 50 2003 1077 1088 Bethmann et al., 2007 A. Bethmann C. Tempelmann R. De Bleser H. Scheich A. Brechmann Determining language laterality by fMRI and dichotic listening Brain Research 1133 2007 145 157 Brancucci et al., 2004 A. Brancucci C. Babiloni F. Babiloni S. Galderisi A. Mucci F. Tecchio F. Zappasodi V. Pizzella G.L. Romani P.M. Rossini Inhibition of auditory cortical responses to ipsilateral stimuli during dichotic listening: evidence from magnetoencephalography European Journal of Neuroscience 19 2004 2329 2336 Broadbent, 1958 D. Broadbent Perception and Communication 1958 Pergamon London Bryden, 1988 M.P. Bryden An overview of the dichotic listening procedure and its relation to cerebral organization K. Hugdahl Handbook of Dichotic Listening: Theory, Methods, and Research 1988 Wiley Chichester, UK 1 43 Budde et al., 2009 M.D. Budde M. Xie A.H. Cross S.K. Song Axial diffusivity is the primary correlate of axonal injury in the experimental autoimmune encephalomyelitis spinal cord: a quantitative pixelwise analysis Journal of Neuroscience 29 2009 2805 2813 Cacace and Mcfarland, 2005 A.T. Cacace D.J. Mcfarland The importance of modality specificity in diagnosing central auditory processing disorder American Journal of Audiology 14 2005 112 123 Chermak and Musiek, 1997 G. Chermak F.E. Musiek Central Auditory Processing Disorders. New Perspectives 1997 Singular Publishing Group San Diego Corbetta et al., 1998 M. Corbetta E. Akbudak T.E. Conturo A.Z. Snyder J.M. Ollinger H.A. Drury M.R. Linenweber S.E. Petersen M.E. Raichle D.C. Van Essen G.L. Shulman A common network of functional areas for attention and eye movements Neuron 21 1998 761 773 Debonis and Moncrieff, 2008 D.A. Debonis D. Moncrieff Auditory processing disorders: an update for speech-language pathologists American Journal of Speech-Language Pathology 17 2008 4 18 Della Penna et al., 2007 S. Della Penna A. Brancucci C. Babiloni R. Franciotti V. Pizzella D. Rossi K. Torquati P.M. Rossini G.L. Romani Lateralization of dichotic speech stimuli is based on specific auditory pathway interactions: neuromagnetic evidence Cerebral Cortex 17 2007 2303 2311 Dramsdahl et al., 2011 M. Dramsdahl R. Westerhausen J. Haavik K. Hugdahl K.J. Plessen Cognitive control in adults with attention-deficit/hyperactivity disorder Psychiatry Research 188 2011 406 410 Dubois et al., 2008 J. Dubois G. Dehaene-Lambertz M. Perrin J.F. Mangin Y. Cointepas E. Duchesnay D. Le Bihan L. Hertz-Pannier Asynchrony of the early maturation of white matter bundles in healthy infants: quantitative landmarks revealed noninvasively by diffusion tensor imaging Human Brain Mapping 29 2008 14 27 Eichele et al., 2005 T. Eichele H. Nordby L.M. Rimol K. Hugdahl Asymmetry of evoked potential latency to speech sounds predicts the ear advantage in dichotic listening Brain Research. Cognitive Brain Research 24 2005 405 412 Emanuel, 2002 D.C. Emanuel The auditory processing battery: survey of common practices Journal of the American Academy of Audiology 13 2002 93 117 (quiz 8\u20139) Emanuel et al., 2011 D.C. Emanuel K.N. Ficca P. Korczak Survey of the diagnosis and management of auditory processing disorder American Journal of Audiology 20 2011 48 60 Fernandes et al., 2006 M.A. Fernandes M.L. Smith W. Logan A. Crawley M.P. Mcandrews Comparing language lateralization determined by dichotic listening and fMRI activation in frontal and temporal lobes in children with epilepsy Brain and Language 96 2006 106 114 Fontoura et al., 2008 D.R. Fontoura M. Branco Dde M. Anes J.C. Costa M.W. Portuguez Language brain dominance in patients with refractory temporal lobe epilepsy: a comparative study between functional magnetic resonance imaging and dichotic listening test Arquivos de Neuro-Psiquiatria 66 2008 34 39 Foundas et al., 2006 A.L. Foundas D.M. Corey M.M. Hurley K.M. Heilman Verbal dichotic listening in right and left-handed adults: laterality effects of directed attention Cortex 42 2006 79 86 Giedd et al., 1999 J.N. Giedd J. Blumenthal N.O. Jeffries F.X. Castellanos H. Liu A. Zijdenbos T. Paus A.C. Evans J.L. Rapoport Brain development during childhood and adolescence: a longitudinal MRI study Nature Neuroscience 2 1999 861 863 Hale et al., 2006 T.S. Hale E. Zaidel J.J. Mcgough J.M. Phillips J.T. Mccracken Atypical brain laterality in adults with ADHD during dichotic listening for emotional intonation and words Neuropsychologia 44 2006 896 904 Haynes and Rees, 2006 J.D. Haynes G. Rees Decoding mental states from brain activity in humans Nature Reviews. Neuroscience 7 2006 523 534 Henry, 1979 R.G. Henry Monaural studies eliciting an hemispheric asymmetry: a bibliography Perceptual and Motor Skills 48 1979 335 338 Henry, 1983 R.G. Henry Monaural studies eliciting an hemispheric asymmetry; a bibliography: II Perceptual and Motor Skills 56 1983 915 918 Hickok and Poeppel, 2007 G. Hickok D. Poeppel The cortical organization of speech processing Nature Reviews. Neuroscience 8 2007 393 402 Hublet et al., 1976 C. Hublet J. Morais P. Bertelson Spatial constraints on focused attention: beyond the right-side advantage Perception 5 1976 3 8 Hugdahl, 1995 K. Hugdahl Dichotic listening: probing temporal lobe functional integrity R.J. Davidson K. Hugdahl Brain Asymmetry 1995 The MIT Press Cambridge, MA Hugdahl, 2002 K. Hugdahl Dichotic listening in the study of auditory laterality K. Hugdahl The Asymmetrical Brain 2002 MIT Press Cambridge, MA 441 476 Hugdahl, 2005 K. Hugdahl Symmetry and asymmetry in the human brain European Review 13 S2 2005 119 133 Hugdahl and Andersson, 1986 K. Hugdahl L. Andersson The \u201cforced-attention paradigm\u201d in dichotic listening to CV-syllables: a comparison between adults and children Cortex 22 1986 417 432 Hugdahl and Hammar, 1997 K. Hugdahl A. Hammar Test\u2013retest reliability for the consonant-vowel syllables dichotic listening paradigm Journal of Clinical and Experimental Neuropsychology 19 1997 667 675 Hugdahl et al., 1997 K. Hugdahl G. Carlsson P. Uvebrant A.J. Lundervold Dichotic-listening performance and intracarotid injections of amobarbital in children and adolescents. Preoperative and postoperative comparisons Archives of Neurology 54 1997 1494 1500 Hund-Georgiadis et al., 2002 M. Hund-Georgiadis U. Lex A.D. Friederici D.Y. Von Cramon Non-invasive regime for language lateralization in right- and left-handers by means of functional MRI and dichotic listening Experimental Brain Research 145 2002 166 176 Jancke and Shah, 2002 L. Jancke N.J. Shah Does dichotic listening probe temporal lobe functions? Neurology 58 2002 736 743 Jancke et al., 2001 L. Jancke T.W. Buchanan K. Lutz N.J. Shah Focused and nonfocused attention in verbal and emotional dichotic listening: an FMRI study Brain and Language 78 2001 349 363 Jerger and Musiek, 2000 J. Jerger F. Musiek Report of the consensus conference on the diagnosis of auditory processing disorders in school-aged children Journal of the American Academy of Audiology 11 2000 467 474 Joachims, 1999 T. Joachims Making Large-scale SVM Learning Practical. Advances in Kernel Methods \u2014 Support Vector Learning 1999 MIT Press Cambridge, MA Katz and Tillery, 2005 J. Katz K.L. Tillery Can central auditory processing tests resist supramodal influences? American Journal of Audiology 14 2005 124 127 (discussion 43\u201350) Keith, 1984 R.W. Keith Dichotic listening in children D.S. Beasley Audition in Children: Methods of Study 1984 College-Hill Press San Diego, CA Keith, 2009 R. Keith SCAN-3 for Children: Tests for Auditory Processing Disorder 2009 Pearson Education San Antonio, TX Kim et al., 2006 J.H. Kim M.D. Budde H.F. Liang R.S. Klein J.H. Russell A.H. Cross S.K. Song Detecting axon damage in spinal cord from a mouse model of multiple sclerosis Neurobiology of Disease 21 2006 626 632 Kimura, 1961 D. Kimura Cerebral dominance and the perception of verbal stimuli Canadian Journal of Psychology 15 1961 166 171 Kimura, 1964 D. Kimura Left-right differences in the perception of melodies Journal of Experimental Psychology 16 1964 355 358 Kimura, 1967 D. Kimura Functional asymmetry of the brain in dichotic listening Cortex 3 1967 163 168 Kimura, 1973 D. Kimura The asymmetry of the human brain Scientific American 228 1973 70 78 Kinoshita et al., 1999 Y. Kinoshita A. Ohnishi K. Kohshi A. Yokota Apparent diffusion coefficient on rat brain and nerves intoxicated with methylmercury Environmental Research 80 1999 348 354 Kinsbourne, 1970 M. Kinsbourne The cerebral basis of lateral asymmetries in attention Acta Psychologica 33 1970 193 201 Kinsbourne, 1973 M. Kinsbourne The control of attention by interaction between the cerebral hemispheres S. Kornblum Attention and Performance IV 1973 Academic Press New York 239 255 Kinsbourne, 1975 M. Kinsbourne The mechanism of hemispheric control of the lateral gradient of attention P.M.A. Rabbitt S. Dornic Attention and Performance V 1975 Academic Press London 81 97 Kinsbourne, 1980 M. Kinsbourne Dichotic imbalance due to isolated hemisphere occlusion or directional rivalry? Brain and Language 11 1980 221 224 Kluender and Lotto, 1999 K.R. Kluender A.J. Lotto Virtues and perils of an empiricist approach to speech perception Journal of the Acoustical Society of America 105 1999 503 511 Knecht et al., 2000 S. Knecht B. Drager M. Deppe L. Bobe H. Lohmann A. Floel E.B. Ringelstein H. Henningsen Handedness and hemispheric language dominance in healthy humans Brain 123 Pt 12 2000 2512 2518 Kodaka et al., 1997 Y. Kodaka A. Mikami K. Kubota Neuronal activity in the frontal eye field of the monkey is modulated while attention is focused on to a stimulus in the peripheral visual field, irrespective of eye movement Neuroscience Research 28 1997 291 298 Kriegeskorte, 2009 N. Kriegeskorte Relating population-code representations between man, monkey, and computational models Frontiers in Neuroscience 3 2009 363 373 Kriegeskorte et al., 2008 N. Kriegeskorte M. Mur D.A. Ruff R. Kiani J. Bodurka H. Esteky K. Tanaka P.A. Bandettini Matching categorical object representations in inferior temporal cortex of man and monkey Neuron 60 2008 1126 1141 Liberman and Whalen, 2000 A.M. Liberman D.H. Whalen On the relation of speech to language Trends in Cognitive Sciences 4 2000 187 196 Lipschutz et al., 2002 B. Lipschutz R. Kolinsky P. Damhaut D. Wikler S. Goldman Attention-dependent changes of activation and connectivity in dichotic listening NeuroImage 17 2002 643 656 Loring et al., 1990 D.W. Loring K.J. Meador G.P. Lee A.M. Murro J.R. Smith H.F. Flanigin B.B. Gallagher D.W. King Cerebral language lateralization: evidence from intracarotid amobarbital testing Neuropsychologia 28 1990 831 838 Luo et al., 2008 F. Luo Q. Wang A. Kashani J. Yan Corticofugal modulation of initial sound processing in the brain Journal of Neuroscience 28 2008 11615 11621 Ma and Suga, 2007 X. Ma N. Suga Multiparametric corticofugal modulation of collicular duration-tuned neurons: modulation in the amplitude domain Journal of Neurophysiology 97 2007 3722 3730 Ma and Suga, 2008 X. Ma N. Suga Corticofugal modulation of the paradoxical latency shifts of inferior collicular neurons Journal of Neurophysiology 100 2008 1127 1134 Mazziotta et al., 1995 J.C. Mazziotta A.W. Toga A. Evans P. Fox J. Lancaster A probabilistic atlas of the human brain: theory and rationale for its development: the international consortium for brain mapping (ICBM) NeuroImage 2 1995 89 101 Metwalli et al., 2010 N.S. Metwalli M. Benatar G. Nair S. Usher X. Hu J.D. Carew Utility of axial and radial diffusivity from diffusion tensor MRI as markers of neurodegeneration in amyotrophic lateral sclerosis Brain Research 1348 2010 156 164 Moncrieff, 2011 D.W. Moncrieff Dichotic listening in children: age-related changes in direction and magnitude of ear advantage Brain and Cognition 76 2011 316 322 Moore et al., 2010 D.R. Moore M.A. Ferguson A.M. Edmondson-Jones S. Ratib A. Riley Nature of auditory processing disorder in children Pediatrics 126 2010 e382 e390 Morais, 1975 J. Morais The effects of ventriloquism on the right-side advantage for verbal material Cognition 3 1975 127 139 Morais and Bertelson, 1973 J. Morais P. Bertelson Laterality effects in diotic listening Perception 2 1973 107 111 Morais and Bertelson, 1975 J. Morais P. Bertelson Spatial position versus ear of entry as determinant of the auditory laterality effects: a stereophonic test Journal of Experimental Psychology. Human Perception and Performance 1 1975 253 262 Musiek et al., 2010 F.E. Musiek J.A. Baran T.J. Bellis G.D. Chermak J.W. Hall Iii R.W. Keith L. Medwestky K. Loftus West M. Young S. Nagle American Academy of Audiology Clinical Practice Guidelines: Diagnosis, Treatment and Management of Children and Adults with Central Auditory Processing Disorder 2010 Naismith et al., 2009 R.T. Naismith J. Xu N.T. Tutlam A. Snyder T. Benzinger J. Shimony J. Shepherd K. Trinkaus A.H. Cross S.K. Song Disability in optic neuritis correlates with diffusion tensor-derived directional diffusivities Neurology 72 2009 589 594 Newman and Sandridge, 2007 C.W. Newman S.A. Sandridge Diagnostic audiology G. Hughes M. Pensak Clinical Otology 2007 Thieme Press New York, NY Norman et al., 2006 K.A. Norman S.M. Polyn G.J. Detre J.V. Haxby Beyond mind-reading: multi-voxel pattern analysis of fMRI data Trends in Cognitive Sciences 10 2006 424 430 Obleser et al., 2008 J. Obleser F. Eisner S.A. Kotz Bilateral speech comprehension reflects differential sensitivity to spectral and temporal features Journal of Neuroscience 28 2008 8116 8123 10.1523/JNEUROSCI.290-08.2008 Oie et al., in press M. Oie E.W. Skogli P.N. Andersen K.T. Hovik K. Hugdahl Differences in cognitive control in children and adolescents with combined and inattentive subtypes of ADHD Child Neuropsychology 2013 (in press) O'toole et al., 2007 A.J. O'toole F. Jiang H. Abdi N. Penard J.P. Dunlop M.A. Parent Theoretical, statistical, and practical perspectives on pattern-based classification approaches to the analysis of functional neuroimaging data Journal of Cognitive Neuroscience 19 2007 1735 1752 Pereira et al., 2009 F. Pereira T. Mitchell M. Botvinick Machine learning classifiers and fMRI: a tutorial overview NeuroImage 45 2009 S199 S209 Schmithorst and Holland, 2004 V.J. Schmithorst S.K. Holland Event-related fMRI technique for auditory processing with hemodynamics unrelated to acoustic gradient noise Magnetic Resonance in Medicine 51 2004 399 402 Schmithorst and Holland, 2006 V.J. Schmithorst S.K. Holland Functional MRI evidence for disparate developmental processes underlying intelligence in boys and girls NeuroImage 31 2006 1366 1379 Schmithorst et al., 2005 V.J. Schmithorst M. Wilke B.J. Dardzinski S.K. Holland Cognitive functions correlate with white matter architecture in a normal pediatric population: a diffusion tensor MRI study Human Brain Mapping 26 2005 139 147 Schmithorst et al., 2007 V.J. Schmithorst S.K. Holland E. Plante Object identification and lexical/semantic access in children: a functional magnetic resonance imaging study of word-picture matching Human Brain Mapping 28 2007 1060 1074 Schmithorst et al., 2011 V.J. Schmithorst S.K. Holland E. Plante Diffusion tensor imaging reveals white matter microstructure correlations with auditory processing ability Ear and Hearing 32 2011 156 167 Schonwiesner et al., 2005 M. Schonwiesner R. Rubsamen D.Y. Von Cramon Hemispheric asymmetry for spectral and temporal processing in the human antero-lateral auditory belt cortex European Journal of Neuroscience 22 2005 1521 1528 Sidtis, 1988 J. Sidtis Dichotic listening after commissurotomy K. Hugdahl Handbook of Dichotic Listening: Theory, Methods and Research 1988 Wiley & Sons New York 161 184 Sparks and Geschwind, 1968 R. Sparks N. Geschwind Dichotic listening after section of neo-cortical commisures Cortex 4 1968 3 16 Springer and Gazzaniga, 1975 S. Springer M. Gazzaniga Dichotic testing of partial and complete split-brain subjects Neuropsychologia 13 1975 341 346 Springer et al., 1978 S. Springer J. Sidtis D. Wilson M. Gazzaniga Left ear performance in dichotic listening following commissurotomy Neuropsychologia 16 1978 305 312 Strauss et al., 1987 E. Strauss W.H. Gaddes J. Wada Performance on a free-recall verbal dichotic listening task and cerebral dominance determined by the carotid amytal test Neuropsychologia 25 1987 747 753 Suga et al., 2002 N. Suga Z. Xiao X. Ma W. Ji Plasticity and corticofugal modulation for hearing in adult animals Neuron 36 2002 9 18 Szaflarski et al., 2006 J.P. Szaflarski V.J. Schmithorst M. Altaye A.W. Byars J. Ret E. Plante S.K. Holland A longitudinal functional magnetic resonance imaging study of language development in children 5 to 11years old Annals of Neurology 59 2006 796 807 Takahashi et al., 2000 M. Takahashi J. Ono K. Harada M. Maeda D.B. Hackney Diffusional anisotropy in cranial nerves with maturation: quantitative evaluation with diffusion MR imaging in rats Radiology 216 2000 881 885 Talairach and Tournoux, 1988 J. Talairach P. Tournoux Co-planar Stereotaxic Atlas of the Human Brain 1988 Thieme Medical Publishers, Inc. New York Taylor et al., 2008 P.C. Taylor M.F. Rushworth A.C. Nobre Choosing where to attend and the medial frontal cortex: an FMRI study Journal of Neurophysiology 100 2008 1397 1406 Thevenaz et al., 1998 P. Thevenaz U.E. Ruttimann M. Unser A pyramid approach to subpixel registration based on intensity IEEE Transactions on Image Processing 7 1998 27 41 Thomsen et al., 2004 T. Thomsen L.M. Rimol L. Ersland K. Hugdahl Dichotic listening reveals functional specificity in prefrontal cortex: an fMRI study NeuroImage 21 2004 211 218 Tzourio et al., 1997 N. Tzourio F.E. Massioui F. Crivello M. Joliot B. Renault B. Mazoyer Functional anatomy of human auditory attention studied with PET NeuroImage 5 1997 63 77 Van Den Noort et al., 2008 M. Van Den Noort K. Specht L.M. Rimol L. Ersland K. Hugdahl A new verbal reports fMRI dichotic listening paradigm for studies of hemispheric asymmetry NeuroImage 40 2008 902 911 Van Ettinger-Veenstra et al., 2010 H.M. Van Ettinger-Veenstra M. Ragnehed M. Hallgren T. Karlsson A.M. Landtblom P. Lundberg M. Engstrom Right-hemispheric brain activation correlates to language performance NeuroImage 49 2010 3481 3488 Vannest et al., 2009 J.J. Vannest P.R. Karunanayaka M. Altaye V.J. Schmithorst E.M. Plante K.J. Eaton J.M. Rasmussen S.K. Holland Comparison of fMRI data from passive listening and active-response story processing tasks in children Journal of Magnetic Resonance Imaging 29 2009 971 976 Vapnik, 1995 V. Vapnik The Nature of Statistical Learning Theory 1995 Springer New York Vapnik et al., 1997 V. Vapnik S. Golowich A. Smola Support vector method for function approximation, regression estimation, and signal processing M. Mozer M. Jordan T. Petsche Neural Information Processing Systems 1997 MIT Press Cambridge, MA Voyer, 2011 D. Voyer Sex differences in dichotic listening Brain and Cognition 76 2011 245 255 Wardak et al., 2006 C. Wardak G. Ibos J.R. Duhamel E. Olivier Contribution of the monkey frontal eye field to covert visual attention Journal of Neuroscience 26 2006 4228 4235 Westerhausen and Hugdahl, 2008 R. Westerhausen K. Hugdahl The corpus callosum in dichotic listening studies of hemispheric asymmetry: a review of clinical and experimental evidence Neuroscience and Biobehavioral Reviews 32 2008 1044 1054 Westerhausen et al., 2006 R. Westerhausen W. Woerner F. Kreuder E. Schweiger K. Hugdahl W. Wittling The role of the corpus callosum in dichotic listening: a combined morphological and diffusion tensor imaging study Neuropsychology 20 2006 272 279 Westerhausen et al., 2009a R. Westerhausen R. Gruner K. Specht K. Hugdahl Functional relevance of interindividual differences in temporal lobe callosal pathways: a DTI tractography study Cerebral Cortex 19 2009 1322 1329 Westerhausen et al., 2009b R. Westerhausen M. Moosmann K. Alho S. Medvedev H. Hamalainen K. Hugdahl Top-down and bottom-up interaction: manipulating the dichotic listening ear advantage Brain Research 1250 2009 183 189 Wilson et al., 2004 S.M. Wilson A.P. Saygin M.I. Sereno M. Iacoboni Listening to speech activates motor areas involved in speech production Nature Neuroscience 7 2004 701 702 Worsley et al., 2002 K.J. Worsley C.H. Liao J. Aston V. Petre G.H. Duncan F. Morales A.C. Evans A general statistical analysis for fMRI data NeuroImage 15 2002 1 15 Xiao and Suga, 2002 Z. Xiao N. Suga Modulation of cochlear hair cells by the auditory cortex in the mustached bat Nature Neuroscience 5 2002 57 63 Zaidel, 1983 E. Zaidel Disconnection syndrome as a model for laterality effects in the normal brain J.B. Hellige Cerebral Hemisphere Asymmetry: Method, Theory, and Application 1983 Praeger New York 95 151 Zatorre, 1989 R.J. Zatorre Perceptual asymmetry on the dichotic fused words test and cerebral speech lateralization determined by the carotid sodium amytal test Neuropsychologia 27 1989 1207 1219 Zatorre et al., 1999 R.J. Zatorre T.A. Mondor A.C. Evans Auditory attention to space and frequency activates similar cerebral systems NeuroImage 10 1999 544 554"
    },
    "10.1016/j.protcy.2013.12.385": {
        "Title": "Time Efficient Optimal Tunning through Various Learning Rules in Unify Computing (TEOTLRUC)",
        "Date": "2013",
        "Text": "serial JL 282073 291210 291871 291884 31 90 Procedia Technology PROCEDIATECHNOLOGY 2013-12-28 2013-12-28 2014-11-04T06:50:50 1-s2.0-S2212017313005471 S2212-0173(13)00547-1 S2212017313005471 10.1016/j.protcy.2013.12.385 S300 S300.3 HEAD-AND-TAIL 1-s2.0-S2212017313X00052 2021-10-14T13:36:05.11053Z 0 0 20130101 20131231 2013 2013-12-28T00:00:00Z rawtext articleinfo articletitlenorm authfirstinitialnorm authfirstsurnamenorm cid cids confeditor contenttype copyright crossmark dateloaded dateloadedtxt datesearch datesort dateupdated dco docsubtype doctype doi eid ewtransactionid hubeid indexeddate issn issnnorm itemstage itemtransactionid itemweight oauserlicense openaccess openarchive pg pgfirst pglast pii piinorm pubdateend pubdatestart pubdatetxt pubyr sortorder srctitle srctitlenorm srctype ssids alllist content oa subj suppl tomb vol volfirst volissue volumelist webpdf webpdfpagecount yearnav affil articletitle auth authfirstini authfull authkeywords authlast primabst ref 2212-0173 22120173 false 10 10 C Volume 10 57 474 481 474 481 2013 2013 2013-01-01 2013-12-31 2013 First International Conference on Computational Intelligence: Modeling Techniques and Applications (CIMTA) 2013 Prof. Jyotsna Kumar Mandal Dr. Anirban Mukhopadhyay article fla Copyright \u00a9 2013 The Authors. Published by Elsevier Ltd. TIMEEFFICIENTOPTIMALTUNNINGTHROUGHVARIOUSLEARNINGRULESINUNIFYCOMPUTINGTEOTLRUC MANDAL J MANDALX2013X474 MANDALX2013X474X481 MANDALX2013X474XJ MANDALX2013X474X481XJ Full 2013-12-28T16:08:00Z http://creativecommons.org/licenses/by-nc-nd/3.0/ OA-Window ElsevierWaived 0 item S2212-0173(13)00547-1 S2212017313005471 1-s2.0-S2212017313005471 10.1016/j.protcy.2013.12.385 282073 2014-11-05T23:31:46.891373-05:00 2013-01-01 2013-12-31 1-s2.0-S2212017313005471-main.pdf https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S2212017313005471/MAIN/application/pdf/f5e4ac683f2bcf4fce0af63cb0f5da81/main.pdf https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2212017313005471/MAIN/application/pdf/f5e4ac683f2bcf4fce0af63cb0f5da81/main.pdf main.pdf pdf true 672160 MAIN 8 1-s2.0-S2212017313005471-main_1.png https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2212017313005471/PREVIEW/image/png/0e9d0a05f55b6df27a3636ad34048302/main_1.png https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S2212017313005471/PREVIEW/image/png/0e9d0a05f55b6df27a3636ad34048302/main_1.png main_1.png png 49810 849 656 IMAGE-WEB-PDF 1 P r o c e d i a T e c h n o l o g y 1 0 ( 2 0 1 3 ) 4 7 4 \u00e2\u20ac\u201c 4 8 1 2212-0173 2013 The Authors. Published by Elsevier Ltd. Open access under CC BY-NC-ND license. Selection and peer-review under responsibility of the University of Kalyani, Department of Computer Science & Engineering doi: 10.1016/j.protcy.2013.12.385 International Conference on Computational Intelligence: Modeling Techniques and Applications (CIMTA) 2013 Time Efficient Optimal Tunning through various Learning Rules in Unify Computing (TEOTLRUC) J.K. Mandal a, **, Arghyadip Chowdhuri a , Arindam Sarkar a a Department of Comouter Sc. & Engg., University of kalyani, Kalyani, Nadia,West Bengal, Kalyani -741235,India Abstract In this paper the effects of learning rules on mutual synchronization of various tree parity machines are presented. The experiment of tree parity machine is not confined to single hidden layer machine. Machines with double and triple hidden layers are also have been studied. Basically a tree parity machine has a single hidden layer. Once two tree parity machine of same size are created then they both are synchronized mutually in order to obtain same weight vectors. If outputs are identical of both the machines then a suitable learning rule is applied to the neural weights of both tree parity machines, in order to generate identical weight values. In this paper the mutual synchronization is examined on all three tree parity machines with different number of hidden layers. Results are compared in terms mutual synchronization time, which shows results for the proposed system. \u00c2\u00a9 2013 The Authors. Published by Elsevier Ltd. Selection and peer-review under responsibility of the University of Kalyani, Department of Computer Science & Engineering. Keywords: Tree Parity Machine; Neural cryptography 1. Introduction Tree parity machines are central to the field of neural cryptography. Neural networks have capacity to learn, so this property can be used in various fields. Neural networks was first used by Dourlens(1995) for the cryptanalysis purpose of DES algorithm. Later neural key exchange came into practice. The idea of neural key exchange centers round the concept of mutual synchronization of weight vectors of tree parity machines. Once these weight values are * Corresponding author. Tel.: +91- 033-25809617; fax:+91-033-25809617. E-mail address: jkm.cse@gmail.com. Available online at www.sciencedirect.com 2013 The Authors. Published by Elsevier Ltd. Open access under CC BY-NC-ND license. Selection and peer-review under responsibility of the University of Kalyani, Department of Computer Science & Engineering ScienceDirect 475 J.K. Mandal et al. / Procedia Technology 10 ( 2013 ) 474 \u00e2\u20ac\u201c 481 same for both the machines then these two networks are ready for encryption techniques [2, 3]. On the other hand unified computing deals with efficient usage of the resources of the computing system. In this paradigm a centralized control is being established to manage the resources. These resources are mostly network and memory usage. So, the neural structure could be used for encryption and decryption purposes. But its not known that which learning rule performs better than other rules in order to synchronize both the tree parity machines in different networks. In this paper TEOTLRUC technique has been proposed to determine which learning rule performs better in which type of network. The learning rules are also studied for various network sizes of varying hidden layers. The organization of this paper is as follows. Section 2 of this paper deals with the structure of tree parity machine. Proposed tree parity machines have been discussed in section 3. Experimental results are described in section 4. Applications of the TPMs are presented in section 5. Conclusions and future scope are drawn in section 6. References are at the end. 2. Structure of the Neural Network Tree parity machine has one output neuron, K hidden neurons and K*N input neurons, where N is the number of inputs for each K hidden neurons. Inputs (X i,j ) to the tree parity machine has two values which is either -1 or +1.The weights between input and hidden neurons ranges between +L and \u00e2\u20ac\u201cL, where L is a integer value. Output value of each hidden neuron is calculated as a sum of all products of input neurons and these weights: \u00cf\u0192 i = sgn \u00e0\u00b5\u00ab \u00e2\u02c6\u2018 \u00e0\u00a1\u00ba \u00e0\u00a2\ufffd\u00e0\u00ad\u20ac\u00e0\u00ab\u0161 \u00e0\u00a2\u0192 \u00e0\u00a2\ufffd,\u00e0\u00a2\ufffd \u00e0\u00a2\u201e \u00e0\u00a2\ufffd,\u00e0\u00a2\ufffd \u00e0\u00b5\u00af (1) Signum is a function, which returns -1,0 or 1: sgn = \u00e1\u2030\ufffd \u00e2\u02c6\u2019\u00e0\u00ab\u0161 \u00e0\u00a2\ufffd\u00e0\u00a2\u0152 \u00e0\u00a2\u017e<0 \u00e0\u00ab\u2122 \u00e0\u00a2\ufffd\u00e0\u00a2\u0152 \u00e0\u00a2\u017e= \u00e0\u00ab\u2122 \u00e0\u00ab\u0161 \u00e0\u00a2\ufffd\u00e0\u00a2\u0152 \u00e0\u00a2\u017e>0 (2) If the scalar product is 0, the output of the hidden neuron is -1 in order to ensure a binary output value. The output of neural network is then computed as the multiplication of all values generated by hidden neurons: \u00cf\u201e = \u00e2\u02c6\ufffd \u00e0\u00ab\u2039 \u00e0\u00a1\u00b7 \u00e0\u00a2\ufffd\u00e0\u00ad\u20ac\u00e0\u00ab\u0161 \u00e0\u00a2\ufffd (3) Fig. 1. Structure of tree parity Machine 476 J.K. Mandal et al. / Procedia Technology 10 ( 2013 ) 474 \u00e2\u20ac\u201c 481 Once two Tree Parity Machines are created then both the parity machines, say A and B go through the following step. Mutual synchronization of A and B: Step 1: Random weight values are assigned from the interval of [+L\u00e2\u20ac\u00a6-L] randomly. Step 2: Random input vectors are either +1 or -1. Step 3: Hidden neurons compute the value of \u00cf\u0192 i where i \u00e2\u02c6\u02c6 {1, 2\u00e2\u20ac\u00a6.K*N} Step4: Output neuron values are then calculated. Step 5: If output of the both the machines A & B are different then move back to the step 2 otherwise a suitable Learning rule is applied to the weight values of the network. Step 6: The change in weight values stops when both machines A and B have exactly same weight vectors. Hebbian learning rules can be used for the synchronization: w i + = w i +x i \u00cf\u201e \u00c6\u0178(\u00cf\u0192 i \u00cf\u201e) \u00c6\u0178(\u00cf\u201e A \u00cf\u201e B ) (4) Anti-Hebbian learning value can also be used: w i + = w i - x i \u00cf\u201e \u00c6\u0178(\u00cf\u0192 i \u00cf\u201e) \u00c6\u0178(\u00cf\u201e A \u00cf\u201e B ) (5) Random - walk learning value can also be used: w i + =w i +x i \u00c6\u0178(\u00cf\u0192 i \u00cf\u201e) \u00c6\u0178(\u00cf\u201e A \u00cf\u201e B ) (6) Now the key values can be used as keys [2, 4, 5, 7, 9, 10] 3. Proposed Multilayer Neural Networks 3.1. Tree Parity Machine with 2 Hidden layers The basic difference between TPM with single layer with TPM with 2 hidden layers is the parameter K is divided into two different parameters i.e. K1 and K2. K2 value represents the number of hidden neurons adjacent to the output layer. For each K2 neuron there K1 number hidden neurons, i.e. the middle hidden layer between the input layer and K2 number output neurons have K1\u00c3\u2014K2 neurons. So, each of K1\u00c3\u2014K2 neurons have N number of inputs to total number of inputs are K1\u00c3\u2014K2\u00c3\u2014N. Each hidden layer number 1 (i.e. with K1\u00c3\u2014K2 neurons) neuron produces \u00cf\u0192 1 i values and each hidden layer number 2 neurons (i.e. with K2 neurons) generates \u00cf\u0192 2 i values. These are \u00e2\u20ac\u201c \u00cf\u0192 1 i = sgn \u00e0\u00b5\u00ab \u00e2\u02c6\u2018 \u00e0\u00a1\u00ba \u00e0\u00a2\ufffd\u00e0\u00ad\u20ac\u00e0\u00ab\u0161 \u00e0\u00a2\u0192 \u00e0\u00a2\ufffd,\u00e0\u00a2\ufffd \u00e0\u00a2\u201e \u00e0\u00a2\ufffd,\u00e0\u00a2\ufffd \u00e0\u00b5\u00af (7) \u00cf\u0192 2 i = sgn \u00e0\u00b5\u00ab \u00e2\u02c6\u2018 \u00e0\u00a1\u00ba \u00e0\u00a2\ufffd\u00e0\u00ad\u20ac\u00e0\u00ab\u0161 \u00e0\u00ab\u2039 \u00e0\u00a2\ufffd \u00e0\u00ab\u0161 \u00e0\u00b5\u00af (8) The sgn function remains as it was explained in section 2. The output of neural network is then computed as the multiplication of all values produced by hidden layer neurons: \u00cf\u201e = \u00e2\u02c6\ufffd \u00e0\u00ab\u2039 \u00e0\u00a2\ufffd \u00e0\u00ab\u203a\u00e0\u00a1\u00b7\u00e0\u00ab\u203a \u00e0\u00a2\ufffd\u00e0\u00ad\u20ac\u00e0\u00ab\u0161 (9) Double hidden layer TPMs is calculating the \u00cf\u0192 i j value two times. So, this TPM ends up with 1 set of weight vector and 2 sets of \u00cf\u0192 values. 477 J.K. Mandal et al. / Procedia Technology 10 ( 2013 ) 474 \u00e2\u20ac\u201c 481 Fig. 2. Tree Parity Machine with 2 hidden layers [1]. Figure 2 shows a tree parity machine of 2 hidden layer with K1= 2 and K2 = 2. The main difference in mutual synchronization between this and TPM discussed in section 2, is in step 4, where layer 1 output values i.e. \u00cf\u0192 1 i and layer 2 output values \u00cf\u0192 2 i are calculated. Thus adds additional computational cost [1]. 3.2. Tree Parity Machine with 3 Hidden layers The basic difference between TPM with single layer with TPM with 3 hidden layers is the parameter K is divided into three different parameters i.e. K1, K2 and K3. For each K3 neuron there are K2 number hidden neurons, i.e. the middle -hidden layer 2 between the hidden layer 1 and 3.Number of layer 2 are neurons K2\u00c3\u2014K3. Each of K2\u00c3\u2014K3 has K1 number of neurons. So hidden layer1 has K1\u00c3\u2014K2\u00c3\u2014K3 neurons. Layer1 now for each K1\u00c3\u2014K2\u00c3\u2014K3 neurons there are N inputs possible. So the input layer has K1\u00c3\u2014K2\u00c3\u2014K3\u00c3\u2014N input neurons and this number represents the size of the multilayer tree parity machine. Each hidden layer number 1 (i.e. with K1\u00c3\u2014K2\u00c3\u2014K3 neurons) neuron generates \u00cf\u0192 1 i values, each hidden layer number 2 neurons (i.e. with K2\u00c3\u2014K3 neurons) gives \u00cf\u0192 2 i value. Each hidden layer number 3 neurons (i.e. with K3 neurons) produce \u00cf\u0192 3 i value. Calculations are as follows \u00e2\u20ac\u201c \u00cf\u0192 1 i = sgn \u00e0\u00b5\u00ab \u00e2\u02c6\u2018 \u00e0\u00af\u2021 \u00e0\u00af\ufffd\u00e0\u00ad\u20ac\u00e0\u00ac\u00b5 \u00dc\u00b9 \u00e0\u00af\u0153,\u00e0\u00af\ufffd \u00dc\u00ba \u00e0\u00af\u0153,\u00e0\u00af\ufffd \u00e0\u00b5\u00af (10) \u00cf\u0192 2 i = sgn \u00e0\u00b5\u00ab \u00e2\u02c6\u2018 \u00e0\u00af\u2021 \u00e0\u00af\ufffd\u00e0\u00ad\u20ac\u00e0\u00ac\u00b5 \u00cf\u0192 \u00e0\u00af\u0153 \u00e0\u00ac\u00b5 \u00e0\u00b5\u00af (11) \u00cf\u0192 3 i = sgn \u00e0\u00b5\u00ab \u00e2\u02c6\u2018 \u00e0\u00af\u2021 \u00e0\u00af\ufffd\u00e0\u00ad\u20ac\u00e0\u00ac\u00b5 \u00cf\u0192 \u00e0\u00af\u0153 \u00e0\u00ac\u00b6 \u00e0\u00b5\u00af (12) The sgn function remains as it was explained in section 2. The output of neural network is then computed as the multiplication of all values produced by hidden layer neurons: 478 J.K. Mandal et al. / Procedia Technology 10 ( 2013 ) 474 \u00e2\u20ac\u201c 481 \u00cf\u201e = \u00e2\u02c6\ufffd \u00cf\u0192 \u00e0\u00af\u0153 \u00e0\u00ac\u00b7\u00e0\u00af\u201e\u00e0\u00ac\u00b6 \u00e0\u00af\u0153\u00e0\u00ad\u20ac\u00e0\u00ac\u00b5 (13) Double hidden layer TPMs is calculating the \u00cf\u0192 i j value three times. So, this TPM ends up with 1 set of weight vector and 3 sets of \u00cf\u0192 values. Fig. 3. Tree Parity Machine with 3 hidden layers [1]. Figure 3 shows a tree parity machine of 2 hidden layer with K1= 2, K2 = 2 and K3=2. The main difference in mutual synchronization between this and TPM discussed in section II, is in step 4, where layer 1 output values i.e. \u00cf\u0192 1 i , layer 2 output values \u00cf\u0192 2 i are calculated and layer 23 output values \u00cf\u0192 3 i are calculated. Thus adds additional computational cost [1]. 4. Results In this section result has been presented for three TPMs with different numbers of hidden layers. In all three networks three learning rules have been applied in order to find out which one is more efficient in terms of total time taken to synchronize both TPMs. 479 J.K. Mandal et al. / Procedia Technology 10 ( 2013 ) 474 \u00e2\u20ac\u201c 481 Fig. 4. Synchronization time vs Network size for 1 hidden layer. In figure 4, its clearly visible that for the interval of 0-50 of TPM network size all three learning rules did perform same way but suddenly near 50 there is a peak in execution time for Anti-hebbian learning rule. For interval 50 -75, in first part there is a dip in synchronization time for Anti-Hebbian rule but later after 60 to 70 network sizes Hebbian learning took more time to tune both networks. In last interval 75 to 100, random walk initially took much time bur later Hebbian rule took more time. Finally it can be stated Random walk took less time than other two learning rules to synchronize both machines. Fig. 5. Synchronization time vs Network size for 2 hidden layers. In the interval 0-50 Anti Hebbian rule took much less time to synchronize two machines. In the interval 50\u00e2\u20ac\u201c75 random walk is efficient. In the interval 75-100 Anti Hebbian consumed much more time than other two rules. 480 J.K. Mandal et al. / Procedia Technology 10 ( 2013 ) 474 \u00e2\u20ac\u201c 481 Fig. 6. Synchronization time vs Network size for 3 hidden layers. In 0-50 and 50-75 intervals Anti Hebbian rule took less time than other two learning rules. For 75-100 random walk took less time to synchronize both machines. Table1: Mutual Synchronization time of different networks. Number of Hidden Layers Learning Rule Network size Synchronization time(Micro sec) 1 Hebbian rule 20 70307.572 1 Anti-Hebbian 60 140132.026 1 Random walk 70 105167.831 2 Hebbian rule 10 14003.386 2 Anti-Hebbian 60 123689.308 2 Random walk 75 139002.183 3 Hebbian rule 10 41210.735 3 Anti-Hebbian 50 91367.187 3 Random walk 80 125907.933 Above table1 shows mutual synchronization time for different networks with different learning rules in terms of micro second. 5. Applications Neural structures are extensively used in cryptography. The idea of neural key exchange basically based on the concept of mutual synchronization of weight vectors of tree parity machines. After mutual synchronization of the weights, the key value is then created depending on application domains like wireless sensor networks, bluetooths etc. Kanter, kinzel and Kanter worked on the secure exchange of information using this technique [5]. 481 J.K. Mandal et al. / Procedia Technology 10 ( 2013 ) 474 \u00e2\u20ac\u201c 481 Rosen-Zvi, Engel and Kanter further worked on the generalization capacity of two layered neural structure[2]. Rosen-Zvi, Einat Klein, Andres Engel and Ido Kanter has stated various applications of neural cryptography[10]. Ruttor, Wolfgang Kinzel, Shacham and kanter further worked on feedback mechanism in neural cryptography [4]. Ruttor, wolfgang Kinzel and Ido Kanter have proposed a technique to replace random input vectors with queries depending on the present state of neural network[4]. T.Godavari, N.R Alanelu and R. Soundararajan discussed the neural cryptographic paradigm in their paper in details [6]. Neural encryption techniques have huge application in wireless sensor networks J.K Mandal and Arindam Sarkar[8,11] have proposed two different techniques for enciphering based on tree parity machine. The first one is based on adaptive Neural Network Guided Secret Key based Encryption through Recursive Positional Modulo-2 Substitution and the other one is adaptive Neural Network Guided block length based Encryption technique. 6. Future Scope and Conclusion This paper presented TEOTLRUC technique for multilayer tree parity machine. Now based on these neural structures. Here the experiment is being done on multilayer TPMS and the effect on them for different learning rules. This paper has shown in 3 different intervals (0-50, 50-75, 75-100) which learning rule consumes less time to synchronize both the machines mutually. This is really helpful in unified computing. Future scope of this technique is that this TEOTLRUC model can be used in wireless communication and in key distribution mechanism to facilitate cryptography. References [1] Arghyadip Chowdhuri, \u00e2\u20ac\u0153Design and Implementation of Energy Aware Neural Cryptographic Techniques\u00e2\u20ac\ufffd, M.Tech. thesis. [2] M. Rosen-Zvi, A. Engel and I. Kanter, \u00e2\u20ac\u0153Generalization and Capacity of Extensively Large Two-Layered Perceptrons\u00e2\u20ac\ufffd, Phys. Rev. E 66,036138, 2002. [3] Sarkar Arindam, Mandal J. K., \u00e2\u20ac\u0153Key Generation and Certification using Multilayer Perceptron in Wireless Communication (KGCMLP)\u00e2\u20ac\ufffd,International Journal of Security, Privacy and Trust Management ( IJSPTM), Vol. 1, No 5, October 2012, DOI : 10.5121/ijsptm.2012.1503, pp 27-43, ISSN 2277 - 5498 [Online]; 2319 - 4103 [Print]. [4] T. Godavari, N. R. Alainelu and R. S Soundararajan \u00e2\u20ac\u0153Cryptography using Neural Networks\u00e2\u20ac\ufffd IEEE Indicom 2005 conference, Chennai, India 11-13 Dec 2005. [5] M. Rosen-Zvi, A. Engel and I. Kanter, \u00e2\u20ac\u0153 Generalization and Capacity of Extensively Large Two-Layered Perceptrons\u00e2\u20ac\ufffd, Phys. Rev. E 66,036138, 2002 [6] L. Shacham, E. Klein,R. Mislovaty, I. Kanter and W.Kinzel,\u00e2\u20ac\ufffd Cooperrating Attackers in Neural Cyptography\u00e2\u20ac\ufffd,Phys Rev. E 69. [7] A. Ruttor, W. Kinzel and Ido Kanter, \u00e2\u20ac\u0153Neural Cryptography with Queries\u00e2\u20ac\ufffd, J. Stat.Mech.P01009 Available in: http://www.iop.org/EJ/article/-search=46330253.4/1742-5468/2005/01/P01009/jstat5_01_p01009.pdf?requestid= yjE7J3fd3BGAIc7K2wi7Kg,2005. [8] A. Ruttor, W. Kinzel, R. Naeh and I. Kanter ,\u00e2\u20ac\ufffd,Genetic Attack on Neural Cryptography.\u00e2\u20ac\ufffd, Phys. Rev.E 73, 036121, 2006. [9] J.K Mandal and Arindam Sarkar, \u00e2\u20ac\u0153An adaptive Neural Network Guided Secret Key based Encryption through Recursive Positional Modulo-2 Substitution for Online Wireless Communication\u00e2\u20ac\ufffd, IEEE-International conference on Recent trends in Information Technology, ICRTIT 2011, MIT, Anna University, Chennai June 3-5 2011. [10] A. Ruttor, W. Kinzel, L. Shacham, I. Kanter,\u00e2\u20ac\ufffd Neural Cryptography with Feedback \u00e2\u20ac\ufffd, Phys. Rev. E 69, 046110 ,2004. [11] J.K Mandal and Arinadam Sarkar, \u00e2\u20ac\u0153An adaptive Neural Network Guided Block Length based cryptosystems for online Wireless communication Network\u00e2\u20ac\ufffd 2011 IEEE. [12] R. Mislovaty, E. Klein, I. Kanter and W. Kinzel,\u00e2\u20ac\ufffd Security of Neural Cryptography\u00e2\u20ac\ufffd, Electronics, Circuits and Systems, 2004. ICECS 2004. Proceedings of the 2004 11th IEEE International Conference on Publication Date: 13-15 Dec. 2004. et al. / Procedia Technology 10 ( 2013 ) 474 \u00e2\u20ac\u201c 481 Rosen-Zvi, Engel and Kanter further worked on the generalization capacity of two layered neural structure[2]. Rosen-Zvi, Einat Klein, Andres Engel and Ido Kanter has stated various applications of neural cryptography[10]. Ruttor, Wolfgang Kinzel, Shacham and kanter further worked on feedback mechanism in neural cryptography [4]. Ruttor, wolfgang Kinzel and Ido Kanter have proposed a technique to replace random input vectors with queries depending on the present state of neural network[4]. T.Godavari, N.R Alanelu and R. Soundararajan discussed the neural cryptographic paradigm in their paper in details [6]. Neural encryption techniques have huge application in wireless sensor networks J.K Mandal and Arindam Sarkar[8,11] have proposed two different techniques for enciphering based on tree parity machine. The first one is based on adaptive Neural Network Guided Secret Key based Encryption through Recursive Positional Modulo-2 Substitution and the other one is adaptive Neural Network Guided block length based Encryption technique. 6. Future Scope and Conclusion This paper presented TEOTLRUC technique for multilayer tree parity machine. Now based on these neural structures. Here the experiment is being done on multilayer TPMS and the effect on them for different learning rules. This paper has shown in 3 different intervals (0-50, 50-75, 75-100) which learning rule consumes less time to synchronize both the machines mutually. This is really helpful in unified computing. Future scope of this technique is that this TEOTLRUC model can be used in wireless communication and in key distribution mechanism to facilitate cryptography. References [1] Arghyadip Chowdhuri, \u00e2\u20ac\u0153Design and Implementation of Energy Aware Neural Cryptographic Techniques\u00e2\u20ac\ufffd, M.Tech. thesis. [2] M. Rosen-Zvi, A. Engel and I. Kanter, \u00e2\u20ac\u0153Generalization and PROTCY 1154 S2212-0173(13)00547-1 10.1016/j.protcy.2013.12.385 The Authors \u2606 Selection and peer-review under responsibility of the University of Kalyani, Department of Computer Science & Engineering. Time Efficient Optimal Tunning through Various Learning Rules in Unify Computing (TEOTLRUC) J.K. Mandal \u204e Arghyadip Chowdhuri Arindam Sarkar Department of Comouter Sc. & Engg., University of kalyani, Kalyani, Nadia,West Bengal, Kalyani -741235,India \u204e Corresponding author. Tel.: +91 033 25809617; fax: +91 033 25809617. In this paper the effects of learning rules on mutual synchronization of various tree parity machines are presented. The experiment of tree parity machine is not confined to single hidden layer machine. Machines with double and triple hidden layers are also have been studied. Basically a tree parity machine has a single hidden layer. Once two tree parity machine of same size are created then they both are synchronized mutually in order to obtain same weight vectors. If outputs are identical of both the machines then a suitable learning rule is applied to the neural weights of both tree parity machines, in order to generate identical weight values. In this paper the mutual synchronization is examined on all three tree parity machines with different number of hidden layers. Results are compared in terms mutual synchronization time, which shows results for the proposed system. Keywords Tree Parity Machine Neural cryptography References [1] Arghyadip Chowdhuri, \u201cDesign and Implementation of Energy Aware Neural Cryptographic Techniques\u201d, M. Tech. thesis. [2] M. Rosen-Zvi, A. Engel and I. Kanter, Generalization and Capacity of Extensively Large Two-Layered Perceptrons, Phys. Rev. E 66, 036138, 2002. [3] Sarkar Arindam, Mandal J. K., Key Generation and Certification using Multilayer Perceptron in Wireless Communication (KGCMLP), International Journal of Security, Privacy and Trust Management (IJSPTM), Vol. 1, No 5, October 2012, DOI: 10.5121/ijsptm.2012.1503, pp 27-43, ISSN 2277-5498 [Online]; 2319-4103.[Print]. [4] T. Godavari, N.R. Alainelu and R. S Soundararajan \u201cCryptography using Neural Networks\u201d IEEE Indicom 2005 conference, Chennai, India 11-13 Dec 2005. [5] M. Rosen-Zvi, A. Engel and I. Kanter, \u201cGeneralization and Capacity of Extensively Large Two-Layered Perceptrons\u201d, Phys. Rev. E 66,036138, 2002. [6] L. Shacham, E. Klein,R. Mislovaty, I. Kanter and W. Kinzel,\u201d Cooperrating Attackers in Neural Cyptography\u201d,Phys Rev. E 69. [7] A. Ruttor, W. Kinzel and Ido Kanter, \u201cNeural Cryptography with Queries\u201d, J. Stat.Mech.P01009 Available in: http://www.iop.org/EJ/article/-search=46330253.4/1742-5468/2005/01/P01009/jstat5_01_p01009.pdf?requestid= yjE7J3fd3BGAIc7K2wi7Kg, 2005. [8] A. Ruttor, W. Kinzel, R. Naeh and I. Kanter,\u201d,Genetic Attack on Neural Cryptography.\u201d, Phys. Rev.E 73, 036121, 2006. [9] J.K. Mandal and Arindam Sarkar, \u201cAn adaptive Neural Network Guided Secret Key based Encryption through Recursive Positional Modulo-2 Substitution for Online Wireless Communication\u201d, IEEE-International conference on Recent trends in Information Technology, ICRTIT 2011, MIT, Anna University, Chennai June 3-5 2011. [10] A. Ruttor, W. Kinzel, L. Shacham, I. Kanter, \u201cNeural Cryptography with Feedback\u201d, Phys. Rev. E 69, 046110,2004. [11] J.K. Mandal and Arinadam Sarkar, \u201cAn adaptive Neural Network Guided Block Length based cryptosystems for online Wireless communication Network\u201d 2011 IEEE. [12] R. Mislovaty, E. Klein, I. Kanter and W. Kinzel, \u201cSecurity of Neural Cryptography\u201d, Electronics, Circuits and Systems, 2004. ICECS 2004. Proceedings of the 2004 11th IEEE International Conference on Publication Date: 13-15 Dec. 2004."
    },
    "10.1016/j.procs.2013.05.029": {
        "Title": "Mobile Cloud Computing Network Attack and Defense Learning System Based on Fuzzy Soft Sets",
        "Date": "2013",
        "Text": "serial JL 280203 291210 291871 31 90 Procedia Computer Science PROCEDIACOMPUTERSCIENCE 2013-05-16 2013-05-16 2015-03-16T04:47:18 1-s2.0-S1877050913001622 S1877-0509(13)00162-2 S1877050913001622 10.1016/j.procs.2013.05.029 S300 S300.4 HEAD-AND-TAIL 1-s2.0-S1877050913X00031 2021-07-28T14:06:26.9917Z 0 0 20130101 20131231 2013 2013-05-16T00:00:00Z rawtext articleinfo articletitlenorm authfirstinitialnorm authfirstsurnamenorm cid cids confeditor contenttype copyright crossmark dateloaded dateloadedtxt datesearch datesort dateupdated dco docsubtype doctype doi eid ewtransactionid hubeid indexeddate issn issnnorm itemstage itemtransactionid itemweight oauserlicense openaccess openarchive pg pgfirst pglast pii piinorm pubdateend pubdatestart pubdatetxt pubyr sortorder srctitle srctitlenorm srctype ssids alllist content oa subj suppl tomb vol volfirst volissue volumelist webpdf webpdfpagecount yearnav affil articletitle auth authfirstini authfull authkeywords authlast primabst ref 1877-0509 18770509 false 17 17 C Volume 17 30 214 221 214 221 2013 2013 2013-01-01 2013-12-31 2013 First International Conference on Information Technology and Quantitative Management Yong Shi Youmin Xi Peter Wolcott Yingjie Tian Jianping Li Daniel Berg Zhengxin Chen Enrique Herrera-Viedma Gang Kou Heeseok Lee Yi Peng Lean Yu article fla Copyright \u00a9 2013 The Authors. Published by Elsevier B.V. MOBILECLOUDCOMPUTINGNETWORKATTACKDEFENSELEARNINGSYSTEMBASEDFUZZYSOFTSETS WANG Y LOTFI 1965 338 353 A MOLODTSOV 1999 19 31 D MAJI 2003 555 562 P RABITRAKUMAR 2001 589 602 YEWANG 2012 P1753 P1757 WANGX2013X214 WANGX2013X214X221 WANGX2013X214XY WANGX2013X214X221XY Full 2013-07-16T12:28:30Z ElsevierWaived http://creativecommons.org/licenses/by-nc-nd/3.0/ OA-Window item S1877-0509(13)00162-2 S1877050913001622 1-s2.0-S1877050913001622 10.1016/j.procs.2013.05.029 280203 2021-07-28T14:06:26.9917Z 2013-01-01 2013-12-31 1-s2.0-S1877050913001622-mainext.pdf https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/egi:10MQ9FLHRCK/MAIN/application/pdf/8e29d3cc94b4296fad97bd54cda86f3e/mainext.pdf mainext.pdf pdf true 585398 MAIN 11 1-s2.0-S1877050913001622-main_1.png https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1877050913001622/PREVIEW/image/png/2e21cca0ba9d811eb35db4ebf93a5f70/main_1.png https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1877050913001622/PREVIEW/image/png/2e21cca0ba9d811eb35db4ebf93a5f70/main_1.png main_1.png png 60474 849 656 IMAGE-WEB-PDF 1 1-s2.0-S1877050913001622-main.pdf https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1877050913001622/MAIN/application/pdf/c709c8718724dd2f4d9a45f3b5b8edb2/main.pdf https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1877050913001622/MAIN/application/pdf/c709c8718724dd2f4d9a45f3b5b8edb2/main.pdf main.pdf pdf true 454706 MAIN 8 1-s2.0-S1877050913001622-main_1.png https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1877050913001622/PREVIEW/image/png/2e21cca0ba9d811eb35db4ebf93a5f70/main_1.png https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1877050913001622/PREVIEW/image/png/2e21cca0ba9d811eb35db4ebf93a5f70/main_1.png main_1.png png 60474 849 656 IMAGE-WEB-PDF 1 Procedia Computer Science 17 ( 2013 ) 214 \u00e2\u20ac\u201c 221 1877-0509 2013 The Authors. Published by Elsevier B.V. Selection and peer-review under responsibility of the organizers of the 2013 International Conference on Information Technology and Quantitative Management doi: 10.1016/j.procs.2013.05.029 Information Technology and Quantitative Management (ITQM2013) Mobile Cloud Computing Network Attack and Defense Learning System Based on Fuzzy Soft Sets Ye Wang a, *, Zengliang Liu b ,Zhao Du c ,Yong Huang a a School of Automation, University of Science and Technology Beijing, Beijing 100083,China b China Institute of Information Operation, National Defense University, Beijing 100091,China c Information Technology Center, Tsinghua University, Beijing,100084 China Abstract In this paper, we propose a new decision-making system ranking method for the virtual machine startup problems by introducing the concept of fuzzy soft sets. Then this method is used for virtual machine management by AMCCM way. It turns the management of a network attack and defense learning system from semi-automatic to fully automatic. Based on the functional and structural design of mobile cloud computing network attack and defense learning system, we hope to bring new ideas to the field of mobile cloud computing. \u00c2\u00a9 2013 The Authors. Published by Elsevier B.V. Selection and/or peer-review under responsibility of the organizers of the 2013 International Conference on Computational Science Keywords: Mobile cloud computing; Fuzzy Soft Sets; Ranking Method; Middleware 1. Introduction With the development of mobile computing and wireless communication technology, mobile learning as a branch of digital learning, is drawing ever growing interest, and becomes a new hot spot in educational technology and related fields. Mobile network attack and defense learning system is reproduced by the offensive and defensive simulation technology and other ways, i.e. the terminal learning for mobile phone, network attack and defense technology and skills, universal education network security, network security training for senior personnel, information warfare for senior personnel and the training platform development. However, the performance of smart phones, tablet PCs, notebooks and other mobile terminal equipment is limited, and the computing power, storage capacity and the media's ability to run are also inadequate. Therefore, it will cause paralysis of the system when large number of users accessing cloud computing at the same time. * Corresponding author. Tel.: +0-86(0)-010-66772122; Mobile:+0-13810746589. E-mail address: yewang_ustb@163.com Available online at www.sciencedirect.com 2013 The Authors. Publishe vier B.V. Selection a peer-review under esponsibility of the rs f the 2013 International Conference on Information Te h ology and Quantitative Management Open access under CC BY-NC-ND license. Open access under CC BY-NC-ND license. 215 Ye Wang et al. / Procedia Computer Science 17 ( 2013 ) 214 \u00e2\u20ac\u201c 221 New ideas for the development of mobile learning systems are urgently needed to meet the requirement of users. Sharing the resources of distributed computing and large-scale heterogeneous system are the key method in implementing mobile learning systems. Cloud computing provides the ideal technical solution for this situation. The powerful computing and storage capacity derived from cloud computing are applied to educational resources, mobile computing technology for the portable devices, mobile and location-based service applications. It can also be combined with mobile education and builds integrated mobile learning system based on cloud computing. Network attack and defense which required rich, real-time, accurate learning will be supported by collaborative learning and situated learning. Domestic research on cloud service management platform and the core software are still at the initial stage, and the management algorithm is mainly initiated by scientific research institutes and universities. Current cloud service resource management algorithm primarily concentrated in system level, but the study in view of the application level is relatively limited. Beside the form of management described above, resource management method oriented basic units could provide automatic deployment, scheduling, execution and resource recycling and other functions that users need. We have proposed an application oriented mobile cloud computing middleware in the paper [5]. The AMCCM (Adaptive Mobile Cloud Computing Middleware) with cloud computing combined the hardware resource management with the application-layer software services in the system to automatically adjust the hardware resources which is responsible for the management, coordination and monitoring for the hardware and software resources on cloud platform. We introduce the concept of fuzzy soft sets for the virtual machine startup problems and propose a new decision-making system ranking method using AMCCM. With the utilization of AMCCM, we turned the management of the virtual machine from semi-automatic to fully automatic, and we achieved this through the functional design and the structural design for cloud computing mobile network attack and defense learning system. 2. Basic Concepts of the Soft Set Theory In order to take advantage of mathematical approach to research and deal with some vague phenomenon, cybernetics expert of the University of California, L.A. Zadeh founded fuzzy set (Fuzzy Sets) in 1965, which is the expansion of classical set. Comparing with classical set collection, the fuzzy set refers to all objects with some kind of vague concepts. Fuzzy math has been widely applied in many fields, such as soft science of artificial intelligence, automatic control and so on. However, fuzzy set theory is not the only way. It is part of the uncertain information theory which has lots of tools to solve realistic problems. In 1999, Molodtsov [2] proposed the concept of soft set to solve many practical problems. In real world, soft set theory has succeeded in many areas. PKMAJI showed the detail of soft set theory [3] and applied it to the decision-making system [4]. Definition 1. (Soft Set) Let U be a set of objects and let E be a set of parameters. Let ()UP denote the power set ofU . A pair (,)FE is called a soft set overU , where F is a mapping given by :()FE PU. Definition 2 .(Soft Subset) Let (,)FA and (,)GB be two soft sets overU , if satisfying the following conditions: (1) A B (2) eA, () ()Fe Ge Then a pair (,)FAis called a soft subset over (,)GB , that is (,) (,)FA GB. Definition 3. (Fuzzy Soft Set) Let U be a set of objects and let E be a non-null set of parameters. Let ()UF denote the power set 216 Ye Wang et al. / Procedia Computer Science 17 ( 2013 ) 214 \u00e2\u20ac\u201c 221 ofU . A E , A pair (,)FA is called a fuzzy soft set overU , where F is a mapping given by :()FE U . Definition 4. (Fuzz Soft Subset) Let (,)FA and (,)GB be two fuzzy soft sets overU , if satisfying the following conditions: (1) A B (2) eA, () ()Fe Ge Then a pair (,)FAis called a soft subset over (,)GB , that is (,) (,)FA GB. 3. Ranking method on fuzzy soft set In order to sort objects this paper proposed a ranking method based on fuzzy soft and used this method in AMCCM. This procedure is illustrated as the following example. 3.1. Representation of Fuzzy Soft Set Suppose we are given a finite set of objects 1234 {, , , },UVVVVUcontains four virtual machines. Parameter Set E={disk_usage cpu_usage thread_usage web_unit_time_response_rate} Expressed as 1234 ={e ,e ,e ,e }E , it describes a virtual machine load. Hence we can assume that: 11 23 4 ( ) { / 0.5, /1, / 0.4, / 0.3,}Fe V V V V 21 2 34 ( ) { / 0.6, / 0.4, /1, / 0.4,}Fe V V V V 31 2 34 ( ) { /0.2, /0.3, /1, /0.8,}Fe V V V V 412 3 4 ( ) { /1, /0.1, /0.5, /0.7,}Fe V V V V Then, we can get the fuzzy soft set 12 3 4 (F,E)={disk_usage_higher_V=F(e ) cpu_usage_higher_V=F(e ) thread_usage_higher_V=F(e ) web_unit_time_response_rate_higher_V=F(e )} i V represents virtual machine, j e is parameters, ij V is value, can be drawn under the Table1: Table 1.Parameters for Virtual machine U 1 e 2 e 3 e 4 e 1 V 0.5 0.6 0.2 1 2 V 1 0.4 0.3 0.1 3 V 0.4 1 1 0.5 4 V 0.3 0.4 0.8 0.7 217 Ye Wang et al. / Procedia Computer Science 17 ( 2013 ) 214 \u00e2\u20ac\u201c 221 3.2. Build Table of Fuzzy Soft Set Let ij C is numerical measurement, as number for Vi membership degree greater than or equal to , , , 1,2,..., . jij VC ij n 0,ij ijC k andC k ,can be drawn under the Table2: Table 2. Fuzzy Soft Set U 1 V 2 V 3 V 4 V 1 V 4 1 2 1 2 V 3 4 3 2 3 V 2 1 4 2 4 V 3 2 1 4 3.3. Ranking Method of Fuzzy Soft Set The ranking method as follows: (1) Input fuzzy soft set (,)FE ; (2) Build table of (,)FE ; (3) Compute by membership degree; (4) Compute sum of line i R , sum of column is i T ; (5) Compute score i S ; (6) Find , ki kS MaxS . Using the above ranking method, if sum of line is i 1 R, n iij i R C sum of column is i 1 , n iij j TT C i 1 , n iij j TT C score is i , iii SS R Tcan be drawn under the Table3: Table 3. Ranking Result U i R j T i S 1 V 8 12 -4 2 V 12 8 4 3 V 9 10 -1 4 V 10 9 1 Then, 2 4iSMaxS , so the first stop of the virtual machine is 2V ,next is 4V ,the ranking is 2, 4, 3, 1VVVV. 218 Ye Wang et al. / Procedia Computer Science 17 ( 2013 ) 214 \u00e2\u20ac\u201c 221 3.4. Used in AMCCM The ranking results applied to system monitoring component of AMCCM, this method not only is clear in concept, simple in calculation , but also has better editing and strong practicability. 4. Introduction of AMCCM Writer describes an environment from cloud computing middleware resource deployment, resource management, resource monitoring, resource control and other aspects in last paper. This environment can help us to dynamic management the relationship between systems and applications, achieve an advantage complementary. Either through virtualization products from the hardware point of view to manage the virtual machine, you can also manage the virtual machine from an application perspective; the ultimate aim is to let the server to provide better quality access speed for our customers. The management strategies driven by the real load situation of each application to start and stop virtual machine, and formed a mobile office framework based on cloud computing. The author put forward a strategy of virtual machine resources management, so that the virtual machine instead of artificial self-management in accordance with need. This framework enables cloud computing implementation has a new option, and cloud computing to provide a multi-business resource balance, thereby improving the efficiency of data reuse. 4.1. Structure of AMCCM The structure of AMCCM is described in Fig.1. It\u00e2\u20ac\u2122s mainly composed by two main components: one is the system monitoring component, monitoring software that comes with VMware products; other is application control component, it is mainly the deployment of applications in each virtual machine. See below for detail description of these two components. Fig.1. Structure of AMCCM The basic principles of their work is this: system monitoring component is responsible for system level monitoring, from the bottom to the virtual machine level CPU, memory, network, disk usage rule customization, once the present conditions it would process by written procedures. Application of monitoring module is prepared to use JAVA, to monitor the operation of middleware application. It mainly monitor the user number, on-line number, accesses the data in response to conditions in current application, can also be through the preparation of procedures for increasing function, strong extensibility. 4.2. Functions of AMCCM AMCCM be essentially similar to the resource monitor. It is responsible for the management of all cloud platform hardware and software resources, coordinating and monitoring work, including the following three 219 Ye Wang et al. / Procedia Computer Science 17 ( 2013 ) 214 \u00e2\u20ac\u201c 221 functions: a) Perform hardware resources are virtualized management, including new virtual environment, modify the virtual environment, and delete the virtual environment and so on. b) Dynamically adjust the virtual state through monitoring and management coordination. When the application's access has a higher pressure, automatic boot has a victualed resource to ease the pressure of the reality of running server. When an application server pressure reduction, automatic stops resources to reduce unnecessary waste of resources. c) Real-time monitor the work of all system, the work of virtual device and the access pressure of application server. 4.3. Workflow of AMCCM And then the middle agent running in the cloud computing virtual machine, Virtual machine object placed on object pool, and easy to middleware to understand the current state of virtual machine running. The working flow of AMCCM including the following steps: Step1: Start virtual machine, and initialization; Step2: According to a defined minimum number of virtual start virtual machine, adding the virtual machine identifier into the object pool. Step3: Real-time listening received message form monitoring component. Step4: Start and stop virtual machine. Step5: Maintain management for object pool. 5. Mobile network attack and defense learning system based on cloud computing 5.1. Structure deployment According to WEB application group, Fig.2 describes the architecture deployment diagram of cloud computing system. It makes resource layer and application layer clearly divided. When the user puts forward new application requirement, the background administrator need increase corresponding resource server through the AMCCM. Deployment and web services which are required by customers could be completed by a series changing operations. Therefore, the cost of the deployment for integration is saved. Fig.2. Structure deployment diagram 220 Ye Wang et al. / Procedia Computer Science 17 ( 2013 ) 214 \u00e2\u20ac\u201c 221 The cloud-based mobile network attack and defense learning system is constructed on a three-tier architecture (UI, BLL, DAL) network platform and cloud platform as showed in Fig.3. Fig.3. Software architecture diagram Mobile terminal Through mobile terminals, system content is rendered for the users and users interact with the system media. Support equipment could be a mobile phone, PDA and other mobile devices. The system provides different interface and functionalities for different categories of users. The users use the mobile terminal through the mobile communication network or a wireless network for communicating with the network platform. The wireless network is either a private network established by a number of institutions, or public network held by communication operators. Based on the three-tier network platform The platform is a bracket system, and does not host any specific data content The main capabilities of this platform is to identify users and the kind of services, and then according to the interface calls cloud computing platform provides related services for users. The presentation layer (UI) user interface handles system interaction and the user's session. The program running in mobile devices is mainly through the browser located in user and the business logic layer. The business logic layer (BLL) is responsible for the presentation of the application request which includes training sets preparing, programs training, system configuration, system booting, real-time monitoring, process monitoring, load training, storage processing, training evaluating, results assessment, analysis the correction of different functions and taking the intervention. When the request of the users is referred to database access, business logic layer will call the service provided by the database access layer. Once database access layer receives business command from the business logic layer, further analyzing and processing requests are submitted to the cloud computing platform through the interface program. If the operations needn\u00e2\u20ac\u2122t any help of database access layer, they are directly submitted to the cloud computing platform for processing. Cloud platform The cloud computing platform is the core part of the system and is also the final implementation of the entire functions module. All the services needed by the user interface are handed over to the cloud computing platform. Cloud platform includes data storage, calculation and management three major modules. Calculation module splits the user's computing tasks into small ones, and then assigns them to distributed nodes for parallel computing with corresponding functions. After all related calculations, cloud platform collects the final results, makes the integration (such as sorting, merging, etc.) and return the final result to users. Data management 221 Ye Wang et al. / Procedia Computer Science 17 ( 2013 ) 214 \u00e2\u20ac\u201c 221 module holds self-management and self-tuning to facilitate inquiry and search operations. The storage module is divided into five sub-modules that is user repository, learning repository, exchange library, service repository, software library according to the three-tier structure network platform. 6. Conclusions From the discussions as above, this decision-making system ranking method not only is clear in concept, simple in calculation, but also has better editing and strong practicability. Currently, education system supported by mobile cloud computing technology is still in the exploratory stage, but the attractive advantages indicate that cloud computing has a strong potential in the field of mobile education. This article introduces an exploration of cloud-based mobile network attack and defense learning system. Based on this system, we hope to bring new ideas to the field of mobile cloud computing. Acknowledgements This work was supported by National Natural Science Foundation of China (No. 90818025). References [1] Lotfi A. Zadeh, Fuzzy Sets, Information and Control 8 (3) (1965) 338-353 [2] D. Molodtsov, Soft Set Theory-First Results, Computers & Mathematics with Applications 37 (4) (1999) 19-31 [3] P.K. Maji, R. Biswas and A.R. Roy, Soft Set Theory, Computers & Mathematics with Applications, 200345,555-562 [4] RabitraKumar, MajiRanjit, BiswasAkhil, Ranjan Roy, Fuzzy Soft Sets, The Jourhal of Fuzzy Mathematics, 20019(3)589-602 [5] YeWang, Wenchao Song, Zengliang Liu , An Oriented-application Adaptive Mobile Cloud Computing Middleware, IEEE CCIS (2012), ,P1753-1757 erent categories of users. The users use the mobile terminal through the mobile communication network or a wireless network for communicating with the network platform. The wireless network is either a private network established by a number of institutions, or public network held by communication operators. Based on the three-tier network platform The platform is a bracket system, and does not host any specific data content The main capabilities of this platform is to identify users and the kind of services, and then according to the interface calls cloud computing platform provides related services for users. The presentation layer (UI) user interface handles system interaction and the user's session. The program running in mobile devices is mainly through the browser located in user and the business logic layer. The business logic layer (BLL) is responsible for the presentation of the application request which includes training sets preparing, programs training, system configuration, system booting, real-time monitoring, process monitoring, load training, storage processing, training evaluating, results assessment, analysis the correction of different functions and taking the intervention. When the request of the users is referred to database access, business logic layer will call the service provided by the database access layer. Once database access layer receives business command from the business logic layer, further analyzing and processing requests are submitted to the cloud computing platform through the interface program. If the operations nee PROCS 1808 S1877-0509(13)00162-2 10.1016/j.procs.2013.05.029 The Authors \u2606 Selection and peer-review under responsibility of the organizers of the 2013 International Conference on Information Technology and Quantitative Management. Mobile Cloud Computing Network Attack and Defense Learning System Based on Fuzzy Soft Sets Ye Wang a * Zengliang Liu b Zhao Du c Yong Huang a a School of Automation, University of Science and Technology Beijing, Beijing 100083,China b China Institute of Information Operation, National Defense University, Beijing 100091,China c Information Technology Center, Tsinghua University, Beijing,100084 China * Corresponding author. Tel.: +0 86(0) 010 66772122; Mobile: 0 13810746589. In this paper, we propose a new decision-making system ranking method for the virtual machine startup problems by introducing the concept of fuzzy soft sets. Then this method is used for virtual machine management by AMCCM way. It turns the management of a network attack and defense learning system from semi-automatic to fully automatic. Based on the functional and structural design of mobile cloud computing network attack and defense learning system, we hope to bring new ideas to the field of mobile cloud computing. Keywords Mobile cloud computing Fuzzy Soft Sets Ranking Method Middleware References [1] A. Lotfi Zadeh Fuzzy Sets Information and Control 8 3 1965 338 353 [2] D. Molodtsov Soft Set Theory-First Results Computers & Mathematics with Applications 37 4 1999 19 31 [3] P.K. Maji R. Biswas A.R. Roy Soft Set Theory Computers & Mathematics with Applications 45 2003 555 562 [4] RabitraKumar MajiRanjit BiswasAkhil Ranjan Roy Fuzzy Soft Sets The Jourhal of Fuzzy Mathematics 9 3 2001 589 602 [5] YeWang Wenchao Song Zengliang Liu An Oriented-application Adaptive Mobile Cloud Computing Middleware IEEE CCIS 2012 P1753 P1757"
    },
    "10.1016/j.jco.2012.09.002": {
        "Title": "Vector-valued reproducing kernel Banach spaces with applications to multi-task learning",
        "Date": "April 2013",
        "Text": "serial JL 272569 291210 291686 291697 31 Journal of Complexity JOURNALCOMPLEXITY 2012-09-20 2012-09-20 2013-02-08T16:42:57 1-s2.0-S0885064X12000817 S0885-064X(12)00081-7 S0885064X12000817 10.1016/j.jco.2012.09.002 S300 S300.1 FULL-TEXT 1-s2.0-S0885064X13X00020 2017-03-31T22:26:07.245411-04:00 0 0 20130401 20130430 2013 2012-09-20T00:00:00Z articleinfo crossmark dco dateupdated tomb dateloaded datesearch indexeddate issuelist volumelist yearnav articletitlenorm authfirstinitialnorm authfirstsurnamenorm cid cids contenttype copyright dateloadedtxt docsubtype doctype doi eid ewtransactionid hubeid issfirst issn issnnorm itemstage itemtransactionid itemweight openaccess openarchive pg pgfirst pglast pii piinorm pubdateend pubdatestart pubdatetxt pubyr sectiontitle sortorder srctitle srctitlenorm srctype subheadings volfirst volissue webpdf webpdfpagecount body mmlmath affil articletitle auth authfirstini authfull authkeywords authlast primabst ref alllist content subj ssids 0885-064X 0885064X false 29 29 2 2 Volume 29, Issue 2 8 195 215 195 215 201304 April 2013 2013-04-01 2013-04-30 2013 REGULAR ARTICLES article fla Copyright \u00a9 2012 Elsevier Inc. All rights reserved. VECTORVALUEDREPRODUCINGKERNELBANACHSPACESAPPLICATIONSMULTITASKLEARNING ZHANG H 1 Introduction 2 Definition and basic properties 3 Feature map representations 4 Examples of vector-valued RKBSs 4.1 The space of sensing matrices 4.2 Tensor products of scalar-valued RKBSs 4.3 Translation invariant vector-valued RKBSs 5 Multi-task learning with Banach spaces 5.1 Existence and uniqueness 5.2 The representer theorem 5.3 Characterization equations References ARGYRIOU 2009 2507 2529 A ARGYRIOU 2010 935 953 A ARONSZAJN 1950 337 404 N BENNETT 2000 57 64 K PROCEEDINGSEVENTEENTHINTERNATIONALCONFERENCEMACHINELEARNING DUALITYGEOMETRYINSVMCLASSIFIERS BURBEA 1984 J BANACHHILBERTSPACESVECTORVALUEDFUNCTIONS CANU 2003 89 110 S ADVANCESINLEARNINGTHEORYMETHODSMODELSAPPLICATIONS FUNCTIONALLEARNINGTHROUGHKERNEL CAPONNETTO 2008 1615 1646 A CARMELI 2006 377 408 C CARMELI 2010 19 61 C CUCKER 2002 1 49 F CUDIA 1963 265 267 D EVGENIOU 2005 615 637 T EVGENIOU 2000 1 50 T GENTILE 2001 213 242 C GILES 1967 436 446 J HEIN 2005 333 359 M HORN 1991 R TOPICSINMATRIXANALYSIS JORGENSEN 2011 745 781 P KIMBER 1995 141 156 D KIMELDORF 1971 82 95 G KOEHLER 1971 363 366 D LUMER 1961 29 43 G MICCHELLI 2004 255 269 C LEARNINGTHEORY AFUNCTIONREPRESENTATIONFORLEARNINGINBANACHSPACES MICCHELLI 2005 177 204 C MICCHELLI 2007 297 319 C SCHOLKOPF 2001 416 426 B PROCEEDINGFOURTEENTHANNUALCONFERENCECOMPUTATIONALLEARNINGTHEORYFIFTHEUROPEANCONFERENCECOMPUTATIONALLEARNINGTHEORY AGENERALIZEDREPRESENTERTHEOREM SCHOLKOPF 2002 B LEARNINGKERNELSSUPPORTVECTORMACHINESREGULARIZATIONOPTIMIZATIONBEYOND SHAWETAYLOR 2004 J KERNELMETHODSFORPATTERNANALYSIS SONG 2011 2713 2729 G SRIPERUMBUDUR 2011 B ADVANCESINNEURALINFORMATIONPROCESSINGSYSTEMSVOL24 LEARNINGINHILBERTVSBANACHSPACESAMEASUREEMBEDDINGVIEWPOINT VAPNIK 1998 V STATISTICALLEARNINGTHEORY VONLUXBURG 2004 669 695 U XU 2009 107 140 Y ZHANG 2002 91 129 T ZHANG 2009 2741 2775 H ZHANG 2012 91 136 H ZHANG 2011 1 25 H ZHANGX2013X195 ZHANGX2013X195X215 ZHANGX2013X195XH ZHANGX2013X195X215XH Full 2017-04-01T01:10:20Z OA-Window ElsevierBranded http://www.elsevier.com/open-access/userlicense/1.0/ item S0885-064X(12)00081-7 S0885064X12000817 1-s2.0-S0885064X12000817 10.1016/j.jco.2012.09.002 272569 2013-02-08T14:16:00.43533-05:00 2013-04-01 2013-04-30 1-s2.0-S0885064X12000817-main.pdf https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/MAIN/application/pdf/6c656a4105f0dcfa1a904412c739e850/main.pdf https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/MAIN/application/pdf/6c656a4105f0dcfa1a904412c739e850/main.pdf main.pdf pdf true 328005 MAIN 21 1-s2.0-S0885064X12000817-main_1.png https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/PREVIEW/image/png/a91b72e43b7d11b98463d920a8ff8366/main_1.png https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/PREVIEW/image/png/a91b72e43b7d11b98463d920a8ff8366/main_1.png main_1.png png 66366 849 656 IMAGE-WEB-PDF 1 1-s2.0-S0885064X12000817-si82.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/ae4348d2405d949eba06d864476458af/si96.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/ae4348d2405d949eba06d864476458af/si96.gif si82 si82.gif gif 129 9 12 ALTIMG 1-s2.0-S0885064X12000817-si665.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/4b9f5f5a22875874e2e0bc0978e8ea8e/si673.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/4b9f5f5a22875874e2e0bc0978e8ea8e/si673.gif si665 si665.gif gif 129 9 12 ALTIMG 1-s2.0-S0885064X12000817-si804.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/077ed1a426fb9e023fceace3885c3106/si804.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/077ed1a426fb9e023fceace3885c3106/si804.gif si804 si804.gif gif 1899 39 411 ALTIMG 1-s2.0-S0885064X12000817-si259.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/7e41d89737891c2e29d01d76c408c5cb/si355.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/7e41d89737891c2e29d01d76c408c5cb/si355.gif si259 si259.gif gif 369 13 107 ALTIMG 1-s2.0-S0885064X12000817-si544.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/e745a2a56fc432c4b59c3610b0084ccd/si224.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/e745a2a56fc432c4b59c3610b0084ccd/si224.gif si544 si544.gif gif 176 10 38 ALTIMG 1-s2.0-S0885064X12000817-si86.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/63ece0456aa5abda63641ae91798941c/si296.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/63ece0456aa5abda63641ae91798941c/si296.gif si86 si86.gif gif 119 9 11 ALTIMG 1-s2.0-S0885064X12000817-si768.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/3bc72098bcd1389c268902d0e633ffab/si273.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/3bc72098bcd1389c268902d0e633ffab/si273.gif si768 si768.gif gif 129 9 12 ALTIMG 1-s2.0-S0885064X12000817-si583.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/8083119a46cb4caeafb6255f2fbddeb1/si583.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/8083119a46cb4caeafb6255f2fbddeb1/si583.gif si583 si583.gif gif 225 10 54 ALTIMG 1-s2.0-S0885064X12000817-si305.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/8904ff5535f18a62016bd300d0eb6f8a/si348.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/8904ff5535f18a62016bd300d0eb6f8a/si348.gif si305 si305.gif gif 144 9 17 ALTIMG 1-s2.0-S0885064X12000817-si415.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/7a873957b9b40db39aea3e23381595bd/si16.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/7a873957b9b40db39aea3e23381595bd/si16.gif si415 si415.gif gif 156 13 32 ALTIMG 1-s2.0-S0885064X12000817-si632.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/5d4ef2c58a5869550d416d570de15d93/si374.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/5d4ef2c58a5869550d416d570de15d93/si374.gif si632 si632.gif gif 135 10 17 ALTIMG 1-s2.0-S0885064X12000817-si454.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/8eb1786ada410dcf9bbd36d493e371b4/si454.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/8eb1786ada410dcf9bbd36d493e371b4/si454.gif si454 si454.gif gif 857 36 215 ALTIMG 1-s2.0-S0885064X12000817-si640.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/29fa9e28e03231dbf7a0ef95e7773ffd/si640.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/29fa9e28e03231dbf7a0ef95e7773ffd/si640.gif si640 si640.gif gif 113 9 9 ALTIMG 1-s2.0-S0885064X12000817-si750.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/500367b0e6afdd969ebc3416a4aa6fbf/si750.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/500367b0e6afdd969ebc3416a4aa6fbf/si750.gif si750 si750.gif gif 497 13 120 ALTIMG 1-s2.0-S0885064X12000817-si579.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/48f9a9c7e58968120d4e127075b75e22/si579.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/48f9a9c7e58968120d4e127075b75e22/si579.gif si579 si579.gif gif 975 46 199 ALTIMG 1-s2.0-S0885064X12000817-si625.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/1560a0dee6a122fc0bbb9e785000aeff/si598.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/1560a0dee6a122fc0bbb9e785000aeff/si598.gif si625 si625.gif gif 149 10 17 ALTIMG 1-s2.0-S0885064X12000817-si412.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/69a859512831c8a29f3cdf66dc934c29/si412.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/69a859512831c8a29f3cdf66dc934c29/si412.gif si412 si412.gif gif 398 16 134 ALTIMG 1-s2.0-S0885064X12000817-si828.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/89845a6dba12661e49294e0bcfc49f48/si828.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/89845a6dba12661e49294e0bcfc49f48/si828.gif si828 si828.gif gif 133 10 14 ALTIMG 1-s2.0-S0885064X12000817-si110.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/b098d5a7b236a8a61d86d3f42e87e32d/si112.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/b098d5a7b236a8a61d86d3f42e87e32d/si112.gif si110 si110.gif gif 116 9 11 ALTIMG 1-s2.0-S0885064X12000817-si346.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/32e887d0838320a7630679113bb323cd/si346.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/32e887d0838320a7630679113bb323cd/si346.gif si346 si346.gif gif 232 12 53 ALTIMG 1-s2.0-S0885064X12000817-si515.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/d5fad66daf7e3af8a9636c9147ab7d02/si515.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/d5fad66daf7e3af8a9636c9147ab7d02/si515.gif si515 si515.gif gif 489 15 143 ALTIMG 1-s2.0-S0885064X12000817-si835.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/5fec6f879c54b9fbdaafaa2aab3dfdb5/si835.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/5fec6f879c54b9fbdaafaa2aab3dfdb5/si835.gif si835 si835.gif gif 133 13 13 ALTIMG 1-s2.0-S0885064X12000817-si586.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/4765386f6adbd3756347dcd1ceb6610c/si586.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/4765386f6adbd3756347dcd1ceb6610c/si586.gif si586 si586.gif gif 1110 51 209 ALTIMG 1-s2.0-S0885064X12000817-si340.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/33855c3d5c62e0d7bd13473fed60028c/si340.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/33855c3d5c62e0d7bd13473fed60028c/si340.gif si340 si340.gif gif 156 19 14 ALTIMG 1-s2.0-S0885064X12000817-si470.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/1e213719929cd636b39c74c52bb792c9/si470.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/1e213719929cd636b39c74c52bb792c9/si470.gif si470 si470.gif gif 303 15 78 ALTIMG 1-s2.0-S0885064X12000817-si533.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/ae4348d2405d949eba06d864476458af/si96.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/ae4348d2405d949eba06d864476458af/si96.gif si533 si533.gif gif 129 9 12 ALTIMG 1-s2.0-S0885064X12000817-si825.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/2c11b432dd2cce56d1a27fcb2b712f9f/si825.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/2c11b432dd2cce56d1a27fcb2b712f9f/si825.gif si825 si825.gif gif 939 39 232 ALTIMG 1-s2.0-S0885064X12000817-si62.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/0ed0ed94f5ca79964478355bab9dfe4d/si13.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/0ed0ed94f5ca79964478355bab9dfe4d/si13.gif si62 si62.gif gif 179 13 33 ALTIMG 1-s2.0-S0885064X12000817-si705.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/ae4348d2405d949eba06d864476458af/si96.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/ae4348d2405d949eba06d864476458af/si96.gif si705 si705.gif gif 129 9 12 ALTIMG 1-s2.0-S0885064X12000817-si295.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/ae4348d2405d949eba06d864476458af/si96.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/ae4348d2405d949eba06d864476458af/si96.gif si295 si295.gif gif 129 9 12 ALTIMG 1-s2.0-S0885064X12000817-si584.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/e31397c78327e203ae80864ca8965250/si584.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/e31397c78327e203ae80864ca8965250/si584.gif si584 si584.gif gif 1276 39 344 ALTIMG 1-s2.0-S0885064X12000817-si290.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/8904ff5535f18a62016bd300d0eb6f8a/si348.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/8904ff5535f18a62016bd300d0eb6f8a/si348.gif si290 si290.gif gif 144 9 17 ALTIMG 1-s2.0-S0885064X12000817-si721.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/66173c4d94832e5cbf84ccec95a8004a/si31.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/66173c4d94832e5cbf84ccec95a8004a/si31.gif si721 si721.gif gif 119 9 11 ALTIMG 1-s2.0-S0885064X12000817-si164.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/79379d560514a5994ea982fc830d08f5/si164.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/79379d560514a5994ea982fc830d08f5/si164.gif si164 si164.gif gif 1257 13 448 ALTIMG 1-s2.0-S0885064X12000817-si376.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/d50700b750408e4116750436c494baa1/si376.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/d50700b750408e4116750436c494baa1/si376.gif si376 si376.gif gif 226 14 39 ALTIMG 1-s2.0-S0885064X12000817-si115.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/63ece0456aa5abda63641ae91798941c/si296.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/63ece0456aa5abda63641ae91798941c/si296.gif si115 si115.gif gif 119 9 11 ALTIMG 1-s2.0-S0885064X12000817-si216.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/ae4348d2405d949eba06d864476458af/si96.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/ae4348d2405d949eba06d864476458af/si96.gif si216 si216.gif gif 129 9 12 ALTIMG 1-s2.0-S0885064X12000817-si703.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/7a2b60190a907e87929841f2f352a8bf/si717.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/7a2b60190a907e87929841f2f352a8bf/si717.gif si703 si703.gif gif 190 12 38 ALTIMG 1-s2.0-S0885064X12000817-si102.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/01b727e74e4adcb2425e161f628ab3f0/si102.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/01b727e74e4adcb2425e161f628ab3f0/si102.gif si102 si102.gif gif 266 13 56 ALTIMG 1-s2.0-S0885064X12000817-si688.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/d45b05f1c17bb5849d2412dfe2ae923d/si769.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/d45b05f1c17bb5849d2412dfe2ae923d/si769.gif si688 si688.gif gif 138 12 14 ALTIMG 1-s2.0-S0885064X12000817-si509.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/66bb91392c090915676d769f8e848275/si509.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/66bb91392c090915676d769f8e848275/si509.gif si509 si509.gif gif 131 9 13 ALTIMG 1-s2.0-S0885064X12000817-si661.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/e0376bbea674aa63525d2dd65facc96b/si661.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/e0376bbea674aa63525d2dd65facc96b/si661.gif si661 si661.gif gif 149 12 20 ALTIMG 1-s2.0-S0885064X12000817-si641.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/24a6c26c1dbebc988ef39132e6bd2972/si641.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/24a6c26c1dbebc988ef39132e6bd2972/si641.gif si641 si641.gif gif 282 12 84 ALTIMG 1-s2.0-S0885064X12000817-si780.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/b426ca0caa014732a24a5a45be954d11/si780.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/b426ca0caa014732a24a5a45be954d11/si780.gif si780 si780.gif gif 974 14 316 ALTIMG 1-s2.0-S0885064X12000817-si230.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/23bb0f9e1216d889b6940c402aed2cc0/si230.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/23bb0f9e1216d889b6940c402aed2cc0/si230.gif si230 si230.gif gif 186 13 28 ALTIMG 1-s2.0-S0885064X12000817-si97.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/63ece0456aa5abda63641ae91798941c/si296.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/63ece0456aa5abda63641ae91798941c/si296.gif si97 si97.gif gif 119 9 11 ALTIMG 1-s2.0-S0885064X12000817-si146.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/3bc72098bcd1389c268902d0e633ffab/si273.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/3bc72098bcd1389c268902d0e633ffab/si273.gif si146 si146.gif gif 129 9 12 ALTIMG 1-s2.0-S0885064X12000817-si396.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/47a438cd00d739a80aa3b62078bfe2ba/si396.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/47a438cd00d739a80aa3b62078bfe2ba/si396.gif si396 si396.gif gif 207 14 39 ALTIMG 1-s2.0-S0885064X12000817-si45.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/66173c4d94832e5cbf84ccec95a8004a/si31.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/66173c4d94832e5cbf84ccec95a8004a/si31.gif si45 si45.gif gif 119 9 11 ALTIMG 1-s2.0-S0885064X12000817-si127.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/896f840cb310b9156e45afd0d7e04bd8/si127.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/896f840cb310b9156e45afd0d7e04bd8/si127.gif si127 si127.gif gif 187 13 35 ALTIMG 1-s2.0-S0885064X12000817-si180.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/70dd145fac296d0a48c10ff10430d99c/si180.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/70dd145fac296d0a48c10ff10430d99c/si180.gif si180 si180.gif gif 2100 47 357 ALTIMG 1-s2.0-S0885064X12000817-si40.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/66173c4d94832e5cbf84ccec95a8004a/si31.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/66173c4d94832e5cbf84ccec95a8004a/si31.gif si40 si40.gif gif 119 9 11 ALTIMG 1-s2.0-S0885064X12000817-si287.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/6a3faf62eb9a4a139a77a058c2fee4a9/si287.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/6a3faf62eb9a4a139a77a058c2fee4a9/si287.gif si287 si287.gif gif 1153 17 369 ALTIMG 1-s2.0-S0885064X12000817-si51.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/66173c4d94832e5cbf84ccec95a8004a/si31.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/66173c4d94832e5cbf84ccec95a8004a/si31.gif si51 si51.gif gif 119 9 11 ALTIMG 1-s2.0-S0885064X12000817-si529.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/427082d5335728eefc1b46523259d9c8/si529.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/427082d5335728eefc1b46523259d9c8/si529.gif si529 si529.gif gif 560 17 172 ALTIMG 1-s2.0-S0885064X12000817-si712.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/3bc72098bcd1389c268902d0e633ffab/si273.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/3bc72098bcd1389c268902d0e633ffab/si273.gif si712 si712.gif gif 129 9 12 ALTIMG 1-s2.0-S0885064X12000817-si653.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/66173c4d94832e5cbf84ccec95a8004a/si31.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/66173c4d94832e5cbf84ccec95a8004a/si31.gif si653 si653.gif gif 119 9 11 ALTIMG 1-s2.0-S0885064X12000817-si716.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/56669c51034bd532b0e36efbccf7498f/si716.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/56669c51034bd532b0e36efbccf7498f/si716.gif si716 si716.gif gif 139 11 16 ALTIMG 1-s2.0-S0885064X12000817-si122.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/3bc72098bcd1389c268902d0e633ffab/si273.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/3bc72098bcd1389c268902d0e633ffab/si273.gif si122 si122.gif gif 129 9 12 ALTIMG 1-s2.0-S0885064X12000817-si809.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/863d644841703e99d9893e60cc2c4a00/si819.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/863d644841703e99d9893e60cc2c4a00/si819.gif si809 si809.gif gif 268 13 65 ALTIMG 1-s2.0-S0885064X12000817-si771.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/8daa69fc4fe3ae57bf307a15e5ca2eb8/si771.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/8daa69fc4fe3ae57bf307a15e5ca2eb8/si771.gif si771 si771.gif gif 337 13 90 ALTIMG 1-s2.0-S0885064X12000817-si472.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/1a00c6bc7512c9470ff28b5e0402dfc3/si445.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/1a00c6bc7512c9470ff28b5e0402dfc3/si445.gif si472 si472.gif gif 145 10 17 ALTIMG 1-s2.0-S0885064X12000817-si766.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/4dca1154f43a6ca353bead64704affdd/si766.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/4dca1154f43a6ca353bead64704affdd/si766.gif si766 si766.gif gif 304 15 73 ALTIMG 1-s2.0-S0885064X12000817-si185.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/9e33184516715a1249847402e8db1d34/si185.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/9e33184516715a1249847402e8db1d34/si185.gif si185 si185.gif gif 1243 19 387 ALTIMG 1-s2.0-S0885064X12000817-si80.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/63ece0456aa5abda63641ae91798941c/si296.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/63ece0456aa5abda63641ae91798941c/si296.gif si80 si80.gif gif 119 9 11 ALTIMG 1-s2.0-S0885064X12000817-si446.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/48f166c4acdfd2633e5b7ee6351a279a/si446.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/48f166c4acdfd2633e5b7ee6351a279a/si446.gif si446 si446.gif gif 153 16 14 ALTIMG 1-s2.0-S0885064X12000817-si250.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/7cf1e5f06150ba82ff5d514a25344f19/si250.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/7cf1e5f06150ba82ff5d514a25344f19/si250.gif si250 si250.gif gif 148 13 15 ALTIMG 1-s2.0-S0885064X12000817-si613.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/fde919b4b6785b688e1f0931ac5fba75/si613.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/fde919b4b6785b688e1f0931ac5fba75/si613.gif si613 si613.gif gif 1675 35 355 ALTIMG 1-s2.0-S0885064X12000817-si684.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/133accca116565ccbca4e57bc0c50488/si684.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/133accca116565ccbca4e57bc0c50488/si684.gif si684 si684.gif gif 203 10 40 ALTIMG 1-s2.0-S0885064X12000817-si543.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/aad40cf8047397c0c31f32a30209ff87/si543.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/aad40cf8047397c0c31f32a30209ff87/si543.gif si543 si543.gif gif 298 13 64 ALTIMG 1-s2.0-S0885064X12000817-si559.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/f34ef91c138ec64168fa409920f65b3c/si559.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/f34ef91c138ec64168fa409920f65b3c/si559.gif si559 si559.gif gif 252 16 43 ALTIMG 1-s2.0-S0885064X12000817-si188.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/14f8f54945adfe361cef082d45397eca/si188.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/14f8f54945adfe361cef082d45397eca/si188.gif si188 si188.gif gif 1019 15 322 ALTIMG 1-s2.0-S0885064X12000817-si235.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/2ab7d2bf7b09fe29cc1c6d61a2e4e511/si235.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/2ab7d2bf7b09fe29cc1c6d61a2e4e511/si235.gif si235 si235.gif gif 196 14 35 ALTIMG 1-s2.0-S0885064X12000817-si603.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/87ad80e99bd606714d024b6aec0c403c/si603.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/87ad80e99bd606714d024b6aec0c403c/si603.gif si603 si603.gif gif 536 14 166 ALTIMG 1-s2.0-S0885064X12000817-si576.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/9b679e1ea10f4ab4e3439643d35a8a99/si576.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/9b679e1ea10f4ab4e3439643d35a8a99/si576.gif si576 si576.gif gif 1182 38 288 ALTIMG 1-s2.0-S0885064X12000817-si267.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/896f840cb310b9156e45afd0d7e04bd8/si127.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/896f840cb310b9156e45afd0d7e04bd8/si127.gif si267 si267.gif gif 187 13 35 ALTIMG 1-s2.0-S0885064X12000817-si402.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/ac336a90858379243e6e5e596626337e/si402.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/ac336a90858379243e6e5e596626337e/si402.gif si402 si402.gif gif 701 41 131 ALTIMG 1-s2.0-S0885064X12000817-si151.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/ae4348d2405d949eba06d864476458af/si96.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/ae4348d2405d949eba06d864476458af/si96.gif si151 si151.gif gif 129 9 12 ALTIMG 1-s2.0-S0885064X12000817-si32.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/6d3472cf641e930c3b2aa804279165ba/si55.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/6d3472cf641e930c3b2aa804279165ba/si55.gif si32 si32.gif gif 137 10 17 ALTIMG 1-s2.0-S0885064X12000817-si426.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/1f30a19640a48c6accfc47b88f7f16aa/si426.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/1f30a19640a48c6accfc47b88f7f16aa/si426.gif si426 si426.gif gif 124 9 12 ALTIMG 1-s2.0-S0885064X12000817-si26.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/036cb9b90893cef26c00380719427644/si214.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/036cb9b90893cef26c00380719427644/si214.gif si26 si26.gif gif 141 10 16 ALTIMG 1-s2.0-S0885064X12000817-si303.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/d331fc587c3941b84642ea730e3b14a7/si291.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/d331fc587c3941b84642ea730e3b14a7/si291.gif si303 si303.gif gif 173 10 38 ALTIMG 1-s2.0-S0885064X12000817-si121.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/751298c4de9f0dfec04f9ba577dcdb1e/si73.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/751298c4de9f0dfec04f9ba577dcdb1e/si73.gif si121 si121.gif gif 125 9 13 ALTIMG 1-s2.0-S0885064X12000817-si475.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/6d9476431a21ceec7ec71ac66c666943/si475.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/6d9476431a21ceec7ec71ac66c666943/si475.gif si475 si475.gif gif 786 19 282 ALTIMG 1-s2.0-S0885064X12000817-si749.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/d6898a4be6347b8fd28e1f81de9efca3/si749.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/d6898a4be6347b8fd28e1f81de9efca3/si749.gif si749 si749.gif gif 325 13 77 ALTIMG 1-s2.0-S0885064X12000817-si592.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/607fbe8726f69e0a2d1d8994488db31d/si592.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/607fbe8726f69e0a2d1d8994488db31d/si592.gif si592 si592.gif gif 539 15 147 ALTIMG 1-s2.0-S0885064X12000817-si495.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/1a00c6bc7512c9470ff28b5e0402dfc3/si445.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/1a00c6bc7512c9470ff28b5e0402dfc3/si445.gif si495 si495.gif gif 145 10 17 ALTIMG 1-s2.0-S0885064X12000817-si227.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/7578340ef224de23cafc1228a40ac227/si698.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/7578340ef224de23cafc1228a40ac227/si698.gif si227 si227.gif gif 111 6 9 ALTIMG 1-s2.0-S0885064X12000817-si460.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/5a8b0324641ac5e849d677db43df8e48/si460.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/5a8b0324641ac5e849d677db43df8e48/si460.gif si460 si460.gif gif 276 13 63 ALTIMG 1-s2.0-S0885064X12000817-si389.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/c707caa447b92f85b0e4b45d9cc41098/si389.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/c707caa447b92f85b0e4b45d9cc41098/si389.gif si389 si389.gif gif 322 14 80 ALTIMG 1-s2.0-S0885064X12000817-si568.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/a922daab0ab2136b7989b2e12774a977/si568.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/a922daab0ab2136b7989b2e12774a977/si568.gif si568 si568.gif gif 134 8 25 ALTIMG 1-s2.0-S0885064X12000817-si795.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/71e5a75156842404ecc03af47156dd48/si795.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/71e5a75156842404ecc03af47156dd48/si795.gif si795 si795.gif gif 124 10 10 ALTIMG 1-s2.0-S0885064X12000817-si393.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/0febe4948c2a06572e7d95809cec81ad/si393.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/0febe4948c2a06572e7d95809cec81ad/si393.gif si393 si393.gif gif 865 41 176 ALTIMG 1-s2.0-S0885064X12000817-si702.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/4b9f5f5a22875874e2e0bc0978e8ea8e/si673.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/4b9f5f5a22875874e2e0bc0978e8ea8e/si673.gif si702 si702.gif gif 129 9 12 ALTIMG 1-s2.0-S0885064X12000817-si794.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/e0376bbea674aa63525d2dd65facc96b/si661.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/e0376bbea674aa63525d2dd65facc96b/si661.gif si794 si794.gif gif 149 12 20 ALTIMG 1-s2.0-S0885064X12000817-si385.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/ae4348d2405d949eba06d864476458af/si96.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/ae4348d2405d949eba06d864476458af/si96.gif si385 si385.gif gif 129 9 12 ALTIMG 1-s2.0-S0885064X12000817-si66.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/66173c4d94832e5cbf84ccec95a8004a/si31.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/66173c4d94832e5cbf84ccec95a8004a/si31.gif si66 si66.gif gif 119 9 11 ALTIMG 1-s2.0-S0885064X12000817-si655.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/66173c4d94832e5cbf84ccec95a8004a/si31.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/66173c4d94832e5cbf84ccec95a8004a/si31.gif si655 si655.gif gif 119 9 11 ALTIMG 1-s2.0-S0885064X12000817-si599.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/3179368a630f1caa0a256bdcfd9e2ff1/si599.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/3179368a630f1caa0a256bdcfd9e2ff1/si599.gif si599 si599.gif gif 208 14 43 ALTIMG 1-s2.0-S0885064X12000817-si199.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/ae4348d2405d949eba06d864476458af/si96.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/ae4348d2405d949eba06d864476458af/si96.gif si199 si199.gif gif 129 9 12 ALTIMG 1-s2.0-S0885064X12000817-si469.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/e0376bbea674aa63525d2dd65facc96b/si661.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/e0376bbea674aa63525d2dd65facc96b/si661.gif si469 si469.gif gif 149 12 20 ALTIMG 1-s2.0-S0885064X12000817-si329.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/534b7e383ae4f774d07257f19cf57e0e/si329.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/534b7e383ae4f774d07257f19cf57e0e/si329.gif si329 si329.gif gif 974 16 332 ALTIMG 1-s2.0-S0885064X12000817-si118.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/e745a2a56fc432c4b59c3610b0084ccd/si224.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/e745a2a56fc432c4b59c3610b0084ccd/si224.gif si118 si118.gif gif 176 10 38 ALTIMG 1-s2.0-S0885064X12000817-si170.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/2960b0bffdda0a9744c7edf7559e4772/si170.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/2960b0bffdda0a9744c7edf7559e4772/si170.gif si170 si170.gif gif 253 13 63 ALTIMG 1-s2.0-S0885064X12000817-si621.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/850354e198dc4891c9f7c063e1196710/si621.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/850354e198dc4891c9f7c063e1196710/si621.gif si621 si621.gif gif 236 13 58 ALTIMG 1-s2.0-S0885064X12000817-si152.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/ae4348d2405d949eba06d864476458af/si96.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/ae4348d2405d949eba06d864476458af/si96.gif si152 si152.gif gif 129 9 12 ALTIMG 1-s2.0-S0885064X12000817-si59.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/60105609159961f4f7e56022101ef7d2/si59.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/60105609159961f4f7e56022101ef7d2/si59.gif si59 si59.gif gif 574 13 194 ALTIMG 1-s2.0-S0885064X12000817-si824.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/d45b05f1c17bb5849d2412dfe2ae923d/si769.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/d45b05f1c17bb5849d2412dfe2ae923d/si769.gif si824 si824.gif gif 138 12 14 ALTIMG 1-s2.0-S0885064X12000817-si758.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/1f9eefde61a003079e8b9215dcd5c868/si560.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/1f9eefde61a003079e8b9215dcd5c868/si560.gif si758 si758.gif gif 119 12 11 ALTIMG 1-s2.0-S0885064X12000817-si537.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/3b256b541b2e524cf0c176801ba1451f/si537.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/3b256b541b2e524cf0c176801ba1451f/si537.gif si537 si537.gif gif 149 13 17 ALTIMG 1-s2.0-S0885064X12000817-si718.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/b3fc0419d66d3dd8cbe8665082ca69b9/si718.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/b3fc0419d66d3dd8cbe8665082ca69b9/si718.gif si718 si718.gif gif 240 13 53 ALTIMG 1-s2.0-S0885064X12000817-si108.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/2061b19ef342d7ace36d2b4b8bdadfdd/si108.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/2061b19ef342d7ace36d2b4b8bdadfdd/si108.gif si108 si108.gif gif 117 7 10 ALTIMG 1-s2.0-S0885064X12000817-si406.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/2abc4792814f0ea767e91e7024430951/si406.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/2abc4792814f0ea767e91e7024430951/si406.gif si406 si406.gif gif 200 10 48 ALTIMG 1-s2.0-S0885064X12000817-si75.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/ae4348d2405d949eba06d864476458af/si96.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/ae4348d2405d949eba06d864476458af/si96.gif si75 si75.gif gif 129 9 12 ALTIMG 1-s2.0-S0885064X12000817-si756.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/2ede830df0579fdafe4ba02dad331dd2/si756.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/2ede830df0579fdafe4ba02dad331dd2/si756.gif si756 si756.gif gif 192 12 38 ALTIMG 1-s2.0-S0885064X12000817-si274.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/ae4348d2405d949eba06d864476458af/si96.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/ae4348d2405d949eba06d864476458af/si96.gif si274 si274.gif gif 129 9 12 ALTIMG 1-s2.0-S0885064X12000817-si538.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/5a8b0324641ac5e849d677db43df8e48/si460.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/5a8b0324641ac5e849d677db43df8e48/si460.gif si538 si538.gif gif 276 13 63 ALTIMG 1-s2.0-S0885064X12000817-si526.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/7656d83646223ed60721982f7e370a4c/si526.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/7656d83646223ed60721982f7e370a4c/si526.gif si526 si526.gif gif 726 37 172 ALTIMG 1-s2.0-S0885064X12000817-si573.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/ee031e9e10815d73036443e5bc05ad4a/si573.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/ee031e9e10815d73036443e5bc05ad4a/si573.gif si573 si573.gif gif 561 16 150 ALTIMG 1-s2.0-S0885064X12000817-si451.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/8434f58d7528f6649d0138b27a6905b5/si451.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/8434f58d7528f6649d0138b27a6905b5/si451.gif si451 si451.gif gif 1298 20 445 ALTIMG 1-s2.0-S0885064X12000817-si344.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/aedfbe8752091e5c8dbd52178e79112f/si344.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/aedfbe8752091e5c8dbd52178e79112f/si344.gif si344 si344.gif gif 1099 52 231 ALTIMG 1-s2.0-S0885064X12000817-si55.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/6d3472cf641e930c3b2aa804279165ba/si55.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/6d3472cf641e930c3b2aa804279165ba/si55.gif si55 si55.gif gif 137 10 17 ALTIMG 1-s2.0-S0885064X12000817-si93.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/cd300f22e7ac12ec6a988d5f16faa242/si93.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/cd300f22e7ac12ec6a988d5f16faa242/si93.gif si93 si93.gif gif 180 13 33 ALTIMG 1-s2.0-S0885064X12000817-si745.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/7a2b60190a907e87929841f2f352a8bf/si717.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/7a2b60190a907e87929841f2f352a8bf/si717.gif si745 si745.gif gif 190 12 38 ALTIMG 1-s2.0-S0885064X12000817-si479.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/a6c5b5ebd755221abd7abe44a69a1580/si479.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/a6c5b5ebd755221abd7abe44a69a1580/si479.gif si479 si479.gif gif 854 17 298 ALTIMG 1-s2.0-S0885064X12000817-si609.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/4b421476f4fec2917196e3c698d0d193/si609.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/4b421476f4fec2917196e3c698d0d193/si609.gif si609 si609.gif gif 1227 16 424 ALTIMG 1-s2.0-S0885064X12000817-si463.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/385087cb381c947c69edd1a34d53376a/si463.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/385087cb381c947c69edd1a34d53376a/si463.gif si463 si463.gif gif 278 13 63 ALTIMG 1-s2.0-S0885064X12000817-si327.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/24a7db054ffedd93cf22b6ea58c02c51/si327.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/24a7db054ffedd93cf22b6ea58c02c51/si327.gif si327 si327.gif gif 138 13 12 ALTIMG 1-s2.0-S0885064X12000817-si676.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/c4ddc19e1bbdc8569818e4c39b5f0f04/si676.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/c4ddc19e1bbdc8569818e4c39b5f0f04/si676.gif si676 si676.gif gif 400 15 101 ALTIMG 1-s2.0-S0885064X12000817-si359.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/ae4348d2405d949eba06d864476458af/si96.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/ae4348d2405d949eba06d864476458af/si96.gif si359 si359.gif gif 129 9 12 ALTIMG 1-s2.0-S0885064X12000817-si126.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/e745a2a56fc432c4b59c3610b0084ccd/si224.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/e745a2a56fc432c4b59c3610b0084ccd/si224.gif si126 si126.gif gif 176 10 38 ALTIMG 1-s2.0-S0885064X12000817-si497.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/e35d4b5e49407e5fcec13f33fd9ca230/si497.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/e35d4b5e49407e5fcec13f33fd9ca230/si497.gif si497 si497.gif gif 123 11 12 ALTIMG 1-s2.0-S0885064X12000817-si392.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/a5a7a089751d8a118018cb99bffb2e31/si392.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/a5a7a089751d8a118018cb99bffb2e31/si392.gif si392 si392.gif gif 328 14 86 ALTIMG 1-s2.0-S0885064X12000817-si341.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/b8ae2bd2489a06a1fda57354d397118a/si341.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/b8ae2bd2489a06a1fda57354d397118a/si341.gif si341 si341.gif gif 1040 48 236 ALTIMG 1-s2.0-S0885064X12000817-si313.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/e34a877b393482811d3b4110b6b4ca7b/si313.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/e34a877b393482811d3b4110b6b4ca7b/si313.gif si313 si313.gif gif 713 14 230 ALTIMG 1-s2.0-S0885064X12000817-si557.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/4e9a98431271cac3353a5171c0666d43/si557.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/4e9a98431271cac3353a5171c0666d43/si557.gif si557 si557.gif gif 240 13 55 ALTIMG 1-s2.0-S0885064X12000817-si302.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/300ec462932745b768d11a3a48b6e853/si608.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/300ec462932745b768d11a3a48b6e853/si608.gif si302 si302.gif gif 200 10 41 ALTIMG 1-s2.0-S0885064X12000817-si194.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/aec35ae0aa396effde8f7b9591bfe5bd/si194.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/aec35ae0aa396effde8f7b9591bfe5bd/si194.gif si194 si194.gif gif 1218 13 435 ALTIMG 1-s2.0-S0885064X12000817-si298.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/3bc72098bcd1389c268902d0e633ffab/si273.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/3bc72098bcd1389c268902d0e633ffab/si273.gif si298 si298.gif gif 129 9 12 ALTIMG 1-s2.0-S0885064X12000817-si738.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/f1f7375752d09923cd4a0d6cfa9514ab/si738.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/f1f7375752d09923cd4a0d6cfa9514ab/si738.gif si738 si738.gif gif 203 12 39 ALTIMG 1-s2.0-S0885064X12000817-si528.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/b199e9f06c6df4177030857fc59b3f35/si518.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/b199e9f06c6df4177030857fc59b3f35/si518.gif si528 si528.gif gif 130 13 10 ALTIMG 1-s2.0-S0885064X12000817-si680.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/b0e827f35ed636c98a13c858b2472efc/si680.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/b0e827f35ed636c98a13c858b2472efc/si680.gif si680 si680.gif gif 276 13 62 ALTIMG 1-s2.0-S0885064X12000817-si297.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/751298c4de9f0dfec04f9ba577dcdb1e/si73.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/751298c4de9f0dfec04f9ba577dcdb1e/si73.gif si297 si297.gif gif 125 9 13 ALTIMG 1-s2.0-S0885064X12000817-si648.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/bd1569a77f69c06ac575a91706c8e32a/si648.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/bd1569a77f69c06ac575a91706c8e32a/si648.gif si648 si648.gif gif 253 15 62 ALTIMG 1-s2.0-S0885064X12000817-si125.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/6e3f173fd86ad3d9a6b753a85e70b37b/si125.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/6e3f173fd86ad3d9a6b753a85e70b37b/si125.gif si125 si125.gif gif 316 13 76 ALTIMG 1-s2.0-S0885064X12000817-si42.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/9dfac2d037a0f91cd68a44fbbeac9386/si42.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/9dfac2d037a0f91cd68a44fbbeac9386/si42.gif si42 si42.gif gif 182 10 34 ALTIMG 1-s2.0-S0885064X12000817-si240.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/8158870f618ec07216925d7ef2497d20/si240.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/8158870f618ec07216925d7ef2497d20/si240.gif si240 si240.gif gif 381 21 103 ALTIMG 1-s2.0-S0885064X12000817-si98.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/c24162421123b0ae5470507f5e731a55/si98.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/c24162421123b0ae5470507f5e731a55/si98.gif si98 si98.gif gif 193 12 35 ALTIMG 1-s2.0-S0885064X12000817-si753.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/d45b05f1c17bb5849d2412dfe2ae923d/si769.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/d45b05f1c17bb5849d2412dfe2ae923d/si769.gif si753 si753.gif gif 138 12 14 ALTIMG 1-s2.0-S0885064X12000817-si261.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/60f93a212c8856a2f83c674c1fcc55f8/si261.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/60f93a212c8856a2f83c674c1fcc55f8/si261.gif si261 si261.gif gif 148 13 16 ALTIMG 1-s2.0-S0885064X12000817-si203.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/0beeb7b9c2c6a76a47cd7acd364aed52/si203.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/0beeb7b9c2c6a76a47cd7acd364aed52/si203.gif si203 si203.gif gif 191 19 27 ALTIMG 1-s2.0-S0885064X12000817-si452.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/503352f62889ebd3b611a2cec084a209/si452.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/503352f62889ebd3b611a2cec084a209/si452.gif si452 si452.gif gif 683 16 229 ALTIMG 1-s2.0-S0885064X12000817-si354.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/a8337077b1f10f3ca2d08f8b71b617be/si354.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/a8337077b1f10f3ca2d08f8b71b617be/si354.gif si354 si354.gif gif 388 14 112 ALTIMG 1-s2.0-S0885064X12000817-si811.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/9541ecaad52f63f58c1404522ee6325d/si811.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/9541ecaad52f63f58c1404522ee6325d/si811.gif si811 si811.gif gif 839 39 206 ALTIMG 1-s2.0-S0885064X12000817-si674.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/a116efd0ca0d88cda1f10f1b17493027/si674.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/a116efd0ca0d88cda1f10f1b17493027/si674.gif si674 si674.gif gif 1092 22 332 ALTIMG 1-s2.0-S0885064X12000817-si383.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/e1bb9023d4c30825d6f7a5bc2d2b9fc4/si383.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/e1bb9023d4c30825d6f7a5bc2d2b9fc4/si383.gif si383 si383.gif gif 245 14 66 ALTIMG 1-s2.0-S0885064X12000817-si157.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/39d3d03e9050bd198f3405a1237fdc5a/si114.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/39d3d03e9050bd198f3405a1237fdc5a/si114.gif si157 si157.gif gif 137 12 13 ALTIMG 1-s2.0-S0885064X12000817-si662.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/8cafcea9b06961349196514d3b08140a/si662.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/8cafcea9b06961349196514d3b08140a/si662.gif si662 si662.gif gif 430 19 104 ALTIMG 1-s2.0-S0885064X12000817-si672.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/6f036bf9effa27aef3c332cad2d9c850/si696.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/6f036bf9effa27aef3c332cad2d9c850/si696.gif si672 si672.gif gif 177 15 20 ALTIMG 1-s2.0-S0885064X12000817-si33.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/24efe90dd088ac9794e53aebed8ff94d/si33.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/24efe90dd088ac9794e53aebed8ff94d/si33.gif si33 si33.gif gif 400 13 138 ALTIMG 1-s2.0-S0885064X12000817-si649.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/4c669bf76198ece30f2f81271889ef3a/si647.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/4c669bf76198ece30f2f81271889ef3a/si647.gif si649 si649.gif gif 121 9 11 ALTIMG 1-s2.0-S0885064X12000817-si285.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/d331fc587c3941b84642ea730e3b14a7/si291.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/d331fc587c3941b84642ea730e3b14a7/si291.gif si285 si285.gif gif 173 10 38 ALTIMG 1-s2.0-S0885064X12000817-si300.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/ae4348d2405d949eba06d864476458af/si96.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/ae4348d2405d949eba06d864476458af/si96.gif si300 si300.gif gif 129 9 12 ALTIMG 1-s2.0-S0885064X12000817-si362.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/300ec462932745b768d11a3a48b6e853/si608.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/300ec462932745b768d11a3a48b6e853/si608.gif si362 si362.gif gif 200 10 41 ALTIMG 1-s2.0-S0885064X12000817-si99.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/02b91199e263bc8fc1c3a139c35cc4a8/si103.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/02b91199e263bc8fc1c3a139c35cc4a8/si103.gif si99 si99.gif gif 291 13 64 ALTIMG 1-s2.0-S0885064X12000817-si535.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/1560a0dee6a122fc0bbb9e785000aeff/si598.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/1560a0dee6a122fc0bbb9e785000aeff/si598.gif si535 si535.gif gif 149 10 17 ALTIMG 1-s2.0-S0885064X12000817-si474.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/60653d6e257e2fa77df8a1f1cca7247e/si474.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/60653d6e257e2fa77df8a1f1cca7247e/si474.gif si474 si474.gif gif 198 11 42 ALTIMG 1-s2.0-S0885064X12000817-si660.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/eb54733b421eed6fff10d25929957df9/si660.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/eb54733b421eed6fff10d25929957df9/si660.gif si660 si660.gif gif 280 12 83 ALTIMG 1-s2.0-S0885064X12000817-si701.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/7bf7970b0f692ec678e95cbb04115322/si701.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/7bf7970b0f692ec678e95cbb04115322/si701.gif si701 si701.gif gif 146 10 20 ALTIMG 1-s2.0-S0885064X12000817-si387.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/d915c0b357736a74d11f4a13346e574d/si387.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/d915c0b357736a74d11f4a13346e574d/si387.gif si387 si387.gif gif 167 9 37 ALTIMG 1-s2.0-S0885064X12000817-si284.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/e8a85ac5bd223f82215965856b7d2c5c/si284.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/e8a85ac5bd223f82215965856b7d2c5c/si284.gif si284 si284.gif gif 193 12 41 ALTIMG 1-s2.0-S0885064X12000817-si28.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/b52b6eac55769cfe911487b12d0007de/si28.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/b52b6eac55769cfe911487b12d0007de/si28.gif si28 si28.gif gif 308 13 94 ALTIMG 1-s2.0-S0885064X12000817-si209.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/a11b74c7d04969849fcd701bd95b4571/si209.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/a11b74c7d04969849fcd701bd95b4571/si209.gif si209 si209.gif gif 387 13 139 ALTIMG 1-s2.0-S0885064X12000817-si511.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/029cdc196dcabd6f93198f1163ed7d25/si511.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/029cdc196dcabd6f93198f1163ed7d25/si511.gif si511 si511.gif gif 212 12 40 ALTIMG 1-s2.0-S0885064X12000817-si502.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/bcd16b6ad5a27e76b260d93481817ddc/si502.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/bcd16b6ad5a27e76b260d93481817ddc/si502.gif si502 si502.gif gif 230 12 50 ALTIMG 1-s2.0-S0885064X12000817-si47.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/b31b9bf5d9100c4710ffde7c4bdcfa81/si47.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/b31b9bf5d9100c4710ffde7c4bdcfa81/si47.gif si47 si47.gif gif 618 32 162 ALTIMG 1-s2.0-S0885064X12000817-si830.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/63ece0456aa5abda63641ae91798941c/si296.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/63ece0456aa5abda63641ae91798941c/si296.gif si830 si830.gif gif 119 9 11 ALTIMG 1-s2.0-S0885064X12000817-si253.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/0eff0aa7faa6ebcc59cbad73b8b1bea1/si253.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/0eff0aa7faa6ebcc59cbad73b8b1bea1/si253.gif si253 si253.gif gif 507 16 143 ALTIMG 1-s2.0-S0885064X12000817-si752.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/4b9f5f5a22875874e2e0bc0978e8ea8e/si673.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/4b9f5f5a22875874e2e0bc0978e8ea8e/si673.gif si752 si752.gif gif 129 9 12 ALTIMG 1-s2.0-S0885064X12000817-si826.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/d45b05f1c17bb5849d2412dfe2ae923d/si769.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/d45b05f1c17bb5849d2412dfe2ae923d/si769.gif si826 si826.gif gif 138 12 14 ALTIMG 1-s2.0-S0885064X12000817-si1.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/9d710977c4c9bed89d27d697d051d04e/si1.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/9d710977c4c9bed89d27d697d051d04e/si1.gif si1 si1.gif gif 132 12 13 ALTIMG 1-s2.0-S0885064X12000817-si23.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/f0c8ac3261a2432447d260455d1df4e1/si23.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/f0c8ac3261a2432447d260455d1df4e1/si23.gif si23 si23.gif gif 479 13 156 ALTIMG 1-s2.0-S0885064X12000817-si699.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/d45b05f1c17bb5849d2412dfe2ae923d/si769.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/d45b05f1c17bb5849d2412dfe2ae923d/si769.gif si699 si699.gif gif 138 12 14 ALTIMG 1-s2.0-S0885064X12000817-si650.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/92d926735b59f6f030ac390734264e5a/si650.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/92d926735b59f6f030ac390734264e5a/si650.gif si650 si650.gif gif 1165 39 335 ALTIMG 1-s2.0-S0885064X12000817-si812.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/ea995469bcf6899fdb501c0115352f5b/si812.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/ea995469bcf6899fdb501c0115352f5b/si812.gif si812 si812.gif gif 192 13 41 ALTIMG 1-s2.0-S0885064X12000817-si183.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/7a2b60190a907e87929841f2f352a8bf/si717.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/7a2b60190a907e87929841f2f352a8bf/si717.gif si183 si183.gif gif 190 12 38 ALTIMG 1-s2.0-S0885064X12000817-si639.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/34516dae50028409959d1a5ccc078045/si639.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/34516dae50028409959d1a5ccc078045/si639.gif si639 si639.gif gif 347 13 102 ALTIMG 1-s2.0-S0885064X12000817-si39.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/91e8b040594b0c2ba5e6eebab1f14259/si39.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/91e8b040594b0c2ba5e6eebab1f14259/si39.gif si39 si39.gif gif 325 13 78 ALTIMG 1-s2.0-S0885064X12000817-si91.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/63ece0456aa5abda63641ae91798941c/si296.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/63ece0456aa5abda63641ae91798941c/si296.gif si91 si91.gif gif 119 9 11 ALTIMG 1-s2.0-S0885064X12000817-si169.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/6de26e062704f4b73d52cefc37e68ee3/si131.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/6de26e062704f4b73d52cefc37e68ee3/si131.gif si169 si169.gif gif 214 12 53 ALTIMG 1-s2.0-S0885064X12000817-si193.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/10183b92410ffec802ebfe05f2cb3f15/si193.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/10183b92410ffec802ebfe05f2cb3f15/si193.gif si193 si193.gif gif 630 13 195 ALTIMG 1-s2.0-S0885064X12000817-si459.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/a03994770f8921be76e18141c174d875/si682.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/a03994770f8921be76e18141c174d875/si682.gif si459 si459.gif gif 190 10 36 ALTIMG 1-s2.0-S0885064X12000817-si678.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/4342d3b8ac6efc7d94fa2214c9620a90/si678.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/4342d3b8ac6efc7d94fa2214c9620a90/si678.gif si678 si678.gif gif 214 12 41 ALTIMG 1-s2.0-S0885064X12000817-si262.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/896f840cb310b9156e45afd0d7e04bd8/si127.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/896f840cb310b9156e45afd0d7e04bd8/si127.gif si262 si262.gif gif 187 13 35 ALTIMG 1-s2.0-S0885064X12000817-si571.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/f34ef91c138ec64168fa409920f65b3c/si559.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/f34ef91c138ec64168fa409920f65b3c/si559.gif si571 si571.gif gif 252 16 43 ALTIMG 1-s2.0-S0885064X12000817-si395.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/bae5da9961984beaab7466378d1ee805/si395.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/bae5da9961984beaab7466378d1ee805/si395.gif si395 si395.gif gif 2420 40 485 ALTIMG 1-s2.0-S0885064X12000817-si608.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/300ec462932745b768d11a3a48b6e853/si608.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/300ec462932745b768d11a3a48b6e853/si608.gif si608 si608.gif gif 200 10 41 ALTIMG 1-s2.0-S0885064X12000817-si270.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/cc34cbac69181c1f35ebea60b2a01e61/si270.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/cc34cbac69181c1f35ebea60b2a01e61/si270.gif si270 si270.gif gif 833 16 250 ALTIMG 1-s2.0-S0885064X12000817-si139.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/dcdf90f28e550064b3cf3e9ea9381686/si139.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/dcdf90f28e550064b3cf3e9ea9381686/si139.gif si139 si139.gif gif 241 13 51 ALTIMG 1-s2.0-S0885064X12000817-si89.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/6053c126d0d822b4278fc5c93589d9a7/si89.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/6053c126d0d822b4278fc5c93589d9a7/si89.gif si89 si89.gif gif 440 13 141 ALTIMG 1-s2.0-S0885064X12000817-si137.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/774b055ca90271340f702b7f3789a8c8/si137.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/774b055ca90271340f702b7f3789a8c8/si137.gif si137 si137.gif gif 360 13 95 ALTIMG 1-s2.0-S0885064X12000817-si760.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/56e2681d7f71da9712f35e8e3ae3e5d9/si760.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/56e2681d7f71da9712f35e8e3ae3e5d9/si760.gif si760 si760.gif gif 328 13 86 ALTIMG 1-s2.0-S0885064X12000817-si14.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/66173c4d94832e5cbf84ccec95a8004a/si31.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/66173c4d94832e5cbf84ccec95a8004a/si31.gif si14 si14.gif gif 119 9 11 ALTIMG 1-s2.0-S0885064X12000817-si488.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/1a121dda348a2bb2a3584e253573ed53/si493.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/1a121dda348a2bb2a3584e253573ed53/si493.gif si488 si488.gif gif 140 13 17 ALTIMG 1-s2.0-S0885064X12000817-si737.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/5c9b804d1af1e2993e86d94824a21eab/si737.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/5c9b804d1af1e2993e86d94824a21eab/si737.gif si737 si737.gif gif 301 18 66 ALTIMG 1-s2.0-S0885064X12000817-si722.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/f67b7772819bef7cccda2397fb93c882/si382.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/f67b7772819bef7cccda2397fb93c882/si382.gif si722 si722.gif gif 122 9 11 ALTIMG 1-s2.0-S0885064X12000817-si793.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/e0376bbea674aa63525d2dd65facc96b/si661.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/e0376bbea674aa63525d2dd65facc96b/si661.gif si793 si793.gif gif 149 12 20 ALTIMG 1-s2.0-S0885064X12000817-si364.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/be2c1200eee00e2cf5c833a6305a0d7b/si364.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/be2c1200eee00e2cf5c833a6305a0d7b/si364.gif si364 si364.gif gif 595 16 172 ALTIMG 1-s2.0-S0885064X12000817-si565.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/64394d9f3caa932b84ee0c5ba7044b62/si565.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/64394d9f3caa932b84ee0c5ba7044b62/si565.gif si565 si565.gif gif 135 15 10 ALTIMG 1-s2.0-S0885064X12000817-si211.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/f93cb8c3b8da00cb8d2afe5c237627c7/si211.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/f93cb8c3b8da00cb8d2afe5c237627c7/si211.gif si211 si211.gif gif 190 11 38 ALTIMG 1-s2.0-S0885064X12000817-si739.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/46aeba859b0d7f2116a5e8f7b3e54574/si739.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/46aeba859b0d7f2116a5e8f7b3e54574/si739.gif si739 si739.gif gif 1065 14 352 ALTIMG 1-s2.0-S0885064X12000817-si48.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/8a38916b94518ec35a7813f35b98ab62/si498.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/8a38916b94518ec35a7813f35b98ab62/si498.gif si48 si48.gif gif 161 12 24 ALTIMG 1-s2.0-S0885064X12000817-si531.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/be823f9b7dcd1f0db68386d2948a84bb/si767.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/be823f9b7dcd1f0db68386d2948a84bb/si767.gif si531 si531.gif gif 143 10 17 ALTIMG 1-s2.0-S0885064X12000817-si549.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/2cf190c8333a48598bed9d43c67a0099/si549.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/2cf190c8333a48598bed9d43c67a0099/si549.gif si549 si549.gif gif 2520 59 534 ALTIMG 1-s2.0-S0885064X12000817-si322.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/332e46e542d9e90bbe27bb349d11d9b9/si322.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/332e46e542d9e90bbe27bb349d11d9b9/si322.gif si322 si322.gif gif 248 13 71 ALTIMG 1-s2.0-S0885064X12000817-si637.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/ae4348d2405d949eba06d864476458af/si96.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/ae4348d2405d949eba06d864476458af/si96.gif si637 si637.gif gif 129 9 12 ALTIMG 1-s2.0-S0885064X12000817-si420.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/28f1246f19fe763834718b7a523866a1/si420.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/28f1246f19fe763834718b7a523866a1/si420.gif si420 si420.gif gif 746 13 273 ALTIMG 1-s2.0-S0885064X12000817-si3.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/e67662a4eaf41d7c1d5a79a8f3e50c5b/si3.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/e67662a4eaf41d7c1d5a79a8f3e50c5b/si3.gif si3 si3.gif gif 172 9 39 ALTIMG 1-s2.0-S0885064X12000817-si659.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/9a5d23b6d66c00b90c46c07c8d776402/si659.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/9a5d23b6d66c00b90c46c07c8d776402/si659.gif si659 si659.gif gif 217 13 34 ALTIMG 1-s2.0-S0885064X12000817-si43.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/eff137513500be35b14db1ebdcb37695/si43.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/eff137513500be35b14db1ebdcb37695/si43.gif si43 si43.gif gif 1132 13 456 ALTIMG 1-s2.0-S0885064X12000817-si228.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/bfa3ac0f10100ba2a42fe2a2f7101709/si228.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/bfa3ac0f10100ba2a42fe2a2f7101709/si228.gif si228 si228.gif gif 2880 85 519 ALTIMG 1-s2.0-S0885064X12000817-si190.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/55658eed8d0ac73e955c55e6c7f58846/si190.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/55658eed8d0ac73e955c55e6c7f58846/si190.gif si190 si190.gif gif 258 13 77 ALTIMG 1-s2.0-S0885064X12000817-si541.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/ae4348d2405d949eba06d864476458af/si96.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/ae4348d2405d949eba06d864476458af/si96.gif si541 si541.gif gif 129 9 12 ALTIMG 1-s2.0-S0885064X12000817-si624.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/3bc72098bcd1389c268902d0e633ffab/si273.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/3bc72098bcd1389c268902d0e633ffab/si273.gif si624 si624.gif gif 129 9 12 ALTIMG 1-s2.0-S0885064X12000817-si84.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/ae4348d2405d949eba06d864476458af/si96.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/ae4348d2405d949eba06d864476458af/si96.gif si84 si84.gif gif 129 9 12 ALTIMG 1-s2.0-S0885064X12000817-si647.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/4c669bf76198ece30f2f81271889ef3a/si647.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/4c669bf76198ece30f2f81271889ef3a/si647.gif si647 si647.gif gif 121 9 11 ALTIMG 1-s2.0-S0885064X12000817-si192.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/2ede830df0579fdafe4ba02dad331dd2/si756.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/2ede830df0579fdafe4ba02dad331dd2/si756.gif si192 si192.gif gif 192 12 38 ALTIMG 1-s2.0-S0885064X12000817-si64.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/66173c4d94832e5cbf84ccec95a8004a/si31.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/66173c4d94832e5cbf84ccec95a8004a/si31.gif si64 si64.gif gif 119 9 11 ALTIMG 1-s2.0-S0885064X12000817-si12.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/6ba4b561ccde83d1035b1b9ee6fed2dc/si12.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/6ba4b561ccde83d1035b1b9ee6fed2dc/si12.gif si12 si12.gif gif 654 19 164 ALTIMG 1-s2.0-S0885064X12000817-si725.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/56669c51034bd532b0e36efbccf7498f/si716.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/56669c51034bd532b0e36efbccf7498f/si716.gif si725 si725.gif gif 139 11 16 ALTIMG 1-s2.0-S0885064X12000817-si506.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/66f70744de7f99b89aea42d5d62cdd58/si506.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/66f70744de7f99b89aea42d5d62cdd58/si506.gif si506 si506.gif gif 288 13 81 ALTIMG 1-s2.0-S0885064X12000817-si833.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/5d4ef2c58a5869550d416d570de15d93/si374.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/5d4ef2c58a5869550d416d570de15d93/si374.gif si833 si833.gif gif 135 10 17 ALTIMG 1-s2.0-S0885064X12000817-si675.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/7e4fd6cef1ca9bf90a792136be8e5b11/si675.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/7e4fd6cef1ca9bf90a792136be8e5b11/si675.gif si675 si675.gif gif 1136 13 416 ALTIMG 1-s2.0-S0885064X12000817-si644.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/1f9eefde61a003079e8b9215dcd5c868/si560.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/1f9eefde61a003079e8b9215dcd5c868/si560.gif si644 si644.gif gif 119 12 11 ALTIMG 1-s2.0-S0885064X12000817-si416.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/562007325859354e7f848e1b1bbedb2d/si416.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/562007325859354e7f848e1b1bbedb2d/si416.gif si416 si416.gif gif 639 13 238 ALTIMG 1-s2.0-S0885064X12000817-si473.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/d8413d08d8e3f3a314729f2f89332c07/si473.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/d8413d08d8e3f3a314729f2f89332c07/si473.gif si473 si473.gif gif 418 14 120 ALTIMG 1-s2.0-S0885064X12000817-si307.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/3bc72098bcd1389c268902d0e633ffab/si273.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/3bc72098bcd1389c268902d0e633ffab/si273.gif si307 si307.gif gif 129 9 12 ALTIMG 1-s2.0-S0885064X12000817-si444.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/ae4348d2405d949eba06d864476458af/si96.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/ae4348d2405d949eba06d864476458af/si96.gif si444 si444.gif gif 129 9 12 ALTIMG 1-s2.0-S0885064X12000817-si751.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/d22e8a0fc89029e4967e5aaccd9ea0f2/si751.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/d22e8a0fc89029e4967e5aaccd9ea0f2/si751.gif si751 si751.gif gif 496 13 130 ALTIMG 1-s2.0-S0885064X12000817-si128.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/8127c4239e88dd1a859f6c09d56ef816/si128.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/8127c4239e88dd1a859f6c09d56ef816/si128.gif si128 si128.gif gif 282 12 79 ALTIMG 1-s2.0-S0885064X12000817-si293.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/8552f61d2e9fc76f52cb300137a3619b/si293.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/8552f61d2e9fc76f52cb300137a3619b/si293.gif si293 si293.gif gif 1236 15 410 ALTIMG 1-s2.0-S0885064X12000817-si112.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/b098d5a7b236a8a61d86d3f42e87e32d/si112.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/b098d5a7b236a8a61d86d3f42e87e32d/si112.gif si112 si112.gif gif 116 9 11 ALTIMG 1-s2.0-S0885064X12000817-si489.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/7dd7fbe05cec32bef1bca16dbc8ac095/si489.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/7dd7fbe05cec32bef1bca16dbc8ac095/si489.gif si489 si489.gif gif 164 15 20 ALTIMG 1-s2.0-S0885064X12000817-si829.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/89845a6dba12661e49294e0bcfc49f48/si828.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/89845a6dba12661e49294e0bcfc49f48/si828.gif si829 si829.gif gif 133 10 14 ALTIMG 1-s2.0-S0885064X12000817-si356.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/a6cb189ce60b685bdaafd8d1e925ea1f/si356.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/a6cb189ce60b685bdaafd8d1e925ea1f/si356.gif si356 si356.gif gif 688 13 223 ALTIMG 1-s2.0-S0885064X12000817-si520.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/1d0e9eae248662275d5285ea6345595b/si520.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/1d0e9eae248662275d5285ea6345595b/si520.gif si520 si520.gif gif 568 26 174 ALTIMG 1-s2.0-S0885064X12000817-si629.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/509692d82aa67cdadbb74587178d8a4e/si629.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/509692d82aa67cdadbb74587178d8a4e/si629.gif si629 si629.gif gif 397 14 109 ALTIMG 1-s2.0-S0885064X12000817-si679.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/b10a9ea0c0c40d0aaa5e991f3d424ded/si418.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/b10a9ea0c0c40d0aaa5e991f3d424ded/si418.gif si679 si679.gif gif 176 9 36 ALTIMG 1-s2.0-S0885064X12000817-si299.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/ae4348d2405d949eba06d864476458af/si96.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/ae4348d2405d949eba06d864476458af/si96.gif si299 si299.gif gif 129 9 12 ALTIMG 1-s2.0-S0885064X12000817-si153.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/58ff8adac18eeb2ce4be84b2f127ea4f/si153.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/58ff8adac18eeb2ce4be84b2f127ea4f/si153.gif si153 si153.gif gif 180 10 40 ALTIMG 1-s2.0-S0885064X12000817-si58.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/04c2043a834f5acd710bf17fd88a74e4/si58.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/04c2043a834f5acd710bf17fd88a74e4/si58.gif si58 si58.gif gif 572 13 179 ALTIMG 1-s2.0-S0885064X12000817-si692.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/e250ce1e6cde492eaa86c1a015c556c5/si692.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/e250ce1e6cde492eaa86c1a015c556c5/si692.gif si692 si692.gif gif 198 11 43 ALTIMG 1-s2.0-S0885064X12000817-si408.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/04c98162f051513e06f0040547e86a12/si408.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/04c98162f051513e06f0040547e86a12/si408.gif si408 si408.gif gif 173 10 34 ALTIMG 1-s2.0-S0885064X12000817-si217.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/63ece0456aa5abda63641ae91798941c/si296.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/63ece0456aa5abda63641ae91798941c/si296.gif si217 si217.gif gif 119 9 11 ALTIMG 1-s2.0-S0885064X12000817-si789.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/9eb35626634fd247a46cc35b3a68967e/si789.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/9eb35626634fd247a46cc35b3a68967e/si789.gif si789 si789.gif gif 145 14 13 ALTIMG 1-s2.0-S0885064X12000817-si30.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/03e0cf037035f6b852423fc3da255e5a/si30.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/03e0cf037035f6b852423fc3da255e5a/si30.gif si30 si30.gif gif 153 11 19 ALTIMG 1-s2.0-S0885064X12000817-si251.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/751298c4de9f0dfec04f9ba577dcdb1e/si73.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/751298c4de9f0dfec04f9ba577dcdb1e/si73.gif si251 si251.gif gif 125 9 13 ALTIMG 1-s2.0-S0885064X12000817-si638.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/63ece0456aa5abda63641ae91798941c/si296.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/63ece0456aa5abda63641ae91798941c/si296.gif si638 si638.gif gif 119 9 11 ALTIMG 1-s2.0-S0885064X12000817-si708.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/751298c4de9f0dfec04f9ba577dcdb1e/si73.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/751298c4de9f0dfec04f9ba577dcdb1e/si73.gif si708 si708.gif gif 125 9 13 ALTIMG 1-s2.0-S0885064X12000817-si404.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/a6e1de41b3236d190fdcd4113ef0048b/si404.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/a6e1de41b3236d190fdcd4113ef0048b/si404.gif si404 si404.gif gif 125 9 12 ALTIMG 1-s2.0-S0885064X12000817-si694.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/ddbb18fc9fd7a1bf0f968edd38d5b461/si694.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/ddbb18fc9fd7a1bf0f968edd38d5b461/si694.gif si694 si694.gif gif 1301 16 446 ALTIMG 1-s2.0-S0885064X12000817-si572.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/21af6f5762951859c53cdaf546091c89/si572.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/21af6f5762951859c53cdaf546091c89/si572.gif si572 si572.gif gif 376 16 92 ALTIMG 1-s2.0-S0885064X12000817-si249.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/3913d993937d03875d10628a225f6402/si249.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/3913d993937d03875d10628a225f6402/si249.gif si249 si249.gif gif 753 16 233 ALTIMG 1-s2.0-S0885064X12000817-si239.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/1a600dcca3ba0dac0d35cb7703de7003/si239.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/1a600dcca3ba0dac0d35cb7703de7003/si239.gif si239 si239.gif gif 686 17 242 ALTIMG 1-s2.0-S0885064X12000817-si309.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/7e41d89737891c2e29d01d76c408c5cb/si355.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/7e41d89737891c2e29d01d76c408c5cb/si355.gif si309 si309.gif gif 369 13 107 ALTIMG 1-s2.0-S0885064X12000817-si815.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/7b0bad82b8dfc023974fc03e190ce659/si815.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/7b0bad82b8dfc023974fc03e190ce659/si815.gif si815 si815.gif gif 583 39 124 ALTIMG 1-s2.0-S0885064X12000817-si819.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/863d644841703e99d9893e60cc2c4a00/si819.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/863d644841703e99d9893e60cc2c4a00/si819.gif si819 si819.gif gif 268 13 65 ALTIMG 1-s2.0-S0885064X12000817-si342.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/09d5b0fc18cf1ecf1517c89e311b9c4c/si342.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/09d5b0fc18cf1ecf1517c89e311b9c4c/si342.gif si342 si342.gif gif 127 10 15 ALTIMG 1-s2.0-S0885064X12000817-si695.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/4b9f5f5a22875874e2e0bc0978e8ea8e/si673.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/4b9f5f5a22875874e2e0bc0978e8ea8e/si673.gif si695 si695.gif gif 129 9 12 ALTIMG 1-s2.0-S0885064X12000817-si711.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/8372aa47d9b8f6eb7290a8f31701dd7b/si711.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/8372aa47d9b8f6eb7290a8f31701dd7b/si711.gif si711 si711.gif gif 1391 39 423 ALTIMG 1-s2.0-S0885064X12000817-si350.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/36f3483bdd58ffc7497d6ddcbc3f7fcc/si350.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/36f3483bdd58ffc7497d6ddcbc3f7fcc/si350.gif si350 si350.gif gif 156 14 16 ALTIMG 1-s2.0-S0885064X12000817-si534.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/fc9f8e370d8be7ab56f99818f8743945/si534.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/fc9f8e370d8be7ab56f99818f8743945/si534.gif si534 si534.gif gif 960 46 215 ALTIMG 1-s2.0-S0885064X12000817-si119.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/ae4348d2405d949eba06d864476458af/si96.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/ae4348d2405d949eba06d864476458af/si96.gif si119 si119.gif gif 129 9 12 ALTIMG 1-s2.0-S0885064X12000817-si159.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/66173c4d94832e5cbf84ccec95a8004a/si31.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/66173c4d94832e5cbf84ccec95a8004a/si31.gif si159 si159.gif gif 119 9 11 ALTIMG 1-s2.0-S0885064X12000817-si468.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/7dd7fbe05cec32bef1bca16dbc8ac095/si489.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/7dd7fbe05cec32bef1bca16dbc8ac095/si489.gif si468 si468.gif gif 164 15 20 ALTIMG 1-s2.0-S0885064X12000817-si83.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/63ece0456aa5abda63641ae91798941c/si296.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/63ece0456aa5abda63641ae91798941c/si296.gif si83 si83.gif gif 119 9 11 ALTIMG 1-s2.0-S0885064X12000817-si422.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/816d5112b2a9ef7bb81ca5cb468f4d1b/si441.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/816d5112b2a9ef7bb81ca5cb468f4d1b/si441.gif si422 si422.gif gif 114 12 8 ALTIMG 1-s2.0-S0885064X12000817-si658.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/bea755d3103fcfaa6b0c0bc42e0d1669/si658.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/bea755d3103fcfaa6b0c0bc42e0d1669/si658.gif si658 si658.gif gif 330 13 84 ALTIMG 1-s2.0-S0885064X12000817-si260.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/f49f680e81e19d19cdbd7d1160d1bfbe/si260.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/f49f680e81e19d19cdbd7d1160d1bfbe/si260.gif si260 si260.gif gif 625 13 214 ALTIMG 1-s2.0-S0885064X12000817-si31.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/66173c4d94832e5cbf84ccec95a8004a/si31.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/66173c4d94832e5cbf84ccec95a8004a/si31.gif si31 si31.gif gif 119 9 11 ALTIMG 1-s2.0-S0885064X12000817-si614.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/7cd37197b4b4a41b000c096c827d4358/si614.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/7cd37197b4b4a41b000c096c827d4358/si614.gif si614 si614.gif gif 813 19 251 ALTIMG 1-s2.0-S0885064X12000817-si272.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/cf8c51035a31ee9ac734946964d3534d/si272.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/cf8c51035a31ee9ac734946964d3534d/si272.gif si272 si272.gif gif 128 9 11 ALTIMG 1-s2.0-S0885064X12000817-si156.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/d5ada1189813b6c48bca3254f7799d12/si156.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/d5ada1189813b6c48bca3254f7799d12/si156.gif si156 si156.gif gif 193 13 28 ALTIMG 1-s2.0-S0885064X12000817-si400.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/1d25536f863274311d19c06ce8fe3025/si400.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/1d25536f863274311d19c06ce8fe3025/si400.gif si400 si400.gif gif 364 16 96 ALTIMG 1-s2.0-S0885064X12000817-si278.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/b9d70c697c5f4ae06caa1fd15402e705/si278.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/b9d70c697c5f4ae06caa1fd15402e705/si278.gif si278 si278.gif gif 193 13 27 ALTIMG 1-s2.0-S0885064X12000817-si493.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/1a121dda348a2bb2a3584e253573ed53/si493.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/1a121dda348a2bb2a3584e253573ed53/si493.gif si493 si493.gif gif 140 13 17 ALTIMG 1-s2.0-S0885064X12000817-si388.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/ae4348d2405d949eba06d864476458af/si96.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/ae4348d2405d949eba06d864476458af/si96.gif si388 si388.gif gif 129 9 12 ALTIMG 1-s2.0-S0885064X12000817-si266.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/e745a2a56fc432c4b59c3610b0084ccd/si224.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/e745a2a56fc432c4b59c3610b0084ccd/si224.gif si266 si266.gif gif 176 10 38 ALTIMG 1-s2.0-S0885064X12000817-si187.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/d58028a06739d2afd199fb2e893129fb/si187.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/d58028a06739d2afd199fb2e893129fb/si187.gif si187 si187.gif gif 155 12 19 ALTIMG 1-s2.0-S0885064X12000817-si796.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/4b9f5f5a22875874e2e0bc0978e8ea8e/si673.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/4b9f5f5a22875874e2e0bc0978e8ea8e/si673.gif si796 si796.gif gif 129 9 12 ALTIMG 1-s2.0-S0885064X12000817-si72.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/751298c4de9f0dfec04f9ba577dcdb1e/si73.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/751298c4de9f0dfec04f9ba577dcdb1e/si73.gif si72 si72.gif gif 125 9 13 ALTIMG 1-s2.0-S0885064X12000817-si198.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/c9e84a85cf9f15da64ec3c4447f45db7/si198.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/c9e84a85cf9f15da64ec3c4447f45db7/si198.gif si198 si198.gif gif 173 12 37 ALTIMG 1-s2.0-S0885064X12000817-si200.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/f8fd41cb4bb061e8bb65419f77f8705b/si200.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/f8fd41cb4bb061e8bb65419f77f8705b/si200.gif si200 si200.gif gif 356 13 102 ALTIMG 1-s2.0-S0885064X12000817-si41.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/3d1bb4bd060d9ee2729cb8e420d4cd15/si41.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/3d1bb4bd060d9ee2729cb8e420d4cd15/si41.gif si41 si41.gif gif 170 9 34 ALTIMG 1-s2.0-S0885064X12000817-si141.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/3bc72098bcd1389c268902d0e633ffab/si273.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/3bc72098bcd1389c268902d0e633ffab/si273.gif si141 si141.gif gif 129 9 12 ALTIMG 1-s2.0-S0885064X12000817-si256.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/ae4348d2405d949eba06d864476458af/si96.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/ae4348d2405d949eba06d864476458af/si96.gif si256 si256.gif gif 129 9 12 ALTIMG 1-s2.0-S0885064X12000817-si225.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/62a5e130244cbf082cfffe8729624cee/si225.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/62a5e130244cbf082cfffe8729624cee/si225.gif si225 si225.gif gif 373 15 88 ALTIMG 1-s2.0-S0885064X12000817-si117.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/d0742554cce677f19e778d6fc4453adc/si117.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/d0742554cce677f19e778d6fc4453adc/si117.gif si117 si117.gif gif 250 13 47 ALTIMG 1-s2.0-S0885064X12000817-si325.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/e07c5cb7c720e1ce1078699bb28a3a12/si325.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/e07c5cb7c720e1ce1078699bb28a3a12/si325.gif si325 si325.gif gif 459 19 143 ALTIMG 1-s2.0-S0885064X12000817-si218.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/751298c4de9f0dfec04f9ba577dcdb1e/si73.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/751298c4de9f0dfec04f9ba577dcdb1e/si73.gif si218 si218.gif gif 125 9 13 ALTIMG 1-s2.0-S0885064X12000817-si136.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/16942eef4f7dc9bc1c91125b3ab02e8c/si136.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/16942eef4f7dc9bc1c91125b3ab02e8c/si136.gif si136 si136.gif gif 1025 15 314 ALTIMG 1-s2.0-S0885064X12000817-si471.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/0c7783e8d2361053a3e037eb8b6050b9/si471.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/0c7783e8d2361053a3e037eb8b6050b9/si471.gif si471 si471.gif gif 290 15 72 ALTIMG 1-s2.0-S0885064X12000817-si654.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/6d3472cf641e930c3b2aa804279165ba/si55.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/6d3472cf641e930c3b2aa804279165ba/si55.gif si654 si654.gif gif 137 10 17 ALTIMG 1-s2.0-S0885064X12000817-si539.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/ae4348d2405d949eba06d864476458af/si96.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/ae4348d2405d949eba06d864476458af/si96.gif si539 si539.gif gif 129 9 12 ALTIMG 1-s2.0-S0885064X12000817-si374.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/5d4ef2c58a5869550d416d570de15d93/si374.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/5d4ef2c58a5869550d416d570de15d93/si374.gif si374 si374.gif gif 135 10 17 ALTIMG 1-s2.0-S0885064X12000817-si450.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/3403a3eceb19b564898fb6f836673d23/si450.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/3403a3eceb19b564898fb6f836673d23/si450.gif si450 si450.gif gif 104 6 8 ALTIMG 1-s2.0-S0885064X12000817-si345.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/ae4348d2405d949eba06d864476458af/si96.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/ae4348d2405d949eba06d864476458af/si96.gif si345 si345.gif gif 129 9 12 ALTIMG 1-s2.0-S0885064X12000817-si308.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/8904ff5535f18a62016bd300d0eb6f8a/si348.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/8904ff5535f18a62016bd300d0eb6f8a/si348.gif si308 si308.gif gif 144 9 17 ALTIMG 1-s2.0-S0885064X12000817-si144.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/63ece0456aa5abda63641ae91798941c/si296.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/63ece0456aa5abda63641ae91798941c/si296.gif si144 si144.gif gif 119 9 11 ALTIMG 1-s2.0-S0885064X12000817-si380.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/27de0a87af55c7ecd2b72293e4fb7cf9/si380.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/27de0a87af55c7ecd2b72293e4fb7cf9/si380.gif si380 si380.gif gif 995 44 191 ALTIMG 1-s2.0-S0885064X12000817-si196.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/e745a2a56fc432c4b59c3610b0084ccd/si224.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/e745a2a56fc432c4b59c3610b0084ccd/si224.gif si196 si196.gif gif 176 10 38 ALTIMG 1-s2.0-S0885064X12000817-si615.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/5bbb7f90fbf38e8d27cb8465415d337e/si615.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/5bbb7f90fbf38e8d27cb8465415d337e/si615.gif si615 si615.gif gif 793 36 199 ALTIMG 1-s2.0-S0885064X12000817-si464.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/1560a0dee6a122fc0bbb9e785000aeff/si598.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/1560a0dee6a122fc0bbb9e785000aeff/si598.gif si464 si464.gif gif 149 10 17 ALTIMG 1-s2.0-S0885064X12000817-si160.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/5eaa0a411d5dc0a19d5517a420b935cb/si160.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/5eaa0a411d5dc0a19d5517a420b935cb/si160.gif si160 si160.gif gif 178 13 34 ALTIMG 1-s2.0-S0885064X12000817-si772.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/89845a6dba12661e49294e0bcfc49f48/si828.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/89845a6dba12661e49294e0bcfc49f48/si828.gif si772 si772.gif gif 133 10 14 ALTIMG 1-s2.0-S0885064X12000817-si85.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/751298c4de9f0dfec04f9ba577dcdb1e/si73.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/751298c4de9f0dfec04f9ba577dcdb1e/si73.gif si85 si85.gif gif 125 9 13 ALTIMG 1-s2.0-S0885064X12000817-si134.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/896f840cb310b9156e45afd0d7e04bd8/si127.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/896f840cb310b9156e45afd0d7e04bd8/si127.gif si134 si134.gif gif 187 13 35 ALTIMG 1-s2.0-S0885064X12000817-si645.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/fd1216415647ab771346d51eecc4cfb4/si645.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/fd1216415647ab771346d51eecc4cfb4/si645.gif si645 si645.gif gif 111 7 9 ALTIMG 1-s2.0-S0885064X12000817-si800.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/4b9f5f5a22875874e2e0bc0978e8ea8e/si673.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/4b9f5f5a22875874e2e0bc0978e8ea8e/si673.gif si800 si800.gif gif 129 9 12 ALTIMG 1-s2.0-S0885064X12000817-si803.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/9d3347a2b23bd366ca6254bde78c7167/si803.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/9d3347a2b23bd366ca6254bde78c7167/si803.gif si803 si803.gif gif 213 13 41 ALTIMG 1-s2.0-S0885064X12000817-si131.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/6de26e062704f4b73d52cefc37e68ee3/si131.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/6de26e062704f4b73d52cefc37e68ee3/si131.gif si131 si131.gif gif 214 12 53 ALTIMG 1-s2.0-S0885064X12000817-si564.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/fa08167b277f03c0173be1ed08bf96e6/si564.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/fa08167b277f03c0173be1ed08bf96e6/si564.gif si564 si564.gif gif 137 15 10 ALTIMG 1-s2.0-S0885064X12000817-si622.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/cf861fff809e8d30a549e28edb46e388/si622.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/cf861fff809e8d30a549e28edb46e388/si622.gif si622 si622.gif gif 131 13 22 ALTIMG 1-s2.0-S0885064X12000817-si421.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/e71e81d82af1319eb58abd1000e71d8d/si421.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/e71e81d82af1319eb58abd1000e71d8d/si421.gif si421 si421.gif gif 271 13 61 ALTIMG 1-s2.0-S0885064X12000817-si467.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/6b243daa3c033f070d609d3a766dc5d2/si467.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/6b243daa3c033f070d609d3a766dc5d2/si467.gif si467 si467.gif gif 214 15 42 ALTIMG 1-s2.0-S0885064X12000817-si221.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/a2b5df91a7521eb6a69e94be3685bce4/si221.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/a2b5df91a7521eb6a69e94be3685bce4/si221.gif si221 si221.gif gif 206 13 33 ALTIMG 1-s2.0-S0885064X12000817-si763.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/1f9eefde61a003079e8b9215dcd5c868/si560.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/1f9eefde61a003079e8b9215dcd5c868/si560.gif si763 si763.gif gif 119 12 11 ALTIMG 1-s2.0-S0885064X12000817-si594.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/3392717230538ad8fa108587856aa256/si594.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/3392717230538ad8fa108587856aa256/si594.gif si594 si594.gif gif 356 16 78 ALTIMG 1-s2.0-S0885064X12000817-si818.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/ae4348d2405d949eba06d864476458af/si96.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/ae4348d2405d949eba06d864476458af/si96.gif si818 si818.gif gif 129 9 12 ALTIMG 1-s2.0-S0885064X12000817-si46.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/d036a5b2a3cb03db252676ed941fe230/si46.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/d036a5b2a3cb03db252676ed941fe230/si46.gif si46 si46.gif gif 225 12 51 ALTIMG 1-s2.0-S0885064X12000817-si147.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/877a6e62144dd06bcf49fd462cfbbfa5/si147.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/877a6e62144dd06bcf49fd462cfbbfa5/si147.gif si147 si147.gif gif 165 10 23 ALTIMG 1-s2.0-S0885064X12000817-si399.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/899fbabd5105b6556ef2c0db374a7e18/si399.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/899fbabd5105b6556ef2c0db374a7e18/si399.gif si399 si399.gif gif 1298 41 270 ALTIMG 1-s2.0-S0885064X12000817-si371.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/92e2fa742f37cccf5182046e2ce28116/si371.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/92e2fa742f37cccf5182046e2ce28116/si371.gif si371 si371.gif gif 198 13 30 ALTIMG 1-s2.0-S0885064X12000817-si280.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/ae4348d2405d949eba06d864476458af/si96.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/ae4348d2405d949eba06d864476458af/si96.gif si280 si280.gif gif 129 9 12 ALTIMG 1-s2.0-S0885064X12000817-si179.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/f8ee6bae5aa809989180175a59884f95/si179.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/f8ee6bae5aa809989180175a59884f95/si179.gif si179 si179.gif gif 2328 45 519 ALTIMG 1-s2.0-S0885064X12000817-si206.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/63ece0456aa5abda63641ae91798941c/si296.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/63ece0456aa5abda63641ae91798941c/si296.gif si206 si206.gif gif 119 9 11 ALTIMG 1-s2.0-S0885064X12000817-si201.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/63ece0456aa5abda63641ae91798941c/si296.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/63ece0456aa5abda63641ae91798941c/si296.gif si201 si201.gif gif 119 9 11 ALTIMG 1-s2.0-S0885064X12000817-si205.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/cda8c711ae98eec71b3b28b70d151394/si205.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/cda8c711ae98eec71b3b28b70d151394/si205.gif si205 si205.gif gif 378 13 115 ALTIMG 1-s2.0-S0885064X12000817-si677.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/378d0574eda471a21e801d62bc82fa0c/si677.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/378d0574eda471a21e801d62bc82fa0c/si677.gif si677 si677.gif gif 308 12 83 ALTIMG 1-s2.0-S0885064X12000817-si202.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/d58028a06739d2afd199fb2e893129fb/si187.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/d58028a06739d2afd199fb2e893129fb/si187.gif si202 si202.gif gif 155 12 19 ALTIMG 1-s2.0-S0885064X12000817-si283.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/5aec234dd6b3a76aea0ec8c24200ac87/si283.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/5aec234dd6b3a76aea0ec8c24200ac87/si283.gif si283 si283.gif gif 210 12 42 ALTIMG 1-s2.0-S0885064X12000817-si536.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/26829cb1e6e4a1f9f90dcfcc1f7810d7/si536.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/26829cb1e6e4a1f9f90dcfcc1f7810d7/si536.gif si536 si536.gif gif 148 14 13 ALTIMG 1-s2.0-S0885064X12000817-si770.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/ed7711251331a7dae909f790066938cf/si770.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/ed7711251331a7dae909f790066938cf/si770.gif si770 si770.gif gif 619 39 131 ALTIMG 1-s2.0-S0885064X12000817-si36.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/aca2b5974cf13a20c1226b49024e3dde/si36.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/aca2b5974cf13a20c1226b49024e3dde/si36.gif si36 si36.gif gif 569 13 176 ALTIMG 1-s2.0-S0885064X12000817-si545.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/91d1c25aa691c7676fc903dd42cd9ddd/si545.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/91d1c25aa691c7676fc903dd42cd9ddd/si545.gif si545 si545.gif gif 213 13 41 ALTIMG 1-s2.0-S0885064X12000817-si181.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/a203400aa5c1a1b376f2b577758ae59e/si181.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/a203400aa5c1a1b376f2b577758ae59e/si181.gif si181 si181.gif gif 985 13 322 ALTIMG 1-s2.0-S0885064X12000817-si788.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/df6286a49d086441e78e0daeb3e34636/si788.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/df6286a49d086441e78e0daeb3e34636/si788.gif si788 si788.gif gif 1020 39 234 ALTIMG 1-s2.0-S0885064X12000817-si588.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/77f0298569020bde47159c0d1032e7cd/si588.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/77f0298569020bde47159c0d1032e7cd/si588.gif si588 si588.gif gif 442 16 118 ALTIMG 1-s2.0-S0885064X12000817-si563.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/846881a2e416352c73a0ca86c03d52ce/si563.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/846881a2e416352c73a0ca86c03d52ce/si563.gif si563 si563.gif gif 321 17 68 ALTIMG 1-s2.0-S0885064X12000817-si551.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/ae4348d2405d949eba06d864476458af/si96.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/ae4348d2405d949eba06d864476458af/si96.gif si551 si551.gif gif 129 9 12 ALTIMG 1-s2.0-S0885064X12000817-si741.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/232036ce7a9ee92b569fd248574b6783/si741.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/232036ce7a9ee92b569fd248574b6783/si741.gif si741 si741.gif gif 212 12 45 ALTIMG 1-s2.0-S0885064X12000817-si373.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/cea370d551937f4522b4594bbfb5cdfb/si373.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/cea370d551937f4522b4594bbfb5cdfb/si373.gif si373 si373.gif gif 369 14 91 ALTIMG 1-s2.0-S0885064X12000817-si357.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/3e15fc3d9207b42d76fbd3efd08ac6c1/si357.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/3e15fc3d9207b42d76fbd3efd08ac6c1/si357.gif si357 si357.gif gif 391 13 100 ALTIMG 1-s2.0-S0885064X12000817-si618.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/1560a0dee6a122fc0bbb9e785000aeff/si598.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/1560a0dee6a122fc0bbb9e785000aeff/si598.gif si618 si618.gif gif 149 10 17 ALTIMG 1-s2.0-S0885064X12000817-si265.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/b897ef1cf311ea1fb7b70c10671204d4/si265.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/b897ef1cf311ea1fb7b70c10671204d4/si265.gif si265 si265.gif gif 423 16 107 ALTIMG 1-s2.0-S0885064X12000817-si95.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/d58028a06739d2afd199fb2e893129fb/si187.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/d58028a06739d2afd199fb2e893129fb/si187.gif si95 si95.gif gif 155 12 19 ALTIMG 1-s2.0-S0885064X12000817-si208.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/47a438cd00d739a80aa3b62078bfe2ba/si396.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/47a438cd00d739a80aa3b62078bfe2ba/si396.gif si208 si208.gif gif 207 14 39 ALTIMG 1-s2.0-S0885064X12000817-si522.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/33e0193d866057dab3e90e595f1b7992/si522.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/33e0193d866057dab3e90e595f1b7992/si522.gif si522 si522.gif gif 147 11 16 ALTIMG 1-s2.0-S0885064X12000817-si104.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/a5b342f79626b60aa857795bb9c3de37/si104.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/a5b342f79626b60aa857795bb9c3de37/si104.gif si104 si104.gif gif 412 13 116 ALTIMG 1-s2.0-S0885064X12000817-si790.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/c83eb284e35cd84c40343664f15a807a/si790.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/c83eb284e35cd84c40343664f15a807a/si790.gif si790 si790.gif gif 128 10 14 ALTIMG 1-s2.0-S0885064X12000817-si177.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/afc1742ccdb006046b10cbe194768ae5/si177.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/afc1742ccdb006046b10cbe194768ae5/si177.gif si177 si177.gif gif 870 13 279 ALTIMG 1-s2.0-S0885064X12000817-si384.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/f103e0fda8f6924cb278d5c1d5233f96/si384.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/f103e0fda8f6924cb278d5c1d5233f96/si384.gif si384 si384.gif gif 2207 67 495 ALTIMG 1-s2.0-S0885064X12000817-si831.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/a03994770f8921be76e18141c174d875/si682.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/a03994770f8921be76e18141c174d875/si682.gif si831 si831.gif gif 190 10 36 ALTIMG 1-s2.0-S0885064X12000817-si348.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/8904ff5535f18a62016bd300d0eb6f8a/si348.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/8904ff5535f18a62016bd300d0eb6f8a/si348.gif si348 si348.gif gif 144 9 17 ALTIMG 1-s2.0-S0885064X12000817-si729.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/8cb5309136b2f66308103603075e6923/si729.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/8cb5309136b2f66308103603075e6923/si729.gif si729 si729.gif gif 841 17 253 ALTIMG 1-s2.0-S0885064X12000817-si349.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/663ff50d777859d4ccf595f77c5fb6d3/si349.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/663ff50d777859d4ccf595f77c5fb6d3/si349.gif si349 si349.gif gif 156 16 15 ALTIMG 1-s2.0-S0885064X12000817-si273.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/3bc72098bcd1389c268902d0e633ffab/si273.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/3bc72098bcd1389c268902d0e633ffab/si273.gif si273 si273.gif gif 129 9 12 ALTIMG 1-s2.0-S0885064X12000817-si360.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/135eb6fc1737bf818e7a11303cb8fd65/si360.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/135eb6fc1737bf818e7a11303cb8fd65/si360.gif si360 si360.gif gif 274 13 69 ALTIMG 1-s2.0-S0885064X12000817-si150.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/3bc72098bcd1389c268902d0e633ffab/si273.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/3bc72098bcd1389c268902d0e633ffab/si273.gif si150 si150.gif gif 129 9 12 ALTIMG 1-s2.0-S0885064X12000817-si213.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/b48fcb0fc7abe3949849f424823ef762/si386.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/b48fcb0fc7abe3949849f424823ef762/si386.gif si213 si213.gif gif 122 6 12 ALTIMG 1-s2.0-S0885064X12000817-si6.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/cad33c0e2eb8129e4f2eb152692d07f9/si6.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/cad33c0e2eb8129e4f2eb152692d07f9/si6.gif si6 si6.gif gif 260 13 65 ALTIMG 1-s2.0-S0885064X12000817-si375.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/3a003b8c8e5fa3bd2a6b33433eb6e77e/si580.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/3a003b8c8e5fa3bd2a6b33433eb6e77e/si580.gif si375 si375.gif gif 152 10 22 ALTIMG 1-s2.0-S0885064X12000817-si334.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/367d662d1e6812a9a06c15d9f5d0806f/si334.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/367d662d1e6812a9a06c15d9f5d0806f/si334.gif si334 si334.gif gif 321 13 105 ALTIMG 1-s2.0-S0885064X12000817-si532.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/ae4348d2405d949eba06d864476458af/si96.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/ae4348d2405d949eba06d864476458af/si96.gif si532 si532.gif gif 129 9 12 ALTIMG 1-s2.0-S0885064X12000817-si670.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/4b9f5f5a22875874e2e0bc0978e8ea8e/si673.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/4b9f5f5a22875874e2e0bc0978e8ea8e/si673.gif si670 si670.gif gif 129 9 12 ALTIMG 1-s2.0-S0885064X12000817-si604.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/dab6869b653ee62c3f07d46119d030df/si604.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/dab6869b653ee62c3f07d46119d030df/si604.gif si604 si604.gif gif 343 14 93 ALTIMG 1-s2.0-S0885064X12000817-si13.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/0ed0ed94f5ca79964478355bab9dfe4d/si13.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/0ed0ed94f5ca79964478355bab9dfe4d/si13.gif si13 si13.gif gif 179 13 33 ALTIMG 1-s2.0-S0885064X12000817-si740.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/031f42ede199d9540bd0c5f6b7100aad/si740.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/031f42ede199d9540bd0c5f6b7100aad/si740.gif si740 si740.gif gif 726 18 224 ALTIMG 1-s2.0-S0885064X12000817-si61.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/66173c4d94832e5cbf84ccec95a8004a/si31.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/66173c4d94832e5cbf84ccec95a8004a/si31.gif si61 si61.gif gif 119 9 11 ALTIMG 1-s2.0-S0885064X12000817-si713.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/ae4348d2405d949eba06d864476458af/si96.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/ae4348d2405d949eba06d864476458af/si96.gif si713 si713.gif gif 129 9 12 ALTIMG 1-s2.0-S0885064X12000817-si423.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/f67b7772819bef7cccda2397fb93c882/si382.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/f67b7772819bef7cccda2397fb93c882/si382.gif si423 si423.gif gif 122 9 11 ALTIMG 1-s2.0-S0885064X12000817-si524.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/28619bb2e9480dbb8e0141e792011d90/si524.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/28619bb2e9480dbb8e0141e792011d90/si524.gif si524 si524.gif gif 200 12 35 ALTIMG 1-s2.0-S0885064X12000817-si226.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/53c0c1310ae933f894553ddae6e84afb/si226.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/53c0c1310ae933f894553ddae6e84afb/si226.gif si226 si226.gif gif 252 13 62 ALTIMG 1-s2.0-S0885064X12000817-si158.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/e745a2a56fc432c4b59c3610b0084ccd/si224.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/e745a2a56fc432c4b59c3610b0084ccd/si224.gif si158 si158.gif gif 176 10 38 ALTIMG 1-s2.0-S0885064X12000817-si60.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/036cb9b90893cef26c00380719427644/si214.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/036cb9b90893cef26c00380719427644/si214.gif si60 si60.gif gif 141 10 16 ALTIMG 1-s2.0-S0885064X12000817-si15.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/22befb90cb79c6c9d3811663485706fa/si15.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/22befb90cb79c6c9d3811663485706fa/si15.gif si15 si15.gif gif 626 20 192 ALTIMG 1-s2.0-S0885064X12000817-si810.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/1e0db6fcb68827a2e617f7cade3a0ade/si810.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/1e0db6fcb68827a2e617f7cade3a0ade/si810.gif si810 si810.gif gif 328 13 90 ALTIMG 1-s2.0-S0885064X12000817-si704.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/3c54e6a5396230fbee659a32c7d5933a/si704.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/3c54e6a5396230fbee659a32c7d5933a/si704.gif si704 si704.gif gif 523 13 128 ALTIMG 1-s2.0-S0885064X12000817-si319.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/751298c4de9f0dfec04f9ba577dcdb1e/si73.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/751298c4de9f0dfec04f9ba577dcdb1e/si73.gif si319 si319.gif gif 125 9 13 ALTIMG 1-s2.0-S0885064X12000817-si175.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/a47bdc740f4927284325e3264130d9b5/si175.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/a47bdc740f4927284325e3264130d9b5/si175.gif si175 si175.gif gif 1326 22 427 ALTIMG 1-s2.0-S0885064X12000817-si764.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/63ece0456aa5abda63641ae91798941c/si296.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/63ece0456aa5abda63641ae91798941c/si296.gif si764 si764.gif gif 119 9 11 ALTIMG 1-s2.0-S0885064X12000817-si643.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/bfdbc581c683fb9b372931fc2f74ecd2/si643.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/bfdbc581c683fb9b372931fc2f74ecd2/si643.gif si643 si643.gif gif 340 14 89 ALTIMG 1-s2.0-S0885064X12000817-si742.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/0b185c68b087775a20dd6f6c8fe5af38/si742.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/0b185c68b087775a20dd6f6c8fe5af38/si742.gif si742 si742.gif gif 909 30 256 ALTIMG 1-s2.0-S0885064X12000817-si245.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/751298c4de9f0dfec04f9ba577dcdb1e/si73.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/751298c4de9f0dfec04f9ba577dcdb1e/si73.gif si245 si245.gif gif 125 9 13 ALTIMG 1-s2.0-S0885064X12000817-si437.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/f67b7772819bef7cccda2397fb93c882/si382.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/f67b7772819bef7cccda2397fb93c882/si382.gif si437 si437.gif gif 122 9 11 ALTIMG 1-s2.0-S0885064X12000817-si656.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/29c88cdb82df3f7777ba5d806115487d/si656.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/29c88cdb82df3f7777ba5d806115487d/si656.gif si656 si656.gif gif 295 12 83 ALTIMG 1-s2.0-S0885064X12000817-si744.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/4b9f5f5a22875874e2e0bc0978e8ea8e/si673.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/4b9f5f5a22875874e2e0bc0978e8ea8e/si673.gif si744 si744.gif gif 129 9 12 ALTIMG 1-s2.0-S0885064X12000817-si805.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/0095759025a155bf78bd49995a353848/si805.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/0095759025a155bf78bd49995a353848/si805.gif si805 si805.gif gif 398 14 99 ALTIMG 1-s2.0-S0885064X12000817-si651.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/3c253f16993bba0ea7f82adb11b3cd5d/si651.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/3c253f16993bba0ea7f82adb11b3cd5d/si651.gif si651 si651.gif gif 108 7 8 ALTIMG 1-s2.0-S0885064X12000817-si330.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/d3be4c9189ea78acf21f724823e5ae87/si330.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/d3be4c9189ea78acf21f724823e5ae87/si330.gif si330 si330.gif gif 141 13 12 ALTIMG 1-s2.0-S0885064X12000817-si315.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/751298c4de9f0dfec04f9ba577dcdb1e/si73.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/751298c4de9f0dfec04f9ba577dcdb1e/si73.gif si315 si315.gif gif 125 9 13 ALTIMG 1-s2.0-S0885064X12000817-si155.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/63ece0456aa5abda63641ae91798941c/si296.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/63ece0456aa5abda63641ae91798941c/si296.gif si155 si155.gif gif 119 9 11 ALTIMG 1-s2.0-S0885064X12000817-si77.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/54a415d155aed19b79b7d18f4b826100/si77.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/54a415d155aed19b79b7d18f4b826100/si77.gif si77 si77.gif gif 388 13 99 ALTIMG 1-s2.0-S0885064X12000817-si418.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/b10a9ea0c0c40d0aaa5e991f3d424ded/si418.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/b10a9ea0c0c40d0aaa5e991f3d424ded/si418.gif si418 si418.gif gif 176 9 36 ALTIMG 1-s2.0-S0885064X12000817-si87.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/d331fc587c3941b84642ea730e3b14a7/si291.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/d331fc587c3941b84642ea730e3b14a7/si291.gif si87 si87.gif gif 173 10 38 ALTIMG 1-s2.0-S0885064X12000817-si508.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/029cdc196dcabd6f93198f1163ed7d25/si511.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/029cdc196dcabd6f93198f1163ed7d25/si511.gif si508 si508.gif gif 212 12 40 ALTIMG 1-s2.0-S0885064X12000817-si448.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/9b7bc3e88e12a3066d1c6c7568a4c0a1/si448.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/9b7bc3e88e12a3066d1c6c7568a4c0a1/si448.gif si448 si448.gif gif 147 9 23 ALTIMG 1-s2.0-S0885064X12000817-si499.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/3a8e5cd4507b245c49726d97e9cfb97f/si499.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/3a8e5cd4507b245c49726d97e9cfb97f/si499.gif si499 si499.gif gif 917 17 303 ALTIMG 1-s2.0-S0885064X12000817-si777.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/0c35ab6e8de67ba505373123a1824ccc/si777.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/0c35ab6e8de67ba505373123a1824ccc/si777.gif si777 si777.gif gif 398 13 103 ALTIMG 1-s2.0-S0885064X12000817-si243.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/082499914e8839feee64c0ea318a6b1d/si243.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/082499914e8839feee64c0ea318a6b1d/si243.gif si243 si243.gif gif 405 13 122 ALTIMG 1-s2.0-S0885064X12000817-si542.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/5ab85ef9af5bd384d05e18d973260f34/si542.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/5ab85ef9af5bd384d05e18d973260f34/si542.gif si542 si542.gif gif 1130 51 243 ALTIMG 1-s2.0-S0885064X12000817-si232.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/b12ab6a0c5cc953e22eaded28cb05862/si232.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/b12ab6a0c5cc953e22eaded28cb05862/si232.gif si232 si232.gif gif 369 15 87 ALTIMG 1-s2.0-S0885064X12000817-si628.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/63ece0456aa5abda63641ae91798941c/si296.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/63ece0456aa5abda63641ae91798941c/si296.gif si628 si628.gif gif 119 9 11 ALTIMG 1-s2.0-S0885064X12000817-si567.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/085601a3faa39120fecc9b501425ba6b/si567.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/085601a3faa39120fecc9b501425ba6b/si567.gif si567 si567.gif gif 980 34 250 ALTIMG 1-s2.0-S0885064X12000817-si514.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/7e4f92d94d9125e556b406099e444c64/si514.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/7e4f92d94d9125e556b406099e444c64/si514.gif si514 si514.gif gif 235 12 54 ALTIMG 1-s2.0-S0885064X12000817-si296.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/63ece0456aa5abda63641ae91798941c/si296.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/63ece0456aa5abda63641ae91798941c/si296.gif si296 si296.gif gif 119 9 11 ALTIMG 1-s2.0-S0885064X12000817-si106.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/ee2107f3f8d07d0cee578828cb27223a/si106.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/ee2107f3f8d07d0cee578828cb27223a/si106.gif si106 si106.gif gif 353 13 90 ALTIMG 1-s2.0-S0885064X12000817-si521.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/959247d29e79bda83a3529ebccbeb051/si521.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/959247d29e79bda83a3529ebccbeb051/si521.gif si521 si521.gif gif 2671 116 394 ALTIMG 1-s2.0-S0885064X12000817-si484.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/b992c64f00a1a079df51534574bb195f/si484.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/b992c64f00a1a079df51534574bb195f/si484.gif si484 si484.gif gif 342 13 105 ALTIMG 1-s2.0-S0885064X12000817-si784.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/0b39aa9b8f2fbb8ee2dd11529f514fb8/si784.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/0b39aa9b8f2fbb8ee2dd11529f514fb8/si784.gif si784 si784.gif gif 142 17 14 ALTIMG 1-s2.0-S0885064X12000817-si611.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/ae4348d2405d949eba06d864476458af/si96.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/ae4348d2405d949eba06d864476458af/si96.gif si611 si611.gif gif 129 9 12 ALTIMG 1-s2.0-S0885064X12000817-si386.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/b48fcb0fc7abe3949849f424823ef762/si386.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/b48fcb0fc7abe3949849f424823ef762/si386.gif si386 si386.gif gif 122 6 12 ALTIMG 1-s2.0-S0885064X12000817-si431.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/68b4d71130853ca3772d78a9c8f07048/si431.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/68b4d71130853ca3772d78a9c8f07048/si431.gif si431 si431.gif gif 736 18 242 ALTIMG 1-s2.0-S0885064X12000817-si25.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/13f17bd982283b6715682c0c132932e0/si25.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/13f17bd982283b6715682c0c132932e0/si25.gif si25 si25.gif gif 134 13 17 ALTIMG 1-s2.0-S0885064X12000817-si142.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/a3e3ec9da8a0ae92eeb4a4cc744f9b35/si142.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/a3e3ec9da8a0ae92eeb4a4cc744f9b35/si142.gif si142 si142.gif gif 181 9 41 ALTIMG 1-s2.0-S0885064X12000817-si255.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/63ece0456aa5abda63641ae91798941c/si296.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/63ece0456aa5abda63641ae91798941c/si296.gif si255 si255.gif gif 119 9 11 ALTIMG 1-s2.0-S0885064X12000817-si44.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/66173c4d94832e5cbf84ccec95a8004a/si31.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/66173c4d94832e5cbf84ccec95a8004a/si31.gif si44 si44.gif gif 119 9 11 ALTIMG 1-s2.0-S0885064X12000817-si517.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/33e0193d866057dab3e90e595f1b7992/si522.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/33e0193d866057dab3e90e595f1b7992/si522.gif si517 si517.gif gif 147 11 16 ALTIMG 1-s2.0-S0885064X12000817-si398.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/9f27a2c9a6bf9f7d225a33f5860a1b1d/si398.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/9f27a2c9a6bf9f7d225a33f5860a1b1d/si398.gif si398 si398.gif gif 214 12 41 ALTIMG 1-s2.0-S0885064X12000817-si589.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/bb79142dcec61e21d84e8c5741f4d793/si589.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/bb79142dcec61e21d84e8c5741f4d793/si589.gif si589 si589.gif gif 711 16 227 ALTIMG 1-s2.0-S0885064X12000817-si361.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/32a06277de05a655c7a05909d6e751d7/si361.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/32a06277de05a655c7a05909d6e751d7/si361.gif si361 si361.gif gif 201 10 41 ALTIMG 1-s2.0-S0885064X12000817-si458.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/ae4348d2405d949eba06d864476458af/si96.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/ae4348d2405d949eba06d864476458af/si96.gif si458 si458.gif gif 129 9 12 ALTIMG 1-s2.0-S0885064X12000817-si755.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/4b9f5f5a22875874e2e0bc0978e8ea8e/si673.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/4b9f5f5a22875874e2e0bc0978e8ea8e/si673.gif si755 si755.gif gif 129 9 12 ALTIMG 1-s2.0-S0885064X12000817-si365.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/8904ff5535f18a62016bd300d0eb6f8a/si348.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/8904ff5535f18a62016bd300d0eb6f8a/si348.gif si365 si365.gif gif 144 9 17 ALTIMG 1-s2.0-S0885064X12000817-si823.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/0a719e77c15a396f559f5f5d7448dd0f/si823.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/0a719e77c15a396f559f5f5d7448dd0f/si823.gif si823 si823.gif gif 190 12 41 ALTIMG 1-s2.0-S0885064X12000817-si736.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/e9e6abc9a4a447b14f791f7f84967b24/si736.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/e9e6abc9a4a447b14f791f7f84967b24/si736.gif si736 si736.gif gif 512 13 155 ALTIMG 1-s2.0-S0885064X12000817-si191.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/05e0f2f53ecf1185e5c48c56c2020455/si191.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/05e0f2f53ecf1185e5c48c56c2020455/si191.gif si191 si191.gif gif 1365 13 518 ALTIMG 1-s2.0-S0885064X12000817-si268.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/cf8c51035a31ee9ac734946964d3534d/si272.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/cf8c51035a31ee9ac734946964d3534d/si272.gif si268 si268.gif gif 128 9 11 ALTIMG 1-s2.0-S0885064X12000817-si318.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/63ece0456aa5abda63641ae91798941c/si296.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/63ece0456aa5abda63641ae91798941c/si296.gif si318 si318.gif gif 119 9 11 ALTIMG 1-s2.0-S0885064X12000817-si7.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/2d7d1a49217b5bb96555af496758068a/si7.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/2d7d1a49217b5bb96555af496758068a/si7.gif si7 si7.gif gif 246 13 52 ALTIMG 1-s2.0-S0885064X12000817-si223.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/63ece0456aa5abda63641ae91798941c/si296.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/63ece0456aa5abda63641ae91798941c/si296.gif si223 si223.gif gif 119 9 11 ALTIMG 1-s2.0-S0885064X12000817-si332.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/3129f241d9ce1fd33921ccee2070e3bc/si332.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/3129f241d9ce1fd33921ccee2070e3bc/si332.gif si332 si332.gif gif 394 13 116 ALTIMG 1-s2.0-S0885064X12000817-si690.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/9dfac2d037a0f91cd68a44fbbeac9386/si42.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/9dfac2d037a0f91cd68a44fbbeac9386/si42.gif si690 si690.gif gif 182 10 34 ALTIMG 1-s2.0-S0885064X12000817-si519.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/9c18c872696aa024b14c54a9887729bd/si519.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/9c18c872696aa024b14c54a9887729bd/si519.gif si519 si519.gif gif 255 13 56 ALTIMG 1-s2.0-S0885064X12000817-si29.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/305fbdef02ddf64c63872c19a4919c28/si29.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/305fbdef02ddf64c63872c19a4919c28/si29.gif si29 si29.gif gif 414 13 136 ALTIMG 1-s2.0-S0885064X12000817-si154.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/ae4348d2405d949eba06d864476458af/si96.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/ae4348d2405d949eba06d864476458af/si96.gif si154 si154.gif gif 129 9 12 ALTIMG 1-s2.0-S0885064X12000817-si683.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/1ab5b81771c4e92efd65ed872311412f/si683.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/1ab5b81771c4e92efd65ed872311412f/si683.gif si683 si683.gif gif 164 9 34 ALTIMG 1-s2.0-S0885064X12000817-si163.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/bae66104f448891b162901b68c76d016/si163.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/bae66104f448891b162901b68c76d016/si163.gif si163 si163.gif gif 191 13 29 ALTIMG 1-s2.0-S0885064X12000817-si358.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/e745a2a56fc432c4b59c3610b0084ccd/si224.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/e745a2a56fc432c4b59c3610b0084ccd/si224.gif si358 si358.gif gif 176 10 38 ALTIMG 1-s2.0-S0885064X12000817-si269.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/60f93a212c8856a2f83c674c1fcc55f8/si261.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/60f93a212c8856a2f83c674c1fcc55f8/si261.gif si269 si269.gif gif 148 13 16 ALTIMG 1-s2.0-S0885064X12000817-si167.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/751298c4de9f0dfec04f9ba577dcdb1e/si73.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/751298c4de9f0dfec04f9ba577dcdb1e/si73.gif si167 si167.gif gif 125 9 13 ALTIMG 1-s2.0-S0885064X12000817-si523.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/973ab4e796b8eeaf70f7851ed8b3e7c3/si523.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/973ab4e796b8eeaf70f7851ed8b3e7c3/si523.gif si523 si523.gif gif 117 10 8 ALTIMG 1-s2.0-S0885064X12000817-si143.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/63ece0456aa5abda63641ae91798941c/si296.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/63ece0456aa5abda63641ae91798941c/si296.gif si143 si143.gif gif 119 9 11 ALTIMG 1-s2.0-S0885064X12000817-si19.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/66173c4d94832e5cbf84ccec95a8004a/si31.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/66173c4d94832e5cbf84ccec95a8004a/si31.gif si19 si19.gif gif 119 9 11 ALTIMG 1-s2.0-S0885064X12000817-si476.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/16231b6444e818b89a97ff5ee2a27afe/si476.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/16231b6444e818b89a97ff5ee2a27afe/si476.gif si476 si476.gif gif 159 9 25 ALTIMG 1-s2.0-S0885064X12000817-si405.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/f3391dbfbf077936ec5b55b4593d1aa4/si405.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/f3391dbfbf077936ec5b55b4593d1aa4/si405.gif si405 si405.gif gif 219 13 51 ALTIMG 1-s2.0-S0885064X12000817-si801.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/71e5a75156842404ecc03af47156dd48/si795.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/71e5a75156842404ecc03af47156dd48/si795.gif si801 si801.gif gif 124 10 10 ALTIMG 1-s2.0-S0885064X12000817-si204.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/63ece0456aa5abda63641ae91798941c/si296.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/63ece0456aa5abda63641ae91798941c/si296.gif si204 si204.gif gif 119 9 11 ALTIMG 1-s2.0-S0885064X12000817-si487.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/1a00c6bc7512c9470ff28b5e0402dfc3/si445.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/1a00c6bc7512c9470ff28b5e0402dfc3/si445.gif si487 si487.gif gif 145 10 17 ALTIMG 1-s2.0-S0885064X12000817-si316.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/3bc72098bcd1389c268902d0e633ffab/si273.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/3bc72098bcd1389c268902d0e633ffab/si273.gif si316 si316.gif gif 129 9 12 ALTIMG 1-s2.0-S0885064X12000817-si195.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/9f8d0f71c2ab0df6381d6e6bf2c3cf9a/si195.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/9f8d0f71c2ab0df6381d6e6bf2c3cf9a/si195.gif si195 si195.gif gif 243 13 55 ALTIMG 1-s2.0-S0885064X12000817-si774.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/89845a6dba12661e49294e0bcfc49f48/si828.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/89845a6dba12661e49294e0bcfc49f48/si828.gif si774 si774.gif gif 133 10 14 ALTIMG 1-s2.0-S0885064X12000817-si761.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/af23308881ae73dffd04fc8cf357ac4e/si761.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/af23308881ae73dffd04fc8cf357ac4e/si761.gif si761 si761.gif gif 911 13 259 ALTIMG 1-s2.0-S0885064X12000817-si67.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/2ed7f73dd2bd8db9c4b3356ff02ff512/si67.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/2ed7f73dd2bd8db9c4b3356ff02ff512/si67.gif si67 si67.gif gif 580 13 182 ALTIMG 1-s2.0-S0885064X12000817-si616.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/415b630f3282f155c9575347f77a2f29/si616.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/415b630f3282f155c9575347f77a2f29/si616.gif si616 si616.gif gif 142 13 14 ALTIMG 1-s2.0-S0885064X12000817-si709.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/8e338df725da1d240b7a2635bafb8a99/si709.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/8e338df725da1d240b7a2635bafb8a99/si709.gif si709 si709.gif gif 325 15 68 ALTIMG 1-s2.0-S0885064X12000817-si103.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/02b91199e263bc8fc1c3a139c35cc4a8/si103.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/02b91199e263bc8fc1c3a139c35cc4a8/si103.gif si103 si103.gif gif 291 13 64 ALTIMG 1-s2.0-S0885064X12000817-si186.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/90dd794fd0fb362a06f392454d68cc48/si94.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/90dd794fd0fb362a06f392454d68cc48/si94.gif si186 si186.gif gif 161 12 19 ALTIMG 1-s2.0-S0885064X12000817-si246.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/8904ff5535f18a62016bd300d0eb6f8a/si348.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/8904ff5535f18a62016bd300d0eb6f8a/si348.gif si246 si246.gif gif 144 9 17 ALTIMG 1-s2.0-S0885064X12000817-si401.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/03331b92e0704b90bd4dc406696ff940/si401.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/03331b92e0704b90bd4dc406696ff940/si401.gif si401 si401.gif gif 152 12 17 ALTIMG 1-s2.0-S0885064X12000817-si673.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/4b9f5f5a22875874e2e0bc0978e8ea8e/si673.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/4b9f5f5a22875874e2e0bc0978e8ea8e/si673.gif si673 si673.gif gif 129 9 12 ALTIMG 1-s2.0-S0885064X12000817-si210.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/c913cbd1f96407d3e6f3681af1005f61/si210.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/c913cbd1f96407d3e6f3681af1005f61/si210.gif si210 si210.gif gif 874 39 176 ALTIMG 1-s2.0-S0885064X12000817-si686.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/9fe72274a74a1cfb8dd09039e1c20d29/si686.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/9fe72274a74a1cfb8dd09039e1c20d29/si686.gif si686 si686.gif gif 561 13 161 ALTIMG 1-s2.0-S0885064X12000817-si669.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/406ce83e22dfe59af2b80988a04a9867/si663.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/406ce83e22dfe59af2b80988a04a9867/si663.gif si669 si669.gif gif 298 13 84 ALTIMG 1-s2.0-S0885064X12000817-si182.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/582abf87b6b4f911eb9f775560dc132f/si182.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/582abf87b6b4f911eb9f775560dc132f/si182.gif si182 si182.gif gif 1099 22 304 ALTIMG 1-s2.0-S0885064X12000817-si257.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/751298c4de9f0dfec04f9ba577dcdb1e/si73.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/751298c4de9f0dfec04f9ba577dcdb1e/si73.gif si257 si257.gif gif 125 9 13 ALTIMG 1-s2.0-S0885064X12000817-si92.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/60e61b3db2afc03f1f6127b372f41412/si92.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/60e61b3db2afc03f1f6127b372f41412/si92.gif si92 si92.gif gif 189 13 33 ALTIMG 1-s2.0-S0885064X12000817-si71.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/63ece0456aa5abda63641ae91798941c/si296.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/63ece0456aa5abda63641ae91798941c/si296.gif si71 si71.gif gif 119 9 11 ALTIMG 1-s2.0-S0885064X12000817-si314.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/63ece0456aa5abda63641ae91798941c/si296.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/63ece0456aa5abda63641ae91798941c/si296.gif si314 si314.gif gif 119 9 11 ALTIMG 1-s2.0-S0885064X12000817-si597.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/8904ff5535f18a62016bd300d0eb6f8a/si348.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/8904ff5535f18a62016bd300d0eb6f8a/si348.gif si597 si597.gif gif 144 9 17 ALTIMG 1-s2.0-S0885064X12000817-si312.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/b8202070dd358e256851896756ecd413/si312.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/b8202070dd358e256851896756ecd413/si312.gif si312 si312.gif gif 538 14 171 ALTIMG 1-s2.0-S0885064X12000817-si174.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/99528987eb957c9efaa7717c99428bad/si174.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/99528987eb957c9efaa7717c99428bad/si174.gif si174 si174.gif gif 773 13 240 ALTIMG 1-s2.0-S0885064X12000817-si417.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/f00927c8b614f951b0984958e9e402ec/si417.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/f00927c8b614f951b0984958e9e402ec/si417.gif si417 si417.gif gif 179 7 44 ALTIMG 1-s2.0-S0885064X12000817-si17.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/66173c4d94832e5cbf84ccec95a8004a/si31.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/66173c4d94832e5cbf84ccec95a8004a/si31.gif si17 si17.gif gif 119 9 11 ALTIMG 1-s2.0-S0885064X12000817-si286.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/896f840cb310b9156e45afd0d7e04bd8/si127.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/896f840cb310b9156e45afd0d7e04bd8/si127.gif si286 si286.gif gif 187 13 35 ALTIMG 1-s2.0-S0885064X12000817-si512.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/e152b692f4a8fdc593d1888b3d1336ad/si512.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/e152b692f4a8fdc593d1888b3d1336ad/si512.gif si512 si512.gif gif 254 12 60 ALTIMG 1-s2.0-S0885064X12000817-si693.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/8ec87f93764d33aa553fc00619dfc547/si693.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/8ec87f93764d33aa553fc00619dfc547/si693.gif si693 si693.gif gif 944 14 316 ALTIMG 1-s2.0-S0885064X12000817-si765.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/202d7c0c03b6e091b6985fa694bd328b/si765.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/202d7c0c03b6e091b6985fa694bd328b/si765.gif si765 si765.gif gif 453 13 132 ALTIMG 1-s2.0-S0885064X12000817-si49.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/66173c4d94832e5cbf84ccec95a8004a/si31.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/66173c4d94832e5cbf84ccec95a8004a/si31.gif si49 si49.gif gif 119 9 11 ALTIMG 1-s2.0-S0885064X12000817-si582.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/56daf6554e0016a4bca39427a1ea5c96/si582.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/56daf6554e0016a4bca39427a1ea5c96/si582.gif si582 si582.gif gif 1035 46 208 ALTIMG 1-s2.0-S0885064X12000817-si552.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/7b5c2dc5441c2902f815df0074d9e8a0/si575.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/7b5c2dc5441c2902f815df0074d9e8a0/si575.gif si552 si552.gif gif 155 13 18 ALTIMG 1-s2.0-S0885064X12000817-si775.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/63ece0456aa5abda63641ae91798941c/si296.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/63ece0456aa5abda63641ae91798941c/si296.gif si775 si775.gif gif 119 9 11 ALTIMG 1-s2.0-S0885064X12000817-si715.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/197ec0b9303f842da9b9490819cc3820/si715.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/197ec0b9303f842da9b9490819cc3820/si715.gif si715 si715.gif gif 466 14 142 ALTIMG 1-s2.0-S0885064X12000817-si578.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/b07fa0c1b6607d55b52d1bb9df65c1d9/si578.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/b07fa0c1b6607d55b52d1bb9df65c1d9/si578.gif si578 si578.gif gif 884 17 305 ALTIMG 1-s2.0-S0885064X12000817-si4.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/d4226f2a1e9b45b0da7d2c8e1fea4a68/si4.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/d4226f2a1e9b45b0da7d2c8e1fea4a68/si4.gif si4 si4.gif gif 130 10 12 ALTIMG 1-s2.0-S0885064X12000817-si53.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/d486d1c0b421e5bb77751a2c688b1c03/si53.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/d486d1c0b421e5bb77751a2c688b1c03/si53.gif si53 si53.gif gif 152 11 20 ALTIMG 1-s2.0-S0885064X12000817-si547.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/5e488c0922e620286eaa26f4330154e3/si547.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/5e488c0922e620286eaa26f4330154e3/si547.gif si547 si547.gif gif 1540 44 384 ALTIMG 1-s2.0-S0885064X12000817-si797.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/e90fce70ff8c553749981341656b34c0/si797.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/e90fce70ff8c553749981341656b34c0/si797.gif si797 si797.gif gif 460 31 92 ALTIMG 1-s2.0-S0885064X12000817-si100.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/72263b01d31bb1d9d1f5c4240a1f32b0/si100.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/72263b01d31bb1d9d1f5c4240a1f32b0/si100.gif si100 si100.gif gif 136 11 14 ALTIMG 1-s2.0-S0885064X12000817-si248.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/6b9fb19ba3d7aa458e6281413b7832bc/si248.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/6b9fb19ba3d7aa458e6281413b7832bc/si248.gif si248 si248.gif gif 615 16 200 ALTIMG 1-s2.0-S0885064X12000817-si806.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/c9fd88604b83220c4101c88f776b8a5b/si806.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/c9fd88604b83220c4101c88f776b8a5b/si806.gif si806 si806.gif gif 942 39 194 ALTIMG 1-s2.0-S0885064X12000817-si168.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/3bc72098bcd1389c268902d0e633ffab/si273.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/3bc72098bcd1389c268902d0e633ffab/si273.gif si168 si168.gif gif 129 9 12 ALTIMG 1-s2.0-S0885064X12000817-si720.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/c1b924f67f4a4ed67090637165178cb6/si720.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/c1b924f67f4a4ed67090637165178cb6/si720.gif si720 si720.gif gif 182 16 36 ALTIMG 1-s2.0-S0885064X12000817-si516.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/cace16a0339a853d94d7de145fb20546/si516.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/cace16a0339a853d94d7de145fb20546/si516.gif si516 si516.gif gif 1064 14 471 ALTIMG 1-s2.0-S0885064X12000817-si78.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/5cad8b5580bdc221fd2c0043d70f9296/si38.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/5cad8b5580bdc221fd2c0043d70f9296/si38.gif si78 si78.gif gif 268 13 52 ALTIMG 1-s2.0-S0885064X12000817-si222.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/c69c0a5b19c5e984b8527487a5bda3ba/si222.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/c69c0a5b19c5e984b8527487a5bda3ba/si222.gif si222 si222.gif gif 205 13 32 ALTIMG 1-s2.0-S0885064X12000817-si335.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/dcb3146a9b7427fe8a169a09710aae51/si335.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/dcb3146a9b7427fe8a169a09710aae51/si335.gif si335 si335.gif gif 184 11 33 ALTIMG 1-s2.0-S0885064X12000817-si138.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/ae4348d2405d949eba06d864476458af/si96.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/ae4348d2405d949eba06d864476458af/si96.gif si138 si138.gif gif 129 9 12 ALTIMG 1-s2.0-S0885064X12000817-si605.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/af41df7eb017df1543520cf9de3ba850/si605.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/af41df7eb017df1543520cf9de3ba850/si605.gif si605 si605.gif gif 1783 41 442 ALTIMG 1-s2.0-S0885064X12000817-si229.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/a2b5df91a7521eb6a69e94be3685bce4/si221.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/a2b5df91a7521eb6a69e94be3685bce4/si221.gif si229 si229.gif gif 206 13 33 ALTIMG 1-s2.0-S0885064X12000817-si294.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/ae4348d2405d949eba06d864476458af/si96.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/ae4348d2405d949eba06d864476458af/si96.gif si294 si294.gif gif 129 9 12 ALTIMG 1-s2.0-S0885064X12000817-si178.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/49deda1d240c08ef627f867fd2913657/si178.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/49deda1d240c08ef627f867fd2913657/si178.gif si178 si178.gif gif 1069 17 341 ALTIMG 1-s2.0-S0885064X12000817-si816.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/ea995469bcf6899fdb501c0115352f5b/si812.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/ea995469bcf6899fdb501c0115352f5b/si812.gif si816 si816.gif gif 192 13 41 ALTIMG 1-s2.0-S0885064X12000817-si184.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/96194d2df9edc924f22c0c5d25cf29ac/si184.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/96194d2df9edc924f22c0c5d25cf29ac/si184.gif si184 si184.gif gif 1588 19 502 ALTIMG 1-s2.0-S0885064X12000817-si57.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/96dea77ed14adab3aac6d201b472693c/si57.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/96dea77ed14adab3aac6d201b472693c/si57.gif si57 si57.gif gif 185 12 39 ALTIMG 1-s2.0-S0885064X12000817-si455.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/f0f4e69215155f0b069f046ff34f09c5/si455.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/f0f4e69215155f0b069f046ff34f09c5/si455.gif si455 si455.gif gif 149 17 15 ALTIMG 1-s2.0-S0885064X12000817-si682.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/a03994770f8921be76e18141c174d875/si682.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/a03994770f8921be76e18141c174d875/si682.gif si682 si682.gif gif 190 10 36 ALTIMG 1-s2.0-S0885064X12000817-si461.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/751298c4de9f0dfec04f9ba577dcdb1e/si73.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/751298c4de9f0dfec04f9ba577dcdb1e/si73.gif si461 si461.gif gif 125 9 13 ALTIMG 1-s2.0-S0885064X12000817-si264.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/a0ec9ca334406a3a6b79a9120e596f57/si264.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/a0ec9ca334406a3a6b79a9120e596f57/si264.gif si264 si264.gif gif 1320 16 453 ALTIMG 1-s2.0-S0885064X12000817-si238.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/e3e6c5f29c10574550b3feafe8980668/si238.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/e3e6c5f29c10574550b3feafe8980668/si238.gif si238 si238.gif gif 286 13 63 ALTIMG 1-s2.0-S0885064X12000817-si706.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/ae4348d2405d949eba06d864476458af/si96.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/ae4348d2405d949eba06d864476458af/si96.gif si706 si706.gif gif 129 9 12 ALTIMG 1-s2.0-S0885064X12000817-si492.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/1a00c6bc7512c9470ff28b5e0402dfc3/si445.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/1a00c6bc7512c9470ff28b5e0402dfc3/si445.gif si492 si492.gif gif 145 10 17 ALTIMG 1-s2.0-S0885064X12000817-si277.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/2b2276c92c2307d4b7aa8ac2819b5e62/si277.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/2b2276c92c2307d4b7aa8ac2819b5e62/si277.gif si277 si277.gif gif 716 13 245 ALTIMG 1-s2.0-S0885064X12000817-si691.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/db32fb86d4101a3bda0fe5de096e0583/si691.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/db32fb86d4101a3bda0fe5de096e0583/si691.gif si691 si691.gif gif 219 12 44 ALTIMG 1-s2.0-S0885064X12000817-si814.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/52edb67a3707afc8c7196b3872b7a14a/si814.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/52edb67a3707afc8c7196b3872b7a14a/si814.gif si814 si814.gif gif 294 16 68 ALTIMG 1-s2.0-S0885064X12000817-si527.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/13c135d2e157e9c64c644fb18d8b8fa2/si527.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/13c135d2e157e9c64c644fb18d8b8fa2/si527.gif si527 si527.gif gif 3601 153 397 ALTIMG 1-s2.0-S0885064X12000817-si602.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/85770d01b4dcafdd9c5f30de8f090e6a/si602.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/85770d01b4dcafdd9c5f30de8f090e6a/si602.gif si602 si602.gif gif 935 36 259 ALTIMG 1-s2.0-S0885064X12000817-si700.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/9b1ccc810b5ec23d64f2b3ecb4f4b391/si700.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/9b1ccc810b5ec23d64f2b3ecb4f4b391/si700.gif si700 si700.gif gif 138 12 12 ALTIMG 1-s2.0-S0885064X12000817-si149.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/53fa06966dd39944dd1bc47af76ca89d/si149.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/53fa06966dd39944dd1bc47af76ca89d/si149.gif si149 si149.gif gif 1250 15 403 ALTIMG 1-s2.0-S0885064X12000817-si620.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/a2f9749c229fd35abdd565cbbb49d30a/si620.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/a2f9749c229fd35abdd565cbbb49d30a/si620.gif si620 si620.gif gif 2259 58 503 ALTIMG 1-s2.0-S0885064X12000817-si38.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/5cad8b5580bdc221fd2c0043d70f9296/si38.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/5cad8b5580bdc221fd2c0043d70f9296/si38.gif si38 si38.gif gif 268 13 52 ALTIMG 1-s2.0-S0885064X12000817-si90.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/ae4348d2405d949eba06d864476458af/si96.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/ae4348d2405d949eba06d864476458af/si96.gif si90 si90.gif gif 129 9 12 ALTIMG 1-s2.0-S0885064X12000817-si324.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/83bffcf7f2c2fb8a1fe713d9c913af19/si324.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/83bffcf7f2c2fb8a1fe713d9c913af19/si324.gif si324 si324.gif gif 138 13 13 ALTIMG 1-s2.0-S0885064X12000817-si310.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/3bc72098bcd1389c268902d0e633ffab/si273.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/3bc72098bcd1389c268902d0e633ffab/si273.gif si310 si310.gif gif 129 9 12 ALTIMG 1-s2.0-S0885064X12000817-si390.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/337ed8e4054648b367992866786d53d5/si390.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/337ed8e4054648b367992866786d53d5/si390.gif si390 si390.gif gif 138 10 15 ALTIMG 1-s2.0-S0885064X12000817-si548.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/bb1a0fcd636e075a1a33fc3ed030d2df/si548.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/bb1a0fcd636e075a1a33fc3ed030d2df/si548.gif si548 si548.gif gif 1763 48 422 ALTIMG 1-s2.0-S0885064X12000817-si165.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/ae4348d2405d949eba06d864476458af/si96.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/ae4348d2405d949eba06d864476458af/si96.gif si165 si165.gif gif 129 9 12 ALTIMG 1-s2.0-S0885064X12000817-si355.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/7e41d89737891c2e29d01d76c408c5cb/si355.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/7e41d89737891c2e29d01d76c408c5cb/si355.gif si355 si355.gif gif 369 13 107 ALTIMG 1-s2.0-S0885064X12000817-si120.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/63ece0456aa5abda63641ae91798941c/si296.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/63ece0456aa5abda63641ae91798941c/si296.gif si120 si120.gif gif 119 9 11 ALTIMG 1-s2.0-S0885064X12000817-si440.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/c0040e88fefde949ccdb6c9bce7d8a88/si440.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/c0040e88fefde949ccdb6c9bce7d8a88/si440.gif si440 si440.gif gif 215 14 34 ALTIMG 1-s2.0-S0885064X12000817-si162.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/35f064e450d6ac1d8cda2fae725326e6/si162.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/35f064e450d6ac1d8cda2fae725326e6/si162.gif si162 si162.gif gif 554 13 203 ALTIMG 1-s2.0-S0885064X12000817-si555.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/2ccc3b95039be8bb620167c4943ef17f/si555.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/2ccc3b95039be8bb620167c4943ef17f/si555.gif si555 si555.gif gif 414 16 126 ALTIMG 1-s2.0-S0885064X12000817-si279.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/ae4348d2405d949eba06d864476458af/si96.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/ae4348d2405d949eba06d864476458af/si96.gif si279 si279.gif gif 129 9 12 ALTIMG 1-s2.0-S0885064X12000817-si379.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/b5ba923665738558a69d1a4bf09250e9/si379.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/b5ba923665738558a69d1a4bf09250e9/si379.gif si379 si379.gif gif 461 14 141 ALTIMG 1-s2.0-S0885064X12000817-si9.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/2a648c93d46dfdc7fdc3953db12a5fdb/si9.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/2a648c93d46dfdc7fdc3953db12a5fdb/si9.gif si9 si9.gif gif 276 13 69 ALTIMG 1-s2.0-S0885064X12000817-si18.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/0ed0ed94f5ca79964478355bab9dfe4d/si13.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/0ed0ed94f5ca79964478355bab9dfe4d/si13.gif si18 si18.gif gif 179 13 33 ALTIMG 1-s2.0-S0885064X12000817-si813.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/047983240be25ffc5f21107caa2fce26/si791.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/047983240be25ffc5f21107caa2fce26/si791.gif si813 si813.gif gif 216 12 44 ALTIMG 1-s2.0-S0885064X12000817-si689.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/8d2ebc5f496dee4f8c745d75169aaf4d/si689.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/8d2ebc5f496dee4f8c745d75169aaf4d/si689.gif si689 si689.gif gif 1410 19 460 ALTIMG 1-s2.0-S0885064X12000817-si242.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/d0c6c37b093e29b15cf0f9322fdbf553/si242.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/d0c6c37b093e29b15cf0f9322fdbf553/si242.gif si242 si242.gif gif 811 20 261 ALTIMG 1-s2.0-S0885064X12000817-si111.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/820f7812e0dba4c9b436a9394cc994cb/si111.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/820f7812e0dba4c9b436a9394cc994cb/si111.gif si111 si111.gif gif 295 15 65 ALTIMG 1-s2.0-S0885064X12000817-si769.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/d45b05f1c17bb5849d2412dfe2ae923d/si769.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/d45b05f1c17bb5849d2412dfe2ae923d/si769.gif si769 si769.gif gif 138 12 14 ALTIMG 1-s2.0-S0885064X12000817-si173.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/5509e3f6b4acf8845917813e4b666e2a/si173.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/5509e3f6b4acf8845917813e4b666e2a/si173.gif si173 si173.gif gif 631 19 164 ALTIMG 1-s2.0-S0885064X12000817-si189.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/a02b15922104eed964c8683a0ca2b5e1/si189.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/a02b15922104eed964c8683a0ca2b5e1/si189.gif si189 si189.gif gif 253 13 63 ALTIMG 1-s2.0-S0885064X12000817-si381.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/deb53688e3ce7f67f24deb3f9a7854b1/si381.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/deb53688e3ce7f67f24deb3f9a7854b1/si381.gif si381 si381.gif gif 174 7 40 ALTIMG 1-s2.0-S0885064X12000817-si442.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/f67b7772819bef7cccda2397fb93c882/si382.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/f67b7772819bef7cccda2397fb93c882/si382.gif si442 si442.gif gif 122 9 11 ALTIMG 1-s2.0-S0885064X12000817-si352.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/efb4a26f269f6187cddfca5d8ff86514/si352.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/efb4a26f269f6187cddfca5d8ff86514/si352.gif si352 si352.gif gif 247 14 55 ALTIMG 1-s2.0-S0885064X12000817-si20.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/2ede830df0579fdafe4ba02dad331dd2/si756.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/2ede830df0579fdafe4ba02dad331dd2/si756.gif si20 si20.gif gif 192 12 38 ALTIMG 1-s2.0-S0885064X12000817-si21.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/13f17bd982283b6715682c0c132932e0/si25.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/13f17bd982283b6715682c0c132932e0/si25.gif si21 si21.gif gif 134 13 17 ALTIMG 1-s2.0-S0885064X12000817-si367.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/7e41d89737891c2e29d01d76c408c5cb/si355.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/7e41d89737891c2e29d01d76c408c5cb/si355.gif si367 si367.gif gif 369 13 107 ALTIMG 1-s2.0-S0885064X12000817-si634.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/aff52a34e8e893d6fcc0dd5ee60c68b4/si634.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/aff52a34e8e893d6fcc0dd5ee60c68b4/si634.gif si634 si634.gif gif 457 14 143 ALTIMG 1-s2.0-S0885064X12000817-si462.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/ae4348d2405d949eba06d864476458af/si96.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/ae4348d2405d949eba06d864476458af/si96.gif si462 si462.gif gif 129 9 12 ALTIMG 1-s2.0-S0885064X12000817-si518.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/b199e9f06c6df4177030857fc59b3f35/si518.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/b199e9f06c6df4177030857fc59b3f35/si518.gif si518 si518.gif gif 130 13 10 ALTIMG 1-s2.0-S0885064X12000817-si465.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/e9f514ab43b93bbde8dbd58dbd0fb8c5/si465.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/e9f514ab43b93bbde8dbd58dbd0fb8c5/si465.gif si465 si465.gif gif 446 14 137 ALTIMG 1-s2.0-S0885064X12000817-si591.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/d07fcd20320a1bbdfb227f96020084f0/si591.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/d07fcd20320a1bbdfb227f96020084f0/si591.gif si591 si591.gif gif 158 7 34 ALTIMG 1-s2.0-S0885064X12000817-si723.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/263fbb301dbdad55629c35bd851d3ce1/si723.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/263fbb301dbdad55629c35bd851d3ce1/si723.gif si723 si723.gif gif 803 16 282 ALTIMG 1-s2.0-S0885064X12000817-si368.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/1893b54a2168d927bd83a59d595709f8/si368.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/1893b54a2168d927bd83a59d595709f8/si368.gif si368 si368.gif gif 729 19 210 ALTIMG 1-s2.0-S0885064X12000817-si787.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/4b9f5f5a22875874e2e0bc0978e8ea8e/si673.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/4b9f5f5a22875874e2e0bc0978e8ea8e/si673.gif si787 si787.gif gif 129 9 12 ALTIMG 1-s2.0-S0885064X12000817-si413.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/ae4348d2405d949eba06d864476458af/si96.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/ae4348d2405d949eba06d864476458af/si96.gif si413 si413.gif gif 129 9 12 ALTIMG 1-s2.0-S0885064X12000817-si666.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/63ece0456aa5abda63641ae91798941c/si296.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/63ece0456aa5abda63641ae91798941c/si296.gif si666 si666.gif gif 119 9 11 ALTIMG 1-s2.0-S0885064X12000817-si626.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/eaf99b6e14e52c2b97b52fa8a02de5d2/si626.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/eaf99b6e14e52c2b97b52fa8a02de5d2/si626.gif si626 si626.gif gif 961 36 277 ALTIMG 1-s2.0-S0885064X12000817-si35.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/5cad8b5580bdc221fd2c0043d70f9296/si38.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/5cad8b5580bdc221fd2c0043d70f9296/si38.gif si35 si35.gif gif 268 13 52 ALTIMG 1-s2.0-S0885064X12000817-si441.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/816d5112b2a9ef7bb81ca5cb468f4d1b/si441.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/816d5112b2a9ef7bb81ca5cb468f4d1b/si441.gif si441 si441.gif gif 114 12 8 ALTIMG 1-s2.0-S0885064X12000817-si369.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/beafc28d7070b885950043831eec871c/si369.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/beafc28d7070b885950043831eec871c/si369.gif si369 si369.gif gif 247 14 53 ALTIMG 1-s2.0-S0885064X12000817-si219.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/378d0574eda471a21e801d62bc82fa0c/si677.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/378d0574eda471a21e801d62bc82fa0c/si677.gif si219 si219.gif gif 308 12 83 ALTIMG 1-s2.0-S0885064X12000817-si321.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/81f132463274c0d8d481b8d66296dfcc/si321.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/81f132463274c0d8d481b8d66296dfcc/si321.gif si321 si321.gif gif 131 16 12 ALTIMG 1-s2.0-S0885064X12000817-si24.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/66173c4d94832e5cbf84ccec95a8004a/si31.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/66173c4d94832e5cbf84ccec95a8004a/si31.gif si24 si24.gif gif 119 9 11 ALTIMG 1-s2.0-S0885064X12000817-si449.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/efa59dda6e5f6ce60520d67d8b3a4764/si449.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/efa59dda6e5f6ce60520d67d8b3a4764/si449.gif si449 si449.gif gif 117 9 11 ALTIMG 1-s2.0-S0885064X12000817-si498.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/8a38916b94518ec35a7813f35b98ab62/si498.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/8a38916b94518ec35a7813f35b98ab62/si498.gif si498 si498.gif gif 161 12 24 ALTIMG 1-s2.0-S0885064X12000817-si145.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/65203618546dfdb8bcd3a134e1c8ebd5/si145.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/65203618546dfdb8bcd3a134e1c8ebd5/si145.gif si145 si145.gif gif 659 14 233 ALTIMG 1-s2.0-S0885064X12000817-si419.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/ae4348d2405d949eba06d864476458af/si96.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/ae4348d2405d949eba06d864476458af/si96.gif si419 si419.gif gif 129 9 12 ALTIMG 1-s2.0-S0885064X12000817-si63.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/66173c4d94832e5cbf84ccec95a8004a/si31.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/66173c4d94832e5cbf84ccec95a8004a/si31.gif si63 si63.gif gif 119 9 11 ALTIMG 1-s2.0-S0885064X12000817-si667.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/63ece0456aa5abda63641ae91798941c/si296.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/63ece0456aa5abda63641ae91798941c/si296.gif si667 si667.gif gif 119 9 11 ALTIMG 1-s2.0-S0885064X12000817-si696.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/6f036bf9effa27aef3c332cad2d9c850/si696.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/6f036bf9effa27aef3c332cad2d9c850/si696.gif si696 si696.gif gif 177 15 20 ALTIMG 1-s2.0-S0885064X12000817-si575.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/7b5c2dc5441c2902f815df0074d9e8a0/si575.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/7b5c2dc5441c2902f815df0074d9e8a0/si575.gif si575 si575.gif gif 155 13 18 ALTIMG 1-s2.0-S0885064X12000817-si323.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/46cf2497f9fdc81f13662b4d477f37c0/si323.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/46cf2497f9fdc81f13662b4d477f37c0/si323.gif si323 si323.gif gif 781 16 272 ALTIMG 1-s2.0-S0885064X12000817-si503.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/4fb0d8f1b07e27552b20349d7762fc5c/si503.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/4fb0d8f1b07e27552b20349d7762fc5c/si503.gif si503 si503.gif gif 287 13 81 ALTIMG 1-s2.0-S0885064X12000817-si554.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/2ede830df0579fdafe4ba02dad331dd2/si756.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/2ede830df0579fdafe4ba02dad331dd2/si756.gif si554 si554.gif gif 192 12 38 ALTIMG 1-s2.0-S0885064X12000817-si619.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/ab3c1a6c41e064a59cc97878745f51cf/si619.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/ab3c1a6c41e064a59cc97878745f51cf/si619.gif si619 si619.gif gif 1249 34 371 ALTIMG 1-s2.0-S0885064X12000817-si707.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/63ece0456aa5abda63641ae91798941c/si296.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/63ece0456aa5abda63641ae91798941c/si296.gif si707 si707.gif gif 119 9 11 ALTIMG 1-s2.0-S0885064X12000817-si370.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/96116837833610f73260856c8e0e316d/si370.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/96116837833610f73260856c8e0e316d/si370.gif si370 si370.gif gif 605 14 188 ALTIMG 1-s2.0-S0885064X12000817-si433.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/21bc58ae6d9269402e318c789efb4fdf/si433.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/21bc58ae6d9269402e318c789efb4fdf/si433.gif si433 si433.gif gif 171 13 32 ALTIMG 1-s2.0-S0885064X12000817-si636.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/fa7294ae26b0c7140f35c1d25367990a/si636.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/fa7294ae26b0c7140f35c1d25367990a/si636.gif si636 si636.gif gif 685 22 157 ALTIMG 1-s2.0-S0885064X12000817-si601.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/faf9c2b2efa2a32e366a836413ae6981/si601.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/faf9c2b2efa2a32e366a836413ae6981/si601.gif si601 si601.gif gif 461 16 131 ALTIMG 1-s2.0-S0885064X12000817-si435.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/755180b49e65cfed33b2d563edf537e9/si435.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/755180b49e65cfed33b2d563edf537e9/si435.gif si435 si435.gif gif 223 15 40 ALTIMG 1-s2.0-S0885064X12000817-si292.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/300ec462932745b768d11a3a48b6e853/si608.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/300ec462932745b768d11a3a48b6e853/si608.gif si292 si292.gif gif 200 10 41 ALTIMG 1-s2.0-S0885064X12000817-si247.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/7e41d89737891c2e29d01d76c408c5cb/si355.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/7e41d89737891c2e29d01d76c408c5cb/si355.gif si247 si247.gif gif 369 13 107 ALTIMG 1-s2.0-S0885064X12000817-si570.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/4599e8254b56c9dbe63850b7072986d9/si623.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/4599e8254b56c9dbe63850b7072986d9/si623.gif si570 si570.gif gif 131 12 10 ALTIMG 1-s2.0-S0885064X12000817-si504.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/590400350b3644fd4c701b2f67e0841a/si504.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/590400350b3644fd4c701b2f67e0841a/si504.gif si504 si504.gif gif 1266 16 477 ALTIMG 1-s2.0-S0885064X12000817-si595.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/0a915e4278154a560f5f50a29c204dd4/si595.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/0a915e4278154a560f5f50a29c204dd4/si595.gif si595 si595.gif gif 396 16 95 ALTIMG 1-s2.0-S0885064X12000817-si74.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/63ece0456aa5abda63641ae91798941c/si296.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/63ece0456aa5abda63641ae91798941c/si296.gif si74 si74.gif gif 119 9 11 ALTIMG 1-s2.0-S0885064X12000817-si561.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/7b5c2dc5441c2902f815df0074d9e8a0/si575.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/7b5c2dc5441c2902f815df0074d9e8a0/si575.gif si561 si561.gif gif 155 13 18 ALTIMG 1-s2.0-S0885064X12000817-si306.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/cf8c51035a31ee9ac734946964d3534d/si272.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/cf8c51035a31ee9ac734946964d3534d/si272.gif si306 si306.gif gif 128 9 11 ALTIMG 1-s2.0-S0885064X12000817-si27.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/ae4348d2405d949eba06d864476458af/si96.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/ae4348d2405d949eba06d864476458af/si96.gif si27 si27.gif gif 129 9 12 ALTIMG 1-s2.0-S0885064X12000817-si116.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/751298c4de9f0dfec04f9ba577dcdb1e/si73.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/751298c4de9f0dfec04f9ba577dcdb1e/si73.gif si116 si116.gif gif 125 9 13 ALTIMG 1-s2.0-S0885064X12000817-si105.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/b2d50eaaf1ce49cb24f6dacbfb486ebf/si105.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/b2d50eaaf1ce49cb24f6dacbfb486ebf/si105.gif si105 si105.gif gif 233 13 42 ALTIMG 1-s2.0-S0885064X12000817-si326.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/c54498d49cf4512e0342c7528535fcb3/si326.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/c54498d49cf4512e0342c7528535fcb3/si326.gif si326 si326.gif gif 587 19 177 ALTIMG 1-s2.0-S0885064X12000817-si271.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/3bc72098bcd1389c268902d0e633ffab/si273.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/3bc72098bcd1389c268902d0e633ffab/si273.gif si271 si271.gif gif 129 9 12 ALTIMG 1-s2.0-S0885064X12000817-si81.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/751298c4de9f0dfec04f9ba577dcdb1e/si73.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/751298c4de9f0dfec04f9ba577dcdb1e/si73.gif si81 si81.gif gif 125 9 13 ALTIMG 1-s2.0-S0885064X12000817-si73.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/751298c4de9f0dfec04f9ba577dcdb1e/si73.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/751298c4de9f0dfec04f9ba577dcdb1e/si73.gif si73 si73.gif gif 125 9 13 ALTIMG 1-s2.0-S0885064X12000817-si132.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/dd779915c6e30f5b5f90c2a02f6cab62/si132.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/dd779915c6e30f5b5f90c2a02f6cab62/si132.gif si132 si132.gif gif 810 15 235 ALTIMG 1-s2.0-S0885064X12000817-si214.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/036cb9b90893cef26c00380719427644/si214.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/036cb9b90893cef26c00380719427644/si214.gif si214 si214.gif gif 141 10 16 ALTIMG 1-s2.0-S0885064X12000817-si481.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/ae4348d2405d949eba06d864476458af/si96.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/ae4348d2405d949eba06d864476458af/si96.gif si481 si481.gif gif 129 9 12 ALTIMG 1-s2.0-S0885064X12000817-si234.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/1c49230aaaefd75576dce556a1cdd7ed/si234.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/1c49230aaaefd75576dce556a1cdd7ed/si234.gif si234 si234.gif gif 192 14 35 ALTIMG 1-s2.0-S0885064X12000817-si336.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/f75b57cad78f2fd5e22dbbbab0b62afe/si336.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/f75b57cad78f2fd5e22dbbbab0b62afe/si336.gif si336 si336.gif gif 293 13 75 ALTIMG 1-s2.0-S0885064X12000817-si505.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/1a00c6bc7512c9470ff28b5e0402dfc3/si445.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/1a00c6bc7512c9470ff28b5e0402dfc3/si445.gif si505 si505.gif gif 145 10 17 ALTIMG 1-s2.0-S0885064X12000817-si491.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/adf9f160eb3b4caac083bed24736e238/si491.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/adf9f160eb3b4caac083bed24736e238/si491.gif si491 si491.gif gif 275 15 67 ALTIMG 1-s2.0-S0885064X12000817-si343.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/5881b33bee72407ede4c391a06a0e513/si343.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/5881b33bee72407ede4c391a06a0e513/si343.gif si343 si343.gif gif 221 19 38 ALTIMG 1-s2.0-S0885064X12000817-si596.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/b9d70c697c5f4ae06caa1fd15402e705/si278.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/b9d70c697c5f4ae06caa1fd15402e705/si278.gif si596 si596.gif gif 193 13 27 ALTIMG 1-s2.0-S0885064X12000817-si558.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/a12d5a4cbf98620367d762d85dbc147a/si558.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/a12d5a4cbf98620367d762d85dbc147a/si558.gif si558 si558.gif gif 132 13 12 ALTIMG 1-s2.0-S0885064X12000817-si727.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/1ece728896ad93d8a560fa43a3e1bff8/si727.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/1ece728896ad93d8a560fa43a3e1bff8/si727.gif si727 si727.gif gif 212 12 42 ALTIMG 1-s2.0-S0885064X12000817-si101.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/fe36d98ef9cea9126dca5804b15a1f58/si101.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/fe36d98ef9cea9126dca5804b15a1f58/si101.gif si101 si101.gif gif 138 11 14 ALTIMG 1-s2.0-S0885064X12000817-si724.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/97da6e4af7f5b342ec402e9a5c410a6c/si724.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/97da6e4af7f5b342ec402e9a5c410a6c/si724.gif si724 si724.gif gif 202 11 42 ALTIMG 1-s2.0-S0885064X12000817-si333.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/e7b2049919ac7d1651aa15d16c395b4f/si333.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/e7b2049919ac7d1651aa15d16c395b4f/si333.gif si333 si333.gif gif 413 32 126 ALTIMG 1-s2.0-S0885064X12000817-si339.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/f1e6c2df4c4d44ed1fe4538895bc639e/si339.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/f1e6c2df4c4d44ed1fe4538895bc639e/si339.gif si339 si339.gif gif 890 47 190 ALTIMG 1-s2.0-S0885064X12000817-si366.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/63ece0456aa5abda63641ae91798941c/si296.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/63ece0456aa5abda63641ae91798941c/si296.gif si366 si366.gif gif 119 9 11 ALTIMG 1-s2.0-S0885064X12000817-si671.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/aeeb9bd5c61186cf1bb64b87cb655154/si671.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/aeeb9bd5c61186cf1bb64b87cb655154/si671.gif si671 si671.gif gif 303 15 83 ALTIMG 1-s2.0-S0885064X12000817-si79.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/ae4348d2405d949eba06d864476458af/si96.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/ae4348d2405d949eba06d864476458af/si96.gif si79 si79.gif gif 129 9 12 ALTIMG 1-s2.0-S0885064X12000817-si207.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/751298c4de9f0dfec04f9ba577dcdb1e/si73.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/751298c4de9f0dfec04f9ba577dcdb1e/si73.gif si207 si207.gif gif 125 9 13 ALTIMG 1-s2.0-S0885064X12000817-si782.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/89845a6dba12661e49294e0bcfc49f48/si828.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/89845a6dba12661e49294e0bcfc49f48/si828.gif si782 si782.gif gif 133 10 14 ALTIMG 1-s2.0-S0885064X12000817-si50.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/66173c4d94832e5cbf84ccec95a8004a/si31.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/66173c4d94832e5cbf84ccec95a8004a/si31.gif si50 si50.gif gif 119 9 11 ALTIMG 1-s2.0-S0885064X12000817-si610.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/ae4348d2405d949eba06d864476458af/si96.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/ae4348d2405d949eba06d864476458af/si96.gif si610 si610.gif gif 129 9 12 ALTIMG 1-s2.0-S0885064X12000817-si16.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/7a873957b9b40db39aea3e23381595bd/si16.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/7a873957b9b40db39aea3e23381595bd/si16.gif si16 si16.gif gif 156 13 32 ALTIMG 1-s2.0-S0885064X12000817-si553.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/ae4348d2405d949eba06d864476458af/si96.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/ae4348d2405d949eba06d864476458af/si96.gif si553 si553.gif gif 129 9 12 ALTIMG 1-s2.0-S0885064X12000817-si773.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/d45b05f1c17bb5849d2412dfe2ae923d/si769.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/d45b05f1c17bb5849d2412dfe2ae923d/si769.gif si773 si773.gif gif 138 12 14 ALTIMG 1-s2.0-S0885064X12000817-si11.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/8b0f3f3abcf91d1e8eb25c7b7e20c0fd/si11.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/8b0f3f3abcf91d1e8eb25c7b7e20c0fd/si11.gif si11 si11.gif gif 432 13 116 ALTIMG 1-s2.0-S0885064X12000817-si781.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/9f75521a62ec050de35f56bdf510e820/si781.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/9f75521a62ec050de35f56bdf510e820/si781.gif si781 si781.gif gif 319 13 93 ALTIMG 1-s2.0-S0885064X12000817-si233.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/4b73b9141f7cd7c2c3e94f0965ffdff7/si233.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/4b73b9141f7cd7c2c3e94f0965ffdff7/si233.gif si233 si233.gif gif 189 12 35 ALTIMG 1-s2.0-S0885064X12000817-si220.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/4342d3b8ac6efc7d94fa2214c9620a90/si678.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/4342d3b8ac6efc7d94fa2214c9620a90/si678.gif si220 si220.gif gif 214 12 41 ALTIMG 1-s2.0-S0885064X12000817-si403.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/bca983ec30fd064bf7807af181470534/si403.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/bca983ec30fd064bf7807af181470534/si403.gif si403 si403.gif gif 1861 51 519 ALTIMG 1-s2.0-S0885064X12000817-si612.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/579d2604a5cc4e618a9f707128f8b274/si612.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/579d2604a5cc4e618a9f707128f8b274/si612.gif si612 si612.gif gif 493 14 140 ALTIMG 1-s2.0-S0885064X12000817-si776.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/896f840cb310b9156e45afd0d7e04bd8/si127.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/896f840cb310b9156e45afd0d7e04bd8/si127.gif si776 si776.gif gif 187 13 35 ALTIMG 1-s2.0-S0885064X12000817-si507.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/a12a400fcab9198c7a10187a1987d9a4/si507.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/a12a400fcab9198c7a10187a1987d9a4/si507.gif si507 si507.gif gif 426 15 126 ALTIMG 1-s2.0-S0885064X12000817-si394.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/68f40a241fba3c7e6a5b1dd47aa14723/si394.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/68f40a241fba3c7e6a5b1dd47aa14723/si394.gif si394 si394.gif gif 250 13 54 ALTIMG 1-s2.0-S0885064X12000817-si791.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/047983240be25ffc5f21107caa2fce26/si791.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/047983240be25ffc5f21107caa2fce26/si791.gif si791 si791.gif gif 216 12 44 ALTIMG 1-s2.0-S0885064X12000817-si500.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/82c31b82a724f1c55bf0f283d08488f9/si500.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/82c31b82a724f1c55bf0f283d08488f9/si500.gif si500 si500.gif gif 753 17 226 ALTIMG 1-s2.0-S0885064X12000817-si382.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/f67b7772819bef7cccda2397fb93c882/si382.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/f67b7772819bef7cccda2397fb93c882/si382.gif si382 si382.gif gif 122 9 11 ALTIMG 1-s2.0-S0885064X12000817-si409.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/506f9dc3b66f28bbe5d44de4c9e54936/si453.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/506f9dc3b66f28bbe5d44de4c9e54936/si453.gif si409 si409.gif gif 191 10 39 ALTIMG 1-s2.0-S0885064X12000817-si477.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/217bb3b19547f6b2200b4e668476a049/si477.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/217bb3b19547f6b2200b4e668476a049/si477.gif si477 si477.gif gif 231 13 49 ALTIMG 1-s2.0-S0885064X12000817-si407.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/ae4348d2405d949eba06d864476458af/si96.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/ae4348d2405d949eba06d864476458af/si96.gif si407 si407.gif gif 129 9 12 ALTIMG 1-s2.0-S0885064X12000817-si562.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/55ff6c8de1257194b8fc7009528c5eaf/si562.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/55ff6c8de1257194b8fc7009528c5eaf/si562.gif si562 si562.gif gif 651 31 156 ALTIMG 1-s2.0-S0885064X12000817-si68.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/63ece0456aa5abda63641ae91798941c/si296.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/63ece0456aa5abda63641ae91798941c/si296.gif si68 si68.gif gif 119 9 11 ALTIMG 1-s2.0-S0885064X12000817-si263.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/7a2b60190a907e87929841f2f352a8bf/si717.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/7a2b60190a907e87929841f2f352a8bf/si717.gif si263 si263.gif gif 190 12 38 ALTIMG 1-s2.0-S0885064X12000817-si275.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/751298c4de9f0dfec04f9ba577dcdb1e/si73.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/751298c4de9f0dfec04f9ba577dcdb1e/si73.gif si275 si275.gif gif 125 9 13 ALTIMG 1-s2.0-S0885064X12000817-si600.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/2de432773272c260418229d2a2d8dbd7/si600.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/2de432773272c260418229d2a2d8dbd7/si600.gif si600 si600.gif gif 1272 19 382 ALTIMG 1-s2.0-S0885064X12000817-si439.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/875441e00744c6508836e569b9812490/si439.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/875441e00744c6508836e569b9812490/si439.gif si439 si439.gif gif 1388 47 329 ALTIMG 1-s2.0-S0885064X12000817-si244.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/63ece0456aa5abda63641ae91798941c/si296.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/63ece0456aa5abda63641ae91798941c/si296.gif si244 si244.gif gif 119 9 11 ALTIMG 1-s2.0-S0885064X12000817-si574.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/1f9eefde61a003079e8b9215dcd5c868/si560.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/1f9eefde61a003079e8b9215dcd5c868/si560.gif si574 si574.gif gif 119 12 11 ALTIMG 1-s2.0-S0885064X12000817-si331.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/76f3dda1ddf0422fafe2d922443907b7/si331.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/76f3dda1ddf0422fafe2d922443907b7/si331.gif si331 si331.gif gif 911 16 371 ALTIMG 1-s2.0-S0885064X12000817-si587.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/8904ff5535f18a62016bd300d0eb6f8a/si348.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/8904ff5535f18a62016bd300d0eb6f8a/si348.gif si587 si587.gif gif 144 9 17 ALTIMG 1-s2.0-S0885064X12000817-si807.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/872b33abf2c313763971bdd43320cdee/si807.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/872b33abf2c313763971bdd43320cdee/si807.gif si807 si807.gif gif 885 39 193 ALTIMG 1-s2.0-S0885064X12000817-si767.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/be823f9b7dcd1f0db68386d2948a84bb/si767.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/be823f9b7dcd1f0db68386d2948a84bb/si767.gif si767 si767.gif gif 143 10 17 ALTIMG 1-s2.0-S0885064X12000817-si697.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/02fe1641db45c94a1bffb31615fef317/si697.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/02fe1641db45c94a1bffb31615fef317/si697.gif si697 si697.gif gif 1323 13 514 ALTIMG 1-s2.0-S0885064X12000817-si114.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/39d3d03e9050bd198f3405a1237fdc5a/si114.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/39d3d03e9050bd198f3405a1237fdc5a/si114.gif si114 si114.gif gif 137 12 13 ALTIMG 1-s2.0-S0885064X12000817-si363.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/61b55f51f102231edb3ac3aba798ab06/si363.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/61b55f51f102231edb3ac3aba798ab06/si363.gif si363 si363.gif gif 1153 17 356 ALTIMG 1-s2.0-S0885064X12000817-si785.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/85aa505bcc6f019adced4af83ce6949c/si785.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/85aa505bcc6f019adced4af83ce6949c/si785.gif si785 si785.gif gif 126 11 13 ALTIMG 1-s2.0-S0885064X12000817-si109.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/700a3cdb8f810c38bf74060087a1c682/si109.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/700a3cdb8f810c38bf74060087a1c682/si109.gif si109 si109.gif gif 610 14 196 ALTIMG 1-s2.0-S0885064X12000817-si569.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/7b5c2dc5441c2902f815df0074d9e8a0/si575.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/7b5c2dc5441c2902f815df0074d9e8a0/si575.gif si569 si569.gif gif 155 13 18 ALTIMG 1-s2.0-S0885064X12000817-si757.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/1ece728896ad93d8a560fa43a3e1bff8/si727.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/1ece728896ad93d8a560fa43a3e1bff8/si727.gif si757 si757.gif gif 212 12 42 ALTIMG 1-s2.0-S0885064X12000817-si606.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/1560a0dee6a122fc0bbb9e785000aeff/si598.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/1560a0dee6a122fc0bbb9e785000aeff/si598.gif si606 si606.gif gif 149 10 17 ALTIMG 1-s2.0-S0885064X12000817-si289.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/ae4348d2405d949eba06d864476458af/si96.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/ae4348d2405d949eba06d864476458af/si96.gif si289 si289.gif gif 129 9 12 ALTIMG 1-s2.0-S0885064X12000817-si231.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/751298c4de9f0dfec04f9ba577dcdb1e/si73.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/751298c4de9f0dfec04f9ba577dcdb1e/si73.gif si231 si231.gif gif 125 9 13 ALTIMG 1-s2.0-S0885064X12000817-si432.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/7435961564609ef67e7524148c60c461/si432.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/7435961564609ef67e7524148c60c461/si432.gif si432 si432.gif gif 317 13 89 ALTIMG 1-s2.0-S0885064X12000817-si480.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/ae4348d2405d949eba06d864476458af/si96.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/ae4348d2405d949eba06d864476458af/si96.gif si480 si480.gif gif 129 9 12 ALTIMG 1-s2.0-S0885064X12000817-si52.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/0ed0ed94f5ca79964478355bab9dfe4d/si13.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/0ed0ed94f5ca79964478355bab9dfe4d/si13.gif si52 si52.gif gif 179 13 33 ALTIMG 1-s2.0-S0885064X12000817-si466.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/ae4348d2405d949eba06d864476458af/si96.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/ae4348d2405d949eba06d864476458af/si96.gif si466 si466.gif gif 129 9 12 ALTIMG 1-s2.0-S0885064X12000817-si598.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/1560a0dee6a122fc0bbb9e785000aeff/si598.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/1560a0dee6a122fc0bbb9e785000aeff/si598.gif si598 si598.gif gif 149 10 17 ALTIMG 1-s2.0-S0885064X12000817-si779.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/c0acb5072b1936f27fa17938b3b81dd8/si779.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/c0acb5072b1936f27fa17938b3b81dd8/si779.gif si779 si779.gif gif 337 13 99 ALTIMG 1-s2.0-S0885064X12000817-si719.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/f67b7772819bef7cccda2397fb93c882/si382.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/f67b7772819bef7cccda2397fb93c882/si382.gif si719 si719.gif gif 122 9 11 ALTIMG 1-s2.0-S0885064X12000817-si483.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/1f842b41dba44d301ea56f853e70f1e9/si483.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/1f842b41dba44d301ea56f853e70f1e9/si483.gif si483 si483.gif gif 231 12 51 ALTIMG 1-s2.0-S0885064X12000817-si482.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/3c253f16993bba0ea7f82adb11b3cd5d/si651.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/3c253f16993bba0ea7f82adb11b3cd5d/si651.gif si482 si482.gif gif 108 7 8 ALTIMG 1-s2.0-S0885064X12000817-si577.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/8904ff5535f18a62016bd300d0eb6f8a/si348.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/8904ff5535f18a62016bd300d0eb6f8a/si348.gif si577 si577.gif gif 144 9 17 ALTIMG 1-s2.0-S0885064X12000817-si135.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/dd6022e9670d8f5142b693706aca5429/si135.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/dd6022e9670d8f5142b693706aca5429/si135.gif si135 si135.gif gif 322 13 76 ALTIMG 1-s2.0-S0885064X12000817-si391.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/31385b88da6a3315b88c75465a558111/si391.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/31385b88da6a3315b88c75465a558111/si391.gif si391 si391.gif gif 246 16 50 ALTIMG 1-s2.0-S0885064X12000817-si37.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/8dd17996a103dcb0ec695006f391022a/si37.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/8dd17996a103dcb0ec695006f391022a/si37.gif si37 si37.gif gif 149 13 24 ALTIMG 1-s2.0-S0885064X12000817-si821.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/89845a6dba12661e49294e0bcfc49f48/si828.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/89845a6dba12661e49294e0bcfc49f48/si828.gif si821 si821.gif gif 133 10 14 ALTIMG 1-s2.0-S0885064X12000817-si129.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/896f840cb310b9156e45afd0d7e04bd8/si127.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/896f840cb310b9156e45afd0d7e04bd8/si127.gif si129 si129.gif gif 187 13 35 ALTIMG 1-s2.0-S0885064X12000817-si241.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/3806112872b62b2017a6fa639dd48bb7/si236.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/3806112872b62b2017a6fa639dd48bb7/si236.gif si241 si241.gif gif 138 13 17 ALTIMG 1-s2.0-S0885064X12000817-si726.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/b27efe018e1d1429ccce4f75f05a74a1/si726.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/b27efe018e1d1429ccce4f75f05a74a1/si726.gif si726 si726.gif gif 417 13 110 ALTIMG 1-s2.0-S0885064X12000817-si631.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/49eace5b06bc6c48c9ab8510245c6ae4/si631.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/49eace5b06bc6c48c9ab8510245c6ae4/si631.gif si631 si631.gif gif 206 14 34 ALTIMG 1-s2.0-S0885064X12000817-si56.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/eed6a8d78ca7833f63086c62a193e7d4/si56.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/eed6a8d78ca7833f63086c62a193e7d4/si56.gif si56 si56.gif gif 209 13 44 ALTIMG 1-s2.0-S0885064X12000817-si69.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/751298c4de9f0dfec04f9ba577dcdb1e/si73.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/751298c4de9f0dfec04f9ba577dcdb1e/si73.gif si69 si69.gif gif 125 9 13 ALTIMG 1-s2.0-S0885064X12000817-si494.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/7752850cbe2303ec721ab2de8efeee42/si494.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/7752850cbe2303ec721ab2de8efeee42/si494.gif si494 si494.gif gif 313 15 78 ALTIMG 1-s2.0-S0885064X12000817-si687.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/e907541d8da504c547e7d18df73bd1f1/si687.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/e907541d8da504c547e7d18df73bd1f1/si687.gif si687 si687.gif gif 140 12 14 ALTIMG 1-s2.0-S0885064X12000817-si438.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/efa59dda6e5f6ce60520d67d8b3a4764/si449.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/efa59dda6e5f6ce60520d67d8b3a4764/si449.gif si438 si438.gif gif 117 9 11 ALTIMG 1-s2.0-S0885064X12000817-si54.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/66173c4d94832e5cbf84ccec95a8004a/si31.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/66173c4d94832e5cbf84ccec95a8004a/si31.gif si54 si54.gif gif 119 9 11 ALTIMG 1-s2.0-S0885064X12000817-si130.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/d82472e0f61b2e1b9622b880c35268f2/si130.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/d82472e0f61b2e1b9622b880c35268f2/si130.gif si130 si130.gif gif 575 13 163 ALTIMG 1-s2.0-S0885064X12000817-si754.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/d45b05f1c17bb5849d2412dfe2ae923d/si769.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/d45b05f1c17bb5849d2412dfe2ae923d/si769.gif si754 si754.gif gif 138 12 14 ALTIMG 1-s2.0-S0885064X12000817-si447.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/1e758441d7875ded13bd7a7b938d172b/si447.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/1e758441d7875ded13bd7a7b938d172b/si447.gif si447 si447.gif gif 289 13 76 ALTIMG 1-s2.0-S0885064X12000817-si2.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/66173c4d94832e5cbf84ccec95a8004a/si31.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/66173c4d94832e5cbf84ccec95a8004a/si31.gif si2 si2.gif gif 119 9 11 ALTIMG 1-s2.0-S0885064X12000817-si581.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/1eb47f5f3bd0e8debb05252e3dbdacb1/si581.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/1eb47f5f3bd0e8debb05252e3dbdacb1/si581.gif si581 si581.gif gif 914 17 318 ALTIMG 1-s2.0-S0885064X12000817-si65.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/6d3472cf641e930c3b2aa804279165ba/si55.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/6d3472cf641e930c3b2aa804279165ba/si55.gif si65 si65.gif gif 137 10 17 ALTIMG 1-s2.0-S0885064X12000817-si496.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/ae4348d2405d949eba06d864476458af/si96.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/ae4348d2405d949eba06d864476458af/si96.gif si496 si496.gif gif 129 9 12 ALTIMG 1-s2.0-S0885064X12000817-si8.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/d1c71abb49f4a111400e9cf6b01438e0/si8.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/d1c71abb49f4a111400e9cf6b01438e0/si8.gif si8 si8.gif gif 708 13 216 ALTIMG 1-s2.0-S0885064X12000817-si698.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/7578340ef224de23cafc1228a40ac227/si698.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/7578340ef224de23cafc1228a40ac227/si698.gif si698 si698.gif gif 111 6 9 ALTIMG 1-s2.0-S0885064X12000817-si429.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/9aa057fbe53bf97ce84892867e8f9954/si429.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/9aa057fbe53bf97ce84892867e8f9954/si429.gif si429 si429.gif gif 836 18 263 ALTIMG 1-s2.0-S0885064X12000817-si607.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/18a792a61ccebc59a6b6785b749f5abe/si607.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/18a792a61ccebc59a6b6785b749f5abe/si607.gif si607 si607.gif gif 219 16 42 ALTIMG 1-s2.0-S0885064X12000817-si5.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/0ed0ed94f5ca79964478355bab9dfe4d/si13.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/0ed0ed94f5ca79964478355bab9dfe4d/si13.gif si5 si5.gif gif 179 13 33 ALTIMG 1-s2.0-S0885064X12000817-si731.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/ae4348d2405d949eba06d864476458af/si96.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/ae4348d2405d949eba06d864476458af/si96.gif si731 si731.gif gif 129 9 12 ALTIMG 1-s2.0-S0885064X12000817-si714.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/aff52a34e8e893d6fcc0dd5ee60c68b4/si634.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/aff52a34e8e893d6fcc0dd5ee60c68b4/si634.gif si714 si714.gif gif 457 14 143 ALTIMG 1-s2.0-S0885064X12000817-si652.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/ae4348d2405d949eba06d864476458af/si96.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/ae4348d2405d949eba06d864476458af/si96.gif si652 si652.gif gif 129 9 12 ALTIMG 1-s2.0-S0885064X12000817-si397.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/7a317c44c834cc79c1942aafae69b682/si397.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/7a317c44c834cc79c1942aafae69b682/si397.gif si397 si397.gif gif 303 14 71 ALTIMG 1-s2.0-S0885064X12000817-si743.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/bb6261695e54d371976f01b321d937cc/si743.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/bb6261695e54d371976f01b321d937cc/si743.gif si743 si743.gif gif 500 16 148 ALTIMG 1-s2.0-S0885064X12000817-si224.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/e745a2a56fc432c4b59c3610b0084ccd/si224.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/e745a2a56fc432c4b59c3610b0084ccd/si224.gif si224 si224.gif gif 176 10 38 ALTIMG 1-s2.0-S0885064X12000817-si834.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/402de32b2f67ad30cdcda681a72ab929/si834.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/402de32b2f67ad30cdcda681a72ab929/si834.gif si834 si834.gif gif 1704 42 452 ALTIMG 1-s2.0-S0885064X12000817-si148.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/f8e2ea0848492eeb693a14be654104d0/si148.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/f8e2ea0848492eeb693a14be654104d0/si148.gif si148 si148.gif gif 1750 25 504 ALTIMG 1-s2.0-S0885064X12000817-si337.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/773c05e3f8c78ee2b35c1f0a64c2a39a/si337.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/773c05e3f8c78ee2b35c1f0a64c2a39a/si337.gif si337 si337.gif gif 267 19 52 ALTIMG 1-s2.0-S0885064X12000817-si212.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/a6e1de41b3236d190fdcd4113ef0048b/si404.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/a6e1de41b3236d190fdcd4113ef0048b/si404.gif si212 si212.gif gif 125 9 12 ALTIMG 1-s2.0-S0885064X12000817-si799.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/63ece0456aa5abda63641ae91798941c/si296.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/63ece0456aa5abda63641ae91798941c/si296.gif si799 si799.gif gif 119 9 11 ALTIMG 1-s2.0-S0885064X12000817-si133.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/d331fc587c3941b84642ea730e3b14a7/si291.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/d331fc587c3941b84642ea730e3b14a7/si291.gif si133 si133.gif gif 173 10 38 ALTIMG 1-s2.0-S0885064X12000817-si140.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/d5b611a3a6a4e25223a16edc9666184e/si140.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/d5b611a3a6a4e25223a16edc9666184e/si140.gif si140 si140.gif gif 513 14 138 ALTIMG 1-s2.0-S0885064X12000817-si301.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/efdec1c4e0c7e070887d4eb1bbef1e7d/si301.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/efdec1c4e0c7e070887d4eb1bbef1e7d/si301.gif si301 si301.gif gif 596 14 196 ALTIMG 1-s2.0-S0885064X12000817-si546.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/6a889083fceaf19bd6504aa4cab4397e/si546.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/6a889083fceaf19bd6504aa4cab4397e/si546.gif si546 si546.gif gif 1865 41 463 ALTIMG 1-s2.0-S0885064X12000817-si560.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/1f9eefde61a003079e8b9215dcd5c868/si560.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/1f9eefde61a003079e8b9215dcd5c868/si560.gif si560 si560.gif gif 119 12 11 ALTIMG 1-s2.0-S0885064X12000817-si485.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/4fb0d8f1b07e27552b20349d7762fc5c/si503.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/4fb0d8f1b07e27552b20349d7762fc5c/si503.gif si485 si485.gif gif 287 13 81 ALTIMG 1-s2.0-S0885064X12000817-si456.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/f36492805f66ec4521bb352551e75502/si456.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/f36492805f66ec4521bb352551e75502/si456.gif si456 si456.gif gif 130 10 13 ALTIMG 1-s2.0-S0885064X12000817-si166.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/63ece0456aa5abda63641ae91798941c/si296.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/63ece0456aa5abda63641ae91798941c/si296.gif si166 si166.gif gif 119 9 11 ALTIMG 1-s2.0-S0885064X12000817-si734.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/c606226de0a751bc16fa071ddf83ff01/si734.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/c606226de0a751bc16fa071ddf83ff01/si734.gif si734 si734.gif gif 215 12 44 ALTIMG 1-s2.0-S0885064X12000817-si490.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/b33680c8f41f6fc462ce35b6ebdee4d2/si490.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/b33680c8f41f6fc462ce35b6ebdee4d2/si490.gif si490 si490.gif gif 222 15 45 ALTIMG 1-s2.0-S0885064X12000817-si378.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/fc84733f3212ede141124fa103d64f40/si378.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/fc84733f3212ede141124fa103d64f40/si378.gif si378 si378.gif gif 663 20 177 ALTIMG 1-s2.0-S0885064X12000817-si428.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/fa5c6d1d9db4d93f9549570e573a7a86/si428.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/fa5c6d1d9db4d93f9549570e573a7a86/si428.gif si428 si428.gif gif 313 13 79 ALTIMG 1-s2.0-S0885064X12000817-si427.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/da71b68006f8375c9122de17aa24137d/si427.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/da71b68006f8375c9122de17aa24137d/si427.gif si427 si427.gif gif 176 18 20 ALTIMG 1-s2.0-S0885064X12000817-si566.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/4de3c9e38db1dbe9182b9a4f1f5e9f4c/si566.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/4de3c9e38db1dbe9182b9a4f1f5e9f4c/si566.gif si566 si566.gif gif 982 34 254 ALTIMG 1-s2.0-S0885064X12000817-si123.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/a3e3ec9da8a0ae92eeb4a4cc744f9b35/si142.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/a3e3ec9da8a0ae92eeb4a4cc744f9b35/si142.gif si123 si123.gif gif 181 9 41 ALTIMG 1-s2.0-S0885064X12000817-si124.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/3809dab0d090bb7550d3315e102ccc9f/si124.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/3809dab0d090bb7550d3315e102ccc9f/si124.gif si124 si124.gif gif 222 13 38 ALTIMG 1-s2.0-S0885064X12000817-si430.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/ae4348d2405d949eba06d864476458af/si96.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/ae4348d2405d949eba06d864476458af/si96.gif si430 si430.gif gif 129 9 12 ALTIMG 1-s2.0-S0885064X12000817-si747.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/1d48fecc50e4c942efd1723bf762ced3/si747.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/1d48fecc50e4c942efd1723bf762ced3/si747.gif si747 si747.gif gif 496 14 131 ALTIMG 1-s2.0-S0885064X12000817-si311.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/3bf703fd57016f2e3ad9c1c96c340b7b/si311.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/3bf703fd57016f2e3ad9c1c96c340b7b/si311.gif si311 si311.gif gif 446 13 130 ALTIMG 1-s2.0-S0885064X12000817-si486.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/c340a3c3e74453c4a0a0da61fc09c8f8/si486.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/c340a3c3e74453c4a0a0da61fc09c8f8/si486.gif si486 si486.gif gif 2039 37 517 ALTIMG 1-s2.0-S0885064X12000817-si436.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/4be6c538c4bcc1543c7973e75e2fcffb/si436.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/4be6c538c4bcc1543c7973e75e2fcffb/si436.gif si436 si436.gif gif 145 12 19 ALTIMG 1-s2.0-S0885064X12000817-si580.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/3a003b8c8e5fa3bd2a6b33433eb6e77e/si580.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/3a003b8c8e5fa3bd2a6b33433eb6e77e/si580.gif si580 si580.gif gif 152 10 22 ALTIMG 1-s2.0-S0885064X12000817-si411.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/1a00c6bc7512c9470ff28b5e0402dfc3/si445.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/1a00c6bc7512c9470ff28b5e0402dfc3/si445.gif si411 si411.gif gif 145 10 17 ALTIMG 1-s2.0-S0885064X12000817-si746.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/d45b05f1c17bb5849d2412dfe2ae923d/si769.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/d45b05f1c17bb5849d2412dfe2ae923d/si769.gif si746 si746.gif gif 138 12 14 ALTIMG 1-s2.0-S0885064X12000817-si728.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/b3fc0419d66d3dd8cbe8665082ca69b9/si718.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/b3fc0419d66d3dd8cbe8665082ca69b9/si718.gif si728 si728.gif gif 240 13 53 ALTIMG 1-s2.0-S0885064X12000817-si525.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/33e0193d866057dab3e90e595f1b7992/si522.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/33e0193d866057dab3e90e595f1b7992/si522.gif si525 si525.gif gif 147 11 16 ALTIMG 1-s2.0-S0885064X12000817-si710.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/4d9c973e673ef85ac911c8d61c4a1736/si710.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/4d9c973e673ef85ac911c8d61c4a1736/si710.gif si710 si710.gif gif 1330 39 393 ALTIMG 1-s2.0-S0885064X12000817-si657.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/697a63eba017ba2cd8d97898e9311a22/si657.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/697a63eba017ba2cd8d97898e9311a22/si657.gif si657 si657.gif gif 200 11 42 ALTIMG 1-s2.0-S0885064X12000817-si663.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/406ce83e22dfe59af2b80988a04a9867/si663.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/406ce83e22dfe59af2b80988a04a9867/si663.gif si663 si663.gif gif 298 13 84 ALTIMG 1-s2.0-S0885064X12000817-si668.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/ae4348d2405d949eba06d864476458af/si96.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/ae4348d2405d949eba06d864476458af/si96.gif si668 si668.gif gif 129 9 12 ALTIMG 1-s2.0-S0885064X12000817-si282.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/45ba59c008c5283fc9a889f769097d56/si282.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/45ba59c008c5283fc9a889f769097d56/si282.gif si282 si282.gif gif 111 7 9 ALTIMG 1-s2.0-S0885064X12000817-si550.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/1560a0dee6a122fc0bbb9e785000aeff/si598.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/1560a0dee6a122fc0bbb9e785000aeff/si598.gif si550 si550.gif gif 149 10 17 ALTIMG 1-s2.0-S0885064X12000817-si353.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/b48fcb0fc7abe3949849f424823ef762/si386.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/b48fcb0fc7abe3949849f424823ef762/si386.gif si353 si353.gif gif 122 6 12 ALTIMG 1-s2.0-S0885064X12000817-si254.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/3bc72098bcd1389c268902d0e633ffab/si273.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/3bc72098bcd1389c268902d0e633ffab/si273.gif si254 si254.gif gif 129 9 12 ALTIMG 1-s2.0-S0885064X12000817-si425.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/1a00c6bc7512c9470ff28b5e0402dfc3/si445.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/1a00c6bc7512c9470ff28b5e0402dfc3/si445.gif si425 si425.gif gif 145 10 17 ALTIMG 1-s2.0-S0885064X12000817-si276.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/63ece0456aa5abda63641ae91798941c/si296.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/63ece0456aa5abda63641ae91798941c/si296.gif si276 si276.gif gif 119 9 11 ALTIMG 1-s2.0-S0885064X12000817-si540.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/3cb2d829cff2435fd5a24b23323c2173/si540.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/3cb2d829cff2435fd5a24b23323c2173/si540.gif si540 si540.gif gif 1212 40 310 ALTIMG 1-s2.0-S0885064X12000817-si642.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/17dd7e9c80db8dddb5d111959d7100b8/si642.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/17dd7e9c80db8dddb5d111959d7100b8/si642.gif si642 si642.gif gif 1152 39 300 ALTIMG 1-s2.0-S0885064X12000817-si735.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/63d9c8adab09ba7022b749e235efc294/si735.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/63d9c8adab09ba7022b749e235efc294/si735.gif si735 si735.gif gif 648 13 206 ALTIMG 1-s2.0-S0885064X12000817-si593.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/cf8c51035a31ee9ac734946964d3534d/si272.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/cf8c51035a31ee9ac734946964d3534d/si272.gif si593 si593.gif gif 128 9 11 ALTIMG 1-s2.0-S0885064X12000817-si501.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/0fed4836b6bfc1bb6c686bd8d960f4ea/si513.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/0fed4836b6bfc1bb6c686bd8d960f4ea/si513.gif si501 si501.gif gif 189 13 36 ALTIMG 1-s2.0-S0885064X12000817-si70.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/ae4348d2405d949eba06d864476458af/si96.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/ae4348d2405d949eba06d864476458af/si96.gif si70 si70.gif gif 129 9 12 ALTIMG 1-s2.0-S0885064X12000817-si733.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/ae4348d2405d949eba06d864476458af/si96.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/ae4348d2405d949eba06d864476458af/si96.gif si733 si733.gif gif 129 9 12 ALTIMG 1-s2.0-S0885064X12000817-si732.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/56669c51034bd532b0e36efbccf7498f/si716.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/56669c51034bd532b0e36efbccf7498f/si716.gif si732 si732.gif gif 139 11 16 ALTIMG 1-s2.0-S0885064X12000817-si530.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/b92cf68a5d6eac878bdcc354eaa26d8e/si530.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/b92cf68a5d6eac878bdcc354eaa26d8e/si530.gif si530 si530.gif gif 877 19 275 ALTIMG 1-s2.0-S0885064X12000817-si113.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/118cf7c3cc88e692a21619b51eb468a9/si113.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/118cf7c3cc88e692a21619b51eb468a9/si113.gif si113 si113.gif gif 269 13 57 ALTIMG 1-s2.0-S0885064X12000817-si252.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/4a4dcc38357c86adf0ed5689f77868aa/si252.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/4a4dcc38357c86adf0ed5689f77868aa/si252.gif si252 si252.gif gif 278 13 59 ALTIMG 1-s2.0-S0885064X12000817-si347.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/63ece0456aa5abda63641ae91798941c/si296.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/63ece0456aa5abda63641ae91798941c/si296.gif si347 si347.gif gif 119 9 11 ALTIMG 1-s2.0-S0885064X12000817-si510.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/8a38916b94518ec35a7813f35b98ab62/si498.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/8a38916b94518ec35a7813f35b98ab62/si498.gif si510 si510.gif gif 161 12 24 ALTIMG 1-s2.0-S0885064X12000817-si717.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/7a2b60190a907e87929841f2f352a8bf/si717.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/7a2b60190a907e87929841f2f352a8bf/si717.gif si717 si717.gif gif 190 12 38 ALTIMG 1-s2.0-S0885064X12000817-si372.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/cbfdccff663918a12db3592796dc2023/si372.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/cbfdccff663918a12db3592796dc2023/si372.gif si372 si372.gif gif 231 13 47 ALTIMG 1-s2.0-S0885064X12000817-si176.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/9f96187b40b09617d69521fd77c0094a/si176.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/9f96187b40b09617d69521fd77c0094a/si176.gif si176 si176.gif gif 1044 13 380 ALTIMG 1-s2.0-S0885064X12000817-si443.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/efa59dda6e5f6ce60520d67d8b3a4764/si449.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/efa59dda6e5f6ce60520d67d8b3a4764/si449.gif si443 si443.gif gif 117 9 11 ALTIMG 1-s2.0-S0885064X12000817-si478.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/ae4348d2405d949eba06d864476458af/si96.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/ae4348d2405d949eba06d864476458af/si96.gif si478 si478.gif gif 129 9 12 ALTIMG 1-s2.0-S0885064X12000817-si802.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/e0376bbea674aa63525d2dd65facc96b/si661.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/e0376bbea674aa63525d2dd65facc96b/si661.gif si802 si802.gif gif 149 12 20 ALTIMG 1-s2.0-S0885064X12000817-si798.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/2230fc527c21263806559213dca12c6c/si798.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/2230fc527c21263806559213dca12c6c/si798.gif si798 si798.gif gif 230 12 51 ALTIMG 1-s2.0-S0885064X12000817-si633.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/49eace5b06bc6c48c9ab8510245c6ae4/si631.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/49eace5b06bc6c48c9ab8510245c6ae4/si631.gif si633 si633.gif gif 206 14 34 ALTIMG 1-s2.0-S0885064X12000817-si281.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/435a7d40ad92f614aabd829fafc01ebd/si281.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/435a7d40ad92f614aabd829fafc01ebd/si281.gif si281 si281.gif gif 472 14 155 ALTIMG 1-s2.0-S0885064X12000817-si236.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/3806112872b62b2017a6fa639dd48bb7/si236.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/3806112872b62b2017a6fa639dd48bb7/si236.gif si236 si236.gif gif 138 13 17 ALTIMG 1-s2.0-S0885064X12000817-si10.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/b7f05d9dbca7771dacf1bfdc886f212c/si10.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/b7f05d9dbca7771dacf1bfdc886f212c/si10.gif si10 si10.gif gif 191 13 37 ALTIMG 1-s2.0-S0885064X12000817-si237.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/40d5ae710b2506f2d92245ca3da257ab/si237.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/40d5ae710b2506f2d92245ca3da257ab/si237.gif si237 si237.gif gif 318 13 83 ALTIMG 1-s2.0-S0885064X12000817-si34.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/87f4d421d707958851fea8e719b7550a/si34.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/87f4d421d707958851fea8e719b7550a/si34.gif si34 si34.gif gif 1135 39 264 ALTIMG 1-s2.0-S0885064X12000817-si172.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/6f4ee9f87701fc1cfe41765f3533f186/si172.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/6f4ee9f87701fc1cfe41765f3533f186/si172.gif si172 si172.gif gif 1042 22 288 ALTIMG 1-s2.0-S0885064X12000817-si197.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/ae4348d2405d949eba06d864476458af/si96.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/ae4348d2405d949eba06d864476458af/si96.gif si197 si197.gif gif 129 9 12 ALTIMG 1-s2.0-S0885064X12000817-si556.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/080d9855961746f5abddc5bed9531da9/si556.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/080d9855961746f5abddc5bed9531da9/si556.gif si556 si556.gif gif 397 13 121 ALTIMG 1-s2.0-S0885064X12000817-si96.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/ae4348d2405d949eba06d864476458af/si96.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/ae4348d2405d949eba06d864476458af/si96.gif si96 si96.gif gif 129 9 12 ALTIMG 1-s2.0-S0885064X12000817-si288.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/3a79ea654daf2c8130b94394692cef81/si288.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/3a79ea654daf2c8130b94394692cef81/si288.gif si288 si288.gif gif 165 9 35 ALTIMG 1-s2.0-S0885064X12000817-si320.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/d3be4c9189ea78acf21f724823e5ae87/si330.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/d3be4c9189ea78acf21f724823e5ae87/si330.gif si320 si320.gif gif 141 13 12 ALTIMG 1-s2.0-S0885064X12000817-si453.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/506f9dc3b66f28bbe5d44de4c9e54936/si453.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/506f9dc3b66f28bbe5d44de4c9e54936/si453.gif si453 si453.gif gif 191 10 39 ALTIMG 1-s2.0-S0885064X12000817-si424.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/f04b0ee9d53c16626c0c595d08521ecf/si424.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/f04b0ee9d53c16626c0c595d08521ecf/si424.gif si424 si424.gif gif 153 14 28 ALTIMG 1-s2.0-S0885064X12000817-si681.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/85c9c36d42e3a6977eca1f309131fc95/si681.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/85c9c36d42e3a6977eca1f309131fc95/si681.gif si681 si681.gif gif 276 13 63 ALTIMG 1-s2.0-S0885064X12000817-si585.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/32a06277de05a655c7a05909d6e751d7/si361.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/32a06277de05a655c7a05909d6e751d7/si361.gif si585 si585.gif gif 201 10 41 ALTIMG 1-s2.0-S0885064X12000817-si304.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/702e8f735b68be7af241d903b1d4998f/si304.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/702e8f735b68be7af241d903b1d4998f/si304.gif si304 si304.gif gif 1501 17 483 ALTIMG 1-s2.0-S0885064X12000817-si410.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/7b5c2dc5441c2902f815df0074d9e8a0/si575.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/7b5c2dc5441c2902f815df0074d9e8a0/si575.gif si410 si410.gif gif 155 13 18 ALTIMG 1-s2.0-S0885064X12000817-si457.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/663ff50d777859d4ccf595f77c5fb6d3/si349.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/663ff50d777859d4ccf595f77c5fb6d3/si349.gif si457 si457.gif gif 156 16 15 ALTIMG 1-s2.0-S0885064X12000817-si817.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/047983240be25ffc5f21107caa2fce26/si791.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/047983240be25ffc5f21107caa2fce26/si791.gif si817 si817.gif gif 216 12 44 ALTIMG 1-s2.0-S0885064X12000817-si291.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/d331fc587c3941b84642ea730e3b14a7/si291.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/d331fc587c3941b84642ea730e3b14a7/si291.gif si291 si291.gif gif 173 10 38 ALTIMG 1-s2.0-S0885064X12000817-si215.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/8f83a884ecb7371e12ecdb49e765291b/si215.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/8f83a884ecb7371e12ecdb49e765291b/si215.gif si215 si215.gif gif 646 13 211 ALTIMG 1-s2.0-S0885064X12000817-si22.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/66173c4d94832e5cbf84ccec95a8004a/si31.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/66173c4d94832e5cbf84ccec95a8004a/si31.gif si22 si22.gif gif 119 9 11 ALTIMG 1-s2.0-S0885064X12000817-si94.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/90dd794fd0fb362a06f392454d68cc48/si94.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/90dd794fd0fb362a06f392454d68cc48/si94.gif si94 si94.gif gif 161 12 19 ALTIMG 1-s2.0-S0885064X12000817-si808.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/ae4348d2405d949eba06d864476458af/si96.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/ae4348d2405d949eba06d864476458af/si96.gif si808 si808.gif gif 129 9 12 ALTIMG 1-s2.0-S0885064X12000817-si822.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/10caf323b93d99867e13e28f06045cc8/si822.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/10caf323b93d99867e13e28f06045cc8/si822.gif si822 si822.gif gif 700 14 229 ALTIMG 1-s2.0-S0885064X12000817-si328.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/d3be4c9189ea78acf21f724823e5ae87/si330.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/d3be4c9189ea78acf21f724823e5ae87/si330.gif si328 si328.gif gif 141 13 12 ALTIMG 1-s2.0-S0885064X12000817-si338.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/cfb6aa3aae601e272ecc3d0f648cfb03/si338.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/cfb6aa3aae601e272ecc3d0f648cfb03/si338.gif si338 si338.gif gif 444 17 131 ALTIMG 1-s2.0-S0885064X12000817-si351.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/9c796098b4239c776a5edd431bc40cf5/si351.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/9c796098b4239c776a5edd431bc40cf5/si351.gif si351 si351.gif gif 220 16 49 ALTIMG 1-s2.0-S0885064X12000817-si635.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/9f1bfbf7af4de20599249ad8bb563f08/si635.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/9f1bfbf7af4de20599249ad8bb563f08/si635.gif si635 si635.gif gif 600 14 183 ALTIMG 1-s2.0-S0885064X12000817-si748.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/68e694d4ad1e205f79474835708149a8/si748.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/68e694d4ad1e205f79474835708149a8/si748.gif si748 si748.gif gif 336 13 85 ALTIMG 1-s2.0-S0885064X12000817-si107.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/e2c8b5bae6f17378785cb34e12d26dc0/si107.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/e2c8b5bae6f17378785cb34e12d26dc0/si107.gif si107 si107.gif gif 315 15 71 ALTIMG 1-s2.0-S0885064X12000817-si792.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/71e5a75156842404ecc03af47156dd48/si795.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/71e5a75156842404ecc03af47156dd48/si795.gif si792 si792.gif gif 124 10 10 ALTIMG 1-s2.0-S0885064X12000817-si630.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/07df8aec68ce2b1c102cb21e2ed1308c/si630.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/07df8aec68ce2b1c102cb21e2ed1308c/si630.gif si630 si630.gif gif 267 13 65 ALTIMG 1-s2.0-S0885064X12000817-si590.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/eaa6ab92cbbd80954012c2f3a9bb809f/si590.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/eaa6ab92cbbd80954012c2f3a9bb809f/si590.gif si590 si590.gif gif 119 9 10 ALTIMG 1-s2.0-S0885064X12000817-si730.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/56669c51034bd532b0e36efbccf7498f/si716.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/56669c51034bd532b0e36efbccf7498f/si716.gif si730 si730.gif gif 139 11 16 ALTIMG 1-s2.0-S0885064X12000817-si783.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/16ceedca64d19c0ec555f573ef590de0/si783.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/16ceedca64d19c0ec555f573ef590de0/si783.gif si783 si783.gif gif 2872 98 390 ALTIMG 1-s2.0-S0885064X12000817-si832.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/4dca1154f43a6ca353bead64704affdd/si766.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/4dca1154f43a6ca353bead64704affdd/si766.gif si832 si832.gif gif 304 15 73 ALTIMG 1-s2.0-S0885064X12000817-si414.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/66173c4d94832e5cbf84ccec95a8004a/si31.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/66173c4d94832e5cbf84ccec95a8004a/si31.gif si414 si414.gif gif 119 9 11 ALTIMG 1-s2.0-S0885064X12000817-si88.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/38ea28ed32274e51efb37e369915ad21/si88.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/38ea28ed32274e51efb37e369915ad21/si88.gif si88 si88.gif gif 252 12 67 ALTIMG 1-s2.0-S0885064X12000817-si759.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/bafa11504e6d6e9c4e5b45811c7e4778/si759.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/bafa11504e6d6e9c4e5b45811c7e4778/si759.gif si759 si759.gif gif 201 13 42 ALTIMG 1-s2.0-S0885064X12000817-si820.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/d45b05f1c17bb5849d2412dfe2ae923d/si769.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/d45b05f1c17bb5849d2412dfe2ae923d/si769.gif si820 si820.gif gif 138 12 14 ALTIMG 1-s2.0-S0885064X12000817-si623.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/4599e8254b56c9dbe63850b7072986d9/si623.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/4599e8254b56c9dbe63850b7072986d9/si623.gif si623 si623.gif gif 131 12 10 ALTIMG 1-s2.0-S0885064X12000817-si258.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/ae64f9642f5e4fbf4a19cac5ed50f3a5/si258.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/ae64f9642f5e4fbf4a19cac5ed50f3a5/si258.gif si258 si258.gif gif 208 9 48 ALTIMG 1-s2.0-S0885064X12000817-si646.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/30839e352c504e5a59b6b3b6a1f54122/si646.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/30839e352c504e5a59b6b3b6a1f54122/si646.gif si646 si646.gif gif 894 13 299 ALTIMG 1-s2.0-S0885064X12000817-si685.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/ec0084b23de12a2d2685533105db1488/si685.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/ec0084b23de12a2d2685533105db1488/si685.gif si685 si685.gif gif 181 9 40 ALTIMG 1-s2.0-S0885064X12000817-si786.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/45f5099fc32467693af856602e8a6b16/si786.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/45f5099fc32467693af856602e8a6b16/si786.gif si786 si786.gif gif 134 9 14 ALTIMG 1-s2.0-S0885064X12000817-si778.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/e5abcdefed96161a8db69241d8bd33e2/si778.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/e5abcdefed96161a8db69241d8bd33e2/si778.gif si778 si778.gif gif 1128 22 306 ALTIMG 1-s2.0-S0885064X12000817-si317.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/ae4348d2405d949eba06d864476458af/si96.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/ae4348d2405d949eba06d864476458af/si96.gif si317 si317.gif gif 129 9 12 ALTIMG 1-s2.0-S0885064X12000817-si171.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/b6b931bd6f19579cf1a48d09121a7b47/si171.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/b6b931bd6f19579cf1a48d09121a7b47/si171.gif si171 si171.gif gif 1412 20 428 ALTIMG 1-s2.0-S0885064X12000817-si161.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/6712c7a3d4d0445ee037a9f2f9cefad6/si161.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/6712c7a3d4d0445ee037a9f2f9cefad6/si161.gif si161 si161.gif gif 188 10 45 ALTIMG 1-s2.0-S0885064X12000817-si513.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/0fed4836b6bfc1bb6c686bd8d960f4ea/si513.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/0fed4836b6bfc1bb6c686bd8d960f4ea/si513.gif si513 si513.gif gif 189 13 36 ALTIMG 1-s2.0-S0885064X12000817-si664.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/63ece0456aa5abda63641ae91798941c/si296.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/63ece0456aa5abda63641ae91798941c/si296.gif si664 si664.gif gif 119 9 11 ALTIMG 1-s2.0-S0885064X12000817-si76.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/2e3252a41203cc3bc554ee2853647eec/si76.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/2e3252a41203cc3bc554ee2853647eec/si76.gif si76 si76.gif gif 821 13 305 ALTIMG 1-s2.0-S0885064X12000817-si617.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/3cb68fe4831a28d82ade71999c129bd4/si617.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/3cb68fe4831a28d82ade71999c129bd4/si617.gif si617 si617.gif gif 126 13 8 ALTIMG 1-s2.0-S0885064X12000817-si627.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/751298c4de9f0dfec04f9ba577dcdb1e/si73.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/751298c4de9f0dfec04f9ba577dcdb1e/si73.gif si627 si627.gif gif 125 9 13 ALTIMG 1-s2.0-S0885064X12000817-si434.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/b1378883c8dd5dcaf0cbf2efaeeb5df3/si434.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/b1378883c8dd5dcaf0cbf2efaeeb5df3/si434.gif si434 si434.gif gif 193 10 38 ALTIMG 1-s2.0-S0885064X12000817-si762.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/4b9f5f5a22875874e2e0bc0978e8ea8e/si673.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/4b9f5f5a22875874e2e0bc0978e8ea8e/si673.gif si762 si762.gif gif 129 9 12 ALTIMG 1-s2.0-S0885064X12000817-si377.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/763269ad716d528caf063af005b6969b/si377.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/763269ad716d528caf063af005b6969b/si377.gif si377 si377.gif gif 508 14 148 ALTIMG 1-s2.0-S0885064X12000817-si445.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/1a00c6bc7512c9470ff28b5e0402dfc3/si445.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/1a00c6bc7512c9470ff28b5e0402dfc3/si445.gif si445 si445.gif gif 145 10 17 ALTIMG 1-s2.0-S0885064X12000817-si827.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0885064X12000817/STRIPIN/image/gif/71e0249d227f557d209cde7929513a92/si827.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0885064X12000817/STRIPIN/image/gif/71e0249d227f557d209cde7929513a92/si827.gif si827 si827.gif gif 296 16 68 ALTIMG YJCOM 1136 S0885-064X(12)00081-7 10.1016/j.jco.2012.09.002 Elsevier Inc. \u2606 This work was partially supported by the US National Science Foundation under grant 0631541 (PI: Jun Zhang), by Guangdong Provincial Government of China through the \u201cComputational Science Innovative Research Team\u201d program, and by Natural Science Foundation of China under grants 11222103, 11101438 and 91130009. Vector-valued reproducing kernel Banach spaces with applications to multi-task learning Haizhang Zhang a b \u204e Jun Zhang c a School of Mathematics and Computational Science, Sun Yat-sen University, Guangzhou 510275, PR China b Guangdong Province Key Laboratory of Computational Science, Sun Yat-sen University, Guangzhou 510275, PR China c Department of Psychology, University of Michigan, Ann Arbor, MI 48109, USA \u204e Corresponding author at: School of Mathematics and Computational Science, Sun Yat-sen University, Guangzhou 510275, PR China. Motivated by multi-task machine learning with Banach spaces, we propose the notion of vector-valued reproducing kernel Banach spaces (RKBSs). Basic properties of the spaces and the associated reproducing kernels are investigated. We also present feature map constructions and several concrete examples of vector-valued RKBSs. The theory is then applied to multi-task machine learning. Especially, the representer theorem and characterization equations for the minimizer of regularized learning schemes in vector-valued RKBSs are established. Keywords Vector-valued reproducing kernel Banach spaces Feature maps Regularized learning The representer theorem Characterization equations 1 Introduction The purpose of this paper is to establish the notion of vector-valued reproducing kernel Banach spaces and demonstrate its applications to multi-task machine learning. Built on the theory of scalar-valued reproducing kernel Hilbert spaces (RKHSs) [3], kernel methods have been proven successful in single task machine learning [10,14,29,30,33]. Multi-task learning where the unknown target function to be learned from finite sample data is vector-valued appears more often in practice. Refs. [13,25] proposed the development of kernel methods for learning multiple related tasks simultaneously. The mathematical foundation used there was the theory of vector-valued RKHSs [5,27]. Recent progresses in vector-valued RKHSs can be found in [7\u20139,38]. In such a framework, both the space of the candidate functions used for approximation and the output space are chosen as a Hilbert space. There are some occasions where it might be desirable to select the space of candidate functions, the output space, or both as Banach spaces. Hilbert spaces constitute a special and limited class of Banach spaces. Any two Hilbert spaces over a common number field with the same dimension are isometrically isomorphic. By reaching out to other Banach spaces, one obtains more variety in geometric structures and norms that are potentially useful for learning and approximation. Moreover, training data might come with intrinsic structures that make them impossible or inappropriate to be embedded into a Hilbert space. Learning schemes based on features in a Hilbert space may not work well for them. Finally, in some applications, a Banach space norm is engaged for some particular purpose. A typical example is the linear programming regularization in coefficient based regularization for machine learning [29], where the \u2113 1 norm is employed to obtain sparsity in the resulting minimizer. There has been considerable work in learning a single task with Banach spaces (see, for example, [4,6,12,15,17,20,24,26,34,36,42]). The difficulty in mapping patterns into a Banach space and making use of these features for learning mainly lies in the lack of an inner product in Banach spaces. In particular, without an appropriate correspondence of the Riesz representation of continuous linear functionals, point evaluations do not have a kernel representation in these studies. Semi-inner products, a mathematical tool discovered by Lumer [23] for the purpose of extending Hilbert space type arguments to Banach spaces, seem to be a natural substitute for inner products in Banach spaces. An illustrative example is that we were able to extend the classical theory of frames and Riesz bases to Banach spaces via semi-inner products [40]. Semi-inner products were first used to machine learning by Der and Lee [12] for the study of large margin classification by hyperplanes in a Banach space. With this tool, we established the notion of scalar-valued reproducing kernel Banach spaces (RKBSs) and investigated regularized learning schemes in RKBSs [37,39]. There has been increasing interest in the application of this new theory [19,31,32,41]. We attempt to build a mathematical foundation for multi-task learning with Banach spaces. Specifically, we shall propose a definition of vector-valued RKBSs and investigate its fundamental properties in the next section. Feature map representations and several concrete examples of vector-valued RKBSs will be presented in Sections 3 and 4, respectively. In Section 5, we investigate regularized learning schemes in vector-valued RKBSs. 2 Definition and basic properties We are concerned with spaces of functions from a fixed set to a vector space. We shall allow the space of functions and the range space both to be a Banach space. Our key tool in dealing with a general Banach space is the semi-inner product [16,23]. Recall that a semi-inner product on a Banach space V is a function from V \u00d7 V to C , denoted by [ \u22c5 , \u22c5 ] V , such that for all f , g , h \u2208 V and \u03b1 , \u03b2 \u2208 C 1. (linearity with respect to the first variable) [ \u03b1 f + \u03b2 g , h ] V = \u03b1 [ f , h ] V + \u03b2 [ g , h ] V ; 2. (positivity) [ f , f ] V > 0 for f \u2260 0 ; 3. (conjugate homogeneity with respect to the second variable) [ f , \u03b1 g ] V = \u03b1 \u00af [ f , g ] V ; 4. (Cauchy\u2013Schwarz inequality) | [ f , g ] V | \u2264 [ f , f ] V 1 / 2 [ g , g ] V 1 / 2 . A semi-inner product [ \u22c5 , \u22c5 ] V on V is said to be compatible if [ f , f ] V 1 / 2 = \u2016 f \u2016 V for all f \u2208 V , where \u2016 \u22c5 \u2016 V denotes the norm on V . Every Banach space has a compatible semi-inner product [16,23]. Let [ \u22c5 , \u22c5 ] V be a compatible semi-inner product on V . Then one sees by the Cauchy\u2013Schwarz inequality that for each f \u2208 B , the linear functional f \u2217 on V defined by (2.1) f \u2217 ( g ) \u2254 [ g , f ] V , g \u2208 V is bounded on V . In other words, f \u2217 lies in the dual space B \u2217 of B . Moreover, we have (2.2) \u2016 f \u2217 \u2016 V \u2217 = \u2016 f \u2016 V and (2.3) f \u2217 ( f ) = \u2016 f \u2016 V \u2016 f \u2217 \u2016 V \u2217 . Introduce the duality mapping J V from V to V \u2217 by setting J V ( f ) \u2254 f \u2217 , f \u2208 V . We desire to represent the continuous linear functionals on the vector-valued RKBS by the semi-inner product. However, the semi-inner product might not be able to fulfill this important role for an arbitrary Banach space. For instance, one verifies that the continuous linear functional \u03bc ( g ) \u2254 \u2211 j = 1 \u221e ( \u2212 1 ) j 1 2 j g ( 1 2 j ) , g \u2208 C ( [ 0 , 1 ] ) on C ( [ 0 , 1 ] ) endowed with the usual maximum norm cannot be represented as \u03bc ( g ) = [ g , f ] , g \u2208 C ( [ 0 , 1 ] ) for any compatible semi-inner product [ \u22c5 , \u22c5 ] on C ( [ 0 , 1 ] ) and any f \u2208 C ( [ 0 , 1 ] ) . The above example indicates that the duality mapping might not be surjective for a general Banach space. Other problems such as non-uniqueness of compatible semi-inner products and non-injectivity of the duality mapping may also occur. To overcome these difficulties, we shall focus on Banach spaces that are uniformly convex and uniformly Fr\u00e9chet differentiable in this preliminary work on vector-valued RKBSs. A Banach space V is uniformly convex if for all \u03b5 > 0 there exists a \u03b4 > 0 such that \u2016 f + g \u2016 V \u2264 2 \u2212 \u03b4 for all f , g \u2208 V with \u2016 f \u2016 V = \u2016 g \u2016 V = 1 and \u2016 f \u2212 g \u2016 V \u2265 \u03b5 . Uniform convexity ensures the injectivity of the duality mapping and the existence and uniqueness of the best approximation to a closed convex subset of V [16]. We also say that V is uniformly Fr\u00e9chet differentiable if for all f , g \u2208 V (2.4) lim t \u2208 R , t \u2192 0 \u2016 f + t g \u2016 V \u2212 \u2016 f \u2016 V t exists and the limit is approached uniformly for all f , g in the unit ball of V . If V is uniformly Fr\u00e9chet differentiable then it has a unique compatible semi-inner product [16]. The differentiability (2.4) of the norm is useful to derive characterization equations for the minimizer of regularized learning schemes in Banach spaces. For simplicity, we call a Banach space uniform if it is both uniformly convex and uniformly Fr\u00e9chet differentiable. An analogue of the Riesz representation theorem holds for uniform Banach spaces. Lemma 2.1 Giles [16] Let V be a uniform Banach space. Then it has a unique compatible semi-inner product [ \u22c5 , \u22c5 ] V and the duality mapping J V is bijective from V to V \u2217 . In other words, for each \u03bc \u2208 V \u2217 there exists a unique f \u2208 V such that \u03bc ( g ) = [ g , f ] V for all g \u2208 V . In this case, (2.5) [ f \u2217 , g \u2217 ] B \u2217 \u2254 [ g , f ] B , f , g \u2208 B defines a compatible semi-inner product on B \u2217 . Let V be a uniform Banach space. We shall always denote by [ \u22c5 , \u22c5 ] V the unique compatible semi-inner product on V . By Lemma 2.1 and Eq. (2.2), the duality mapping is bijective and isometric from V to V \u2217 . It is also conjugate homogeneous by property 3 of semi-inner products. However, it is non-additive unless V reduces to a Hilbert space. As a consequence, a compatible semi-inner product is in general conjugate homogeneous but non-additive with respect to its second variable. Namely, [ f , g + h ] V \u2260 [ f , g ] V + [ f , h ] V in general. We are ready to present the definition of vector-valued RKBSs. Let \u039b be a Banach space which we shall sometimes call the output space and X be a prescribed set which is usually called the input space. A space B is called a Banach space of \u039b -valued functions on X if it consists of certain functions from X to \u039b and the norm on B is compatible with point evaluations in the sense that \u2016 f \u2016 B = 0 if and only if f ( x ) = 0 for all x \u2208 X . For instance, L p ( [ 0 , 1 ] ) , p \u2265 1 is not a Banach space of functions while C ( [ 0 , 1 ] ) is. We restrict our consideration to Banach spaces of functions so that point evaluations (usually referred to as \u201csampling\u201d in applications) are well-defined. Definition 2.2 We call B a \u039b -valued RKBS on X if both B and \u039b are uniform and B is a Banach space of functions from X to \u039b such that for every x \u2208 X , the point evaluation \u03b4 x : B \u2192 \u039b defined by \u03b4 x ( f ) \u2254 f ( x ) , f \u2208 B is continuous from B to \u039b . We shall derive a reproducing kernel for so defined vector-valued RKBSs. Throughout the rest of the paper, we let [ \u22c5 , \u22c5 ] B and [ \u22c5 , \u22c5 ] \u039b be the unique semi-inner products and J B and J \u039b the associated duality mappings on B and \u039b , respectively. For two Banach spaces V 1 , V 2 , we denote by M ( V 1 , V 2 ) the set of all the bounded operators from V 1 to V 2 and L ( V 1 , V 2 ) the subset of M ( V 1 , V 2 ) of those bounded operators that are also linear. When V 1 = V 2 , M ( V 1 , V 2 ) is abbreviated as M ( V 1 ) . For each T \u2208 M ( V 1 , V 2 ) , we denote by \u2016 T \u2016 M ( V 1 , V 2 ) the greatest lower bound of all the nonnegative constants \u03b1 such that \u2016 T u \u2016 V 2 \u2264 \u03b1 \u2016 u \u2016 V 1 for all u \u2208 V 1 . When T is also linear, this quantity equals the operator norm \u2016 T \u2016 L ( V 1 , V 2 ) of T in L ( V 1 , V 2 ) . In those languages, we require that the point evaluation \u03b4 x on a \u039b -valued RKBS on X belongs to L ( B , \u039b ) for all x \u2208 X . Theorem 2.3 Let B be a \u039b -valued RKBS on X . Then there exists a unique function K from X \u00d7 X to M ( \u039b ) such that (1) K ( x , \u22c5 ) \u03be \u2208 B for all x \u2208 X and \u03be \u2208 \u039b , (2) for all f \u2208 B , x \u2208 X , and \u03be \u2208 \u039b (2.6) [ f ( x ) , \u03be ] \u039b = [ f , K ( x , \u22c5 ) \u03be ] B , (3) for all x , y \u2208 X (2.7) \u2016 K ( x , y ) \u2016 M ( \u039b ) \u2264 \u2016 \u03b4 x \u2016 L ( B , \u039b ) \u2016 \u03b4 y \u2016 L ( B , \u039b ) . Proof Let x \u2208 X and \u03be \u2208 \u039b . As \u03b4 x \u2208 L ( B , \u039b ) , we see that (2.8) | [ f ( x ) , \u03be ] \u039b | \u2264 \u2016 f ( x ) \u2016 \u039b \u2016 \u03be \u2016 \u039b \u2264 \u2016 \u03b4 x \u2016 L ( B , \u039b ) \u2016 f \u2016 B \u2016 \u03be \u2016 \u039b . The above inequality together with the linearity of the semi-inner product with respect to its first variable implies that f \u2192 [ f ( x ) , \u03be ] \u039b is a bounded linear functional on B . By Lemma 2.1, there exists a unique function g x , \u03be \u2208 B such that (2.9) [ f ( x ) , \u03be ] \u039b = [ f , g x , \u03be ] B . Define a function K from X \u00d7 X to the set of operators from \u039b to \u039b by setting K ( x , y ) \u03be \u2254 g x , \u03be ( y ) , x , y \u2208 X , \u03be \u2208 \u039b . Clearly, K satisfies the two requirements (1) and (2). It is also unique by the uniqueness of the function g x , \u03be satisfying (2.9). It remains to show that it is bounded. To this end, we get by (2.8) that \u2016 K ( x , \u22c5 ) \u03be \u2016 B = sup f \u2208 B , \u2016 f \u2016 B \u2264 1 | [ f , K ( x , \u22c5 ) ] B | = sup f \u2208 B , \u2016 f \u2016 B \u2264 1 | [ f ( x ) , \u03be ] \u039b | \u2264 \u2016 \u03b4 x \u2016 L ( B , \u039b ) \u2016 \u03be \u2016 \u039b . It follows that \u2016 K ( x , y ) \u03be \u2016 B \u2264 \u2016 \u03b4 y \u2016 L ( B , \u039b ) \u2016 K ( x , \u22c5 ) \u03be \u2016 B \u2264 \u2016 \u03b4 x \u2016 L ( B , \u039b ) \u2016 \u03b4 y \u2016 L ( B , \u039b ) \u2016 \u03be \u2016 \u039b , which proves (2.7).\u25a1 We call the above function K the reproducing kernel of B . It coincides with the usual reproducing kernel when B is a Hilbert space and \u039b = C , and with the vector-valued reproducing kernel when both B and \u039b are Hilbert spaces. We explore basic properties of vector-valued RKBSs and its reproducing kernels for further investigation and applications. Let ( \u03b4 x ) \u2217 be the adjoint operator of \u03b4 x for all x \u2208 X . Denote for a Banach space V by ( \u22c5 , \u22c5 ) V the bilinear form on V \u00d7 V \u2217 defined by ( v , \u03bc ) V \u2254 \u03bc ( v ) , v \u2208 V , \u03bc \u2208 V \u2217 . Thus, ( \u03b4 x ) \u2217 is defined by (2.10) ( f , ( \u03b4 x ) \u2217 \u03be \u2217 ) B = ( \u03b4 ( x ) ( f ) , \u03be \u2217 ) \u039b = ( f ( x ) , \u03be \u2217 ) \u039b = [ f ( x ) , \u03be ] \u039b , f \u2208 B , \u03be \u2208 \u039b . Proposition 2.4 Let B be a \u039b -valued RKBS on X and K its reproducing kernel. Then there holds for all x , y \u2208 X and \u03be , \u03b7 , \u03c4 \u2208 \u039b that (2.11) [ K ( x , x ) \u03be , \u03be ] \u039b \u2265 0 , | [ K ( x , y ) \u03be , \u03b7 ] \u039b | \u2264 [ K ( x , x ) \u03be , \u03be ] \u039b 1 / 2 [ K ( y , y ) \u03b7 , \u03b7 ] \u039b 1 / 2 , (2.12) \u2016 K ( x , y ) \u2016 M ( \u039b ) \u2264 \u2016 K ( x , x ) \u2016 M ( \u039b ) 1 / 2 \u2016 K ( y , y ) \u2016 M ( \u039b ) 1 / 2 , (2.13) K ( x , \u22c5 ) \u03be = J B \u2212 1 ( \u03b4 x ) \u2217 J \u039b ( \u03be ) , (2.14) K ( x , y ) ( \u03b1 \u03be ) = \u03b1 K ( x , y ) \u03be for all \u03b1 \u2208 C , (2.15) \u2016 K ( x , \u22c5 ) \u03be \u2016 B \u2264 \u2016 \u03b4 x \u2016 L ( B , \u039b ) \u2016 \u03be \u2016 \u039b , \u2016 K ( x , \u22c5 ) \u03be \u2016 B \u2264 \u2016 K ( x , x ) \u2016 M ( \u039b ) 1 / 2 \u2016 \u03be \u2016 \u039b , (2.16) ( K ( x , \u22c5 ) \u03be ) \u2217 + ( K ( x , \u22c5 ) \u03b7 ) \u2217 = ( K ( x , \u22c5 ) \u03c4 ) \u2217 whenever \u03c4 \u2217 = \u03be \u2217 + \u03b7 \u2217 , (2.17) span { ( K ( x , \u22c5 ) \u03be ) \u2217 : x \u2208 X , \u03be \u2208 \u039b } is dense in B \u2217 . Proof By (2.6), (2.18) [ K ( x , x ) \u03be , \u03be ] \u039b = [ K ( x , \u22c5 ) \u03be , K ( x , \u22c5 ) \u03be ] B = \u2016 K ( x , \u22c5 ) \u03be \u2016 B 2 \u2265 0 , which proves the first inequality in Eq. (2.11). For the second one, we use the Cauchy\u2013Schwarz inequality of semi-inner products to get that | [ K ( x , y ) \u03be , \u03b7 ] \u039b | = | [ K ( x , \u22c5 ) \u03be , K ( y , \u22c5 ) \u03b7 ] B | \u2264 [ K ( x , \u22c5 ) \u03be , K ( x , \u22c5 ) \u03be ] B 1 / 2 [ K ( y , \u22c5 ) \u03b7 , K ( y , \u22c5 ) \u03b7 ] B 1 / 2 = [ K ( x , x ) \u03be , \u03be ] \u039b 1 / 2 [ K ( y , y ) \u03b7 , \u03b7 ] \u039b 1 / 2 . It follows from (2.11) that | [ K ( x , y ) \u03be , \u03b7 ] \u039b | \u2264 \u2016 K ( x , x ) \u03be \u2016 \u039b 1 / 2 \u2016 \u03be \u2016 \u039b 1 / 2 \u2016 K ( y , y ) \u03b7 \u2016 \u039b 1 / 2 \u2016 \u03b7 \u2016 \u039b 1 / 2 \u2264 \u2016 K ( x , x ) \u2016 M ( \u039b ) 1 / 2 \u2016 K ( y , y ) \u2016 M ( \u039b ) 1 / 2 \u2016 \u03be \u2016 \u039b \u2016 \u03b7 \u2016 \u039b . Since \u2016 K ( x , y ) \u03be \u2016 \u039b = sup { | [ K ( x , y ) \u03be , \u03b7 ] \u039b | : \u03b7 \u2208 \u039b , \u2016 \u03b7 \u2016 \u039b = 1 } , we have by the above equation that \u2016 K ( x , y ) \u03be \u2016 \u039b \u2264 \u2016 K ( x , x ) \u2016 M ( \u039b ) 1 / 2 \u2016 K ( y , y ) \u2016 M ( \u039b ) 1 / 2 \u2016 \u03be \u2016 \u039b , which proves (2.12). Turning to (2.13), we notice for each f \u2208 B that [ f , J B \u2212 1 ( \u03b4 x ) \u2217 J \u039b ( \u03be ) ] B = ( f , ( \u03b4 x ) \u2217 J \u039b ( \u03be ) ) B = ( \u03b4 x ( f ) , \u03be \u2217 ) \u039b = ( f ( x ) , \u03be \u2217 ) \u039b = [ f ( x ) , \u03be ] \u039b , which together with (2.6) confirms (2.13). Since the duality mappings are conjugate homogeneous, we have by (2.13) that K ( x , \u22c5 ) ( \u03b1 \u03be ) = J B \u2212 1 ( \u03b4 x ) \u2217 J \u039b ( \u03b1 \u03be ) = \u03b1 J B \u2212 1 ( \u03b4 x ) \u2217 J \u039b ( \u03be ) = \u03b1 K ( x , \u22c5 ) \u03be , which implies (2.14). Recall that the duality mappings J B and J \u039b are isometric. Note also that a bounded linear operator and its adjoint have equal operator norms. Using these two facts, we obtain from Eq. (2.13) that \u2016 K ( x , \u22c5 ) \u03be \u2016 B \u2264 \u2016 ( \u03b4 x ) \u2217 \u2016 L ( \u039b \u2217 , B \u2217 ) \u2016 \u03be \u2016 \u039b = \u2016 \u03b4 x \u2016 L ( B , \u039b ) \u2016 \u03be \u2016 \u039b , which is the first inequality in (2.15). The second one follows immediately from (2.18). Let \u03be , \u03b7 , \u03c4 \u2208 \u039b be such that \u03c4 \u2217 = \u03be \u2217 + \u03b7 \u2217 . By (2.13), ( K ( x , \u22c5 ) \u03be ) \u2217 + ( K ( x , \u22c5 ) \u03b7 ) \u2217 = ( \u03b4 x ) \u2217 \u03be \u2217 + ( \u03b4 x ) \u2217 \u03b7 \u2217 = ( \u03b4 x ) \u2217 ( \u03be \u2217 + \u03b7 \u2217 ) = ( \u03b4 x ) \u2217 \u03c4 \u2217 = ( K ( x , \u22c5 ) \u03c4 ) \u2217 . Eq. (2.16) hence holds true. For the last property, let us assume that there exists some f \u2208 B that vanishes on span { ( K ( x , \u22c5 ) \u03be ) \u2217 : x \u2208 X , \u03be \u2208 \u039b } . Then [ f ( x ) , \u03be ] \u039b = [ f , K ( x , \u22c5 ) \u03be ] B = ( f , ( K ( x , \u22c5 ) \u03be ) \u2217 ) B = 0 for all x \u2208 X , \u03be \u2208 \u039b , which implies that f ( x ) = 0 for all x \u2208 X . As B is a Banach space of functions, f = 0 as a vector in the Banach space B . Therefore, (2.17) is true. The proof is complete.\u25a1 We observe by the above proposition that the reproducing kernel of a vector-valued RKBS enjoys many properties similar to those of the reproducing kernel of a vector-valued RKHS. However, there are many significant differences due to the nature of a semi-inner product. First, although for all x , y \u2208 X , K ( x , y ) remains a homogeneous bounded operator on \u039b , it is generally non-additive. This can be seen from (2.13), where J \u039b or J B \u2212 1 is non-additive. Second, it is well-known that when \u039b is a Hilbert space, a function K : X \u00d7 X \u2192 L ( \u039b ) is the reproducing kernel of some \u039b -valued RKHS on X if and only if for all finite \u03be j \u2208 \u039b and pairwise distinct x j \u2208 X , j = 1 , 2 , \u2026 , m , (2.19) \u2211 j = 1 m \u2211 k = 1 m [ K ( x j , x k ) \u03be j , \u03be k ] \u039b \u2265 0 . Although (2.19) still holds for the reproducing kernel of a vector-valued RKBS when m \u2264 2 and the number field is R , it may cease to be true once the number of sampling points m exceeds 2. An example will be constructed in the next section. Finally, the denseness property (2.17) in the dual space B \u2217 does not necessarily imply that (2.20) span \u00af { K ( x , \u22c5 ) \u03be : x \u2208 X , \u03be \u2208 \u039b } = B . A negative example will also be given in the next section after we present a construction of vector-valued RKBSs through feature maps. Before that, we present another important property of a vector-valued RKBS. Proposition 2.5 Let B be a \u039b -valued RKBS on X . Suppose that f n \u2208 B , n \u2208 N converges to some f 0 \u2208 B then f n ( x ) converges to f 0 ( x ) in the topology of \u039b for each x \u2208 X . The convergence is uniform on the set where \u2016 K ( x , x ) \u2016 M ( \u039b ) is bounded. Proof Suppose that \u2016 f n \u2212 f \u2016 B converges 0 as n tends to infinity. We get by (2.15) that \u2016 f n ( x ) \u2212 f ( x ) \u2016 \u039b = sup \u03be \u2208 \u039b , \u2016 \u03be \u2016 \u039b = 1 | [ f n ( x ) \u2212 f ( x ) , \u03be ] \u039b | = sup \u03be \u2208 \u039b , \u2016 \u03be \u2016 \u039b = 1 | [ f n \u2212 f , K ( x , \u22c5 ) \u03be ] B | \u2264 sup \u03be \u2208 \u039b , \u2016 \u03be \u2016 \u039b = 1 \u2016 f n \u2212 f \u2016 B \u2016 K ( x , \u22c5 ) \u03be \u2016 B \u2264 \u2016 f n \u2212 f \u2016 B \u2016 K ( x , x ) \u2016 M ( \u039b ) 1 / 2 . Therefore, f n ( x ) converges pointwise to f ( x ) on X and the convergence is uniform on the set where \u2016 K ( x , x ) \u2016 M ( \u039b ) is bounded.\u25a1 3 Feature map representations Feature map representations form the most important way of expressing reproducing kernels. To introduce feature maps for the reproducing kernel of a vector-valued RKBS, we need the notion of the generalized adjoint [22] of a bounded linear operator between Banach spaces. Let V 1 , V 2 be two uniform Banach spaces with the compatible semi-inner products [ \u22c5 , \u22c5 ] V 1 and [ \u22c5 , \u22c5 ] V 2 , respectively. The generalized adjoint T \u2020 of a T \u2208 L ( V 1 , V 2 ) is an operator in M ( V 2 , V 1 ) defined by [ T u , v ] V 2 = [ u , T \u2020 v ] V 1 , u \u2208 V 1 , v \u2208 V 2 . It can be verified that T \u2020 = J V 1 \u2212 1 T \u2217 J V 2 . Thus, T \u2020 is indeed bounded as \u2016 T \u2020 \u2016 M ( V 2 , V 1 ) = \u2016 T \u2217 \u2016 L ( V 2 \u2217 , V 1 \u2217 ) = \u2016 T \u2016 L ( V 1 , V 2 ) . We are in a position to present a characterization of the reproducing kernel of a vector-valued RKBS. Theorem 3.1 A function K : X \u00d7 X \u2192 M ( \u039b ) is the reproducing kernel of some \u039b -valued RKBS on X if and only if there exist a uniform Banach space W and a mapping \u03a6 : X \u2192 L ( W , \u039b ) such that (3.1) K ( x , y ) = \u03a6 ( y ) \u03a6 \u2020 ( x ) , x , y \u2208 X , and (3.2) span \u00af { ( \u03a6 \u2020 ( x ) \u03be ) \u2217 : x \u2208 X , \u03be \u2208 \u039b } = W \u2217 . Here \u03a6 \u2020 is the function from X to M ( \u039b , W ) defined by \u03a6 \u2020 ( x ) \u2254 ( \u03a6 ( x ) ) \u2020 , x \u2208 X . Proof Suppose that K is the reproducing kernel of some \u039b -valued RKBS B on X . Set W \u2254 B and define \u03a6 : X \u2192 L ( W , \u039b ) by ( \u03a6 ( x ) ) ( f ) \u2254 f ( x ) , f \u2208 B , x \u2208 X . To identify \u03a6 \u2020 , we observe by the reproducing property (2.6) for all \u03be \u2208 \u039b and f \u2208 B that [ f , \u03a6 \u2020 ( x ) \u03be ] B = [ ( \u03a6 ( x ) ) f , \u03be ] \u039b = [ f ( x ) , \u03be ] \u039b = [ f , K ( x , \u22c5 ) \u03be ] B , x \u2208 X , \u03be \u2208 \u039b , which implies that \u03a6 \u2020 ( x ) \u03be = K ( x , \u22c5 ) \u03be for all x \u2208 X and \u03be \u2208 \u039b . Requirement (3.2) is fulfilled by (2.17). By the forms of \u03a6 and \u03a6 \u2020 , we obtain that \u03a6 ( y ) \u03a6 \u2020 ( x ) \u03be = \u03a6 ( y ) ( K ( x , \u22c5 ) \u03be ) = K ( x , y ) \u03be , which proves (3.1). On the other hand, suppose that K is of the form (3.1) in terms of some mapping \u03a6 satisfying the denseness condition (3.2). We shall construct the RKBS that takes K as its reproducing kernel. For this purpose, we let B be composed of functions from X to \u039b of the following form f u ( x ) \u2254 \u03a6 ( x ) u , x \u2208 X for some u \u2208 W . Since each \u03a6 ( x ) is a linear operator, B is a linear vector space. We impose a norm on B by setting \u2016 f u \u2016 B \u2254 \u2016 u \u2016 W , u \u2208 W . To verify that this is a well-defined norm, it suffices to show that the representer u of a function f u \u2208 B is unique. Assume that f u = 0 . Then for all x \u2208 X and \u03be \u2208 \u039b , ( u , ( \u03a6 \u2020 ( x ) \u03be ) \u2217 ) W = [ u , \u03a6 \u2020 ( x ) \u03be ] W = [ \u03a6 ( x ) u , \u03be ] \u039b = [ 0 , \u03be ] \u039b = 0 , which combined with (3.2) implies that u = 0 . The arguments also show that B is a Banach space of functions. Moreover, it is a uniform Banach space as it is isometrically isomorphic to W . Clearly, we have for each x \u2208 X and u \u2208 W that \u2016 f u ( x ) \u2016 \u039b = \u2016 \u03a6 ( x ) u \u2016 \u039b \u2264 \u2016 \u03a6 ( x ) \u2016 L ( W , \u039b ) \u2016 u \u2016 W = \u2016 \u03a6 ( x ) \u2016 L ( W , \u039b ) \u2016 f u \u2016 B , which shows that point evaluations are bounded on B . We conclude that B is a \u039b -valued RKBS on X . It remains to prove that K is the reproducing kernel of B . To this end, we identify the unique compatible semi-inner product on B as [ f u , f v ] B \u2254 [ u , v ] W , u , v \u2208 W , and observe for all u \u2208 W and x \u2208 X that [ f u , K ( x , \u22c5 ) \u03be ] B = [ f u , \u03a6 ( \u22c5 ) \u03a6 \u2020 ( x ) \u03be ] B = [ u , \u03a6 \u2020 ( x ) \u03be ] W = [ \u03a6 ( x ) u , \u03be ] \u039b = [ f u ( x ) , \u03be ] \u039b , which is what we want. The proof is complete.\u25a1 We call the Banach space W and the mapping \u03a6 in Theorem 3.1 a pair of feature space and feature map for K , respectively. The proof of Theorem 3.1 contains a construction of vector-valued RKBSs by feature maps, which we pull out separately as a corollary below. Corollary 3.2 Let W be a uniform Banach space and \u03a6 : X \u2192 L ( W , \u039b ) be a feature map of K that satisfies (3.1) and (3.2) . Then the linear vector space B \u2254 { \u03a6 ( \u22c5 ) u : u \u2208 W } endowed with the norm \u2016 \u03a6 ( \u22c5 ) u \u2016 B \u2254 \u2016 u \u2016 W , u \u2208 W and compatible semi-inner product [ \u03a6 ( \u22c5 ) u , \u03a6 ( \u22c5 ) v ] B \u2254 [ u , v ] W , u , v \u2208 W is a \u039b -valued RKBS on X with the reproducing kernel K given by (3.1) . As an interesting application of Corollary 3.2, we shall show that a vector-valued RKBS is always isometrically isomorphic to a scalar-valued RKBS on a different input space. Corollary 3.3 If B is a \u039b -valued RKBS on X then the following linear vector space B \u0303 of complex-valued functions f \u0303 on X \u0303 \u2254 X \u00d7 \u039b of the form f \u0303 ( x , \u03be ) \u2254 [ f ( x ) , \u03be ] \u039b , x \u2208 X , \u03be \u2208 \u039b , f \u2208 B is an RKBS on X \u0303 with the norm \u2016 f \u0303 \u2016 B \u0303 \u2254 \u2016 f \u2016 B , f \u2208 B and the compatible semi-inner product [ f \u0303 , g \u0303 ] B \u0303 \u2254 [ f , g ] B , f , g \u2208 B . The reproducing kernel K \u0303 of B \u0303 is K \u0303 ( ( x , \u03be ) , ( y , \u03b7 ) ) \u2254 [ K ( x , y ) \u03be , \u03b7 ] \u039b , x , y \u2208 X , \u03be , \u03b7 \u2208 \u039b . Proof It suffices to point out that B \u0303 is constructed by Corollary 3.2 via the choices \u039b \u2254 C , W \u2254 B , \u03a6 ( x , \u03be ) \u2254 ( K ( x , \u22c5 ) \u03be ) \u2217 , ( x , \u03be ) \u2208 X \u0303 . The feature map satisfies the denseness condition by (2.17).\u25a1 We shall next construct by Corollary 3.2 a simple vector-valued RKBS to show that the reproducing kernel of a general vector-valued RKBS might not satisfy (2.19) or (2.20). Let p , q , r , s \u2208 ( 1 , + \u221e ) satisfy that (3.3) 1 p + 1 q = 1 r + 1 s = 1 . Here, for the sake of convenience in enumerating elements from a finite set, we set N l \u2254 { 1 , 2 , \u2026 , l } for l \u2208 N . For each \u03b3 \u2208 ( 1 , + \u221e ) and l \u2208 N , \u2113 \u03b3 l denotes the Banach space of all vectors u = ( u j : j \u2208 N l ) \u2208 C l with the norm \u2016 u \u2016 \u2113 \u03b3 l \u2254 ( \u2211 j = 1 l | u j | \u03b3 ) 1 / \u03b3 < + \u221e . The space \u2113 \u03b3 l is a uniform Banach space with the compatible semi-inner product [ u , v ] \u2113 \u03b3 l \u2254 \u2211 j = 1 l u j v j \u00af | v j | \u03b3 \u2212 2 \u2016 v \u2016 \u2113 \u03b3 l \u03b3 \u2212 2 , u , v \u2208 \u2113 \u03b3 l . The dual element u \u2217 of u \u2208 \u2113 \u03b3 l is hence given by (3.4) u \u2217 \u2254 ( v j \u00af | v j | \u03b3 \u2212 2 \u2016 v \u2016 \u2113 \u03b3 l \u03b3 \u2212 2 : j \u2208 N l ) , u \u2208 \u2113 \u03b3 l . Non-completeness of the linear span of the reproducing kernel in B . We give a counterexample of (2.20) first. Let m , n \u2208 N . We choose the output space \u039b and feature space W as \u2113 p n and \u2113 r m , respectively. Thus, we have that \u039b \u2217 = \u2113 q n and W \u2217 = \u2113 s m . The input space will be chosen as a set of m discrete points X \u2254 { x j : j \u2208 N m } . A feature map \u03a6 : X \u2192 L ( W , \u039b ) should satisfy the denseness condition (3.2). We note by the definition of the generalized adjoint that this condition is equivalent to (3.5) span \u00af { \u03a6 \u2217 ( x ) \u03be \u2217 : x \u2208 X , \u03be \u2208 \u039b } = W \u2217 , where \u03a6 \u2217 ( x ) \u2254 ( \u03a6 ( x ) ) \u2217 for all x \u2208 X . Let us take a close look at Eq. (2.20). By Corollary 3.2, a general function in B is of the form f u \u2254 \u03a6 ( \u22c5 ) u for some u \u2208 W . Eq. (2.20) does not hold true if and only if there exists a nontrivial u \u2208 W such that [ K ( x , \u22c5 ) \u03be , f u ] B = [ \u03a6 ( \u22c5 ) \u03a6 \u2020 ( x ) \u03be , \u03a6 ( \u22c5 ) u ] B = [ \u03a6 \u2020 ( x ) \u03be , u ] W = 0 , which in turn is equivalent to that span { \u03a6 \u2020 ( x ) \u03be : x \u2208 X , \u03be \u2208 \u039b } is not dense in W . We conclude that to construct a \u039b -valued RKBS for which (2.20) is not true, it suffices to find a feature map \u03a6 : X \u2192 L ( W , \u039b ) that satisfies (3.5) but (3.6) span \u00af { \u03a6 \u2020 ( x ) \u03be : x \u2208 X , \u03be \u2208 \u039b } \u2acb W . To this end, we find a sequence of vectors w j \u2208 C m and set (3.7) \u03a6 \u2217 ( x j ) \u03be \u2217 \u2254 ( \u03be \u2217 ) 1 w j , j \u2208 N m , where ( \u03be \u2217 ) 1 is the first component of the vector \u03be \u2217 \u2208 C n . Since for each j \u2208 N m , \u03a6 \u2217 ( x j ) is a linear operator from \u039b \u2217 to W \u2217 and both the spaces are finite-dimensional, \u03a6 \u2217 ( x j ) is bounded. We reformulate (3.5) and (3.6) to get that they are respectively equivalent to (3.8) span { w j : j \u2208 N m } = C m and (3.9) span { J W \u2212 1 w j : j \u2208 N m } \u2acb C m . Here for a vector u = ( u j : j \u2208 N m ) \u2208 C m , we get by (3.4) that J W \u2212 1 u = ( u j \u00af | u j | s \u2212 2 \u2016 u \u2016 \u2113 s m s \u2212 2 : j \u2208 N m ) . Therefore, the task reduces to the searching of an m \u00d7 m nonsingular matrix A that becomes singular when we apply the function t \u2192 t \u00af | t | s \u2212 2 to each of its components. We find two such matrices as shown below m = 4 , s = 4 , A 1 \u2254 [ 0 8 2 4 5 0 5 1 5 4 6 9 0 9 4 8 ] , and m = 4 , s = 5 , A 2 \u2254 [ 9 9 9 9 8 6 0 2 6 9 2 1 7 4 9 9 ] . Non-positive-definiteness of the reproducing kernel of B . We shall give an example to show that (2.19) might not hold true for the reproducing kernel of a vector-valued RKBS when the number m of sampling points exceeds 2. In fact, we let m = 3 and B be constructed as in the above example with { w j : j \u2208 N 3 } to be appropriately chosen in the definition (3.7) of \u03a6 \u2217 . Our purpose is to find w j \u2208 C 3 and \u03be j \u2208 \u039b , j \u2208 N 3 such that (3.10) \u2211 j = 1 3 \u2211 k = 1 3 [ K ( x j , x k ) \u03be j , \u03be k ] B < 0 . We first note for all j , k \u2208 N 3 that [ K ( x j , x k ) \u03be j , \u03be k ] \u039b = [ \u03a6 ( x k ) \u03a6 \u2020 ( x j ) \u03be j , \u03be k ] \u039b = [ \u03a6 \u2020 ( x j ) \u03be j , \u03a6 \u2020 ( x k ) \u03be k ] \u039b = [ ( \u03a6 \u2020 ( x k ) \u03be k ) \u2217 , ( \u03a6 \u2020 ( x j ) \u03be j ) \u2217 ] \u039b \u2217 = [ \u03a6 \u2217 ( x k ) ( \u03be k ) \u2217 , \u03a6 \u2217 ( x j ) ( \u03be j ) \u2217 ] \u039b \u2217 . We shall choose \u03be j \u2208 \u039b so that ( ( \u03be j ) \u2217 ) 1 = 1 for each j \u2208 N 3 . With the choice, we obtain by (3.7) and the above equation that \u2211 j = 1 3 \u2211 k = 1 3 [ K ( x j , x k ) \u03be j , \u03be k ] B = \u2211 j = 1 3 \u2211 k = 1 3 [ w k , w j ] \u2113 s 3 . The conclusion is that for (3.10) to hold, it suffices to find w j \u2208 C 3 , j \u2208 N 3 that form a basis for C 3 but \u2211 j = 1 3 \u2211 k = 1 3 [ w k , w j ] \u2113 s 3 < 0 . Two examples are shown below s = 4 , [ w 1 , w 2 , w 3 ] = [ 4 \u2212 2 \u2212 3 3 \u2212 5 4 1 \u2212 1 1 ] , and s = 5 , [ w 1 , w 2 , w 3 ] = [ 3 2 \u2212 3 2 \u2212 3 3 \u2212 5 0 4 ] . 4 Examples of vector-valued RKBSs We present several examples of vector-valued RKBSs in this section. The first one of them is applicable to learning a sensing matrix. 4.1 The space of sensing matrices Spaces involved in this example are all over the field R of real numbers. The input space and the output space are chosen by X \u2254 R d and \u039b \u2254 R n . The vector-valued RKBS B consists of all the n \u00d7 d real matrices. Each A \u2208 B is considered to be a function from R d to R n with the point evaluation A ( x ) \u2254 A x , x \u2208 R d . To find a norm that makes B a uniform Banach space, we first point out that a finite-dimensional Banach space V is uniform if and only if its norm is strictly convex. For a proof of this simple fact, see, for example, [40]. Recall that \u2016 \u22c5 \u2016 V is said to be strictly convex if for all u , v \u2208 V \u2216 { 0 } , \u2016 u + v \u2016 V = \u2016 u \u2016 V + \u2016 v \u2016 V always implies that u = \u03b1 v for some \u03b1 > 0 . Strictly convex norms on B include \u2022 column-wise norms: (4.1) \u2016 A \u2016 B \u2254 G ( \u2016 a 1 \u2016 1 , \u2016 a 2 \u2016 2 , \u2026 , \u2016 a d \u2016 d ) , A \u2208 B , where for each j \u2208 N d , a j is the j -th column of A and \u2016 \u22c5 \u2016 j is a strictly convex norm on R n , and G is a strictly convex function from R + d to R + \u2254 [ 0 , \u221e ) that is strictly increasing with respect to each of its variables and is homogeneous in the sense that G ( \u03b1 x ) = \u03b1 G ( x ) for all x \u2208 R + d and \u03b1 \u2208 R + . It is straightforward to verify that under the above conditions, (4.1) is indeed a strictly convex norm on B . An explicit instance is (4.2) \u2016 A \u2016 B \u2254 \u2016 ( \u2016 a j \u2016 \u2113 p n : j \u2208 N d ) \u2016 \u2113 r d , A \u2208 B , where p , r \u2208 ( 1 , + \u221e ) . One can easily transform a column-wise norm \u2016 \u22c5 \u2016 B into a row-wise norm by equipping A \u2208 B with \u2016 A T \u2016 B , where A T is the transpose of A . \u2022 the p -th Schatten norm (see, Section 3.5 of [18]): \u2016 A \u2016 B \u2254 ( \u2211 j = 1 min ( n , d ) ( \u03c3 j ( A ) ) p ) 1 / p , A \u2208 B , p \u2208 ( 1 , + \u221e ) , where \u03c3 j ( A ) is the j -th singular value of A . The p -th Schatten norm belongs to the class of matrix norms that are invariant under multiplication by unitary matrices. We shall look at the reproducing kernel of B when it is endowed with the norm (4.2) and the output space R n is equipped with the norm of \u2113 \u03b3 n for some \u03b3 \u2208 ( 1 , + \u221e ) . Let q , s be the conjugate numbers of p and r , respectively. In other words, they satisfy (3.3). We proceed by (2.6) that ( A x , \u03be \u2217 ) \u2113 \u03b3 n = [ A , K ( x , \u22c5 ) \u03be ] B = ( A , ( K ( x , \u22c5 ) \u03be ) \u2217 ) B , A \u2208 B , x \u2208 R d , \u03be \u2208 R n , which implies that (4.3) ( K ( x , \u22c5 ) \u03be ) \u2217 = \u03be \u2217 x T , x \u2208 R d , \u03be \u2208 R n . The dual element of A \u2208 B is given by A \u2217 = 1 \u2016 A \u2016 B r \u2212 2 [ a j \u2217 \u2016 a j \u2016 \u2113 p n r \u2212 2 : j \u2208 N d ] , where a j \u2217 is the dual vector of a j in \u2113 p n . The reproducing kernel of B can be derived from the above two equation. Its explicit form is too complicated to be presented. We shall see from the study of regularized learning schemes in vector-valued RKBSs that the identification (4.3) of its dual is usually more important. 4.2 Tensor products of scalar-valued RKBSs Let n \u2208 N and B j , j \u2208 N n be scalar-valued RKBSs on an input space X . We let B be the tensor product of B j , j \u2208 N n . Thus, it consists of C n -valued functions of the form f = ( f j \u2208 B j : j \u2208 N n ) . To define a norm on B , we choose functions N , N \u2217 from R + n to R + that are strictly convex, strictly increasing with respect to each of the variables, homogeneous, and satisfy that x \u2192 N \u2217 ( | x | ) is the dual norm of x \u2192 N ( | x | ) on R n . Here, | x | \u2254 ( | x j | : j \u2208 N n ) for each x \u2208 R n . An example is N ( x ) \u2254 \u2016 x \u2016 \u2113 p n , N \u2217 ( x ) \u2254 \u2016 x \u2016 \u2113 q n , x \u2208 R + n , where p , q are a pair of conjugate numbers in ( 1 , + \u221e ) . With such two gauge functions, we impose the following norm on B (4.4) \u2016 f \u2016 B \u2254 N ( \u2016 f 1 \u2016 B 1 , \u2016 f 2 \u2016 B 2 , \u2026 , \u2016 f n \u2016 B n ) , f \u2208 B . Proposition 4.1 The tensor product space B with the norm (4.4) is a uniform Banach space. Proof We first show that (4.4) defines a uniform convex norm on B . It is straightforward to verify that it is a norm. Let \u03b5 be a fixed positive number and f , g \u2208 B be such that \u2016 f \u2016 B = \u2016 g \u2016 B = 1 and \u2016 f \u2212 g \u2016 B \u2265 \u03b5 . We have that N ( \u2016 f 1 + g 1 \u2016 B 1 , \u2026 , \u2016 f n + g n \u2016 B n ) \u2264 N ( \u2016 f 1 \u2016 B 1 + \u2016 g 1 \u2016 B 1 , \u2026 , \u2016 f n \u2016 B n + \u2016 g n \u2016 B n ) \u2264 N ( \u2016 f 1 \u2016 B 1 , \u2026 , \u2016 f n \u2016 B n ) + N ( \u2016 g 1 \u2016 B 1 , \u2026 , \u2016 g n \u2016 B n ) . As all the norms on R n are equivalent, N is continuous on R + n , and vectors x \u2208 R + n satisfying N ( | x | ) = 1 form a compact subset in R n . We also recall that N is strictly increasing with respect to each of its variables and | x | \u2192 N ( | x | ) is a strictly convex norm on R n . We conclude from these two facts and the above equation that B is uniform convex if there exists some positive constant \u03b5 \u2032 independent of f , g such that max { \u2016 f j \u2016 B j + \u2016 g j \u2016 B j \u2212 \u2016 f j + g j \u2016 B j : j \u2208 N n } \u2265 \u03b5 \u2032 or max { | \u2016 f j \u2016 B j \u2212 \u2016 g j \u2016 B j | : j \u2208 N n } \u2265 \u03b5 \u2032 . Assume to the contrary that such a positive constant does not exist. It implies that for all \u03b2 > 0 , there exist f , g \u2208 B that satisfy \u2016 f \u2212 g \u2016 B \u2265 \u03b5 and \u2016 f j \u2016 B j + \u2016 g j \u2016 B j \u2212 \u2016 f j + g j \u2016 B j < \u03b2 , | \u2016 f j \u2016 B j \u2212 \u2016 g j \u2016 B j | < \u03b2 for all j \u2208 N n . Again, as any two norms on R n are equivalent, the inequality \u2016 f \u2212 g \u2016 B \u2265 \u03b5 implies that \u2016 f k \u2212 g k \u2016 B k \u2265 \u03b5 0 > 0 for some k \u2208 N n and some positive constant \u03b5 0 independent of f , g . The conclusion is that there exist some k \u2208 N n and some positive constants M , \u03b5 0 > 0 such that for all \u03b2 > 0 , there exist u , v \u2208 B k such that \u2016 u \u2016 B k \u2264 M , \u2016 v \u2016 B k \u2264 M and (4.5) \u2016 u \u2212 v \u2016 B k \u2265 \u03b5 0 , | \u2016 u \u2016 B k \u2212 \u2016 v \u2016 B k | < \u03b2 , \u2016 u \u2016 B k + \u2016 v \u2016 B k \u2212 \u2016 u + v \u2016 B k < \u03b2 . We shall show that the above equation contradicts the uniform convexity of B k . We may choose \u03b2 so small that \u03b2 < \u03b5 0 / 4 . It follows from the first two inequalities of (4.5) that (4.6) \u2016 u \u2016 B k \u2265 \u03b5 0 4 , \u2016 v \u2016 B k \u2265 \u03b5 0 4 . To proceed, we estimate that \u2016 u \u2016 u \u2016 B k \u2212 v \u2016 v \u2016 B k \u2016 B k = \u2016 u \u2016 u \u2016 B k \u2212 v \u2016 u \u2016 B k + v \u2016 u \u2016 B k \u2212 v \u2016 v \u2016 B k \u2016 B k \u2265 1 \u2016 u \u2016 B k \u2016 u \u2212 v \u2016 B k \u2212 \u2016 v \u2016 B k | 1 \u2016 u \u2016 B k \u2212 1 \u2016 v \u2016 B k | \u2265 \u03b5 0 \u2212 \u03b2 \u2016 u \u2016 B k \u2265 3 \u03b5 0 4 M . By the uniform convexity of B k , there exist a positive constant \u03b4 dependent on \u03b5 0 , M and the space B k only such that (4.7) \u2016 u \u2016 u \u2016 B k + v \u2016 v \u2016 B k \u2016 B k < 2 \u2212 \u03b4 . Finally, we get by (4.5)\u2013(4.7) that \u2016 u \u2016 B k + \u2016 v \u2016 B k \u2212 \u2016 u + v \u2016 B k = \u2016 u \u2016 B k + \u2016 v \u2016 B k \u2212 \u2016 u \u2016 B k \u2016 u \u2016 u \u2016 B k + v \u2016 v \u2016 B k + v \u2016 u \u2016 B k \u2212 v \u2016 v \u2016 B k \u2016 B k \u2265 \u2016 u \u2016 B k + \u2016 v \u2016 B k \u2212 ( 2 \u2212 \u03b4 ) \u2016 u \u2016 B k \u2212 \u2016 u \u2016 B k \u2016 v \u2016 B k | 1 \u2016 u \u2016 B k \u2212 1 \u2016 v \u2016 B k | \u2265 \u2016 u \u2016 B k + \u2016 v \u2016 B k + | \u2016 u \u2016 B k \u2212 \u2016 v \u2016 B k | \u2212 ( 2 \u2212 \u03b4 ) \u2016 u \u2016 B k \u2265 \u03b4 \u2016 u \u2016 B k \u2265 \u03b5 0 \u03b4 4 , which contradicts to the third inequality of (4.5) as \u03b2 can be arbitrarily small. It is clear that B \u2217 = { ( f j \u2217 : j \u2208 N n ) : f \u2208 B } with the norm \u2016 ( f j \u2217 : j \u2208 N n ) \u2016 B \u2217 = N \u2217 ( \u2016 f 1 \u2217 \u2016 B 1 \u2217 , \u2026 , \u2016 f n \u2217 \u2016 B n \u2217 ) . Similar arguments to those above prove that B \u2217 is uniformly convex. By the fact (see [11]) that a Banach space is uniformly Fr\u00e9chet differentiable if and only if its dual is uniformly convex, B is uniform.\u25a1 We next identify the reproducing kernel of B with the following norm \u2016 f \u2016 B \u2254 ( \u2211 j = 1 n \u2016 f j \u2016 B j p ) 1 / p , f \u2208 B . Let the output space C n be equipped with the norm of \u2113 r n and let K j be the reproducing kernel of B j , j \u2208 N n . The unique compatible semi-inner product on B is given by [ f , g ] B \u2254 1 \u2016 g \u2016 B p \u2212 2 \u2211 j = 1 n [ f j , g j ] B j \u2016 g j \u2016 B j p \u2212 2 , f , g \u2208 B . The duality mapping on B is hence of the form (4.8) f \u2217 \u2254 ( f j \u2217 \u2016 f j \u2016 B j p \u2212 2 \u2016 f \u2016 B p \u2212 2 : j \u2208 N n ) , f \u2208 B . To find an expression for ( K ( x , \u22c5 ) \u03be ) \u2217 for x \u2208 X and \u03be \u2208 C n , we deduce that [ f ( x ) , \u03be ] \u2113 r n = 1 \u2016 \u03be \u2016 \u2113 r n r \u2212 2 \u2211 j = 1 n \u03be j \u00af | \u03be j | r \u2212 2 f j ( x ) = 1 \u2016 \u03be \u2016 \u2113 r n r \u2212 2 \u2211 j = 1 n \u03be j \u00af | \u03be j | r \u2212 2 [ f j , K j ( x , \u22c5 ) ] B j . It follows that (4.9) ( K ( x , \u22c5 ) \u03be ) \u2217 = ( \u03be j \u00af | \u03be j | r \u2212 2 \u2016 \u03be \u2016 \u2113 r n r \u2212 2 ( K j ( x , \u22c5 ) ) \u2217 : j \u2208 N n ) , x \u2208 X , \u03be \u2208 C n . By Eqs. (4.8) and (4.9), \u2016 K ( x , \u22c5 ) \u03be \u2016 B = 1 \u2016 \u03be \u2016 \u2113 r n r \u2212 2 ( \u2211 j = 1 n ( | \u03be j | r \u2212 1 K j ( x , x ) ) q ) 1 / q , x \u2208 X , \u03be \u2208 C n and K ( x , y ) \u03be = ( \u03be j | \u03be j | K j ( x , y ) ( \u2016 K ( x , \u22c5 ) \u03be \u2016 B p \u2212 2 | \u03be j | r \u2212 1 \u2016 \u03be \u2016 \u2113 r n r \u2212 2 K j ( x , x ) p \u2212 2 2 ) 1 / ( p \u2212 1 ) : j \u2208 N n ) , x , y \u2208 X , \u03be \u2208 C n . 4.3 Translation invariant vector-valued RKBSs A C n -valued RKBS B on R d is said to be translation invariant if translations are isometric on B , namely, if for each f \u2208 B and x \u2208 R d , f ( \u22c5 + x ) \u2208 B and \u2016 f ( \u22c5 + x ) \u2016 B = \u2016 f \u2016 B . It was proved in [35] that a scalar-valued RKHS is translation invariant if and only if its reproducing kernel is of the form \u03c8 ( x \u2212 y ) for some scalar-valued function \u03c8 . For the Banach space case, as a reproducing kernel alone does not determine its RKBS, we do not have such a characterization. Our purpose in this subsection is to construct a class of translation invariant vector-valued RKBSs by the Fourier transform. Denote by L 1 ( R d ) the Banach space of Lebesgue measurable functions f on R d equipped with the norm \u2016 f \u2016 L 1 ( R d ) \u2254 \u222b R d | f ( x ) | d x . For \u03c6 \u2208 L 1 ( R d ) , its Fourier transform \u03c6 \u02c6 and inverse Fourier transform \u03c6 \u030c are respectively given by \u03c6 \u02c6 ( t ) \u2254 1 ( 2 \u03c0 ) d \u222b R d \u03c6 ( x ) e \u2212 i x \u22c5 t d x , t \u2208 R d and \u03c6 \u030c ( t ) \u2254 1 ( 2 \u03c0 ) d \u222b R d \u03c6 ( x ) e i x \u22c5 t d x , t \u2208 R d . Here x \u22c5 t is the standard inner product on R d . To start the construction, we let \u03d5 be a nonnegative function in L 1 ( R d ) with \u222b R d \u03d5 ( x ) d x = 1 and denote by L p ( R d , d \u03d5 ) , p \u2208 ( 1 , + \u221e ) , the Banach space of Lebesgue measurable functions f on R d with the norm \u2016 f \u2016 L p ( R d , d \u03d5 ) \u2254 ( \u222b R d | f ( x ) | p \u03d5 ( x ) d x ) 1 / p < + \u221e . The feature space W is chosen as W \u2254 { u = ( u 1 , \u2026 , u n ) : u j \u2208 L p ( R d , d \u03d5 ) , j \u2208 N n } endowed with the norm \u2016 u \u2016 W \u2254 ( \u2211 j = 1 n \u2016 u j \u2016 L p ( R d , d \u03d5 ) p ) 1 / p . Its dual space W \u2217 is given by W \u2217 = { w = ( w 1 , \u2026 , w n ) : w j \u2208 L q ( R d , d \u03d5 ) , j \u2208 N n } with the norm \u2016 w \u2016 W \u2217 \u2254 ( \u2211 j = 1 n \u2016 w j \u2016 L q ( R d , d \u03d5 ) q ) 1 / q . The bilinear form on W \u00d7 W \u2217 is ( u , w ) W = \u2211 j = 1 n \u222b R d u j ( x ) w j ( x ) \u03d5 ( x ) d x , u \u2208 W , w \u2208 W \u2217 . Moreover, the dual element of u \u2208 W is u \u2217 = ( u j \u2217 \u2016 u j \u2016 L p ( R d , d \u03d5 ) p \u2212 2 \u2016 u \u2016 W p \u2212 2 : j \u2208 N n ) . By Proposition 4.1, W is a uniform Banach space. Our feature map \u03a6 : R d \u2192 L ( W , C n ) is then defined by \u03a6 ( x ) u \u2254 S ( u \u03d5 ) \u02c6 ( x ) , x \u2208 R d , u \u2208 W , where S is an invertible n \u00d7 n matrix and ( u \u03d5 ) \u02c6 \u2254 ( ( u j \u03d5 ) \u02c6 : j \u2208 N n ) . The map \u03a6 is well-defined as f \u03d5 \u2208 L 1 ( R d ) for all f \u2208 L p ( R d , d \u03d5 ) by the H\u00f6lder inequality. We also notice that \u03a6 ( x ) is continuous from W to C n for each x \u2208 R d by the fact that | ( f \u03d5 ) \u02c6 ( x ) | \u2264 \u2016 f \u03d5 \u2016 L 1 ( R d ) \u2264 \u2016 f \u2016 L p ( R d , d \u03d5 ) for all f \u2208 L p ( R d , d \u03d5 ) . One sees that the adjoint operator \u03a6 \u2217 : R d \u2192 L ( C n , W \u2217 ) is given by \u03a6 \u2217 ( x ) ( \u03b7 ) = e \u2212 i x \u22c5 t ( 2 \u03c0 ) d S T \u03b7 , x \u2208 R d , \u03b7 \u2208 C n . Clearly, the denseness condition (3.5) is satisfied. The equivalent condition (3.2) hence holds true. We obtain by Corollary 3.2 that B \u2254 { f u \u2254 S ( u \u03d5 ) \u02c6 : u \u2208 W } with the norm \u2016 f u \u2016 B \u2254 \u2016 u \u2016 W and compatible semi-inner product [ S ( u \u03d5 ) \u02c6 , S ( v \u03d5 ) \u02c6 ] B = [ u , v ] W = \u2211 j = 1 n 1 \u2016 v \u2016 W p \u2212 2 \u222b R d u j ( x ) v j ( x ) \u00af | v j ( x ) | p \u2212 2 \u03d5 ( x ) d x is a C n -valued RKBS. It is translation invariant because for all y \u2208 R d and u \u2208 W \u2016 S ( u \u03d5 ) \u02c6 ( \u22c5 + y ) \u2016 B = \u2016 S ( e \u2212 i y \u22c5 t u \u03d5 ) \u02c6 \u2016 B = \u2016 e \u2212 y \u22c5 t u \u2016 W = \u2016 u \u2016 W = \u2016 S ( u \u03d5 ) \u02c6 \u2016 B . To understand the reproducing kernel of B , we present the dual space of B B \u2217 = { S ( u \u2217 \u03d5 ) \u030c : u \u2208 W } with the norm, compatible semi-inner product and bilinear form \u2016 S ( u \u2217 \u03d5 ) \u030c \u2016 B \u2217 = \u2016 u \u2217 \u2016 W \u2217 , [ S ( u \u2217 \u03d5 ) \u030c , S ( v \u2217 \u03d5 ) \u030c ] B \u2217 = [ v , u ] W , ( S ( u \u03d5 ) \u02c6 , S ( v \u2217 \u03d5 ) \u030c ) B = ( u , v \u2217 ) W . With these preparations, we identify by (2.6) that ( K ( x , \u22c5 ) \u03be ) \u2217 = S ( v x , \u03be \u2217 \u03d5 ) \u030c , x \u2208 R d , \u03be \u2208 C n , where v x , \u03be \u2217 ( t ) \u2254 e \u2212 i x \u22c5 t ( 2 \u03c0 ) d S T \u03be \u2217 , t \u2208 R d and \u03be \u2217 is the dual element of \u03be in C n under a strictly convex norm. By the above two equations, ( K ( x , \u22c5 ) \u03be ) \u2217 ( y ) = 1 ( 2 \u03c0 ) d S S T \u03be \u2217 \u03d5 \u02c6 ( x \u2212 y ) , x , y \u2208 R d , \u03be \u2208 C n . We also derive that K ( x , y ) \u03be = \u2016 S T \u03be \u2217 \u2016 \u2113 q n p \u2212 2 p \u2212 1 ( 2 \u03c0 ) d S ( ( S T \u03be \u2217 ) j \u00af | ( ( S T \u03be \u2217 ) j ) | p \u2212 2 p \u2212 1 : j \u2208 N n ) T \u03d5 \u02c6 ( y \u2212 x ) , x , y \u2208 R d , \u03be \u2208 C n . We remark that when p = 2 , C n is endowed with the standard Euclidean norm \u2016 \u22c5 \u2016 , and \u03d5 is the Gaussian function, K becomes the Gaussian kernel for C n -valued RKHS K ( x , y ) = S S \u2217 exp ( \u2212 \u2016 x \u2212 y \u2016 2 2 ) , x , y \u2208 R d , which confirms the validity of the above construction. 5 Multi-task learning with Banach spaces We discuss the applications of vector-valued RKBSs to the learning of vector-valued functions from finite samples. Specifically, suppose that the unknown target function is from the input space X to an output space \u039b and the observations of the function on given sampling points { x j : j \u2208 N m } \u2286 X are available. The observation at x j , j \u2208 N m could be f ( x j ) or the application of some continuous linear functional in \u039b \u2217 on f ( x j ) . And it is usually corrupted by noise in practice. To handle the noise and have a good generalization error, we shall follow the regularization methodology. For notational simplicity, let x \u2254 ( x j : j \u2208 N m ) \u2208 X m and f ( x ) \u2254 ( f ( x j ) : j \u2208 N m ) \u2208 \u039b m . A general learning scheme has the following form (5.1) inf f \u2208 B Q ( f ( x ) ) + \u03bb \u03a8 ( \u2016 f \u2016 B ) , where B is a chosen \u039b -valued RKBS on X , Q : \u039b m \u2192 R + is a loss function, \u03bb is a positive regularization parameter, and \u03a8 : R + \u2192 R + is called a regularizer. We are concerned with the existence and uniqueness, representation, and solving of the minimizer of (5.1). Before moving on to these topics, let us see some examples of learning schemes of the form (5.1): \u2013 Regularization networks (5.2) Q ( f ( x ) ) \u2254 \u2211 j = 1 m \u2016 f ( x j ) \u2212 \u03be j \u2016 \u039b 2 , \u03a8 ( \u2016 f \u2016 B ) \u2254 \u2016 f \u2016 B 2 , where \u03be j \u2208 \u039b , j \u2208 N m are observed outputs of f at x . In general, one may use (5.3) Q ( f ( x ) ) = P ( \u2016 f ( x 1 ) \u2212 \u03be 1 \u2016 \u039b , \u2026 , \u2016 f ( x m ) \u2212 \u03be m \u2016 \u039b ) , where P is a function from R + m \u2192 R + . A particular choice of P leads to the support vector machine regression. \u2013 Support vector machine regression \u039b \u2254 R n , Q ( f ( x ) ) = \u2211 j = 1 m max ( 0 , \u2016 f ( x j ) \u2212 \u03be j \u2016 \u2113 1 n \u2212 \u03b5 ) , where \u03b5 is a positive constant standing for the tolerance level. \u2013 Spectral learning: when B is the space of sensing matrices introduced in the last section with a unitarily invariant matrix norm, (5.1) is the special spectral learning considered in [2]. 5.1 Existence and uniqueness The weak topology is the weakest topology on a Banach space V such that elements in V \u2217 remain continuous on V . A sequence u n \u2208 V , n \u2208 N , is said to converge weakly to u 0 \u2208 V if for each \u03bc \u2208 V \u2217 , \u03bc ( u n ) converges to \u03bc ( u 0 ) . We call a regularizer \u03a8 : R + \u2192 R + admissible if it is continuous and nondecreasing on R + with (5.4) lim t \u2192 \u221e \u03a8 ( t ) = + \u221e . Proposition 5.1 If Q : \u039b m \u2192 R + is continuous with respect to each of its variables under the weak topology on \u039b and \u03a8 is an admissible regularizer then (5.1) has at least a minimizer. Proof Arguments similar to those in the proof of Proposition 4 in [39] still apply to the vector-valued case considered here.\u25a1 When \u039b is finite-dimensional, any two topologies on it are equivalent. Thus, continuity under the weak topology is equivalent to continuity with respect to the norm of \u039b . Corollary 5.2 Let B be finite-dimensional. If Q : \u039b m \u2192 R + is continuous with respect to each of its variables and \u03a8 is an admissible regularizer then (5.1) has at least a minimizer. We next deal with the case when the loss function has the form (5.3). Proposition 5.3 If P : R + m \u2192 R + is continuous on R + m and nondecreasing with respect to each of its variables and the regularizer \u03a8 is admissible then (5.5) inf f \u2208 B P ( \u2016 f ( x 1 ) \u2212 \u03be 1 \u2016 \u039b , \u2026 , \u2016 f ( x m ) \u2212 \u03be m \u2016 \u039b ) + \u03bb \u03a8 ( \u2016 f \u2016 B ) has a minimizer. Proof Set E ( f ) \u2254 P ( \u2016 f ( x 1 ) \u2212 \u03be 1 \u2016 \u039b , \u2026 , \u2016 f ( x m ) \u2212 \u03be m \u2016 \u039b ) + \u03bb \u03a8 ( \u2016 f \u2016 B ) , f \u2208 B and \u03b5 0 \u2254 inf f \u2208 B E ( f ) . Using the arguments similar to those in [39], we can find a sequence f n \u2208 B , n \u2208 N that is weakly convergent to some f 0 \u2208 B , and some \u03b1 > 0 such that \u2016 f 0 \u2016 B \u2264 \u03b1 and \u2016 f n \u2016 B \u2264 \u03b1 for all n \u2208 N . Moreover, for any \u03f5 > 0 there exists some N \u2208 N such that for n > N , (5.6) \u03a8 ( \u2016 f n \u2016 B ) \u2265 \u03a8 ( \u2016 f 0 \u2016 B ) \u2212 \u03f5 . Since f n converges weakly to f 0 , by (2.6) lim n \u2192 \u221e [ f n ( x j ) \u2212 \u03be j , f 0 ( x j ) \u2212 \u03be j ] \u039b = [ f 0 ( x j ) \u2212 \u03be j , f 0 ( x j ) \u2212 \u03be j ] \u039b for all j \u2208 N m . It implies by the Cauchy\u2013Schwarz inequality of semi-inner products that for any \u03b4 > 0 there exists some N \u2032 \u2208 N such that for n > N \u2032 (5.7) \u2016 f n ( x j ) \u2212 \u03be j \u2016 B \u2265 \u2016 f 0 ( x j ) \u2212 \u03be j \u2016 B \u2212 \u03b4 for all j \u2208 N m . Since \u2016 f 0 ( x j ) \u2212 \u03be j \u2016 B , \u2016 f n ( x j ) \u2212 \u03be j \u2016 B \u2264 max { \u03b1 \u2016 \u03b4 x j \u2016 L ( B , \u039b ) + \u2016 \u03be j \u2016 \u039b : j \u2208 N m } and \u03a8 is uniformly continuous on compact subsets of R + m and is nondecreasing with respect to each of its variables, we get by (5.7) that P ( \u2016 f n ( x 1 ) \u2212 \u03be 1 \u2016 \u039b , \u2026 , \u2016 f n ( x m ) \u2212 \u03be m \u2016 \u039b ) \u2265 P ( \u2016 f 0 ( x 1 ) \u2212 \u03be 1 \u2016 \u039b , \u2026 , \u2016 f 0 ( x m ) \u2212 \u03be m \u2016 \u039b ) \u2212 \u03f5 for sufficiently large n . This combined with (5.6) proves that f 0 is a minimizer of (5.5).\u25a1 For uniqueness of the minimizer, we have the following routine result. Proposition 5.4 If Q is convex on \u039b m and \u03a8 is strictly increasing and strictly convex then (5.1) has at most one minimizer. Proof It is straightforward that the function mapping f \u2208 B to Q ( f ( x ) ) + \u03bb \u03a8 ( \u2016 f \u2016 B ) is strictly convex on B .\u25a1 We close this subsection with the following corollary to the above propositions. Corollary 5.5 Let B be a \u039b -valued RKBS on X . Then inf f \u2208 B E ( f ) has a unique minimizer for the following choices of regularization functionals: E ( f ) = \u2211 j = 1 m \u2016 f ( x j ) \u2212 \u03be j \u2016 \u039b p + \u03bb \u2016 f \u2016 B r , p \u2208 [ 1 , + \u221e ) , r \u2208 ( 1 , + \u221e ) , E ( f ) = \u2211 j = 1 m max ( 0 , \u2016 f ( x j ) \u2212 \u03be j \u2016 \u039b \u2212 \u03b5 ) + \u03bb \u2016 f \u2016 B r , r \u2208 ( 1 , + \u221e ) , \u03b5 > 0 . 5.2 The representer theorem We study the representation of the minimizer of (5.1) by the reproducing kernel K of B . The result, known as the representer theorem in the scalar-valued and vector-valued RKHS cases, was due to [21] and [25], respectively. For more references on this subject for the RKHS case, see [1,28] and the references cited therein. We established the representer theorem for scalar-valued RKBSs in [37,39]. The representer theorem is closely related to the minimal norm interpolation. We start with examining the latter problem. Let x \u2254 ( x j : j \u2208 N m ) \u2208 X m be a fixed set of sampling points. Denote for each z \u2254 ( \u03b7 j : j \u2208 N m ) \u2208 \u039b m by I z the set of functions f \u2208 B that satisfy the interpolation condition f ( x ) = z . We need two notations for the proof of the representer theorem for the minimal norm interpolation. For a subset A of Banach space V , A \u22a5 stands for the set of all the continuous linear functionals on V that vanish on A , and for B \u2286 V \u2217 , \u22a5 B \u2254 { u \u2208 V : \u03bc ( u ) = 0 for all \u03bc \u2208 B } . Lemma 5.6 Let z \u2208 \u039b m . If I z is nonempty then the minimal norm interpolation problem (5.8) inf { \u2016 f \u2016 B : f \u2208 I z } has a unique minimizer. A function f 0 \u2208 B is the minimizer of (5.8) if and only if f ( x ) = z and (5.9) f 0 \u2217 \u2208 span \u00af { ( K ( x j , \u22c5 ) \u03be ) \u2217 : j \u2208 N m , \u03be \u2208 \u039b } . Proof Clearly, I z is a closed convex subset of B . A minimizer of (5.8) is the best approximation in I z to the origin 0 of B . It is well-known that a closed convex subset in a uniform convex Banach space has a unique best approximation to a point in the same space. By this fact, (5.8) has a unique minimizer. It is also trivial that f 0 \u2208 I z is the minimizer if and only if \u2016 f 0 + g \u2016 B \u2265 \u2016 f 0 \u2016 B for all g \u2208 I 0 . By the characterization of best approximation by the semi-inner product established in [16], the above equation holds if and only if [ g , f 0 ] = 0 for all g \u2208 I 0 , which can be equivalently expressed as f 0 \u2217 \u2208 ( I 0 ) \u22a5 . Note that g \u2208 I 0 if and only if [ g , K ( x j , \u22c5 ) \u03be ] B = [ g ( x j ) , \u03be ] \u039b = 0 for all j \u2208 N m and \u03be \u2208 \u039b , which is equivalent to that g \u2208 \u22a5 { ( K ( x j , \u22c5 ) \u03be ) \u2217 : j \u2208 N m , \u03be \u2208 \u039b } . We conclude that f 0 \u2208 I z is the minimizer of (5.8) if and only if f 0 \u2217 \u2208 ( \u22a5 { ( K ( x j , \u22c5 ) \u03be ) \u2217 : j \u2208 N m , \u03be \u2208 \u039b } ) \u22a5 . By the Hahn\u2013Banach theorem, for each B \u2208 B \u2217 , ( \u22a5 B ) \u22a5 = span \u00af B . The proof is hence complete.\u25a1 The above lemma enables us to prove the main result of the section without much effort. Theorem 5.7 Suppose that (5.1) has at least a minimizer. If the regularizer is nondecreasing then (5.1) has a minimizer that satisfies (5.9) . If \u03a8 is strictly increasing then every minimizer of (5.1) must satisfy (5.9) . Proof Let f \u2208 B be a minimizer of (5.1). We let f 0 be the minimizer of (5.10) min { \u2016 g \u2016 B : g \u2208 I f ( x ) } . Then \u2016 f 0 \u2016 B \u2264 \u2016 f \u2016 B and f 0 ( x ) = f ( x ) . It follows that Q ( f 0 ( x ) ) = Q ( f ( x ) ) while \u03a8 ( \u2016 f 0 \u2016 B ) \u2264 \u03a8 ( \u2016 f \u2016 B ) as \u03a8 is nondecreasing. Therefore, f 0 is a minimizer of (5.1). By Lemma 5.6, f 0 satisfies (5.9). Suppose that \u03a8 is strictly increasing and f \u2208 B does not satisfy (5.9). Again, we let f 0 \u2208 B be the minimizer of (5.10). As f does not satisfy (5.9), f \u2260 f 0 by Lemma 5.6. Thus, \u2016 f \u2016 B > \u2016 f 0 \u2016 B . The consequence is that while Q ( f ( x ) ) = Q ( f 0 ( x ) ) , \u03a8 ( \u2016 f \u2016 B ) > \u03a8 ( \u2016 f 0 \u2016 B ) because \u03a8 is strictly increasing. Therefore, f cannot be the minimizer of (5.1). The proof is complete.\u25a1 5.3 Characterization equations We consider the solving of the regularized learning scheme (5.1) in this subsection. We try to make use of the representer theorem. To this end, we note that the output space \u039b is usually finite-dimensional in practice. Let us assume that (5.1) has a unique minimizer f 0 , dim ( \u039b ) = n < + \u221e , and { e l \u2217 : l \u2208 N n } is a basis for B \u2217 . In this case, we see by property (2.16) of the reproducing kernel K that f 0 has the form (5.11) f 0 \u2217 = \u2211 j = 1 m ( K ( x j , \u22c5 ) \u03b7 j ) \u2217 for some \u03b7 j \u2208 \u039b , j \u2208 N m . It hence suffices to find the finite model parameters \u03b7 j \u2019s in order to obtain f 0 . To this end, one may substitute (5.11) into (5.1) to convert the original minimization problem in a potentially infinite-dimensional Banach space into one about the finitely many parameters \u03b7 j \u2019s. We next show how the reformulation can be done under the finite-dimensionality assumption on \u039b . As each \u03be \u2208 \u039b is uniquely determined by { [ \u03be , e l ] \u039b : l \u2208 N n } . We may rewrite the regularization functional as (5.12) min f \u2208 B R ( ( [ f ( \u03be j ) , e l ] \u039b : j \u2208 N m , l \u2208 N n ) ) + \u03bb \u03a8 ( \u2016 f \u2016 B ) for some function R : C m \u00d7 n \u2192 R + . By (2.5) and (2.6) [ f ( \u03be j ) , e l ] \u039b = [ f , K ( x j , \u22c5 ) e l ] B = [ ( K ( x j , \u22c5 ) e l ) \u2217 , f \u2217 ] B \u2217 . For the regularizer part, we have by (2.2) that \u2016 f \u2016 B = \u2016 f \u2217 \u2016 B \u2217 . Therefore, the parameters \u03b7 j \u2019s in (5.11) are the minimizer of min \u03c4 \u2208 \u039b m R ( ( [ ( K ( x j , \u22c5 ) e l ) \u2217 , \u2211 k = 1 m ( K ( x k , \u22c5 ) \u03c4 k ) \u2217 ] B \u2217 : j \u2208 N m , l \u2208 N n ) ) + \u03bb \u03a8 ( \u2016 \u2211 j = 1 m ( K ( x j , \u22c5 ) \u03c4 j ) \u2217 \u2016 B \u2217 ) . Unlike the RKHS case, the above minimization problem is usually non-convex with respect to \u03c4 j \u2217 or \u03c4 j even when R and \u03a8 are both convex. The reason is that a semi-inner product is generally non-additive with respect to its second variable. In some occasions, one is able to derive a characterization equation for the minimization problem (5.1), which together with the representer theorem constitutes a powerful tool in converting the minimization into a system of equations about the model parameters in the representer theorem. We shall derive characterization equations for the particular example of (5.1) (5.13) min f \u2208 B \u2211 j = 1 m \u03c6 ( \u2016 f ( x j ) \u2212 \u03be j \u2016 \u039b ) + \u03bb \u03a8 ( \u2016 f \u2016 B ) , where \u03be j stands for the observation of the target function at x j for j \u2208 N m , and \u03c6 is a chosen loss function from R + to R + . We shall assume that both \u03c6 and \u03a8 are continuously differentiable and (5.14) lim t \u2192 0 + \u03c6 \u2032 ( t ) t = 0 . For convenience, we make the convention that 0 / 0 \u2254 0 . The next two results hold for any \u039b regardless of its dimension. Theorem 5.8 Let \u03a8 and \u03c6 be continuously differentiable on R + with (5.14) . A function f 0 \u2260 0 is the minimizer of (5.13) if and only if (5.15) \u03bb \u03a8 \u2032 ( \u2016 f 0 \u2016 B ) \u2016 f 0 \u2016 B f 0 \u2217 + \u2211 j = 1 m \u03c6 \u2032 ( \u2016 f 0 ( x j ) \u2212 \u03be j \u2016 B ) \u2016 f 0 ( x j ) \u2212 \u03be j \u2016 B ( K ( x j , \u22c5 ) ( f 0 ( x j ) \u2212 \u03be j ) ) \u2217 = 0 . The zero function is the minimizer of (5.13) if and only if (5.16) \u2016 T \u2016 B \u2217 \u2264 \u03bb \u03a8 \u2032 ( 0 ) , where T \u2254 \u2211 j = 1 m \u03c6 \u2032 ( \u2016 \u03be j \u2016 \u039b ) \u2016 \u03be j \u2016 \u039b ( K ( x j , \u22c5 ) \u03be j ) \u2217 . Proof The proof is similar to that for the scalar-valued RKBS case in [39]. One only needs to handle the semi-inner product in vector-valued RKBSs carefully.\u25a1 In the sequel, we discuss the application of the above theorem to the regularization networks (5.17) min f \u2208 B \u2211 j = 1 m \u2016 f ( x j ) \u2212 \u03be j \u2016 \u039b 2 + \u03bb \u2016 f \u2016 B 2 . To this end, we say that the point evaluations on B at x j , j \u2208 N m are essentially linearly independent if for all \u03b7 j \u2208 \u039b , j \u2208 N m \u2211 j = 1 m [ f ( x j ) , \u03b7 j ] \u039b = 0 for all f \u2208 B necessitates that \u03b7 j = 0 for each j \u2208 N m . By (2.6), \u03b4 x j , j \u2208 N m are essentially linearly independent if and only if \u2211 j = 1 m ( K ( x j , \u22c5 ) \u03b7 j ) \u2217 = 0 implies that \u03b7 j = 0 for each j \u2208 N m . Corollary 5.9 Suppose that the point evaluations on B at x j , j \u2208 N m are essentially linearly independent. Then f 0 is the minimizer of the regularization network (5.17) if and only if it is of the form (5.11) where the parameters \u03b7 j \u2019s satisfy (5.18) \u03bb \u03b7 j + f 0 ( x j ) \u2212 \u03be j = 0 for all j \u2208 N m . Proof For the regularization network (5.17), (5.15) and (5.16) are equivalent to each other when f 0 = 0 . By Theorem 5.8, f 0 is the minimizer of (5.17) if and only if (5.19) \u03bb f 0 \u2217 + \u2211 j = 1 m ( K ( x j , \u22c5 ) ( f 0 ( x j ) \u2212 \u03be j ) ) \u2217 = 0 . Thus, f 0 has the form (5.11). Since \u03b4 x j , j \u2208 N m are essentially linearly independent, (5.19) is equivalent to that the parameters \u03b7 j \u2019s in (5.11) satisfy (5.18). The proof is complete.\u25a1 Similarly, one may substitute the representer theorem into the characterization equations (5.15) and (5.18) to reduce the minimization problem to the solving of a system of equations about the parameters \u03b7 j \u2019s. Again, due to the non-additivity of a semi-inner product with respect to its second variable, the resulting equations are generally nonlinear about the parameters. We conduct the reformulation when \u039b is of finite dimension n \u2208 N and { e l \u2217 : l \u2208 N n } forms a basis for \u039b \u2217 . In this case, (5.18) can be reformulated as \u03bb [ \u03b7 j , e l ] \u039b + [ ( K ( x j , \u22c5 ) e l ) \u2217 , \u2211 k = 1 m ( K ( x k , \u22c5 ) \u03b7 k ) \u2217 ] B \u2217 = [ \u03be j , e l ] , j \u2208 N m , l \u2208 N n . We shall leave the solution of the resulting non-convex minimization problem and nonlinear equations about the parameters in the representer theorem for future study. References [1] A. Argyriou C.A. Micchelli M. Pontil When is there a representer theorem? Vector versus matrix regularizers J. Mach. Learn. Res. 10 2009 2507 2529 [2] A. Argyriou C.A. Micchelli M. Pontil On spectral learning J. Mach. Learn. Res. 11 2010 935 953 [3] N. Aronszajn Theory of reproducing Kernels Trans. Amer. Math. Soc. 68 1950 337 404 [4] K.P. Bennett E.J. Bredensteiner Duality and geometry in SVM classifiers P. Langley Proceeding of the Seventeenth International Conference on Machine Learning 2000 Morgan Kaufmann San Francisco 57 64 [5] J. Burbea P. Masani Banach and Hilbert Spaces of Vector-valued Functions Pitman Research Notes in Mathematics vol. 90 1984 Pitman Boston, MA [6] S. Canu X. Mary A. Rakotomamonjy Functional learning through Kernel J. Suykens G. Horvath S. Basu C. Micchelli J. Vandewalle Advances in Learning Theory: Methods, Models and Applications NATO Science Series III: Computer and Systems Sciences vol. 190 2003 IOS Press Amsterdam 89 110 [7] A. Caponnetto C.A. Micchelli M. Pontil Y. Ying Universal multi-task Kernels J. Mach. Learn. Res. 9 2008 1615 1646 [8] C. Carmeli E. De Vito A. Toigo Vector valued reproducing Kernel Hilbert spaces of integrable functions and Mercer theorem Anal. Appl. 4 2006 377 408 [9] C. Carmeli E. De Vito A. Toigo V. Umanita Vector valued reproducing Kernel Hilbert spaces and universality Anal. Appl. 8 2010 19 61 [10] F. Cucker S. Smale On the mathematical foundations of learning Bull. Amer. Math. Soc. 39 2002 1 49 [11] D.F. Cudia On the localization and directionalization of uniform convexity Bull. Amer. Math. Soc. 69 1963 265 267 [12] R. Der, D. Lee, Large-margin classification in Banach spaces, in: JMLR Workshop and Conference Proceedings, 2: AISTATS, 2007, pp. 91\u201398. [13] T. Evgeniou C.A. Micchelli M. Pontil Learning multiple tasks with Kernel methods J. Mach. Learn. Res. 6 2005 615 637 [14] T. Evgeniou M. Pontil T. Poggio Regularization networks and support vector machines Adv. Comput. Math. 13 2000 1 50 [15] C. Gentile A new approximate maximal margin classification algorithm J. Mach. Learn. Res. 2 2001 213 242 [16] J.R. Giles Classes of semi-inner-product spaces Trans. Amer. Math. Soc. 129 1967 436 446 [17] M. Hein O. Bousquet B. Sch\u00f6lkopf Maximal margin classification for metric spaces J. Comput. System Sci. 71 2005 333 359 [18] R.A. Horn C.R. Johnson Topics in Matrix Analysis 1991 Cambridge University Press Cambridge [19] P.E.T. Jorgensen E.P.J. Pearse Gel\u2019fand triples and boundaries of infinite networks New York J. Math. 17 2011 745 781 [20] D. Kimber P.M. Long On-line learning of smooth functions of a single variable Theoret. Comput. Sci. 148 1995 141 156 [21] G. Kimeldorf G. Wahba Some results on Tchebycheffian spline functions J. Math. Anal. Appl. 33 1971 82 95 [22] D.O. Koehler A note on some operator theory in certain semi-inner-product spaces Proc. Amer. Math. Soc. 30 1971 363 366 [23] G. Lumer Semi-inner-product spaces Trans. Amer. Math. Soc. 100 1961 29 43 [24] C.A. Micchelli M. Pontil A function representation for learning in Banach spaces Learning Theory Lecture Notes in Computer Science vol. 3120 2004 Springer Berlin 255 269 [25] C.A. Micchelli M. Pontil On learning vector-valued functions Neural Comput. 17 2005 177 204 [26] C.A. Micchelli M. Pontil Feature space perspectives for learning the Kernel Mach. Learn. 66 2007 297 319 [27] G.B. Pedrick, Theory of reproducing kernels for Hilbert spaces of vector valued functions, Technical Report 19, University of Kansas, 1957. [28] B. Sch\u00f6lkopf R. Herbrich A.J. Smola A generalized representer theorem Proceeding of the Fourteenth Annual Conference on Computational Learning Theory and the Fifth European Conference on Computational Learning Theory 2001 Springer-Verlag London 416 426 [29] B. Sch\u00f6lkopf A.J. Smola Learning with Kernels: Support Vector Machines, Regularization, Optimization, and Beyond 2002 MIT Press Cambridge, Mass [30] J. Shawe-Taylor N. Cristianini Kernel Methods for Pattern Analysis 2004 Cambridge University Press Cambridge [31] G. Song H. Zhang Reproducing kernel Banach spaces with the \u2113 1 norm II: error analysis for regularized least square regression Neural Comput. 23 2011 2713 2729 [32] B. Sriperumbudur K. Fukumizu G. Lanckriet Learning in Hilbert vs. Banach spaces: a measure embedding viewpoint Advances in Neural Information Processing Systems, vol. 24 2011 MIT Press Cambridge [33] V.N. Vapnik Statistical Learning Theory 1998 Wiley New York [34] U. von Luxburg O. Bousquet Distance-based classification with Lipschitz functions J. Mach. Learn. Res. 5 2004 669 695 [35] Y. Xu H. Zhang Refinement of reproducing Kernels J. Mach. Learn. Res. 10 2009 107 140 [36] T. Zhang On the dual formulation of regularized linear systems with convex risks Mach. Learn. 46 2002 91 129 [37] H. Zhang Y. Xu J. Zhang Reproducing Kernel Banach spaces for machine learning J. Mach. Learn. Res. 10 2009 2741 2775 [38] H. Zhang Y. Xu Q. Zhang Refinement of operator-valued reproducing Kernels J. Mach. Learn. Res. 13 2012 91 136 [39] H. Zhang, J. Zhang, Regularized learning in Banach spaces as an optimization problem: representer theorems, J. Global Optim. (in press). [40] H. Zhang J. Zhang Frames, Riesz bases, and sampling expansions in Banach spaces via semi-inner products Appl. Comput. Harmon. Anal. 31 2011 1 25 [41] F. Zhdanov, Theory and applications of competitive prediction, Ph.D. Thesis, University of London, 2011. [42] D. Zhou, B. Xiao, H. Zhou, R. Dai, Global geometry of SVM classifiers, Technical Report 30-5-02, Institute of Automation, Chinese Academy of Sciences, 2002."
    },
    "10.1016/j.jbi.2013.08.007": {
        "Title": "Learning classification models from multiple experts",
        "Date": "December 2013",
        "Text": "serial JL 272371 291210 291682 291870 291901 31 Journal of Biomedical Informatics JOURNALBIOMEDICALINFORMATICS 2013-09-13 2013-09-13 2014-10-01T00:19:33 1-s2.0-S1532046413001226 S1532-0464(13)00122-6 S1532046413001226 10.1016/j.jbi.2013.08.007 S300 S300.3 FULL-TEXT 1-s2.0-S1532046413X00073 2015-05-15T06:30:58.629321-04:00 0 0 20131201 20131231 2013 2013-09-13T00:00:00Z absattachment articleinfo articletitlenorm authfirstinitialnorm authfirstsurnamenorm cid cids confeditor contenttype copyright crossmark dateloaded dateloadedtxt datesearch datesort dateupdated dco docsubtype doctype doi eid ewtransactionid hubeid indexeddate issfirst issn issnnorm issuelist itemstage itemtransactionid itemweight openaccess openarchive pg pgfirst pglast pii piinorm pubdateend pubdatestart pubdatetxt pubyr sectiontitle sortorder srctitle srctitlenorm srctype ssids alllist content subj subheadings tomb vol volfirst volissue volumelist webpdf webpdfpagecount yearnav figure table body mmlmath acknowledge affil appendices articletitle auth authfirstini authfull authkeywords authlast footnotes grantnumber grantsponsor highlightsabst primabst ref specialabst 1532-0464 15320464 true 46 46 6 6 Volume 46, Issue 6 19 1125 1135 1125 1135 201312 December 2013 2013-12-01 2013-12-31 2013 Special Section: Social Media Environments Alejandro Rodr\u00edguez Gonz\u00e1lez Miguel Angel Mayer Jesualdo Tom\u00e1s Fern\u00e1ndez-Breis Regular Research Papers article fla Copyright \u00a9 2013 Elsevier Inc. All rights reserved. LEARNINGCLASSIFICATIONMODELSMULTIPLEEXPERTS VALIZADEGAN H 1 Introduction 2 Background 2.1 Related work 3 Methodology 3.1 Multiple Experts Support Vector Machines (ME-SVM) 3.2 Optimization 4 Experimental evaluation 4.1 Data 4.2 Temporal feature extraction 4.3 Experimental set-up 4.4 Results and discussion 4.4.1 Learning consensus model 4.4.2 Modeling individual experts 4.4.3 Self-consistency and consensus-consistency 5 Conclusion Acknowledgements Appendix A Derivation of Eq. (4) from Eq. (3) Appendix B Features used for constructing the predictive models References BATAL 2012 280 288 I PROCEEDINGSINTERNATIONALCONFERENCEKNOWLEDGEDISCOVERYDATAMINING MININGRECENTTEMPORALPATTERNSFOREVENTDETECTIONINMULTIVARIATETIMESERIESDATA BATAL 2011 358 365 I IEEEINTERNATIONALCONFERENCEBIOINFORMATICSBIOMEDICINEBIBM APATTERNMININGAPPROACHFORCLASSIFYINGMULTIVARIATETEMPORALDATA BEZDEK 2002 288 300 J PROCEEDINGS2002AFSSINTERNATIONALCONFERENCEFUZZYSYSTEMS NOTESALTERNATINGOPTIMIZATION BISHOP 2006 C PATTERNRECOGNITIONMACHINELEARNING BOYD 2004 S CONVEXOPTIMIZATION COMBI 2010 C TEMPORALINFORMATIONSYSTEMSINMEDICINE DAWID 1979 20 28 A EVGENIOU 2004 109 117 T PROCEEDINGSINTERNATIONALCONFERENCEKNOWLEDGEDISCOVERYDATAMINING REGULARIZEDMULTITASKLEARNING HAUSKRECHT 2013 47 55 M KOLLER 2009 D PROBABILISTICGRAPHICALMODELSPRINCIPLESTECHNIQUES RAYKAR 2010 1297 1322 V SCHOLKOPF 2001 B LEARNINGKERNELSSUPPORTVECTORMACHINESREGULARIZATIONOPTIMIZATIONBEYOND SCHOLKOPF 2002 B LEARNINGKERNELSSUPPORTVECTORMACHINESREGULARIZATIONOPTIMIZATIONBEYOND SHENG 2008 614 622 V PROCEEDINGSINTERNATIONALCONFERENCEKNOWLEDGEDISCOVERYDATAMINING GETANOTHERLABELIMPROVINGDATAQUALITYDATAMININGUSINGMULTIPLENOISYLABELERS SNOW 2008 254 263 R CONFERENCEEMPIRICALMETHODSNATURALLANGUAGEPROCESSING CHEAPFASTBUTGOODEVALUATINGNONEXPERTANNOTATIONSFORNATURALLANGUAGETASKS VALIZADEGAN 2007 1417 1424 H ADVANCESINNEURALINFORMATIONPROCESSINGSYSTEMS GENERALIZEDMAXIMUMMARGINCLUSTERINGUNSUPERVISEDKERNELLEARNING VAPNIK 1995 V NATURESTATISTICALLEARNINGTHEORY WARKENTIN 2003 535 555 T WARKENTIN 2000 1703 1708 T VALIZADEGANX2013X1125 VALIZADEGANX2013X1125X1135 VALIZADEGANX2013X1125XH VALIZADEGANX2013X1125X1135XH Full 2014-12-01T00:02:24Z OA-Window ElsevierBranded http://www.elsevier.com/open-access/userlicense/1.0/ item S1532-0464(13)00122-6 S1532046413001226 1-s2.0-S1532046413001226 10.1016/j.jbi.2013.08.007 272371 2014-10-01T02:41:15.28077-04:00 2013-12-01 2013-12-31 1-s2.0-S1532046413001226-main.pdf https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/MAIN/application/pdf/affc5c9bc087e422358f73ff7545217e/main.pdf https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/MAIN/application/pdf/affc5c9bc087e422358f73ff7545217e/main.pdf main.pdf pdf true 1093731 MAIN 11 1-s2.0-S1532046413001226-main_1.png https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/PREVIEW/image/png/2c492bcae559fe20c6de6f8e58a74419/main_1.png https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/PREVIEW/image/png/2c492bcae559fe20c6de6f8e58a74419/main_1.png main_1.png png 61559 849 656 IMAGE-WEB-PDF 1 1-s2.0-S1532046413001226-si9.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/STRIPIN/image/gif/aa9059555865dbc53bc692773df5eba5/si4.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/STRIPIN/image/gif/aa9059555865dbc53bc692773df5eba5/si4.gif si9 si9.gif gif 260 20 17 ALTIMG 1-s2.0-S1532046413001226-si8.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/STRIPIN/image/gif/2586cfaeb66a9e0c1c4a21d7b7c78117/si8.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/STRIPIN/image/gif/2586cfaeb66a9e0c1c4a21d7b7c78117/si8.gif si8 si8.gif gif 1308 23 240 ALTIMG 1-s2.0-S1532046413001226-si7.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/STRIPIN/image/gif/a84748b614d5417827c4083d2ade1a2b/si7.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/STRIPIN/image/gif/a84748b614d5417827c4083d2ade1a2b/si7.gif si7 si7.gif gif 1093 23 193 ALTIMG 1-s2.0-S1532046413001226-si6.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/STRIPIN/image/gif/30c32f784fe89ce884ca1848352250b8/si6.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/STRIPIN/image/gif/30c32f784fe89ce884ca1848352250b8/si6.gif si6 si6.gif gif 1013 21 187 ALTIMG 1-s2.0-S1532046413001226-si5.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/STRIPIN/image/gif/f50486d6a1031d68aa3a9b27aa6d1c46/si5.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/STRIPIN/image/gif/f50486d6a1031d68aa3a9b27aa6d1c46/si5.gif si5 si5.gif gif 591 19 102 ALTIMG 1-s2.0-S1532046413001226-si4.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/STRIPIN/image/gif/aa9059555865dbc53bc692773df5eba5/si4.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/STRIPIN/image/gif/aa9059555865dbc53bc692773df5eba5/si4.gif si4 si4.gif gif 260 20 17 ALTIMG 1-s2.0-S1532046413001226-si38.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/STRIPIN/image/gif/44b97bde3c6a70dd2417f81c88a79fdf/si38.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/STRIPIN/image/gif/44b97bde3c6a70dd2417f81c88a79fdf/si38.gif si38 si38.gif gif 4607 153 425 ALTIMG 1-s2.0-S1532046413001226-si37.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/STRIPIN/image/gif/84de4678cf12c5bff1aa0302eb652b30/si37.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/STRIPIN/image/gif/84de4678cf12c5bff1aa0302eb652b30/si37.gif si37 si37.gif gif 500 17 96 ALTIMG 1-s2.0-S1532046413001226-si36.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/STRIPIN/image/gif/d6315637aa3e81e61d07b8e659ed6497/si36.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/STRIPIN/image/gif/d6315637aa3e81e61d07b8e659ed6497/si36.gif si36 si36.gif gif 6437 301 296 ALTIMG 1-s2.0-S1532046413001226-si35.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/STRIPIN/image/gif/9c1513805bc274e4c650d15f1bde34c7/si35.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/STRIPIN/image/gif/9c1513805bc274e4c650d15f1bde34c7/si35.gif si35 si35.gif gif 8967 277 393 ALTIMG 1-s2.0-S1532046413001226-si34.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/STRIPIN/image/gif/5e63b45daadc0dd2572d8f794f0857db/si34.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/STRIPIN/image/gif/5e63b45daadc0dd2572d8f794f0857db/si34.gif si34 si34.gif gif 873 17 162 ALTIMG 1-s2.0-S1532046413001226-si33.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/STRIPIN/image/gif/acff6997f37027df2fa45c8e40d2535e/si33.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/STRIPIN/image/gif/acff6997f37027df2fa45c8e40d2535e/si33.gif si33 si33.gif gif 10708 293 497 ALTIMG 1-s2.0-S1532046413001226-si32.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/STRIPIN/image/gif/80d104cba30782e7984692877c976ca1/si32.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/STRIPIN/image/gif/80d104cba30782e7984692877c976ca1/si32.gif si32 si32.gif gif 371 20 50 ALTIMG 1-s2.0-S1532046413001226-si31.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/STRIPIN/image/gif/f3d2378e7a37c09cd3cfee37cf0b7342/si3.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/STRIPIN/image/gif/f3d2378e7a37c09cd3cfee37cf0b7342/si3.gif si31 si31.gif gif 249 20 17 ALTIMG 1-s2.0-S1532046413001226-si30.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/STRIPIN/image/gif/0033ce8501733d83e5938502303dc1bb/si22.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/STRIPIN/image/gif/0033ce8501733d83e5938502303dc1bb/si22.gif si30 si30.gif gif 235 20 15 ALTIMG 1-s2.0-S1532046413001226-si3.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/STRIPIN/image/gif/f3d2378e7a37c09cd3cfee37cf0b7342/si3.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/STRIPIN/image/gif/f3d2378e7a37c09cd3cfee37cf0b7342/si3.gif si3 si3.gif gif 249 20 17 ALTIMG 1-s2.0-S1532046413001226-si29.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/STRIPIN/image/gif/3587364fb64a82582ce781da6571133c/si29.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/STRIPIN/image/gif/3587364fb64a82582ce781da6571133c/si29.gif si29 si29.gif gif 1007 46 168 ALTIMG 1-s2.0-S1532046413001226-si28.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/STRIPIN/image/gif/ded0c55235c5a7f39873b905b52f894f/si28.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/STRIPIN/image/gif/ded0c55235c5a7f39873b905b52f894f/si28.gif si28 si28.gif gif 1143 48 151 ALTIMG 1-s2.0-S1532046413001226-si27.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/STRIPIN/image/gif/0033ce8501733d83e5938502303dc1bb/si22.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/STRIPIN/image/gif/0033ce8501733d83e5938502303dc1bb/si22.gif si27 si27.gif gif 235 20 15 ALTIMG 1-s2.0-S1532046413001226-si26.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/STRIPIN/image/gif/0033ce8501733d83e5938502303dc1bb/si22.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/STRIPIN/image/gif/0033ce8501733d83e5938502303dc1bb/si22.gif si26 si26.gif gif 235 20 15 ALTIMG 1-s2.0-S1532046413001226-si25.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/STRIPIN/image/gif/bd1cbe7b326c01d85ac77222b8ab531b/si25.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/STRIPIN/image/gif/bd1cbe7b326c01d85ac77222b8ab531b/si25.gif si25 si25.gif gif 7202 327 397 ALTIMG 1-s2.0-S1532046413001226-si24.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/STRIPIN/image/gif/d4c54fe3146b2858a168fd90380fea55/si24.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/STRIPIN/image/gif/d4c54fe3146b2858a168fd90380fea55/si24.gif si24 si24.gif gif 1222 65 171 ALTIMG 1-s2.0-S1532046413001226-si23.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/STRIPIN/image/gif/b840bdbdaa78d3298d63873c6c1ea587/si23.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/STRIPIN/image/gif/b840bdbdaa78d3298d63873c6c1ea587/si23.gif si23 si23.gif gif 1139 30 191 ALTIMG 1-s2.0-S1532046413001226-si22.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/STRIPIN/image/gif/0033ce8501733d83e5938502303dc1bb/si22.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/STRIPIN/image/gif/0033ce8501733d83e5938502303dc1bb/si22.gif si22 si22.gif gif 235 20 15 ALTIMG 1-s2.0-S1532046413001226-si21.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/STRIPIN/image/gif/ca98ea188b4e6c5c77b99f8eee1c5ad4/si21.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/STRIPIN/image/gif/ca98ea188b4e6c5c77b99f8eee1c5ad4/si21.gif si21 si21.gif gif 858 21 148 ALTIMG 1-s2.0-S1532046413001226-si20.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/STRIPIN/image/gif/709450b889c3f519fd150ea7d5c0b14c/si20.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/STRIPIN/image/gif/709450b889c3f519fd150ea7d5c0b14c/si20.gif si20 si20.gif gif 5975 158 569 ALTIMG 1-s2.0-S1532046413001226-si2.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/STRIPIN/image/gif/f82711249776a999a758997c54b18218/si2.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/STRIPIN/image/gif/f82711249776a999a758997c54b18218/si2.gif si2 si2.gif gif 773 23 128 ALTIMG 1-s2.0-S1532046413001226-si19.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/STRIPIN/image/gif/185f97b383706f5e568784f7750c96a1/si19.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/STRIPIN/image/gif/185f97b383706f5e568784f7750c96a1/si19.gif si19 si19.gif gif 5586 158 529 ALTIMG 1-s2.0-S1532046413001226-si18.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/STRIPIN/image/gif/396ccfaccc49c51e44ead67f131e9ce2/si18.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/STRIPIN/image/gif/396ccfaccc49c51e44ead67f131e9ce2/si18.gif si18 si18.gif gif 936 30 229 ALTIMG 1-s2.0-S1532046413001226-si17.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/STRIPIN/image/gif/6680d894a90d44b4394af86ca8e8ae72/si17.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/STRIPIN/image/gif/6680d894a90d44b4394af86ca8e8ae72/si17.gif si17 si17.gif gif 911 30 234 ALTIMG 1-s2.0-S1532046413001226-si16.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/STRIPIN/image/gif/27b53238cb595195f421376f31a37c87/si16.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/STRIPIN/image/gif/27b53238cb595195f421376f31a37c87/si16.gif si16 si16.gif gif 3926 52 662 ALTIMG 1-s2.0-S1532046413001226-si15.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/STRIPIN/image/gif/98fdb2f29a9842287f1e056bea5a149f/si15.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/STRIPIN/image/gif/98fdb2f29a9842287f1e056bea5a149f/si15.gif si15 si15.gif gif 616 17 120 ALTIMG 1-s2.0-S1532046413001226-si14.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/STRIPIN/image/gif/844a8d3f7692f1a3ef78585728bea411/si14.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/STRIPIN/image/gif/844a8d3f7692f1a3ef78585728bea411/si14.gif si14 si14.gif gif 231 14 21 ALTIMG 1-s2.0-S1532046413001226-si13.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/STRIPIN/image/gif/0918f8f246d93f994edbf7f5b4e5bf2a/si13.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/STRIPIN/image/gif/0918f8f246d93f994edbf7f5b4e5bf2a/si13.gif si13 si13.gif gif 249 17 19 ALTIMG 1-s2.0-S1532046413001226-si12.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/STRIPIN/image/gif/6e05328527648f8b9962eb15d1bcedff/si12.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/STRIPIN/image/gif/6e05328527648f8b9962eb15d1bcedff/si12.gif si12 si12.gif gif 236 15 21 ALTIMG 1-s2.0-S1532046413001226-si11.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/STRIPIN/image/gif/ef17778371696c5eefefdcacc2a16ffb/si11.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/STRIPIN/image/gif/ef17778371696c5eefefdcacc2a16ffb/si11.gif si11 si11.gif gif 254 18 19 ALTIMG 1-s2.0-S1532046413001226-si10.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/STRIPIN/image/gif/6ea41257769968ec331f1be799f6b83d/si10.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/STRIPIN/image/gif/6ea41257769968ec331f1be799f6b83d/si10.gif si10 si10.gif gif 1641 44 169 ALTIMG 1-s2.0-S1532046413001226-si1.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/STRIPIN/image/gif/6332f2e4bbb7a8080507a9054bebd612/si1.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/STRIPIN/image/gif/6332f2e4bbb7a8080507a9054bebd612/si1.gif si1 si1.gif gif 620 19 111 ALTIMG 1-s2.0-S1532046413001226-gr7_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/gr7/HIGHRES/image/jpeg/d8e86f87ba787ba4b66e38edf30fa468/gr7_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/gr7/HIGHRES/image/jpeg/d8e86f87ba787ba4b66e38edf30fa468/gr7_lrg.jpg gr7 gr7_lrg.jpg jpg 617281 1892 2624 IMAGE-HIGH-RES 1-s2.0-S1532046413001226-gr6_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/gr6/HIGHRES/image/jpeg/6054a70706c5020ad6ec347dc9554030/gr6_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/gr6/HIGHRES/image/jpeg/6054a70706c5020ad6ec347dc9554030/gr6_lrg.jpg gr6 gr6_lrg.jpg jpg 810544 1884 3369 IMAGE-HIGH-RES 1-s2.0-S1532046413001226-gr5_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/gr5/HIGHRES/image/jpeg/90873e868b8554ab2135b14ca3ef5b2e/gr5_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/gr5/HIGHRES/image/jpeg/90873e868b8554ab2135b14ca3ef5b2e/gr5_lrg.jpg gr5 gr5_lrg.jpg jpg 309781 1020 2529 IMAGE-HIGH-RES 1-s2.0-S1532046413001226-gr4_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/gr4/HIGHRES/image/jpeg/4bab60e7c9bad379f2dddd5bd03c894c/gr4_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/gr4/HIGHRES/image/jpeg/4bab60e7c9bad379f2dddd5bd03c894c/gr4_lrg.jpg gr4 gr4_lrg.jpg jpg 195072 728 2382 IMAGE-HIGH-RES 1-s2.0-S1532046413001226-gr3_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/gr3/HIGHRES/image/jpeg/0160137c11a414ab7f85d04971c6b854/gr3_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/gr3/HIGHRES/image/jpeg/0160137c11a414ab7f85d04971c6b854/gr3_lrg.jpg gr3 gr3_lrg.jpg jpg 76045 536 1562 IMAGE-HIGH-RES 1-s2.0-S1532046413001226-gr2_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/gr2/HIGHRES/image/jpeg/6d666756904ed5581ca9d581efb554fc/gr2_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/gr2/HIGHRES/image/jpeg/6d666756904ed5581ca9d581efb554fc/gr2_lrg.jpg gr2 gr2_lrg.jpg jpg 163099 1307 1597 IMAGE-HIGH-RES 1-s2.0-S1532046413001226-gr1_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/gr1/HIGHRES/image/jpeg/d3ce9ac011979d2be4ccb59a9cae284b/gr1_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/gr1/HIGHRES/image/jpeg/d3ce9ac011979d2be4ccb59a9cae284b/gr1_lrg.jpg gr1 gr1_lrg.jpg jpg 62585 446 1423 IMAGE-HIGH-RES 1-s2.0-S1532046413001226-fx1_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/fx1/HIGHRES/image/jpeg/2b5a6c4282ba6478cb7f658b963af5b7/fx1_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/fx1/HIGHRES/image/jpeg/2b5a6c4282ba6478cb7f658b963af5b7/fx1_lrg.jpg fx1 true fx1_lrg.jpg jpg 185828 886 1450 IMAGE-HIGH-RES 1-s2.0-S1532046413001226-gr7.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/gr7/DOWNSAMPLED/image/jpeg/41651547804466dc9caca2ba748c58f3/gr7.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/gr7/DOWNSAMPLED/image/jpeg/41651547804466dc9caca2ba748c58f3/gr7.jpg gr7 gr7.jpg jpg 82629 428 593 IMAGE-DOWNSAMPLED 1-s2.0-S1532046413001226-gr6.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/gr6/DOWNSAMPLED/image/jpeg/9f55841a36e306a5028f2e7eacc08d82/gr6.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/gr6/DOWNSAMPLED/image/jpeg/9f55841a36e306a5028f2e7eacc08d82/gr6.jpg gr6 gr6.jpg jpg 99644 426 761 IMAGE-DOWNSAMPLED 1-s2.0-S1532046413001226-gr5.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/gr5/DOWNSAMPLED/image/jpeg/0230d02d132479e86ab5d37d7c5bc958/gr5.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/gr5/DOWNSAMPLED/image/jpeg/0230d02d132479e86ab5d37d7c5bc958/gr5.jpg gr5 gr5.jpg jpg 37512 230 571 IMAGE-DOWNSAMPLED 1-s2.0-S1532046413001226-gr4.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/gr4/DOWNSAMPLED/image/jpeg/4aa395521105c697d117ff1ad82856ac/gr4.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/gr4/DOWNSAMPLED/image/jpeg/4aa395521105c697d117ff1ad82856ac/gr4.jpg gr4 gr4.jpg jpg 31759 170 556 IMAGE-DOWNSAMPLED 1-s2.0-S1532046413001226-gr3.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/gr3/DOWNSAMPLED/image/jpeg/18be4a6c34951d4caf05b62c6655572d/gr3.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/gr3/DOWNSAMPLED/image/jpeg/18be4a6c34951d4caf05b62c6655572d/gr3.jpg gr3 gr3.jpg jpg 16784 121 353 IMAGE-DOWNSAMPLED 1-s2.0-S1532046413001226-gr2.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/gr2/DOWNSAMPLED/image/jpeg/1dd412bfc5dd368358f9d7cdf09c9044/gr2.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/gr2/DOWNSAMPLED/image/jpeg/1dd412bfc5dd368358f9d7cdf09c9044/gr2.jpg gr2 gr2.jpg jpg 32398 305 373 IMAGE-DOWNSAMPLED 1-s2.0-S1532046413001226-gr1.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/gr1/DOWNSAMPLED/image/jpeg/a6d118f94c057bd5165c22ed8561de5c/gr1.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/gr1/DOWNSAMPLED/image/jpeg/a6d118f94c057bd5165c22ed8561de5c/gr1.jpg gr1 gr1.jpg jpg 13878 103 329 IMAGE-DOWNSAMPLED 1-s2.0-S1532046413001226-fx1.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/fx1/DOWNSAMPLED/image/jpeg/fd9627eddf7f32de2e0e1847050da6b3/fx1.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/fx1/DOWNSAMPLED/image/jpeg/fd9627eddf7f32de2e0e1847050da6b3/fx1.jpg fx1 true fx1.jpg jpg 30438 200 327 IMAGE-DOWNSAMPLED 1-s2.0-S1532046413001226-gr7.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/gr7/THUMBNAIL/image/gif/98a07bea9de63ec7638fbf45ecbd5392/gr7.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/gr7/THUMBNAIL/image/gif/98a07bea9de63ec7638fbf45ecbd5392/gr7.sml gr7 gr7.sml sml 8379 158 219 IMAGE-THUMBNAIL 1-s2.0-S1532046413001226-gr6.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/gr6/THUMBNAIL/image/gif/34e626844214d8669b5bcda96c0376e5/gr6.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/gr6/THUMBNAIL/image/gif/34e626844214d8669b5bcda96c0376e5/gr6.sml gr6 gr6.sml sml 6646 122 219 IMAGE-THUMBNAIL 1-s2.0-S1532046413001226-gr5.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/gr5/THUMBNAIL/image/gif/c061eb121e0f7958357e67617600bd3a/gr5.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/gr5/THUMBNAIL/image/gif/c061eb121e0f7958357e67617600bd3a/gr5.sml gr5 gr5.sml sml 4730 88 219 IMAGE-THUMBNAIL 1-s2.0-S1532046413001226-gr4.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/gr4/THUMBNAIL/image/gif/73254e1dd95d53c8328817267512b319/gr4.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/gr4/THUMBNAIL/image/gif/73254e1dd95d53c8328817267512b319/gr4.sml gr4 gr4.sml sml 3814 67 219 IMAGE-THUMBNAIL 1-s2.0-S1532046413001226-gr3.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/gr3/THUMBNAIL/image/gif/4d3f9ac4cbad6ef28883d49c20bde155/gr3.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/gr3/THUMBNAIL/image/gif/4d3f9ac4cbad6ef28883d49c20bde155/gr3.sml gr3 gr3.sml sml 3607 75 219 IMAGE-THUMBNAIL 1-s2.0-S1532046413001226-gr2.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/gr2/THUMBNAIL/image/gif/b5a6219d63ac2f064a54e1bd871598fb/gr2.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/gr2/THUMBNAIL/image/gif/b5a6219d63ac2f064a54e1bd871598fb/gr2.sml gr2 gr2.sml sml 5079 164 200 IMAGE-THUMBNAIL 1-s2.0-S1532046413001226-gr1.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/gr1/THUMBNAIL/image/gif/83aab7fc2c5f4dfe828e2793c54619e6/gr1.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/gr1/THUMBNAIL/image/gif/83aab7fc2c5f4dfe828e2793c54619e6/gr1.sml gr1 gr1.sml sml 2059 69 219 IMAGE-THUMBNAIL 1-s2.0-S1532046413001226-fx1.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/fx1/THUMBNAIL/image/gif/afc7ff45f080d4fe8e172282d9367c05/fx1.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/fx1/THUMBNAIL/image/gif/afc7ff45f080d4fe8e172282d9367c05/fx1.sml fx1 true fx1.sml sml 8004 134 219 IMAGE-THUMBNAIL YJBIN 2049 S1532-0464(13)00122-6 10.1016/j.jbi.2013.08.007 Elsevier Inc. Fig. 1 The consensus model and its relation to individual expert models. Fig. 2 The experts\u2019 specific linear models w k are generated from the consensus linear model u. The circles show instances that are mislabeled with respect to individual expert\u2019s models and are used to define the model self consistency. Fig. 3 Graphical representation of the auxiliary probabilistic model that is related to our objective function. The circles in the graph represent random variables. Shaded circles are observed variables, regular (unshaded) circles denote hidden (or unobserved) random variables. The rectangles denote plates that represent structure replications, that is, there are k different expert models w k , and each is used to generate labels for N k examples. Parameters not enclosed in circles (e.g. \u03b7) denote the hyperparameters of the model. Fig. 4 The figure illustrates a subset of 10 temporal features used for mapping time-series for numerical lab tests. Fig. 5 Effect of the number of training examples on the quality of the model when: (Left) every example is labeled by just one expert and (Right) every example is labeled by all three experts. Fig. 6 Learning of expert-specific models. The figure shows the results for three expert specific models generated by the ME-SVM and the standard SVM methods, and compares them to models generated by the Majority\u2217 and Raykar\u2217 methods. First line: different examples are given to different experts and Second line: the same examples are given to all experts. Fig. 7 (left-top) Agreement of experts with labels given by the senior expert; (right-top) learned self-consistency parameters for Experts 1\u20133; (left-bottom) learned consensus-consistency parameters for Experts 1\u20133; (right-bottom) cumulative self and consensus consistencies for Expert 1\u20133. Table 1 Features used for constructing the predictive models. The features were extracted from time series data in electronic health records using methods from Hauskrecht et al. [11,20,12]. Clinical variables Features Platelet count (PLT) 1 Last PLT value measurement 2 Time elapsed since last PLT measurement 3 Pending PLT result 4 Known PLT value result indicator 5 Known trend PLT results 6 PLT difference for last two measurements 7 PLT slope for last two measurements 8 PLT % drop for last two measurements 9 Nadir HGB value 10 PLT difference for last and nadir values 11 Apex PLT value 12 PLT difference for last and apex values 13 PLT difference for last and baseline values 14 Overall PLT slope Hemoglobin (HGB) 15 Last HGB value measurement 16 Time elapsed since last HGB measurement 17 Pending HGB result 18 Known HGB value result indicator 19 Known trend HGB results 20 HGB difference for last two measurements 21 HGB slope for last two measurements 22 HGB % drop for last two measurements 23 Nadir HGB value 24 HGB difference for last and nadir values 25 Apex HGB value 26 HGB difference for last and apex values 27 HGB difference for last and baseline values 28 Overall HGB slope White Blood Cell count (WBC) 29 Last WBC value measurement 30 Time elapsed since last WBC measurement 31 Pending WBC result 32 Known WBC value result indicator 33 Known trend WBC results 34 WBC difference for last two measurements 35 WBC slope for last two measurements 36 WBC % drop for last two measurements 37 Nadir WBC value 38 WBC difference for last and nadir values 39 Apex WBC value 40 WBC difference for last and apex values 41 WBC difference for last and baseline values 42 Overall WBC slope Heparin 43 Patient on Heparin 44 Time elapsed since last administration of Heparin 45 Time elapsed since first administration of Heparin 46 Time elapsed since last change in Heparin administration Major heart procedure 47 Patient had a major heart procedure in past 24h 48 Patient had a major heart procedure during the stay 49 Time elapsed since last major heart procedure 50 Time elapsed since first major heart procedure Learning classification models from multiple experts Hamed Valizadegan Quang Nguyen Milos Hauskrecht \u204e Department of Computer Science, University of Pittsburgh, United States Department of Computer Science University of Pittsburgh United States \u204e Corresponding author. Tel.: +1 412 624 8845. Graphical abstract Building classification models from clinical data using machine learning methods often relies on labeling of patient examples by human experts. Standard machine learning framework assumes the labels are assigned by a homogeneous process. However, in reality the labels may come from multiple experts and it may be difficult to obtain a set of class labels everybody agrees on; it is not uncommon that different experts have different subjective opinions on how a specific patient example should be classified. In this work we propose and study a new multi-expert learning framework that assumes the class labels are provided by multiple experts and that these experts may differ in their class label assessments. The framework explicitly models different sources of disagreements and lets us naturally combine labels from different human experts to obtain: (1) a consensus classification model representing the model the group of experts converge to, as well as, and (2) individual expert models. We test the proposed framework by building a model for the problem of detection of the Heparin Induced Thrombocytopenia (HIT) where examples are labeled by three experts. We show that our framework is superior to multiple baselines (including standard machine learning framework in which expert differences are ignored) and that our framework leads to both improved consensus and individual expert models. Keywords Classification learning with multiple experts Consensus models 1 Introduction The availability of patient data in Electronic Health Records (EHRs) gives us a unique opportunity to study different aspects of patient care, and obtain better insights into different diseases, their dynamics and treatments. The knowledge and models obtained from such studies have a great potential in health care quality improvement and health care cost reduction. Machine learning and data mining methods and algorithms play an important role in this process. The main focus of this paper is on the problem of building (learning) classification models from clinical data and expert defined class labels. Briefly, the goal is to learn a classification model f: x \u2192 y that helps us to map a patient instance x to a binary class label y, representing, for example, the presence or absence of an adverse condition, or the diagnosis of a specific disease. Such models, once they are learned can be used in patient monitoring, or disease and adverse event detection. The standard machine learning framework assumes the class labels are assigned to instances by a uniform labeling process. However, in the majority of practical settings the labels come from multiple experts. Briefly, the class labels are either acquired (1) during the patient management process and represent the decision of the human expert that is recorded in the EHR (say diagnosis) or (2) retrospectively during a separate annotation process based on past patient data. In the first case, there may be different physicians that manage different patients, hence the class labels naturally originate from multiple experts. Whilst in the second (retrospective) case, the class label can in principle be provided by one expert, the constraints on how much time a physician can spend on patient annotation process often requires to distribute the load among multiple experts. Accepting the fact that labels are provided by multiple experts, the complication is that different experts may have different subjective opinion about the same patient case. The differences may be due to experts\u2019 knowledge, subjective preferences and utilities, and expertise level. This may lead to disagreements in their labels, and variation in the patient case labeling due to these disagreements. However, we would like to note that while we do not expect all experts to agree on all labels, we also do not expect the expert\u2019s label assessment to be random; the labels provided by different experts are closely related by the condition (diagnosis, an adverse event) they represent. Given that the labels are provided by multiple experts, two interesting research questions arise. The first question is whether there is a model that would represent well the labels the group of experts would assign to each patient case. We refer to such a group model as to the (group) consensus model. The second question is whether it is possible to learn such a consensus model purely from label assessments of individual experts, that is, without access to any consensus/meta labels, and this as efficiently as possible. To address the above issues, we propose a new multi-expert learning framework that starts from data labeled by multiple experts and builds: (1) a consensus model representing the classification model the experts collectively converge to, and (2) individual expert models representing the class label decisions exhibited by individual experts. Fig. 1 shows the relations between these two components: the experts\u2019 specific models and the consensus model. We would like to emphasize again that our framework builds the consensus model without access to any consensus/meta labels. To represent relations among the consensus and expert models, our framework considers different sources of disagreement that may arise when multiple experts label a case and explicitly represents them in the combined multi-expert model. In particular our framework assumes the following sources for expert disagreements: \u2022 Differences in the risks annotators associate with each class label assignment: diagnosing a patient as not having a disease when the patient has disease, carries a cost due to, for example, a missed opportunity to treat the patient, or longer patient discomfort and suffering. A similar, but different cost is caused by incorrectly diagnosing a patient. The differences in the expert-specific utilities (or costs) may easily explain differences in their label assessments. Hence our goal is to develop a learning framework that seeks a model consensus, and that, at the same time, permits experts who have different utility biases. \u2022 Differences in the knowledge (or model) experts use to label examples: while diagnoses provided by different experts may be often consistent, the knowledge they have and features they consider when making the disease decision may differ, potentially leading to differences in labeling. It is not rare when two expert physicians disagree on a complex patient case due to differences firmly embedded in their knowledge and understanding of the disease. These differences are best characterized as differences in their knowledge or model they used to diagnose the patient. \u2022 Differences in time annotators spend when labeling each case: different experts may spend different amount of time and care to analyze the same case and its subtleties. This may lead to labeling inconsistency even within the expert\u2019s own model. We experiment with and test our multi-expert framework on the Heparin Induced Thrombocytopenia (HIT) [23] problem where our goal is to build a predictive model that can, as accurately as possible, assess the risk of the patient developing the HIT condition and predict HIT alerts. We have obtained the HIT alert annotations from three different experts in clinical pharmacy. In addition we have also acquired a meta-annotation from the fourth (senior) expert who in addition to patient cases have seen the annotations and assessments given by other three experts. We show that our framework outperforms other machine learning frameworks (1) when it predicts a consensus label for future (test) patients and (2) when it predicts individual future expert labels. 2 Background The problem of learning accurate classification models from clinical data that are labeled by human experts with respect to some condition of interest is important for many applications such as diagnosis, adverse event detection, monitoring and alerting, and the design of recommender systems. Standard classification learning framework assumes the training data set D = { ( x i , y i ) } i = 1 n consists of n data examples, where x i is a d-dimensional feature vector and y i is a corresponding binary class label. The objective is to learn a classification function: f: x \u2192 y that generalizes well to future data. The key assumption for learning the classification function f in the standard framework is that examples in the training data D are independent and generated by the same (identical) process, hence there are no differences in the label assignment process. However, in practice, especially in medicine, the labels are provided by different humans. Consequently, they may vary and are subject to various sources of subjective bias and variations. We develop and study a new multi-expert classification learning framework for which labels are provided by multiple experts, and that accounts for differences in subjective assessments of these experts when learning the classification function. Briefly, we have m different experts who assign labels to examples. Let D k = x i k , y i k i = 1 n k denotes training data specific for the expert k, such that x i k is a d-dimensional input example and y i k is binary label assigned by expert k. Given the data from multiple experts, our main goal is to learn the classification mapping: f: x \u2192 y that would generalize well to future examples and would represent a good consensus model for all these experts. In addition, we can learn the expert specific classification functions g k : x \u2192 y k for all k =1,\u2026, m that predicts as accurately as possible the label assignment for that expert. The learning of f is a difficult problem because (1) the experts\u2019 knowledge and reliability could vary and (2) each expert can have different preferences (or utilities) for different labels, leading to different biases towards negative or positive class. Therefore, even if two experts have the same relative understanding of a patient case their assigned labels may be different. Under these conditions, we aim to combine the subjective labels from different experts to learn a good consensus model. 2.1 Related work Methodologically our multi-expert framework builds upon models and results in two research areas: multi-task learning and learning-from-crowds, and combines them to achieve the above goals. The multi-task learning framework [9,27] is applied when we want to learn models for multiple related (correlated) tasks. This framework is used when one wants to learn more efficiently the model by borrowing the data, or model components from a related task. More specifically, we can view each expert and his/her labels as defining a separate classification task. The multi-task learning framework then ties these separate but related tasks together, which lets us use examples labeled by all experts to learn better individual expert models. Our approach is motivated and builds upon the multi-task framework proposed by Evgeniou and Pontil [9] that ties individual task models using a shared task model. However, we go beyond this framework by considering and modeling the reliability and biases of the different experts. The learning-from-crowds framework [17,18] is used to infer consensus on class labels from labels provided jointly by multiple annotators (experts). The existing methods developed for the problem range from the simple majority approach to more complex consensus models representing the reliability of different experts. In general the methods developed try to either (1) derive a consensus of multiple experts on the label of individual examples or (2) build a model that defines the consensus for multiple experts and can be applied to future examples. We will review these in the following. The simplest and most commonly used approach for defining the label consensus on individual examples is the majority voting. Briefly, the consensus on the labels for an example is the label assigned by the majority of reviewers. The main limitation of the majority voting approach is that it assumes all experts are equally reliable. The second limitation is that although the approach defines the consensus on labels for existing examples, it does not directly define a consensus model that can be used to predict consensus labels for future examples; although one may use the labels obtained from majority voting to train a model in a separate step. Improvements and refinements of learning a consensus label or model take into account and explicitly model some of the sources of annotator disagreements. Sheng et al. [17] and Snow et al. [18] showed the benefits of obtaining labels from multiple non-experts and unreliable annotators. Dawid and Skene [8] proposed a learning framework in which biases and skills of annotators were modeled using a confusion matrix. This work was later generalized and extended in [25,24,26] by modeling difficulty of examples. Finally, Raykar et al. [14] used an expectation\u2013maximization (EM) algorithm to iteratively learn the reliability of annotators. The initial reliability estimates were obtained using the majority vote. The current state-of-the-art learning methods with multiple human annotators are the works of Raykar et al. [14], Welinder et al. [24], and Yan et al. [26]. Among these, only Raykar et al. [14] uses a framework similar to the one we use in this paper; that is, it assumes (1) not all examples are labeled by all experts and (2) the objective is to construct a good classification model. However, the model differs from our approach in how it models the skills and biases of the human annotators. Also the authors in [14] show that their approach improves over simple baselines only when the number of annotators is large (more than 40). This is practical when the labeling task is easy so crowd-sourcing services like Amazon Mechanical Turk can be utilized. However, it is not practical in domains in which the annotation is time consuming. In real world or scientific domains that involve uncertainty, including medicine, it is infeasible to assume the same patient case is labeled in parallel by many different experts. Indeed the most common cases is when every patient instance is labeled by just one expert. The remaining state-of-the-art learning from crowds methods, i.e. the works of Welinder et al. [24] and Yan et al. [26], are optimized for different settings than ours. Welinder et al. [24] assumes that there is no feature vector available for the cases; it only learns expert specific models g k s, and it does not attempt to learn a consensus model f. On the other hand, Yan et al. [26] assumes that each example is labeled by all experts in parallel. As noted earlier, this is unrealistic, and most of the time each example is labeled only by one expert. The approach we propose in this paper overcomes these limitations and is flexible in that it can learn the models when there is one or more labels per example. In addition, our approach differs from the work of Yan et al. [26] in how we parameterize and optimize our model. 3 Methodology We aim to combine data labeled by multiple experts and build (1) a unified consensus classification model f for these experts and (2) expert-specific models g k , for all k =1,\u2026, m that can be applied to future data. Fig. 2 illustrates the idea of our framework with linear classification models. Briefly, let us assume a linear consensus model f with parameters (weights) u and b from which linear expert-specific models g k s with parameters w k and b k are generated. Given the consensus model, the consensus label on example x is positive if u T x + b \u2a7e0, otherwise it is negative. Similarly, the expert model g k for expert k assigns a positive label to example x if w k T x + b k \u2a7e 0 , otherwise the label is negative. To simplify the notation in the rest of the paper, we include the bias term b for the consensus model in the weights vector u, the biases b k in w k s, and extend the input vector x with constant 1. The consensus and expert models in our framework and their labels are linked together using two reliability parameters: 1. \u03b1 k : the self-consistency parameter that characterizes how reliable the labeling of expert k is; it is the amount of consistency of expert k within his/her own model w k . 2. \u03b2 k : the consensus-consistency parameter that models how consistent the model of expert k is with respect to the underlying consensus model u. This parameter models the differences in the knowledge or expertise of the experts. We assume, all deviations of the expert specific models from the consensus model are adequately modeled by these expert-specific reliability parameters. In the following we present the details of the overall model and how reliability parameters are incorporated into the objective function. 3.1 Multiple Experts Support Vector Machines (ME-SVM) Our objective is to learn the parameters u of the consensus model and parameters w k for all expert-specific models from the data. We combine this objective with the objective of learning the expert specific reliability parameters \u03b1 k and \u03b2 k . We have expressed the learning problem in terms of the objective function based on the max-margin classification framework [16,19] which is used, for example, by support vector machines (SVMs). However, due to its complexity we motivate and explain its components using an auxiliary probabilistic graphical model that we later modify to obtain the final max-margin objective function. Fig. 3 shows the probabilistic graphical model representation [5,13] that refines the high level description presented in Fig. 2. Briefly, the consensus model u is defined by a Gaussian distribution with zero mean and precision parameter \u03b7 as: (1) p ( u | 0 d , \u03b7 ) = N ( 0 d , \u03b7 - 1 I d ) where I d is the identity matrix of size d, and 0 d is a vector of size d with all elements equal to 0. The expert-specific models are generated from a consensus model u. Every expert k has his/her own specific model w k that is a noise corrupted version of the consensus model u; that is, we assume that expert k, w k , is generated from a Gaussian distribution with mean u and an expert-specific precision \u03b2 k : p ( w k | u , \u03b2 k ) = N u , \u03b2 k - 1 I d The precision parameter \u03b2 k for the expert k determines how much w k differs from the consensus model. Briefly, for a small \u03b2 k , the model w k tends to be very different from the consensus model u, while for a large \u03b2 k the models will be very similar. Hence, \u03b2 k represents the consistency of the reviewer specific model w k with the consensus model u, or, in short, consensus-consistency. The parameters of the expert model w k relate examples (and their features) x to labels. We assume this relation is captured by the regression model: p y i k | x i k , w k , \u03b1 k = N w k T x i k , \u03b1 k - 1 where \u03b1 k is the precision (inverse variance) and models the noise that may corrupt expert\u2019s label. Hence \u03b1 k defines the self-consistency of expert k. Please also note that although y i k is binary, similarly to [9,27], we model the label prediction and related noise using the Gaussian distribution. This is equivalent to using the squared error loss as the classification loss. We treat the self-consistency and consensus-consistency parameters \u03b1 k and \u03b2 k as random variables, and model their priors using Gamma distributions. More specifically, we define: (2) p ( \u03b2 k | \u03b8 \u03b2 , \u03c4 \u03b2 ) = G ( \u03b8 \u03b2 , \u03c4 \u03b2 ) p ( \u03b1 k | \u03b8 \u03b1 , \u03c4 \u03b1 ) = G ( \u03b8 \u03b1 , \u03c4 \u03b1 ) where hyperparameters \u03b8 \u03b2 k and \u03c4 \u03b2 k represent the shape and the inverse scale parameter of the Gamma distribution representing \u03b2 k . Similarly, \u03b8 \u03b1 k and \u03c4 \u03b1 k are the shape and the inverse scale parameter of the distribution representing \u03b1 k . Using the above probabilistic model we seek to learn the parameters of the consensus u and expert-specific models W from data. Similarly to Raykar et al. [14] we optimize the parameters of the model by maximizing the posterior probability p(u, W, \u03b1, \u03b2\u2223X, y, \u03be), where \u03be is the collection of hyperparameters \u03b7 , \u03b8 \u03b2 k , \u03c4 \u03b2 k , \u03b8 \u03b1 k , \u03c4 \u03b1 k . The posterior probability can be rewritten as follows: (3) p ( u , W , \u03b1 , \u03b2 | X , y , \u03be ) \u221d p ( u | 0 d , \u03b7 ) \u220f k = 1 m p ( \u03b2 k | \u03b8 \u03b2 , \u03c4 \u03b2 ) p ( \u03b1 k | \u03b8 \u03b1 , \u03c4 \u03b1 ) p ( w k | u , \u03b2 k ) \u220f i = 1 n k p y i k | x i k , \u03b1 k , w k where X = x 1 1 ; \u2026 ; x n 1 1 ; \u2026 ; x 1 m ; \u2026 ; x n m m is the matrix of examples labeled by all the experts, and y = y 1 1 ; \u2026 ; y n 1 1 ; \u2026 ; y m 1 ; \u2026 ; y n m m are their corresponding labels. Similarly, X k and y k are the examples and their labels from expert k. Direct optimization (maximization) of the above function is difficult due to the complexities caused by the multiplication of many terms. A common optimization trick to simplify the objective function is to replace the original complex objective function with the logarithm of that function. This conversion reduces the multiplication to summation [5]. Logarithm function is a monotonic function and leads to the same optimization solution as the original problem. Negative logarithm is usually used to cancel many negative signs produced by the logarithm of exponential distributions. This changes the maximization to minimization. We follow the same practice and take the negative logarithm of the above expression to obtain the following problem (see Appendix A for the details of the derivation): (4) min u , w , \u03b1 , \u03b2 \u03b7 2 \u2016 u \u2016 2 + 1 2 \u2211 k = 1 m \u03b1 k \u2211 i = 1 n k y i k - w k T x i k 2 + 1 2 \u2211 k = 1 m \u03b2 k \u2016 w k - u \u2016 2 + \u2211 k = 1 m ( - ln ( \u03b2 k ) - n k ln ( \u03b1 k ) ) + \u2211 k = 1 m ( - ( \u03b8 \u03b2 k - 1 ) ln ( \u03b2 k ) + \u03c4 \u03b2 k \u03b2 k ) + \u2211 k = 1 m ( - ( \u03b8 \u03b1 k - 1 ) ln ( \u03b1 k ) + \u03c4 \u03b1 k \u03b1 k ) Although we can solve the objective function in Eq. (4) directly, we replace the squared error function in Eq. (4) with the hinge loss 1 Hinge loss is a loss function originally designed for training large margin classifiers such as support vector machines. The minimization of this loss leads to a classification decision boundary that has the maximum distance to the nearest training example. Such a decision boundary has interesting properties, including good generalization ability [15,21]. 1 for two reasons: (1) the hinge loss function is a tighter surrogate for the zero-one (error) loss used for classification than the squared error loss[15] and (2) the hinge loss function leads to the sparse kernel solution [5]. Sparse solution means that the decision boundary depends on a smaller number of training examples. Sparse solutions are more desirable specially when the models are extended to non-linear case where the similarity of the unseen examples needs to be evaluated with respect to the training examples on which the decision boundary is dependent. By replacing the squared errors with the hinge loss we obtain the following objective function: (5) min u , w , \u03b1 , \u03b2 \u03b7 2 \u2016 u \u2016 2 + 1 2 \u2211 k = 1 m \u03b1 k \u2211 i = 1 n k max 0 , 1 - y i k w k T x i k ) + 1 2 \u2211 k = 1 m \u03b2 k \u2016 w k - u \u2016 2 + \u2211 k = 1 m ( - ln ( \u03b2 k ) - n k ln ( \u03b1 k ) ) + \u2211 k = 1 m ( - ( \u03b8 \u03b2 k - 1 ) ln ( \u03b2 k ) + \u03c4 \u03b2 k \u03b2 k ) + \u2211 k = 1 m ( - ( \u03b8 \u03b1 k - 1 ) ln ( \u03b1 k ) + \u03c4 \u03b1 k \u03b1 k ) We minimize the above objective function with respect to the consensus model u, the expert specific model w k , and expert specific reliability parameters \u03b1 k and \u03b2 k . 3.2 Optimization We need to optimize the objective function in Eq. (5) with regard to parameters of the consensus model u, the expert-specific models w k , and expert-specific parameters \u03b1 k and \u03b2 k . Similarly to the SVM, the hinge loss term: max 0 , 1 - y i k w k T x i k in Eq. (5) can be replaced by a constrained optimization problem with a new parameter \u220a i k . Briefly, from the optimization theory, the following two equations are equivalent [6]: min w k max 0 , 1 - y i k w k T x i k and min \u220a i k , w k \u220a i k s.t. y i k w k T x i k > 1 - \u220a i k Now replacing the hinge loss terms in Eq. (5), we obtain the equivalent optimization problem: (6) min u , w , \u220a , \u03b1 , \u03b2 \u03b7 2 \u2016 u \u2016 2 + 1 2 \u2211 k = 1 m \u03b1 k \u2211 i = 1 n k \u220a i k + 1 2 \u2211 k = 1 m \u03b2 k \u2016 w k - u \u2016 2 + \u2211 k = 1 m ( - ln ( \u03b2 k ) - n k ln ( \u03b1 k ) ) + \u2211 k = 1 m ( - ( \u03b8 \u03b2 k - 1 ) ln ( \u03b2 k ) + \u03c4 \u03b2 k \u03b2 k + \u2211 k = 1 m ( - ( \u03b8 \u03b1 k ) - 1 ) ln ( \u03b1 k ) + \u03c4 \u03b1 k \u03b1 k ) s . t . y i k w k T x i k \u2a7e 1 - \u220a i k , k = 1 \u22ef m , i = 1 \u22ef n k \u220a i k \u2a7e 0 , k = 1 \u22ef m , i = 1 \u22ef n k where \u220a denote the new set of \u220a i k parameters. We optimize the above objective function using the alternating optimization approach [4]. Alternating optimization splits the objective function into two (or more) easier subproblems, each depends only on a subset of (hidden/learning) variables. After initializing the variables, it iterates over optimizing each set by fixing the other set until there is no change of values of all the variables. For our problem, diving the learning variables into two subsets, {\u03b1, \u03b2} and {u, w} makes each subproblem easier, as we describe below. After initializing the first set of variables, i.e. \u03b1 k =1 and \u03b2 k =1, we iterate by performing the following two steps in our alternating optimization apparoach: \u2022 Learning u and w k : In order to learn the consensus model u and expert specific model w k , we consider the reliability parameters \u03b1 k and \u03b2 k as constants. This will lead to an SVM form optimization to obtain u and w k . Notice that \u220a i k is also learned as part of SVM optimization. \u2022 Learning \u03b1 k and \u03b2 k : By fixing u, w k for all experts, and \u220a , we can minimize the objective function in Eq. (6) by computing the derivative with respect to \u03b1 and \u03b2 . This results in the following closed form solutions for \u03b1 k and \u03b2 k : (7) \u03b1 k = 2 ( n k + \u03b8 \u03b1 k - 1 ) \u2211 y i k = 1 \u220a i k + 2 \u03c4 \u03b1 k (8) \u03b2 k = 2 \u03b8 \u03b2 k \u2016 w k - u \u2016 2 + 2 \u03c4 \u03b2 k Notice that \u220a i k is the amount of violation of label constraint for example x i k (i.e. the ith example labeled by expert k) thus \u2211 i = 1 \u220a i k is the summation of all labeling violations for model of expert k. This implies that \u03b1 k is inversely proportional to the amount of misclassification of examples by expert k according to its specific model w k . As a result, \u03b1 k represents the consistency of the labels provided by expert k with his/her own model. \u03b2 k is inversely related to the difference of the model of expert k (i.e. w k ) with the consensus model u. Thus it is the consistency of the model learned for expert k from the consensus model u. 4 Experimental evaluation We test the performance of our methods on clinical data obtained from EHRs for post-surgical cardiac patients and the problem of monitoring and detection of the Heparin Induced Thrombocytopenia (HIT) [23,22]. HIT is an adverse immune reaction that may develop if the patient is treated for a longer time with heparin, the most common anticoagulation treatment. If the condition is not detected and treated promptly it may lead to further complications, such as thrombosis, and even to patient\u2019s death. An important clinical problem is the monitoring and detection of patients who are at risk of developing the condition. Alerting when this condition becomes likely prevents the aggravation of the condition and appropriate countermeasures (discontinuation of the heparin treatment or switch to an alternative anticoagulation treatment) may be taken. In this work, we investigate the possibility of building a detector from patient data and human expert assessment of patient cases with respect to HIT and the need to raise the HIT alert. This corresponds to the problem of learning a classification model from data where expert\u2019s alert or no-alert assessments define class labels. 4.1 Data The data used in the experiments were extracted from over 4486 electronic health records (EHRs) in Post-surgical Cardiac Patient (PCP) database [11,20,12]. The initial data consisted of over 51,000 unlabeled patient-state instances obtained by segmenting each EHR record in time with 24-h period. Out of these we have selected 377 patient instances using a stratified sampling approach that were labeled by clinical pharmacists who attend and manage patients with HIT. Since the chance of observing HIT is relatively low, the stratified sampling was used to increase the chance of observing patients with positive labels. Briefly, a subset of strata covered expert-defined patterns in the EHR associated with the HIT or its management, such as, the order of the HPF4 lab test used to confirm the condition [22]. We asked three clinical pharmacists to provide us with labels showing if the patient is at the risk of HIT and if they would agree to raise an alert on HIT if the patient was encountered prospectively. The assessments were conducted using a web-based graphical interface (called PATRIA) we have developed to review EHRs of patients in the PCP database and their instances. All three pharmacists worked independently and labeled all 377 instances. After the first round of expert labeling (with three experts) we asked a (senior) expert on HIT condition to label the data, but this time, the expert in addition to information in the EHR also had access to the labels of the other three experts. This process led to 88 positive and 289 negative labels. We used the judgement and labels provided by this expert as consensus labels. We note that alternative ways of defining consensus labels in the study would be possible. For example, one could ask the senior expert to label the cases independent of labels of other reviewers and consider expert\u2019s labels as surrogates for the consensus labels. Similarly one can ask all three experts to meet and resolve the cases they disagree on. However, these alternative designs come with the different limitations. First, not seeing the labels of other reviewers the senior expert would make a judgment on the labels on her own and hence it would be hard to speak about consensus labels. Second, the meeting of the experts and the resolution of the differences on every case in the study in person would be hard to arrange and time consuming to undertake. Hence, we see the option of using senior expert\u2019s opinion to break the ties as a reasonable alternative that (1) takes into account labels from all experts and (2) resolves them without arranging a special meeting of all experts involved. In addition, we would like to emphasize that the labels provided by the (senior) expert were only used to evaluate the quality of the different consensus models. That is, we did not use the labels provided by that expert when training the different consensus models, and only applied them in the evaluation phase. 4.2 Temporal feature extraction The EHR consists of complex multivariate time series data that reflect sequences of lab values, medication administrations, procedures performed, etc. In order to use these for building HIT prediction models, a small set of temporal features representing well the patient state with respect to HIT for any time t is needed. However, finding a good set of temporal features is an extremely challenging task [10,2,7,3,1]. Briefly, the clinical time series, are sampled at irregular times, have missing values, and their length may vary depending on the time elapsed since the patient was admitted to the hospital. All these make the problem of summarizing the information in the time series hard. In this work, we address the above issues by representing the patient state at any (segmentation) time t using a subset of pre-defined temporal feature mappings proposed by Hauskrecht et al. [11,20,12] that let us convert patient\u2019s information known at time t to a fixed length feature vector. The feature mappings define temporal features such as last observed platelet count value, most recent platelet count trend, or, the length of time the patient is on medication. Fig. 4 illustrates a subset of 10 feature mappings (out of 14) that we applied to summarize time series for numeric lab tests. We used feature mappings for five clinical variables useful for the detection of HIT: Platelet counts, Hemoglobin levels, White Blood Cell Counts, Heparin administration record, Major heart procedure. The full list of features generated for these variables is listed in Appendix B. Briefly, temporal features for numeric lab tests: Platelet counts, Hemoglobin levels and White Blood Cell Counts used feature mappings illustrated in Fig. 4 plus additional features representing the presence of last two values, and pending test. The heparin features summarize if the patient is currently on the heparin or not, and the timing of the administration, such as the time elapsed since the medication was started, and the time since last change in its administration. The heart procedure features summarize whether the procedure was performed or not and the time elapsed since the last and first procedure. The feature mappings when applied to EHR data let us map each patient instance to a vector of 50 features. These features were then used to learn the models in all subsequent experiments. The alert labels assigned to patient instances by experts were used as class labels. 4.3 Experimental set-up To demonstrate the benefits of our multi-expert learning framework we used patient instances labeled by four experts as outlined above. The labeled data were randomly split into the training and test sets, such that 2/3 of examples were used for training examples and 1/3 for testing. We trained all models in the experimental section on the training set and evaluated on the test set. We used the Area Under the ROC Curve (AUC) on the test set as the main statistic for all comparisons. We repeated train/test split 100 times and report the average and 95% confidence interval. We compare the following algorithms: \u2022 SVM-baseline: This is a model obtained by training a linear SVM classifier that considers examples and their labels and ignores any expert information. We use the model as a baseline. \u2022 Majority: This model selects the label in the training data using the majority vote and learns a linear SVM classifier on examples with the majority label. This model is useful only when multiple experts label the same patient instance. Notice that SVM and Majority performs exactly the same if each example is labeled by one and only one expert. \u2022 Raykar: This is the algorithm and model developed by Raykar et al. [14]. We used the same setting as discussed in [14]. \u2022 ME-SVM: This is the new method we propose in this paper. We set the parameters \u03b7 = \u03c4 \u03b1 = \u03c4 \u03b2 =1, \u03b8 \u03b1 = \u03b8 \u03b2 =1. \u2022 SE-SVM: Senior-Expert-SVM (SE-SVM) is the SVM model trained using the consensus labels provided by our senior pharmacist. Note that this method does not derive a consensus model from labels given by multiple experts; instead, it \u2018cheats\u2019 and learns consensus model directly from consensus labels. This model and its results are used for comparison purposes only and serve as the reference point. We investigate two aspects of the proposed ME-SVM method: 1. The performance of the consensus model on the test data when it is evaluated on the labels provided by the senior expert on HIT. 2. The performance of the expert-specific model w k for expert k when it is evaluated on the examples labeled by that expert. 4.4 Results and discussion 4.4.1 Learning consensus model The cost of labeling examples in medical domain is typically very high, so in practice we may have a very limited number of training data. Therefore, it is important to have a model that can efficiently learn from a small number of training examples. We investigate how different methods perform when the size of training data varies. For this experiment we randomly sample examples from the training set to feed the models and evaluate them on the test set. We simulated and tested two different ways of labeling the examples used for learning the model: (1) every example was given to just one expert, and every expert labeled the same number of examples and (2) every example was given to all experts, that is, every example was labeled three times. The results are shown in Fig. 5 . The x-axis shows the total number of cases labeled by the experts. The left and right plots respectively show the results when labeling options 1 and 2 are used. First notice that our method that explicitly models experts\u2019 differences and their reliabilities consistently outperforms other consensus methods in both strategies, especially when the number of training examples is small. This is particularly important when labels are not recorded in the EHRs and must be obtained via a separate post-processing step, which can turn out to be rather time-consuming and requires additional expert effort. In contrast to our method the majority voting does not model the reliability of different experts and blindly considers the consensus label as the majority vote of labels provided by different experts. The SVM method is a simple average of reviewer specific models and does not consider the reliability of different experts in the combination. The Raykar method, although modeling the reliabilities of different experts, assumes that the experts have access to the label generated by the consensus model and report a perturbed version of the consensus label. This is not realistic because it is not clear why the expert perturb the labels if they have access to consensus model. In contrary, our method assumes that different experts aim to use a model similar to consensus model to label the cases however their model differs from the label of the consensus model because of their differences in the domain knowledge, expertise and utility functions. Thus, our method uses a more intuitive way and realistic approach to model the label generating process. Second, by comparing the two strategies for labeling patient instances we see that option 1, where each reviewer labels different patient instances, is better (in terms of the total labeling effort) than option 2 where all reviewers label the same instances. This shows that the diversity in patient examples seen by the framework helps and our consensus model is improving faster, which is what we intuitively expect. Finally, note that our method performs very similarly to the SE-SVM \u2013 the model that \u2018cheats\u2019 and is trained directly on the consensus labels given by the senior pharmacist. This verifies that our framework is effective in finding a good consensus model without having access to the consensus labels. 4.4.2 Modeling individual experts One important and unique feature of our framework when compared to other multi-expert learning frameworks is that it models explicitly the individual experts\u2019 models w k , not just the consensus model u. In this section, we study the benefit of the framework for learning the expert specific models by analyzing how the model for any of the experts can benefit from labels provided by other experts. In other words we investigate the question: Can we learn an expert model better by borrowing the knowledge and labels from other experts? We compared the expert specific models learned by our framework with the following baselines: \u2022 SVM: We trained a separate SVM model for each expert using patient instances labeled only by that expert. We use this model as a baseline. \u2022 Majority \u2217: This is the Majority model described in the previous section. However, since Majority model does not give expert specific models, we use the consensus model learned by the Majority method in order to predict the labels of each expert. \u2022 Raykar \u2217: This is the model developed by Raykar et al. [14], as described in the previous section. Similarly to Majority, Raykar\u2019s model does not learn expert specific models. Hence, we use the consensus model it learns to predict labels of individual experts. \u2022 ME-SVM: This is the new method we propose in this paper, that generates expert specific models as part of its framework. Similarly to Section 4.4.1, we assume two different ways of labeling the examples: (1) every example was given to just one expert, and every expert labeled the same number of examples and (2) every example was given to all experts, that is every example was labeled three times. We are interested in learning individual prediction models for three different experts. If we have a budget to label some number of patient instances, say, 240, and give 80 instances to each expert, then we have can an individual expert model from: (1) all 240 examples by borrowing from the instances labeled by the other experts or (2) only its own 80 examples. The hypothesis is that learning from data and labels given by all three experts collectively is better than learning each of them individually. The hypothesis is also closely related to the goal of multi-task learning, where the idea is to use knowledge, models or data available for one task to help learning of models for related domains. The results for this experiment are summarized in Fig. 6 , where x-axis is the number of training examples fed to the models and y-axis shows how well the models can predict individual experts\u2019 labels in terms of the AUC score. The first (upper) line of sub-figures shows results when each expert labels a different set of patient instances, whereas the second (lower) line of sub-figures shows results when instances are always labeled by all three experts. The results show that our ME-SVM method outperforms the SVM trained on experts\u2019 own labels only. This confirms that learning from three experts collectively helps to learn expert-specific models better than learning from each expert individually and that our framework enables such learning. In addition, the results of Majority\u2217 and Raykar\u2217 methods show that using their consensus models to predict expert specific labels is not as effective and that their performance is worse than our framework that relies on expert specific models. 4.4.3 Self-consistency and consensus-consistency As we described in Section 3, we model self-consistency and consensus-consistency with parameters \u03b1 k and \u03b2 k . \u03b1 k measures how consistent the labeling of expert k is with his/her own model and \u03b2 k measures how consistent the model of expert k is with respect to the consensus model. The optimization problem we proposed in Eq. (6) aims to learn not just the parameters u and w k of the consensus and experts\u2019 models, but also the parameters \u03b1 k and \u03b2 k , and this without having access to the labels from the senior expert. In this section, we attempt to study and interpret the values of the reliability parameters as they are learned by our framework and compare them to empirical agreements in between the senior (defining the consensus) and other experts. Fig. 7 a shows the agreements of labels provided by the three experts with labels given by the senior expert, which we assumed gives the consensus labels. From this figure we see that Expert 2 agrees with the consensus labels the most, followed by Expert 3 and then Expert 1. The agreement is measured in terms of the absolute agreement, and reflects the proportion of instances for which the two labels agree. Fig. 7b and c show the values of the reliability parameters \u03b1 and \u03b2, respectively. The x-axis in these figures shows how many training patient instances per reviewer are fed to the model. Normalized self-consistency in Fig. 7b is the normalized value of \u03b1 k in Eq. (6). Normalized consensus-consistency in Fig. 7c is the normalized inverse value of Euclidean distance between an expert specific model and consensus model: 1/\u2225w k \u2212 u\u2225, which is proportional to \u03b2 k in Eq. (6). In Fig. 7d we add the two consistency measures in an attempt to measure the overall consistency in between the senior expert (consensus) and other experts. As we can see, at the beginning when there is no training data all experts are assumed to be the same (much like the majority voting approach). However, as the learning progresses with more training examples available, the consistency measures are updated and their values define the contribution of each expert to the learning of consensus model: the higher the value the larger the contribution. Fig. 7b shows that expert 3 is the best in terms of self-consistency given the linear model, followed by expert 2 and then expert 1. This means expert 3 is very consistent with his model, that is, he likely gives the same labels to similar examples. Fig. 7c shows that expert 2 is the best in terms of consensus-consistency, followed by expert 3 and then expert 1. This means that although expert 2 is not very consistent with respect to his own linear model his model appears to converge closer to the consensus model. In other words, expert 2 is the closest to the expected consensus in terms of the expertise but deviates with some labels from his own linear model than expert 3 does. 2 We would like to note that the self-consistency and consensus-consistency parameters learned by our framework are learned together and hence it is possible one consistency measure may offset or compensate for the value of the other measure during the optimization. In that case the interpretation of the parameters as presented may not be as straightforward. 2 Fig. 7d shows the summation of the two consistency measures. By comparing Fig. 7a and d we observe that the overall consistency mimics well the agreements in between the expert defining the consensus and other experts, especially when the number of patient instances labeled and used to train our model increases. This is encouraging, since the parameters defining the consistency measures are learned by our framework only from the labels of the three experts and hence the framework never sees the consensus labels. 5 Conclusion The construction of predictive classification models from clinical data often relies on labels reflecting subjective human assessment of the condition of interest. In such a case, differences among experts may arise leading to potential disagreements on the class label that is assigned to the same patient case. In this work, we have developed and investigated a new approach to combine class-label information obtained from multiple experts and learn a common (consensus) classification model. We have shown empirically that our method outperforms other state-of-the-art methods when building such a model. In addition to learning a common classification model, our method also learns expert specific models. This addition provides us with an opportunity to understand the human experts\u2019 differences and their causes which can be helpful, for example, in education and training, or in resolving disagreements in the patient assessment and patient care. Acknowledgements This research work was supported by Grants R01LM010019 and R01GM088224 from the National Institutes of Health. Its content is solely the responsibility of the authors and does not necessarily represent the official views of the NIH. Appendix A Derivation of Eq. (4) from Eq. (3) In this appendix, we give a more detailed derivation of Eq. (4) from (3): p ( u , W , \u03b7 , \u03b1 , \u03b2 | X , y , \u03be ) \u221d p ( u | 0 d , \u03b7 ) \u220f k = 1 m p ( \u03b2 k | \u03b8 \u03b2 , \u03c4 \u03b2 ) p ( \u03b1 k | \u03b8 \u03b1 , \u03c4 \u03b1 ) p ( w k | u , \u03b2 k ) \u220f i = 1 n k p y i k | x i k , \u03b1 k , w k = N u | 0 , \u03b2 k - 1 I d \u220f k = 1 m G ( \u03b2 k | \u03b8 \u03b2 , \u03c4 \u03b2 ) G ( \u03b1 k | \u03b8 \u03b1 , \u03c4 \u03b1 ) N ( w k | u , \u03b2 k - 1 I d ) \u220f i = 1 n k N y i k | w k \u22a4 x i k , \u03b1 k = \u03b7 k 2 \u03c0 e - \u03b7 \u2016 u \u2016 2 2 \u00d7 \u220f k = 1 m 1 \u0393 ( \u03b8 \u03b2 ) \u03c4 \u03b2 \u03b8 \u03b2 \u03b2 k \u03b8 \u03b2 - 1 e - \u03c4 \u03b2 \u03b2 k 1 \u0393 ( \u03b8 \u03b1 ) \u03c4 \u03b1 \u03b8 \u03b1 \u03b1 k \u03b8 \u03b1 - 1 e - \u03c4 \u03b1 \u03b1 k \u03b2 k 2 \u03c0 e - \u03b2 k \u2016 w k - u \u2016 2 2 \u220f i = 1 n k \u03b1 k 2 \u03c0 e - \u03b1 k y i k - w k \u22a4 x i k 2 2 Taking the negative logarithm of p ( u , W , \u03b7 , \u03b1 , \u03b2 \u2223 X , y , \u03be ) that lets us to convert the maximization problem to minimization, we get: - ln p ( u , W , \u03b7 , \u03b1 , \u03b2 \u2223 X , y , \u03be ) = - ln ( \u03b7 ) - log ( 2 \u03c0 ) + 1 2 \u03b7 \u2016 u \u2016 2 + \u2211 k = 1 m ( ln ( \u0393 ( \u03b8 \u03b2 ) ) - \u03b8 \u03b2 ln ( \u03c4 \u03b2 ) - ( \u03b8 \u03b2 - 1 ) ln ( \u03b2 k ) + \u03c4 \u03b2 \u03b2 k ) + \u2211 k = 1 m ( ln ( \u0393 ( \u03b8 \u03b1 ) ) - \u03b8 \u03b1 ln ( \u03c4 \u03b1 ) - ( \u03b8 \u03b1 - 1 ) ln ( \u03b1 k ) + \u03c4 \u03b1 \u03b1 k ) + \u2211 k = 1 m - ln ( \u03b2 k ) + ln ( 2 \u03c0 ) + 1 2 \u03b2 k \u2016 w k - u \u2016 2 ) + \u2211 k = 1 m \u2211 i = 1 n k - ln ( \u03b1 k ) + ln ( 2 \u03c0 ) + 1 2 \u03b1 k \u2016 y i k - w k \u22ba x i k \u2016 2 Rewriting the above equation we get: - ln p ( u , W , \u03b7 , \u03b1 , \u03b2 \u2223 X , y , \u03be ) = 1 2 \u03b7 \u2016 u \u2016 2 + \u2211 k = 1 m ( - ( \u03b8 \u03b2 - 1 ) ln ( \u03b2 k ) + \u03c4 \u03b2 \u03b2 k ) + \u2211 k = 1 m ( - ( \u03b8 \u03b1 - 1 ) ln ( \u03b1 k ) + \u03c4 \u03b1 \u03b1 k ) + \u2211 k = 1 m - ln ( \u03b2 k ) + 1 2 \u03b2 k \u2016 w k - u \u2016 2 + \u2211 k = 1 m \u2211 i = 1 n k - ln ( \u03b1 k ) + 1 2 \u03b1 k \u2016 y i k - w k \u22ba x i k \u2016 2 + A where A sums all constant terms that can be ignored during the optimization step, and that include terms involving hyperparameters \u03b7 , \u03b8 \u03b1 , \u03c4 \u03b1 , \u03b8 \u03b2 that are constants. By ignoring A and rearranging the remaining terms we get Eq. 4. Removing the constants terms (i.e. those related to \u03b7, \u03b8 \u03b1 , \u03c4 \u03b1 , \u03b8 \u03b2 and \u03c4 \u03b2 , we will have: 1 2 \u03b7 \u2016 u \u2016 2 + \u2211 k = 1 m - ( \u03b8 \u03b2 - 1 ) log ( \u03b2 k ) + \u03c4 \u03b2 \u03b2 k - ( \u03b8 \u03b1 - 1 ) log ( \u03b1 k ) + \u03c4 \u03b1 \u03b1 k - log ( \u03b2 k ) + 1 2 \u03b2 k \u2016 w k - u \u2016 2 + \u2211 i = 1 n k - log ( \u03b1 k ) + 1 2 \u03b1 k y i k - w k \u22a4 x i k 2 Rearranging the terms in the above equation, we obtain Eq. (4). Appendix B Features used for constructing the predictive models See Table 1 . References [1] Iyad Batal Dmitriy Fradkin James Harrison Fabian Moerchen Milos Hauskrecht Mining recent temporal patterns for event detection in multivariate time series data Proceedings of the international conference on Knowledge discovery and data mining 2012 ACM 280 288 [2] Batal Iyad, Sacchi Lucia, Bellazzi Riccardo, Hauskrecht Milos. Multivariate time series classification with temporal abstractions. In: Proceedings of Florida Artificial intelligence research society conference; 2009. [3] Iyad Batal Hamed Valizadegan Gregory F. Cooper Milos Hauskrecht A pattern mining approach for classifying multivariate temporal data IEEE international conference on bioinformatics and biomedicine (BIBM) 2011 IEEE 358 365 [4] James C. Bezdek Richard J. Hathaway Some notes on alternating optimization Proceedings of the 2002 AFSS international conference on fuzzy systems Calcutta: advances in soft computing, AFSS \u201902 2002 Springer-Verlag London, UK, UK 288 300 [5] Christopher M. Bishop Pattern recognition and machine learning 2006 Springer [6] Stephen Boyd Lieven Vandenberghe Convex optimization 2004 Cambridge University Press New York, NY, USA [7] Carlo Combi Elpida Keravnou-Papailiou Yuval Shahar Temporal information systems in medicine 2010 Springer Publishing Company, Incorporated [8] A.P. Dawid A.M. Skene Maximum likelihood estimation of observer error-rates using the em algorithm Appl Stat 28 1 1979 20 28 [9] Theodoros Evgeniou Massimiliano Pontil Regularized multi-task learning Proceedings of the international conference on Knowledge discovery and data mining 2004 ACM New York, NY, USA 109 117 [10] Hauskrecht M, Fraser H. Modeling treatment of ischemic heart disease with partially observable markov decision processes. In: Proceedings of the AMIA annual symposium; 1998. p. 538\u201342. [11] Hauskrecht M, Valko M, Batal I, Clermont G, Visweswaran S, Cooper GF. Conditional outlier detection for clinical alerting. In: Proceedings of the AMIA annual symposium; 2010. p. 286\u2013890. [12] Milos Hauskrecht Iyad Batal Michal Valko Shyam Visweswaran Gregory F. Cooper Gilles Clermont Outlier detection for patient monitoring and alerting J Biomed Inform 46 1 2013 47 55 [13] Daphne Koller Nir Friedman Probabilistic graphical models: principles and techniques 2009 MIT Press [14] V.C. Raykar S. Yu L.H. Zhao G.H. Valadez C. Florin L. Bogoni Learning from crowds Journal of Machine Learning Research 11 2010 1297 1322 [15] Bernhard Scholkopf Alexander J. Smola Learning with kernels: support vector machines, regularization, optimization, and beyond 2001 MIT Press Cambridge, MA, USA [16] Bernhard Scholkopf Alexander J. Smola Learning with kernels: support vector machines, regularization, optimization, and beyond 2002 MIT Press Cambridge, MA, USA [17] Victor S. Sheng Foster Provost Panagiotis G. Ipeirotis Get another label? Improving data quality and data mining using multiple, noisy labelers Proceedings of the international conference on Knowledge discovery and data mining 2008 ACM 614 622 [18] Rion Snow Brendan O\u2019Connor Daniel Jurafsky Andrew Y. Ng Cheap and fast\u2014but is it good?: Evaluating non-expert annotations for natural language tasks Conference on Empirical Methods on Natural Language Processing 2008 Association for Computational Linguistics Stroudsburg, PA, USA 254 263 [19] Hamed Valizadegan Rong Jin Generalized maximum margin clustering and unsupervised kernel learning B. Sch\u00f6lkopf J. Platt T. Hoffman Advances in neural information processing systems vol. 19 2007 MIT Press Cambridge, MA 1417 1424 [20] Valko Michal, Hauskrecht Milos. Feature importance analysis for patient management decisions. In: Proceedings of the 13th international congress on medical informatics; 2010. p. 861\u20135. [21] Vladimir N. Vapnik The nature of statistical learning theory 1995 Springer-Verlag New York, Inc. New York, NY, USA [22] TE. Warkentin Heparin-induced thrombocytopenia: pathogenesis and management Br J Haematol 2003 535 555 [23] TE. Warkentin JI. Sheppard P. Horsewood Impact of the patient population on the risk for heparin-induced thrombocytopenia Blood 2000 1703 1708 [24] Welinder Peter, Branson Steve, Belongie Serge, Perona Pietro. The multidimensional wisdom of crowds. In: Advances in neural information processing systems; 2010, 2424\u20132432. [25] Whitehill Jacob, Ruvolo Paul, fan Wu Ting, Bergsma Jacob, Movellan Javier. Whose vote should count more: optimal integration of labels from labelers of unknown expertise. In: Advances in neural information processing systems; 2009. p. 2035\u201343. [26] Yan Yan, Fung Glenn, Dy Jennifer, Rosales Romer. Modeling annotator expertise: learning when everybody knows a bit of something. In: Proceedings of the international conference on Artificial Intelligence and Statistics; April 2010. [27] Zhang Yu, Yeung Dit-Yan. A convex formulation for learning task relationships in multi-task learning. In: Proceedings of the international conference on the Uncertainty in Artificial Intelligence; 2010."
    },
    "10.1016/j.proeng.2013.04.074": {
        "Title": "Abductive and Deductive Approach in Learning from Examples Method for Technological Decisions Making",
        "Date": "2013",
        "Text": "serial JL 278653 291210 291884 31 90 Procedia Engineering PROCEDIAENGINEERING 2013-05-10 2013-05-10 2014-11-04T06:36:18 1-s2.0-S1877705813008072 S1877-7058(13)00807-2 S1877705813008072 10.1016/j.proeng.2013.04.074 S300 S300.3 HEAD-AND-TAIL 1-s2.0-S1877705813X00086 2021-10-14T13:41:10.036582Z 0 0 20130101 20131231 2013 2013-05-10T00:00:00Z rawtext articleinfo articletitlenorm authfirstinitialnorm authfirstsurnamenorm cid cids confeditor contenttype copyright crossmark dateloaded dateloadedtxt datesearch datesort dateupdated dco docsubtype doctype doi eid ewtransactionid hubeid indexeddate issn issnnorm itemstage itemtransactionid itemweight oauserlicense openaccess openarchive pg pgfirst pglast pii piinorm pubdateend pubdatestart pubdatetxt pubyr sortorder srctitle srctitlenorm srctype ssids alllist content oa subj suppl tomb vol volfirst volissue volumelist webpdf webpdfpagecount yearnav affil articletitle auth authfirstini authfull authkeywords authlast primabst ref 1877-7058 18777058 false 57 57 C Volume 57 72 583 588 583 588 2013 2013 2013-01-01 2013-12-31 2013 Modern Building Materials, Structures and Techniques Algirdas Juozapaitis Povilas Vaini\u016bnas Edmundas Kazimieras Zavadskas article fla Copyright \u00a9 2013 The Authors. ABDUCTIVEDEDUCTIVEAPPROACHINLEARNINGEXAMPLESMETHODFORTECHNOLOGICALDECISIONSMAKING ANETA K ANETAX2013X583 ANETAX2013X583X588 ANETAX2013X583XK ANETAX2013X583X588XK Full 2013-07-16T12:29:19Z http://creativecommons.org/licenses/by-nc-nd/3.0/ OA-Window ElsevierWaived 0 item S1877-7058(13)00807-2 S1877705813008072 1-s2.0-S1877705813008072 10.1016/j.proeng.2013.04.074 278653 2014-11-04T06:44:58.051467-05:00 2013-01-01 2013-12-31 1-s2.0-S1877705813008072-main.pdf https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1877705813008072/MAIN/application/pdf/9b74725bf323033b368d03733e2151b5/main.pdf https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1877705813008072/MAIN/application/pdf/9b74725bf323033b368d03733e2151b5/main.pdf main.pdf pdf true 353030 MAIN 6 1-s2.0-S1877705813008072-main_1.png https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1877705813008072/PREVIEW/image/png/42747cbdb34391b4ea3bcf97200b09ea/main_1.png https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1877705813008072/PREVIEW/image/png/42747cbdb34391b4ea3bcf97200b09ea/main_1.png main_1.png png 63320 849 656 IMAGE-WEB-PDF 1 P r o c e d i a E n g i n e e r i n g 5 7 ( 2 0 1 3 ) 5 8 3 \u00e2\u20ac\u201c 5 8 8 1877-7058 2013 The Authors. Published by Elsevier Ltd. Open access under CC BY-NC-ND license. Selection and peer-review under responsibility of the Vilnius Gediminas Technical University doi: 10.1016/j.proeng.2013.04.074 11th International Conference on Modern Building Materials, Structures and Techniques, MBMST 2013 Abductive and Deductive Approach in Learning from Examples Method for Technological Decisions Making Konczak Aneta a \u00e2\u02c6\u2014 , Paslawski Jerzy b a, b Division of Construction Engineering and Management, Institute of Structural Engineernig, Faculty of Civil and Environmental Engineering, Poznan University of Technology, 5, Piotrowo Str., PL-60-965 Poznan, Poland Abstract One of the fundamental problems in building engineering is to ensure conformance between the planned and the actual course of construction works. What may help solve this problem is a database with examples of performance of similar processes in analogous environmental conditions that enables estimating the basic process parameters (time, cost, quality, etc.). Case-based reasoning in a hybrid advisory system may play an important role between the rule-based reasoning and the machine learning when the data that has been gathered enables inference based on analogies with the completed processes, but their number is still inadequate for application of machine learning. Introduction of the abductive approach is intended to enable a detailed analysis of causes of nonconformances \u00e2\u20ac\u201c a limited number of examples facilitate this. This is an example of cooperation between a human (search for causes based on intuition) and a computer (systematic gathering of examples). The authors also plan to use simulations to verify the abductive hypotheses. In the final part of the article, an example of application of case-based reasoning in the process of delivery of ready-mix concrete is presented. \u00c2\u00a9 Selection and peer-review under responsibility of the Vilnius Gediminas Technical University. Keywords: Hybrid advisory system, case-based reasoning, simulation, abductive approach. 1. Introduction During performance of a construction project there are usually many disruptions and difficulties that force the persons involved in the project to change their decisions and to look for new solutions. Consequently, the typical approach to management of construction projects, based on a single technological and organizational scenario, is very risky. Given the changing conditions, a contractor is required to stop the works or to continue to risk financial losses or failure to meet the quality requirements. Thanks to accumulation and use of experiences, it is possible to gain an easy access to alternative solutions. They provide an opportunity to continue the processes but most importantly enable achieving the assumed results related to schedule, costs, quality, etc. In order to achieve the rational results during performance of a project, it is thus necessary to: \u00e2\u20ac\u00a2 use a knowledge base containing examples of prior performances of processes in a broad spectrum of environmental conditions; \u00e2\u20ac\u00a2 monitor the environment in order to evaluate and record data for future projects. Based on previous projects, one may estimate the process parameters and use them to select the optimum solution to a given decision-making problem. In order to estimate the basic parameters of process performance options, one may use different methods [1]: \u00e2\u20ac\u00a2 multiple regression analysis (MRA) [2], [3]; * Corresponding author. E-mail address: a aneta.konczak@put.poznan.pl; b jerzy.pasl wski@put.poznan.pl Available online at www.sciencedirect.com 2013 The Authors. Published by Elsevier Ltd. Open access under CC BY-NC-ND license. Selection and peer-review under responsibility of the Vilnius Gediminas Technical University 584 Konczak Aneta and Paslawski Jerzy / Procedia Engineering 57 ( 2013 ) 583 \u00e2\u20ac\u201c 588 \u00e2\u20ac\u00a2 artificial neural networks (ANN) [4]; \u00e2\u20ac\u00a2 simulation methods [5]; and \u00e2\u20ac\u00a2 case-based reasoning methods [1, 6\u00e2\u20ac\u201c8, 20]. An important success driver is to combine various methods in order to achieve synergy (hybrid systems): an analogy resulting from similarity between recurring construction processes performed in similar conditions, an abductive approach aimed at analyzing the causes of irregularities in the performance of processes, and simulation modeling aimed to verify the hypotheses generated in the process of analyzing the cases. 2. Advisory systems supporting technological decision making Advisory systems based on knowledge gathering provide an opportunity to reduce the problems associated with difficulties in planning of construction processes. At the early stage of development of such systems, it is reasonable to use rule-based reasoning similar to the concept of traditional expert systems, based on knowledge contained in standards, instructions, procedures, and rules elaborated by experts. At the next stage, as the knowledge from cases is gathered, one may introduce case-based reasoning, based on a relatively small number of examples of performance of a specific construction process. At the next stage, one may use machine learning based on the use of artificial neural networks and simulation. These methods may be implemented only if a sufficiently large database with cases is available. Use of advisory systems is justified only when the possibility to index the cases is used skillfully and critical evaluation of the process performance results is performed. Experience and intuition of the system user is thus necessary in order to achieve synergy between the capacities of a human and a computer (considered to be one of the key objectives of creation and implementation of hybrid advisory systems). The functioning of the hybrid advisory system assumed using various tools/methods depending on the unique characteristics of the problem and the progress achieved in the development of the system (simulation [14], flexibility, ANN [4], MCDM [15, 16], evolution algorithms [17], material modification [18] and case analysis [19]. 3. Case-Based Reasoning The use of knowledge from previous cases, which is the topic of this article, is based on case-based reasoning. The case- based reasoning (CBR) consists in solving problems based on previous analogous cases [9]. The CBR speeds up the acquisition of the ability to handle difficult situations. It is based on: \u00e2\u20ac\u00a2 use of previous cases in order to explain new situations [8]; \u00e2\u20ac\u00a2 use of previous cases in order to critically and rationally evaluate new situations; \u00e2\u20ac\u00a2 reasoning based on previous cases in order to interpret new cases; \u00e2\u20ac\u00a2 development of new solutions in new situations based on previous experiences [10]. Fig. 1. Algorithm of case-based knowledge use 585 Konczak Aneta and Paslawski Jerzy / Procedia Engineering 57 ( 2013 ) 583 \u00e2\u20ac\u201c 588 Monitoring of another performance of a recurring construction process is the source of valuable information that can be analyzed and used to supplement the knowledge base. When planning new cases, decision makers use the knowledge based on the previous performances of the process in similar conditions. Parameters of similar cases are used to select a new solution. The applied solution must be monitored and controlled in order to evaluate it later and describe it by analyzing its results at later stages. When solving problems using the CBR method, it is also important to see the failures that cause the decision maker's expectations to be unfulfilled. Regardless of the results of the decisions made, each action enables drawing conclusions and contributes to the enlargement of the knowledge base. Cases with positive outcomes can be used to solve problems in new cases. Failures, on the other hand, serve the purpose of warning against potential new problems. Consequently, each analyzed (and described) case should be included in the database to be used in the future (Fig. 1). 4. Abductive and deductive approach in CBR The key to proper use of knowledge is using both deductive thinking and abductive thinking. This is because it is not enough to supplement the knowledge base with parameters from previous experiences only. It is also important to describe those cases that will enable supplementing the knowledge base with information on the causes of possible failures. Thus, each monitored case must be analyzed from the point of view of the causes of possible disruptions. Abduction and deduction are integral problem-solving methods. Deduction consists in drawing conclusions from what is known, e.g. the best medicine for flue is aspirin. Abduction explains what is known (or likely) to us, e.g. fever is caused by flue. As far as the algorithm of knowledge use in construction process management is concerned, abduction is used for analyzing and searching for causes of deviations. The basic model of abduction is the following [21]: DC\u00e2\u2020\u2019 D ________ C\u00e2\u02c6\u00b4 (1) The DC\u00e2\u2020\u2019 description pertains to the following relation: cause of disturbance \u00e2\u2020\u2019disturbance. One must keep in mind that abduction is a reasoning system based on hypotheses. The cause that one is looking for is only a suspicion regarding the occurring deviations. Consequently, explanation of the reasons behind the deviations does not guarantee that a solution will be found when another similar disruption occurs. The logic of abduction is the following [11]: 1. !P ),(.2 PKA\u00c2\u00ac )*,(.3 PKA\u00c2\u00ac ()( ) 4. , pres A KH P 1 5. , , n H meetsaditionalcriteriaS S\u00e2\u20ac\u00a6 )(,.6 HCrThus Cr HThus,.7 (2) In formula (2), P is the objective, i.e. learning the cause of the disruptions. K and K* (as an expansion of K) are the knowledge bases of the subject, and A(K,P) is the achievement of the objective based on the K base, which is impossible based on current resources. The objective of abduction is to elaborate hypothesis H which will enable satisfying the demand of \u00e2\u20ac\u0153purported cognitive achievability\u00e2\u20ac\ufffd (when some additional criteria S 1 , ... , S n , have been met). It is reason ble to consider the hypothesis (Cr(H)) and possibly to accept it (H cr ). Deduction reasoning, on the other hand, consists in using the gathered information and logical selection of a solution that, in specific performance conditions at the building site, appears to be the most advantageous. 586 Konczak Aneta and Paslawski Jerzy / Procedia Engineering 57 ( 2013 ) 583 \u00e2\u20ac\u201c 588 5. Proposed approach The key element of proposed approach is based on abductive approach, which is included for eliminate causes of disruptions and create a base of net cases. In order to improve the ability to make proper decisions in abductive and deductive thinking, it is understandable that knowledge from experience should be used as a way to find the most similar case (CBR abduction and deduction). Such a case, in turn, enables finding the best solution to the occurring problems. The abduction model adapted to CBR method must be expanded to include an analogous case Q\u00e2\u20ac\u2122 and analogous disturbance D\u00e2\u20ac\u2122 which has analogous causes C\u00e2\u20ac\u2122. The basic model of CBR abduction is the following [21]: DC\u00e2\u2020\u2019 '~DD 'D ________ 'C\u00e2\u02c6\u00b4 (3) The proposed method of learning from examples is based on the systematic collection of data, in which the deduction is to be used in finding the best solutions based on previous and similar cases. The abductive approach is designed to find the causes of disruptions and eliminating anomalies in stored cases (Fig. 2). The result is pure/net case. Fig. 2. Learning cycle based on abduction and deduction approach 6. Case study An example of application of knowledge from experiences described herein is concreting of reinforced concrete structures. The consecutive stages of the concreting cycle are loading of the concrete truck, transport to the building site, testing of the concrete mix (if it does not meet the requirements, it is sent back to the plant), unloading (if the pump is busy, the concrete truck must wait until it is unloaded), washout (and possible waiting in a line), and return to the concrete plant (Fig. 3). The random nature of the loading, delivery, and pouring of the concrete mix leads to situations where the concrete trucks are unused (usually the concrete plant and the pumps are regarded as the leading machines). However, in order to find an analogous case, one must first determine the preset parameters of the process that are important from the point of view of the analogy being searched for. Graham and Smith [12] given five key factors of this type: the type of the concreted element, the month, the weather, the concreting volume, and the number of concrete trucks delivering the concrete mix. According to Dunlop and Smith [13], other factors that have significant impact on the efficiency of concreting are the distance between the concrete plant and the building site, the capacity of the concrete truck, the capacity of the pump, and the type and age of the pump. The example discussed in the article is delivery of concrete mix to make a 50 cm thick substructure layer at the toll collection point on a motorway. In the case in question, there was no need to use a pump. The gathering of cases needed to determine the efficiency was started by identifying the criteria describing the cases gathered in the base: 1. Element type (slab = SLA, wall = WAL, foundation = BAS, other = OTH) \u00e2\u20ac\u201c this refers to a change in the efficiency depending on the shape and dimensions of structural elements; 587 Konczak Aneta and Paslawski Jerzy / Procedia Engineering 57 ( 2013 ) 583 \u00e2\u20ac\u201c 588 Fig. 3. Delivery of ready-mix concrete 2. Temperature (to \u00e2\u20ac\u201c15 \u00c2\u00b0C- EL, from \u00e2\u20ac\u201c14 \u00c2\u00b0C to \u00e2\u20ac\u201c5 \u00c2\u00b0C- L, from \u00e2\u20ac\u201c4 \u00c2\u00b0C to \u00e2\u20ac\u201c0 \u00c2\u00b0C- HL, from 1 \u00c2\u00b0C to 5 \u00c2\u00b0C- LM, from 6 \u00c2\u00b0C to 15 \u00c2\u00b0C- M, from 16 \u00c2\u00b0C to 25 \u00c2\u00b0C- MH, above 26 \u00c2\u00b0C \u00e2\u20ac\u201c EH) \u00e2\u20ac\u201c this refers to the air temperature during the transport and the pouring of the concrete mix; 3. Weather (sunny, overcast, rainy, snowy, sunny spells) \u00e2\u20ac\u201c this refers to the weather conditions at the time of delivery and pouring of the concrete mix; Subjective criterion based on the user\u00e2\u20ac\u2122s opinion; 4. Concreted volume (0-9, 10-19, 20-29, ..., 340-349, above 350 [m 3 ]) \u00e2\u20ac\u201c the volume of the structural element; 5. Capacity of the concrete trucks (6-8 \u00e2\u20ac\u201c L, 9-10 \u00e2\u20ac\u201c M, 11-12 \u00e2\u20ac\u201c H [m 3 ]) \u00e2\u20ac\u201c the nominal capacity of the concrete trucks; 6. Number of concrete trucks (1-5 \u00e2\u20ac\u201c L, 6-10 \u00e2\u20ac\u201c M, 11-15 \u00e2\u20ac\u201c H, above 16 \u00e2\u20ac\u201c EH [ea]) \u00e2\u20ac\u201c the number of concrete trucks used to transport the concrete mix; 7. Working hours (6:01-7:00 AM, 7:01-9:00 AM, 9:01-12:00 AM, 12:01-2:00 PM, 2:01-4:00 PM, 4:01-6:00 PM, 6:01 PM- 6:00 AM) \u00e2\u20ac\u201c the times at which the concrete mix is being transported. A part of the data table for several cases is shown below (Table 1). Table 1. Data on concrete mix deliveries No. Pour type Temperature Weather Vol. of truck No. of trucks Working hours Time of the ride Abduction 1 SLA LM overcast 6 9 6:01PM-6:00AM 0:42 2 SLA LM overcast 6 9 6:01PM-6:00AM 0:32 3 SLA LM overcast 6 9 6:01PM-6:00AM 0:38 4 SLA LM overcast 6 9 6:01PM-6:00AM 0:58 accident on the route 5 SLA LM overcast 7,5 9 6:01PM-6:00AM 0:38 Based on the cases above, it can be concluded that the main reason for delays and reduced efficiency of concreting is the changing conditions of traffic. In such conditions, two basic solutions are available: 1) to adjust the number of concrete trucks to match the variable traffic problems (e.g. at 6.01 PM/7.00 AM \u00e2\u20ac\u201c 9 trucks; 9.01 AM/2.00 PM and 4.01PM/6.00 PM \u00e2\u20ac\u201c 11 trucks, and 7.01 AM/9.00 AM and 2.01 PM/4.00 PM \u00e2\u20ac\u201c 13 trucks); 2) to change the location of the concrete mix plant (maybe install a field mix plant to support such a large building project). 588 Konczak Aneta and Paslawski Jerzy / Procedia Engineering 57 ( 2013 ) 583 \u00e2\u20ac\u201c 588 7. Conclusions The approach to supporting decision making processes related to selection of construction process performance variants based on the abductive and deductive approach in learning from examples method described here, with practical examples enable drawing the following conclusions: 1. The diversity of sources of disruptions in construction management justifies using the abduction approach. 2. Gathering knowledge from cases is an intermediate stage of development of a hybrid advisory system that fits between rule-based reasoning and machine learning, e.g. artificial neural networks. 3. The proposed concept can be implemented during performance of cyclic construction processes by a specialized contractor. 4. It is recommended to use an irregularity elimination mechanism based on abduction reasoning. 5. Use of simulations and case-based reasoning will enable achieving synergy, thus increasing the effectiveness and efficiency of the proposed method. Acknowledgements The authors would like to thank the Institute of Structural Engineering of the Poznan University of Technology for the support from its statutory activities fund. References [1] Koo, C., Hong, T., Hyun, C., & Koo, K., 2010. A CBR-based hybrid model for predicting a construction duration and cost based on project characteristics in multi-family housing projects, Canadian Journal of Civil Engineering 37(5), pp. 739-752. http://dx.doi.org/10.1139/L10-007 [2] Le-Hoai, L., Young Dai Lee, Y. D., Nguyen, A. T., 2013. Estimating time performance for building construction projects in Vietnam, KSCE Journal of Civil Engineering 17(1), pp. 1-8. http://dx.doi.org/10.1007/s12205-013-0862-3 [3] Kaplinski, O., Janusz, L., 2006. Three phases of multifactor modelling of construction processes, Journal of Civil Engineering a d Management 12(2), pp. 127-134. [4] Gajzler, M., 2011. Neural networks in the advisory system for repairs of industrial concrete floors, Compu r Assisted Mecha ics and Engin ering Sciences 18(4), pp. 255-263. [5] Liu, X., Wang, Z., Jin, D., 2011. Risk evaluation of cost for hydropower construction under risk fixed schedule probabilityusing monte carlo simulation method, Technics Technologies Education Management 6(2), pp. 287-299. [6] Arditi, D., Tokdemir, O. B., 1999. Using case-based reasoning to predict the outcome of construction litigation, C mputer-Aided Civil and Infrastructure Engineering 14(6), pp. 385-393. [7] Dogan, S., Arditi, D., Murat Gunaydin, H., 2006. Determining attribute weights in a CBR model for early cost prediction of structu al systems, Journal of Construction Engineering and Management 132(10), pp. 1092-1098. [8] Ryu, H., Lee, H., Park, M., 2007. Construction planning method using case-based reasoning (CONPLA-CBR), Journal f Computing in Civil Engineering 21(6), pp. 410-22. http://dx.doi.org/10.1061/(ASCE)0887-3801(2007)21:6(410) [9] Aamodt, A., Plaza, E., 1994. Case-based reasoning: foundational issues, methodological variations, and System Approaches, AI Communications 7(1), pp. 39-59. [10] Kolodner, J. L., 1992. An introduction to case-based reasoning, Artificial Intelligence Review 6(1), pp. 3-34. http://dx.d i.or /10.1007/BF00155578 [11] Gabbay, D. M., Woods, J., 2006. Advice in Abductive Logic, Logic Journal of the IGPL 14(2), pp. 189-219. [12] Graham, D., Smith, S., 2004. Estimating the productivity of cyclic construction operations using case-based reasoning, Advanced Engineering Informatics 18(1), pp. 17\u00e2\u20ac\u201c28. http://dx.doi.org/10.1016/j.aei.2004.03.001 [13] Dunlop, P., Smith, S., 2003. Estimating key characteristics of the concrete delivery and placement process using linear regression a alysis, Civil Engineering and Enviromental Systems 20(4), pp. 273-29. http://dx.doi.org/10.1080/1028660031000091599 [14] Jaskowski, P., Czarnigowska, A., Tokarski, Z., Sobotka, A., 2013. Simulation for selection road works equipment, Baltic Journal of Road and Bridge Engineering [in Press]. [15] Zavadskas, E. K., Turskis, Z., 2011. Multiple criteria decision making (MCDM) methods in economics: an overview, Technological and Economic Development of Economy 17(2), pp. 397-427. http://dx.doi.org/10.3846/20294913.2011.593291 [16] Zavadskas, E. K., Turskis, Z., Tamosaitiene, J., 2011. Selection of construction enterprises management strategy based on the SWOT and multi- criteria analysis, Archives of Civil and Mechanical Engineering 11(4), pp. 1063-1082. http://dx.doi.org/10.1016/S1644-9665(12)60096-X [17] Jaskowski, P., Sobotka, A., 2006. Scheduling construction projects using evolutionary algorithm, Journal of Construction Engineering and Management 132(8), pp. 861-870. http://dx.doi.org/10.1061/(ASCE)0733-9364(2006)132:8(861) [18] Slowik, M., 2012. Modelling of the inverse creep of road bitumen modified with SBS copolymer, Baltic Journal of Road and Bridg Engineering 7(1), pp. 68-75. http://dx.doi.org/10.3846/bjrbe.2012.10 [19] Ustinovichius, L., Rasiulis, R., Ignatavi\u00c4\ufffdius, C., Vilutien, T. 2012. Analysis of waterproofing defects and technology development for car parking roofs: Lithuanian case, Journal of Civil Engineering and Management 18(4), pp. 519-529. http://dx.doi.org/10.3846/13923730.2012.701231 [20] Yau, N., Yang, J., 1998. Case-based reasoning in construction management, Computer-Aided Civil and Infrastructure Engineering 13(2), pp. 143-150. http://dx.doi.org/10.1111/0885-9507.00094 [21] Sun, Z., Finnie, G., Weber, K., 2005. Abductive case based reasoning, International Journal of Intelligent Systems, 20(9), pp. 957- 983.http://dx.doi.org/10.1002/int.20101 . Estimating time performance for building construction projects in Vietnam, KSCE Journal of Civil Engineering 17(1), pp. 1-8. http://dx.doi.org/10.1007/s12205-013-0862-3 [3] Kaplinski, O., Janusz, L., 2006. Three phases of multifactor modelling of construction processes, Journal of Civil Engineering a d Management 12(2), pp. 127-134. [4] Gajzler, M., 2011. Neural networks in the advisory system for repairs of industrial concrete floors, Compu r Assisted Mecha ics and Engin ering Sciences 18(4), pp. 255-263. [5] Liu, X., Wang, Z., Jin, D., 2011. Risk evaluation of cost for hydropower construction under risk fixed schedule probabilityusing monte carlo simulation method, Technics Technologies Education Management 6(2), pp. 287-299. [6] Arditi, D., Tokdemir, O. B., 1999. Using case-based reasoning to predict the outcome of construction litigation, C mputer-Aided Civil and Infrastructure Engineering 14(6), pp. 385-393. [7] Dogan, S., Arditi, D., Murat Gunaydin, H., 2006. Determining attribute weights in a CBR model for early cost prediction of structu al systems, Journal of Construction Engineering and Management 132(10), pp. 1092-1098. [8] Ryu, H., Lee, H., Park, M., 2007. Construction planning method using case-based reasoning (CONPLA-CBR), Journal f Computing in Civil Engineering 21(6), pp. 410-22. http://dx.doi.org/10.1061/(ASCE)0887-3801(2007)21:6(410) [9] Aamodt, A., Plaza, E., 1994. Case-based reasoning: foundational issues, methodological variations, and System Approaches, AI Communications 7(1), pp. 39-59. [10] Kolodner, J. L., 1992. An introduction to case-based reasoning, Artificial Intelligence Review 6(1), pp. 3-34. http://dx.d i.or /10.1007/BF00155578 [11] Gabbay, D. M., Woods, J., 2006. Advice in Abductive Logic, Logic Journal of the IGPL 14(2), pp. 189-219. [12] Graham, D., Smith, S., 2004. Estimating the productivity of cyclic construction operations using case-based reasoning, Advanced Engineering Informatics 18(1), pp. 17\u00e2\u20ac\u201c28. http://dx.doi.org/10.1016/j.aei.2004.03.001 [13] Dunlop, P., Smith, S., 2003. Estimating key characteristics of the concrete delivery and placement process using linear regression a alysis, Civil Engineering and Enviromental Systems 20(4), pp. 273-29. http://dx.doi.org/10.1080/1028660031000091599 [14] Jaskowski, P., Czarnigowska, A., Tokarski, Z., Sobotka, A., 2013. Simulation for selection road works equipment, Baltic Journal of Road and Bridge Engineering [in Press]. [15] Zavadskas, E. K., Turskis, Z., 2011. Multiple criteria decision making (MCDM) methods in economics: an overview, Technological and Economic Development of Economy 17(2), pp. 397-427. http://dx.doi.org/10.3846/20294913.2011.59 PROENG 12019 S1877-7058(13)00807-2 10.1016/j.proeng.2013.04.074 The Authors \u2606 Selection and peer-review under responsibility of the Vilnius Gediminas Technical University. Abductive and Deductive Approach in Learning from Examples Method for Technological Decisions Making Konczak Aneta \u204e Paslawski Jerzy Division of Construction Engineering and Management, Institute of Structural Engineernig, Faculty of Civil and Environmental Engineering, Poznan University of Technology, 5, Piotrowo Str., PL-60-965 Poznan, Poland \u204e Corresponding author. One of the fundamental problems in building engineering is to ensure conformance between the planned and the actual course of construction works. What may help solve this problem is a database with examples of performance of similar processes in analogous environmental conditions that enables estimating the basic process parameters (time, cost, quality, etc.). Case-based reasoning in a hybrid advisory system may play an important role between the rule-based reasoning and the machine learning when the data that has been gathered enables inference based on analogies with the completed processes, but their number is still inadequate for application of machine learning. Introduction of the abductive approach is intended to enable a detailed analysis of causes of nonconformances \u2013 a limited number of examples facilitate this. This is an example of cooperation between a human (search for causes based on intuition) and a computer (systematic gathering of examples). The authors also plan to use simulations to verify the abductive hypotheses. In the final part of the article, an example of application of case-based reasoning in the process of delivery of ready-mix concrete is presented. Keywords Hybrid advisory system case-based reasoning simulation abductive approach References [1] Koo, C., Hong, T., Hyun, C., & Koo, K., 2010. A CBR-based hybrid model for predicting a construction duration and cost based on project characteristics in multi-family housing projects, Canadian Journal of Civil Engineering 37(5), pp. 739-752. http://dx.doi.org/10.1139/L10-007. [2] Le-Hoai, L., Young Dai Lee, Y.D., Nguyen, A.T., 2013. Estimating time performance for building construction projects in Vietnam, KSCE Journal of Civil Engineering 17(1), pp. 1-8. http://dx.doi.org/10.1007/s12205-013-0862-3. [3] Kaplinski, O., Janusz, L., 2006. Three phases of multifactor modelling of construction processes, Journal of Civil Engineering and Management 12(2), pp. 127-134. [4] Gajzler, M., 2011. Neural networks in the advisory system for repairs of industrial concrete floors, Computer Assisted Mechanics and Engineering Sciences 18(4), pp. 255-263. [5] Liu, X., Wang, Z., Jin, D., 2011. Risk evaluation of cost for hydropower construction under risk fixed schedule probability using monte carlo simulation method, Technics Technologies Education Management 6(2), pp. 287-299. [6] Arditi, D., Tokdemir, O.B., 1999. Using case-based reasoning to predict the outcome of construction litigation, Computer-Aided Civil and Infrastructure Engineering 14(6), pp. 385-393. [7] Dogan, S., Arditi, D., Murat Gunaydin, H., 2006. Determining attribute weights in a CBR model for early cost prediction of structural systems, Journal of Construction Engineering and Management 132(10), pp. 1092-1098. [8] Ryu, H., Lee, H., Park, M., 2007. Construction planning method using case-based reasoning (CONPLA-CBR), Journal of Computing in Civil Engineering 21(6), pp. 410-22. http://dx.doi.org/10.1061/(ASCE)0887-3801(2007)21:6(410). [9] Aamodt, A., Plaza, E., 1994. Case-based reasoning: foundational issues, methodological variations, and System Approaches, AI Communications 7(1), pp. 39-59. [10] Kolodner, J.L., 1992. An introduction to case-based reasoning, Artificial Intelligence Review 6(1), pp. 3-34. http://dx.doi.org/10.1007/BF00155578. [11] Gabbay, D.M., Woods, J., 2006. Advice in Abductive Logic, Logic Journal of the IGPL 14(2), pp. 189-219. [12] Graham, D., Smith, S., 2004. Estimating the productivity of cyclic construction operations using case-based reasoning, Advanced Engineering Informatics 18(1), pp. 17-28. http://dx.doi.org/10.1016/j.aei.2004.03.001. [13] Dunlop, P., Smith, S., 2003. Estimating key characteristics of the concrete delivery and placement process using linear regression analysis, Civil Engineering and Enviromental Systems 20(4), pp. 273-29. http://dx.doi.org/10.1080/1028660031000091599. [14] Jaskowski, P., Czarnigowska, A., Tokarski, Z., Sobotka, A., 2013. Simulation for selection road works equipment, Baltic Journal of Road and Bridge Engineering [in Press]. [15] Zavadskas, E.K., Turskis, Z., 2011. Multiple criteria decision making (MCDM) methods in economics: an overview, Technological and Economic Development of Economy 17(2), pp. 397-427. http://dx.doi.org/10.3846/20294913.2011.593291. [16] Zavadskas, E.K., Turskis, Z., Tamosaitiene, J., 2011. Selection of construction enterprises management strategy based on the SWOT and multi- criteria analysis, Archives of Civil and Mechanical Engineering 11(4), pp. 1063-1082. http://dx.doi.org/10.1016/S1644-9665(12)60096-X. [17] Jaskowski, P., Sobotka, A., 2006. Scheduling construction projects using evolutionary algorithm, Journal of Construction Engineering and Management 132(8), pp. 861-870. http://dx.doi.org/10.1061/(ASCE)0733-9364(2006)132:8(861). [18] Slowik, M., 2012. Modelling of the inverse creep of road bitumen modified with SBS copolymer, Baltic Journal of Road and Bridge Engineering 7(1), pp. 68-75. http://dx.doi.org/10.3846/bjrbe.2012.10. [19] Ustinovichius, L., Rasiulis, R., Ignatavi\u010dius, C., Vilutien, T. 2012. Analysis of waterproofing defects and technology development for car parking roofs: Lithuanian case, Journal of Civil Engineering and Management 18(4), pp. 519-529. http://dx.doi.org/10.3846/13923730.2012.701231. [20] Yau, N., Yang, J., 1998. Case-based reasoning in construction management, Computer-Aided Civil and Infrastructure Engineering 13(2), pp. 143-150. http://dx.doi.org/10.1111/0885-9507.00094. [21] Sun, Z., Finnie, G., Weber, K., 2005. Abductive case based reasoning, International Journal of Intelligent Systems, 20(9), pp. 957-983.http://dx.doi.org/10.1002/int.20101."
    },
    "10.1016/j.procir.2013.06.036": {
        "Title": "A Systematic Approach on Developing Action-oriented, Competency-based Learning Factories",
        "Date": "2013",
        "Text": "serial JL 282173 291210 291885 31 90 Procedia CIRP PROCEDIACIRP 2013-06-24 2013-06-24 2014-11-04T06:36:18 1-s2.0-S2212827113003053 S2212-8271(13)00305-3 S2212827113003053 10.1016/j.procir.2013.06.036 S300 S300.3 HEAD-AND-TAIL 1-s2.0-S2212827113X00046 2021-10-14T13:14:58.57322Z 0 0 20130101 20131231 2013 2013-06-24T00:00:00Z rawtext articleinfo articletitlenorm authfirstinitialnorm authfirstsurnamenorm cid cids confeditor contenttype copyright crossmark dateloaded dateloadedtxt datesearch datesort dateupdated dco docsubtype doctype doi eid ewtransactionid hubeid indexeddate issn issnnorm itemstage itemtransactionid itemweight oauserlicense openaccess openarchive pg pgfirst pglast pii piinorm pubdateend pubdatestart pubdatetxt pubyr sortorder srctitle srctitlenorm srctype ssids alllist content oa subj suppl tomb vol volfirst volissue volumelist webpdf webpdfpagecount yearnav affil articletitle auth authfirstini authfull authkeywords authlast primabst ref 2212-8271 22128271 false 7 7 C Volume 7 98 580 585 580 585 2013 2013 2013-01-01 2013-12-31 2013 Forty Sixth CIRP Conference on Manufacturing Systems 2013 Pedro F. Cunha article fla Copyright \u00a9 2013 The Authors. Published by Elsevier B.V. ASYSTEMATICAPPROACHDEVELOPINGACTIONORIENTEDCOMPETENCYBASEDLEARNINGFACTORIES TISCH M TISCHX2013X580 TISCHX2013X580X585 TISCHX2013X580XM TISCHX2013X580X585XM Full 2013-07-16T12:28:15Z http://creativecommons.org/licenses/by-nc-nd/3.0/ OA-Window ElsevierWaived 0 item S2212-8271(13)00305-3 S2212827113003053 1-s2.0-S2212827113003053 10.1016/j.procir.2013.06.036 282173 2014-11-04T07:22:29.715003-05:00 2013-01-01 2013-12-31 1-s2.0-S2212827113003053-main.pdf https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S2212827113003053/MAIN/application/pdf/4a9a506325d0e8e2936596c311e8415b/main.pdf https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2212827113003053/MAIN/application/pdf/4a9a506325d0e8e2936596c311e8415b/main.pdf main.pdf pdf true 612070 MAIN 6 1-s2.0-S2212827113003053-main_1.png https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2212827113003053/PREVIEW/image/png/df85ca1f49afeb8e189d8120cceef1a2/main_1.png https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S2212827113003053/PREVIEW/image/png/df85ca1f49afeb8e189d8120cceef1a2/main_1.png main_1.png png 47234 849 656 IMAGE-WEB-PDF 1 2212-8271 2013 The Authors. Published by Elsevier B.V. Selection and peer-review under responsibility of Professor Pedro Filipe do Carmo Cunha doi: 10.1016/j.procir.2013.06.036 Procedia CIRP 7 ( 2013 ) 580 \u00e2\u20ac\u201c 585 Forty Sixth CIRP Conference on Manufacturing Systems 2013 A systematic approach on developing action-oriented, competency- based Learning Factories M. Tisch* a , C. Hertle a , J. Cachay a , E. Abele a , J. Metternich a , R. Tenberg b a Institute of Production Management, Technology and Machine Tools, Petersenstra\u00c3\u0178e 30, 64287 Darmstadt, Germany b Depatment of Technical Teaching and Learning, Alexanderstra\u00c3\u0178e 6, 64283 Darmstadt, Germany * Corresponding author. Tel.: +49-6151-166622; fax: +49-6151-163356. E-mail address: tisch@ptw.tu-darmstadt.de Abstract As a next challenge, in terms of enhancing and training programs are remodeled by the means of a competency-oriented, scientific-founded didactic concept. Therefore, based on a multi-level study on Learning Factories focusing on their design and use, a systematic approach to further develop quasi-real, effective learning environments in the field of manufacturing systems is conceived. As a result competency-oriented Learning uirements can be implemented with the use of fewer input resources and an increased success in applied competencies in real situations. \u00c2\u00a9 2013 The Authors. Published by Elsevier B.V. Selection and/or peer-review under responsibility of Professor Pedro Filipe do Carmo Cunha Keywords: Learning Factory; Competency development; Action-oriented learning; Didactic transformation 1. Introduction as shorter product life cycles and a rising number of product variants, require companies to quickly adapt to an ever more rapidly changing economic, social, and technological framework, in order to not lag behind global competitors [1]. prerequisite for a competitive, future-oriented production since it enables fast problem solving and continuous improvement in the whole production process [2]. Here, the concept of the Learning Factory offers a well suited continuous improvement philosophy is facilitated by as a genuine part of the overall learning concept [3]. To fully exploit the benefits Learning Factories offer, a competency-oriented, scientific-founded approach for the systematic development and configuration of these learning environments is necessary. 2. Learning Factories for competency development Learning Factories pursue an action-oriented approach with participants acquiring competencies through structured self-learning processes in a production-technological learning environment. Learning Factories thereby integrate different teaching methods with the objective of moving the teaching- learning processes closer to real industrial problems. In order to solve such problems, specific Competencies are in general [4]. In view of the dynamics of the market it is important to understand competency development in production as a crucial enabler for continuous improvement and staying competitive. In recent years, quite a number of Learning Factories have been established worldwide which can be differ- entiated into Learning Factories for education, industry, and research [5]. To understand how these existing Learning Factories are configured a further assessment of their features is necessary. For a classification of Learning Factories regarding their potential on Available online at www.sciencedirect.com 2013 The Authors. Published by Elsevier B.V. Selection and peer-review under responsibility of Professor Pedro Filipe do Carmo Cunha Open access under CC BY-NC-ND license. Open access under CC BY-NC-ND license. 581 M. Tisch et al. / Procedia CIRP 7 ( 2013 ) 580 \u00e2\u20ac\u201c 585 changeability, reference is made to the study of Wagner et al. [6]. Herein, the changeability of Learning Factories has been identified as an important design requirement in order to address a large variety of potential problems. More features of Learning Factories are covered in the survey conducted within the European Initiative on Learning Factories. This survey has addressed ten universities, all being members of the initiative, with the aim on creating a typology of existing Learning Factories (see Fig. 1). Fig. 1: Learning Factory Typology The typology maps a variety of features that combine to footprints of particular Learning Factories. The features highlighted red in Fig. 1 can be seen as the characteristic ing Factories as they are used, targeted, and integrated by all of the Learning Factories that have participated in the survey. However, identifying these characteristic features is not sufficient for developing new Learning Factories in a way that enables their full potential. 3. Current problems of Learning Factory design Compared to traditional teaching, Learning Factories have achieved greater application-performance as well as higher degree of action-substantiating knowledge [7,8]. In terms of enhancing the success in competency development four problems of existing Learning Factories need to be dealt with: First, existing Learning Factories were usually designed by technical experts of the simulated environment. For this reason, the resulting settings are strongly focused on the authentic mapping of real factory sceneries, without deriving the applied didactic concepts with a scientific approach to efficiency and effectiveness aspects regarding competency development [9]. Due to missing empirical evidence no statements on the strengths and weaknesses of different teaching-learning arrangements can be made. Accordingly, the integration of educationalists in the development of further Learning Factories is to be aimed in order to analyze, evaluate, validate, and redesign different Learning Factory arrangements [10]. Second, the development of Learning Factories is usually not based on any structured approach. The intuitive, experience based design of Learning Factories leads again and again to new pilot situations with correspondingly large pioneering efforts, and high uncertainty at least initially, the result is a predictable low efficiency of the factory design process [9]. Third, regarding the planning of the Learning Factory hardly a competency-based approach is identified. Here, the media, didactical and technical design of Learning Factories has to be focused on an effective development of intended competencies [11]. Today considerable parts of intuitively designed training modules do not always contribute to the self- act. Last, the transfer of problem-solving procedures and waste elimination from Learning Factories to the real factory is often hampered by an inadequate allocation of staff to certain training modules, due to an often missing target orientation of training management [8]. 4. The Learning Factory Curriculum Guide Learning Factories should not only represent specific issues or problems in manufacturing engineering, but always aim at the ability to act self-organized in complex production environments [12]. So in the long term it is not enough to merely demonstrate state-of-the-art manufacturing environments each Learning Factory must be based on a didactic-technological approach, which supports the development of self-organized acting. The theoretically conceptualized approach of this paper will be referred to as Learning Factory Curriculum Guide (LFC-Guide, see Fig. 2). The LFC-Guide offers a systematic approach to design action-oriented, competency-based Learning Factories, which will be explained in the following sections. Additionally, the inclusion of didactic findings as well as a new target orientation of training management is provided. The basic idea of the LFC-Guide is to provide a Learning Factory design which suits the development of required competencies for a certain target group of trainees. Thus, intended competencies represent a key component in the LFC-Guide (see Figure 2). They are the result of a systematic analysis of organizational and personnel conditions (i.e. purpose, production type, and target group). characteristic features operating organization industry consulting university technical college professional school type of use education / training research further industrial use industrial target groups operational staff engineer manager academic target groups students research staff / post graduated other target groups lean experts / lean specialist other consultants selected industries mechanical and plant industry automotive industry chemical industry electrical industry insurance, banks, etc. product real product arteficial (didactic) product production process machining assembly logistics IT indirect productio n module content process impr. diagnosis system design quality control quality material flow techn. opt. lean transfer integrated departments production distribu- tion pur- chasing ideas mgmt. design / develop- ment prod. planning / control integrated teaching methods presentation demon- stration tutorial web-based training simulation game discussion case study role play experimen- tal game learning cells 582 M. Tisch et al. / Procedia CIRP 7 ( 2013 ) 580 \u00e2\u20ac\u201c 585 Fig. 2: Learning Factory Curriculum Guide On basis of those competencies, both, the educational technological infrastructure of the Learning Factory are derived. In order to complete the Learning Factory design the educational level and the technological infrastructure must be aligned. In summary, the LFC- Guide follows two crucial steps of creating competency- oriented learning systems. First, relevant subject matters with respect to the exemplary, the present and the future importance have to be determined [13]. And more essential, specific competencies defined as learning objectives must be conducted [12]. In the following the focus-setting as well as the content selection of most relevant aspects together with the identification of intended competencies is referred to as 1 st didactic transformation [14]. Second, regarding specific conditions (like technology, participation, and regional specificity), the design of learning systems and suited learning situations in order to develop the intended competencies effectively is implemented. The configuration of a suited Learning Factory by planning instruction, interaction, and media will be referred to as 2 nd didactic transformation [14,15]. 4.1. The first didactic transformation The LFC-Guide enables the focused competency development and facilitates the initial target formation in terms of a complete curriculum: The realization of those learning objectives verbalized as intended competencies must be anticipated, concretized and verified in the first didactic transformation [12]. Learning Factories have been individually designed by different organizations, e.g. producing companies, universities, vocational schools or consultant firms. Each of those operators has fundamentally different requirements for its individual Learning Factory. type of production is directly dependent on th industry. Hereby, the complete range from one-off (e.g. large machine tools production) to high volume (e.g. automotive production) or continuous production (e.g. production of emulsion paint) can be covered. Likewise dependent from the operating organization is the Identified manifestations are professional training, education, and research in production-related topics. In the individual case a detailed target specification is obligatory. The Learning is contingent on the operating organization as well as its purpose. Potential target groups may be students of bachelor and master study programs, consultants as well as professionals and managers of various hierarchy levels. Taking explicitly purpose, and target group in the design process is decisive for exploiting its full potential. Goal of the first didactic transformation is the formulation of intended competencies. Those competencies can be differentiated into four highly interdependent categories: Specialist and methodological competencies, personal competencies, activity- and application-oriented competencies and social- communicative competencies [16]. It is assumed that all four competency categories can be supported in Learning Factories. However, the Learning Factory focus lies in particular on specialist and methodological competencies [9]. are derived from . Assigning specific actions and necessary knowledge to these identified competencies is an important step towards the development of teaching modules. Fig. 3 exemplarily shows such an assignment which can be referred to as competency transformation . Fig. 3: Competency Transformation operating organization purpose target group teaching methods & media intended learning process intended competencies production type manufactured product manufacturing process 1 st didactic transformation 2 nd didactic transformation Compe- tency Sub-competency Correspon- ding action Knowledge base p e r f o r m a w a s t e a n a l y s i s 1.1 to decide whether the waste analysis is useful in a specific situation Decision on application of waste analysis Knowledge about purpose and range of performing waste analysis; Understanding that a waste analysis is the starting point for process optimization 1.2 Participants ability to identify waste Recognition of waste in the analyzed area Definition of waste and the concept of value; Knowledge about the process of waste analysis; Waste reduces the value and contradicts customer requirements; Waste is only identified with on-site visits 1.3 583 M. Tisch et al. / Procedia CIRP 7 ( 2013 ) 580 \u00e2\u20ac\u201c 585 In this manner, the necessary knowledge base can be defined and unnecessary knowledge-elements can be excluded from training modules. Here, the knowledge base consists of technical, process, and conceptual knowledge, which can be action-substantiating knowledge or an action-overarching knowledge base [16]. The competency transformation establishes the basis for the subsequent second didactic transformation. 4.2. The second didactic transformation In the second didactic transformation didactical and methodical reflections have to complement the technological infrastructure of particular Learning Factories. Based on the intended competencies suited teaching methods and specific learning processes have to be anticipated for methodic and medial modeling of the learning environment. In the following the key elements of the second didactic transformation are described in detail before their integration into the LFC-Guide will be discussed. The challenge is to identify the teaching methods, which help developing intended competencies best. This is supported by a classification of methods according to their strengths and weaknesses [17]. Fig. 4 shows the classification of teaching methods in use within the research group. It covers teaching methods like presentation, discussion, case study, demonstration, role play, simulation, etc. following [10,17,18] and thereby creates a morphology of teaching methods. Fig. 4: Morphology of Teaching Methods illustrated When introducing new knowledge to participants of a Learning Factory module, a teaching method setup can be structured in two different ways. One way is by starting off with the theory and then showing problems to the participants, which they can approach with the previously learned. Hence, as an analogy to lean principles . Another way consists of a presentation of the problem to the participants before they know the theory, e.g. methods, on how to address it. With this approach the participants are eager to learn how to solve the presented (ideally real life) problem and therefore pull for the theory needed [3]. Fig. 5 shows the two teaching concepts described above as a course of events during a defined curriculum. Fig. 5: Problem Pull vs. Theory Push [19] To further describe the second didactic transformation applied in the LFC-Guide, the intended learning processes need to be specified. Here, the intended learning processes can be categorized into formal and informal learning processes, which are in opposition, but also complement each other in the Learning Factory concept [20]. Here, informal learning is action-oriented and usually includes problem-solving in an authentic environment. Even though the setting of the Learning Factory itself has more of a formal character, informal learning processes are observed during the hands-on exercises. In the Learning Factory context, the formal learning processes usually contribute a science-oriented, objective part of the program, e.g. during the presentation and explanation of necessary professional and conceptual knowledge. Formal and informal learning complement one another as the utilized teaching methods not only impart knowledge but develop [21]. In order to create authentic project situations in various specific learning settings, the intended learning processes are based on the model of complete action, which describes a closed loop of planning, executing, and evaluating [22]. Cluster Criteria Characteristic i n v o l v e d p e r s o n s degree of instructor- receiver involvement emphasis on instructor instructor- receiver involvement emphasis on receiver role of the instructor lecturer tutor coach mentor l e a r n i n g e n v i r o n m e n t reality relationship of learning environment traditional classroom simulation environment simulated real prod. real factory work relationship of learning work immanent work bound work related spatial relationship of learning environment and workplace separated close to workplace integrated impact regarding the risk of production low risk medium risk high risk p r o c e s s type of learning process external controlled self-controlled transferability low medium high subject matter in given time low medium high r e s o u r c e s time flexibility for performing the teaching methods low medium high time effort for preparation and planning low medium high material resources low medium high spatial resources low medium high staff resources low medium high costs per participant low medium high requirements on instructor low medium high scalability of teaching method low medium high repeatability of teaching method low medium high practical examples for clarification real problem statements in the spotlight problem- solving in real situation teaching of theory problem statement in real situation problem- solving in real situation teaching of theory 584 M. Tisch et al. / Procedia CIRP 7 ( 2013 ) 580 \u00e2\u20ac\u201c 585 Many established Learning Factories have selected their product and corresponding manufacturing processes prior to identifying the competencies they want to build up. In contrary, this paper states the need of utilizing the manufactured product and the manufacturing processes as well as teaching methods and media respectively as a support to develop the intended competencies. As shown in Fig. 2, these elements exist in a complex, mutual dependency. After having described the educational level of the Learning Factory, the following paragraph explains the technological infrastructure. The designated production type has a significant influence on the manufacturing processes to be selected, since those processes strongly affect the authenticity of the created learning environment. The process engineering industry, for example, has different requirements on the manufacturing processes in the Learning Factory than the serial production industry. Thus, in this case the manufacturing processes should preferably map continuous production over single dispatch item production. Additionally the manufacturing processes together with the product should correspond with the teaching methods used in the Learning Factory in conveying the intended competencies. Therefore, as described above, these competencies need to be identified prior to establishing the manufacturing processes and the product in the Learning Factory. Altogether the adjusted design of the technological infrastructure and the educational level represent the second didactic transformation in the LFC-Guide. 5. Research aim and methodology Research aim is the validation of the LFC-Guide. To support its underlying assumptions, a systematic multi- level study with 20 Learning Factories is conducted. The study consists of a triangulation of expert interviews and on-site process observations and reveals relationships within specific fundamental design parameters, e.g. layout, product, and learning targets. This allows linkage to suitable Learning Factory configurations. The semi-structured interviews conducted with personnel of existing Learning Factories in Europe form the first part of the study. The study group consists of Learning Factories operated by universities, companies, dedicated consulting firms, and vocational schools. To draw qualitative conclusions about the technical-didactic approach, an interview questionnaire geared to the structure of the LFC-Guide is created. In the second part of the study, a qualitative empirical survey is conducted, which consists of on-site observations of training courses with industry personnel at selected learning factories by research staff from didactics and production engineering. The investigation of the complex competency development (both specific and multidisciplinary) is accomplished with detailed case-by-case analyses. Furthermore the influence of individual dispositions, such as general and specific professional interests, epistemological beliefs, motivation to learn and perform, and the attitude to study, on the individual learning outcome is examined. Hereby, the specific observation focus is on the complementation of formal and informal learning processes. 6. Results Studies involving European Learning Factories suggest a positive impact on the design process as well as the designed learning system using the structure described and the links suspected in the presented LFC- Guide. In the interviews conducted, the LFC-Guide is considered consistent. The underlying elements of the guide are evaluated by the surveyed experts as a complete, self-contained coverage of all factors influencing the Learning Factory planning and implementation. An industry interviewee identifies the advantage of the LFC- guide explains from a didactic point of view, what elements we need to consider and in which order to plan Overall, from the evaluation of expert interviews and on-site participative observations three main results for designing new Learning Factories along the LFC-Guide can be accentuated: Competency-oriented design of learning targets Consideration of a didactic orientation Integration of heterogeneous target groups in the Learning Factory modules Regarding the competency orientation, all interviewees explicitly point out the building of capacity to act in complex real-world situations as the primary goal of a Learning Factory. This mentions implicitly the importance of the development of competencies to solve complex problems and tasks in the field of manufacturing engineering. Such a disposition for real- life situations can only be achieved with a competency- oriented curriculum. Therefore, learning targets of Learning Factories are aligned accordingly, i.e. the assigned actions as well as the respective corresponding knowledge elements for intended competencies have to be enlisted. The participatory observations in training programs with industry employees demonstrate the importance of considering a didactic orientation in the Learning Factory. In particular by integrating reflection and feedback elements in training modules, it is possible to complete the learning process and thus improve learning 585 M. Tisch et al. / Procedia CIRP 7 ( 2013 ) 580 \u00e2\u20ac\u201c 585 outcomes. The ratio between self and external control of learning processes has to interact with the surrounding teaching-learning arrangement. Neither classroom instruction only nor a fully self-directed learning process promises best results. The didactic-methodological configuration of training programs should always be designed in consideration of efficiency criteria using a combination of teaching methods in order to control the self-learning processes. In most of the surveyed Learning Factories, including the Process Learning Factory CiP, different target groups are so far predominantly trained in homogeneous groups. In the interviews experts agree, however, that the Learning Factory treatment should particularly prepare the cooperation of employees in real workplace situations. Therefore, Learning Factory curriculum modules should consider the design of special programs that are aimed at heterogeneous target groups as a requirement. An interview partner from industry confirms this claim arising from his own practical seek to provide trainings with the entire group. This way we can address Overall, the results support the structure of the LFC- Guide as well as its relationships for configuring a systematic, didactic well-founded and competency- oriented Learning Factory. 7. Conclusion The study described in chapter 5 will be continued and further assesses the LFC-Guide and the associated system Learning Factory in additional quantitative studies. These will be focused on companies that do not have a Learning Factory, yet. Furthermore, the study is planned to be extended to implement the LFC-Guide in setting up a new Learning Factory in an efficient and structured manner. The introduced LFC-Guide offers a new approach for the systematic development of effective and more efficient Learning Factories. It addresses the problems of early adopted Learning Factories, like the missing target orientation or inadequate integration of didactic findings. As a result competency-oriented Learning Factories implemented with the use of fewer input resources and an increased success in applied competencies in real situations. The results drawn off the studies are promising, though they are limited to experimental studies within the Learning Factories, blanking out transfer abilities of participants. However, since Learning Factories are no end in itself, positive outcomes for participants and companies are necessary. Future research should include the processes before and after the Learning Factory configuring and setting it up beforehand as well as the participants applying the taught methods in practice. This way, a continuous improvement of the Learning Factory is enabled. Thus, the participation in a Learning Factory needs to be considered a real treatment. References [1] Abele E, Reinhart G, 2011, Zukunft der Produktion, Carl Hanser, M\u00c3\u00bcnchen. [2] Abele E, Cachay J, Wennemer J, 2011, Kompetenzentwicklung und Mitarbeiterf\u00c3\u00bchrung bei Verbesserungsprozessen in schlanken Produktionssystemen, Industrie Management, GITO, Berlin, 27/4:14 8. [3] Cachay J, Abele E, 2012, Developing Competencies for Continuous Improvement Processes on the Shop Floor through Learning Factories, Procedia CIRP/3:638 43. [4] Erpenbeck J, Rosenstiel L von, 2007, Handbuch Kompetenzmessung, Sch\u00c3\u00a4ffer-Poeschel, Stuttgart. [5] Sihn W, Gerhard D, Bleicher F, Vision and implementation of the Learning and Innovation Factory of the Vienna University of Technology. In: Sihn W. 2nd Conference on Learning Factories - Competitive production in Europe through education and training, 2012, p. 160 77. [6] Wagner U, AlGeddawy T, ElMaraghy H, M\u00c3\u00bcller E, 2012, The State-of-the-Art and Prospects of Learning Factories, Procedia CIRP, 3/0:109 14. [7] Cachay J, Wennemer J, Abele E, Tenberg R, 2012, Study on action-oriented learning with a Learning Factory approach, Procedia - Social and Behavioral Sciences/55:1144 53. [8] Reiner D, 2009, Methode der kompetenzorientierten Transformation zum nachhaltig schlanken Produktionssystem, Shaker, Aachen. [9] Abele E, Bechtloff S, Cachay J, Tenberg R, 2012, Lernfabriken einer neuen Generation, Zeitschrift f\u00c3\u00bcr wirtschaftlichen Fabrikbetrieb (ZWF), 107/3:147 51. [10] Kuper H, Glaab A, Albrecht K, B\u00c3\u00b6ttcher L, 2012, Arbeitsplatznahe Betriebliche Lernformen. Kompendium. [11] Steffen M, May D, Deuse J, The Industrial Engineering Laboratory. In: IEEE. Global Engineering Education Conference (EDUCON), 2012, p. 1 10. [12] Abele E, Tenberg R, Wennemer J, Cachay J, 2010, Kompetenzentwicklung in Lernfabriken f\u00c3\u00bcr die Produktion, Zeitschrift f\u00c3\u00bcr Wirtschaftlichen Fabrikbetrieb ZWF, Carl Hanser Verlag, M\u00c3\u00bcnchen, 105/10:909 913. [13] Klafki W, 1958, Didaktische Analyse als Kern der Unterrichts- vorbereitung, Die Deutsche Schule (DDS), 50/10:450 70. [14] Tenberg R, 2011, Kompetenzorientierung statt Performanz- orientierung, Berufs- und Wirtschaftsp\u00c3\u00a4dagogik online (bwp), 201 17. [15] Kerres M, 2001, Multimediale und telemediale Lernumgebungen, Oldenbourg, M\u00c3\u00bcnchen. [16] Tenberg R, 2011, Vermittlung fachlicher und \u00c3\u00bcberfachlicher Kompetenzen in technischen Berufen, Steiner, Stuttgart. [17] Bonz B, 2009, Methodik, Schneider-Verl. Hohengehren, Baltmannsweiler. [18] Bonz B, 2006, Methoden der schulischen Berufsbildung. In: Arnold R, Lipsmeier A. Handbuch der Berufsbildung. Wiesbaden: VS Verl. f\u00c3\u00bcr Sozialwiss., p. 328 41. [19] Cachay J, Abele E, 2012, Developing Competencies for Continuous Improvement Processes on the Shop Floor through Learning Factories. presentation, Athens, Greece. [20] Eraut M, 2004, Informal learning in the workplace, Studies in Continuing Education, 26/2:247 73. [21] Marsick VJ, Watkins KE, 2001, Informal and Incidental Learning, New Directions for Adult and Continuing Education, 2001/89:25 34. [22] Hacker W, 2005, Allgemeine Arbeitspsychologie, Huber, Bern. t addresses the problems of early adopted Learning Factories, like the missing target orientation or inadequate integration of didactic findings. As a result competency-oriented Learning Factories implemented with the use of fewer input resources and an increased success in applied competencies in real situations. The results drawn off the studies are promising, though they are limited to experimental studies within the Learning Factories, blanking out transfer abilities of participants. However, since Learning Factories are no end in itself, positive outcomes for participants and companies are necessary. Future research should include the processes before and after the Learning Factory configuring and setting it up beforehand as well as the participants applying the taught methods in practice. This way, a continuous improvement of the Learning Factory is enabled. Thus, the participation in a Learning Factory needs to be considered a real treatment. References [1] Abele E, Reinhart G, 2011, Zukunft der Produktion, Carl Hanser, M\u00c3\u00bcnchen. [2] Abele E, Cachay J, Wennemer J, 2011, Kompetenzentwicklung und Mitarbeiterf\u00c3\u00bchrung bei Verbesserungsprozessen in schlanken Produktionssystemen, Industrie Management, GITO, Berlin, 27/4:14 8. [3] Cachay J, Abele E, 2012, Developing Competencies for Continuous Improvement Processes on the Shop Floor through Learning Factories, Procedia CIRP/3:638 43. [4] Erpenbeck J, Rosenstiel L von, 2007, Handbuch Kompetenzmessung, Sch\u00c3\u00a4ffer-Poeschel, Stuttgart. [5] Sihn W, Gerhard D, Bleicher F, Vision and implementation of the Learning and Innovation Factory of the Vienna University of Technology. In: Sihn W. 2nd Conference on Learning Factories - Competitive production in Europe through education and training, 2012, p. 160 77. [6] Wagner U, AlGeddawy T, ElMaraghy H, M\u00c3\u00bcller E, 2012, The State-of-the-Art and Prospects of Learning Factories, Procedia CIRP, 3/0:109 14. [7] Cachay J, Wennemer J, Abele E, Tenberg R, 2012, Study on action-oriented learning with a Learning Factory approach, Procedia - Social and Behavioral Sciences/55:1144 53. [8] Reiner D, 2009, Methode der kompetenzorientierten Transformation zum nachhaltig schlanken Produktionssystem, Shaker, Aachen. [9] Abele E, Bechtloff S, Cachay J, Tenberg R, 2012, Lernfabriken einer neuen Generation, Zeitschrift f\u00c3\u00bcr wirtschaftlichen Fabrikbetrieb (ZWF), 107/3:147 51. [10] Kuper H, Glaab A, Albrecht K, B\u00c3\u00b6ttcher L, 2012, Arbeitsplatznahe Betriebliche Lernformen. Kompendium. [11] Steffen M, May D, Deuse J, The Industrial E PROCIR 563 S2212-8271(13)00305-3 10.1016/j.procir.2013.06.036 The Authors \u2606 Selection and peer-review under responsibility of Professor Pedro Filipe do Carmo Cunha. A Systematic Approach on Developing Action-oriented, Competency-based Learning Factories M. Tisch a \u204e C. Hertle a J. Cachay a E. Abele a J. Metternich a R. Tenberg b a Institute of Production Management, Technology and Machine Tools, Petersenstra\u00dfe 30, 64287 Darmstadt, Germany b Depatment of Technical Teaching and Learning, Alexanderstra\u00dfe 6, 64283 Darmstadt, Germany \u204e Corresponding author. Tel.: +49 6151 166622; fax: +49 6151 163356. As a next challenge, in terms of enhancing employees\u2019 improvement abilities with the use of Learning Factories, existing education and training programs are remodeled by the means of a competency-oriented, scientific-founded didactic concept. Therefore, based on a multi-level study on Learning Factories focusing on their design and use, a systematic approach to further develop quasi-real, effective learning environments in the field of manufacturing systems is conceived. As a result competency-oriented Learning Factories meeting the industries\u2019 requirements can be implemented with the use of fewer input resources and an increased success in applied competencies in real situations. Keywords Learning Factory Competency development Action-oriented learning Didactic transformation References [1] Abele E, Reinhart G, 2011, Zukunft der Produktion, Carl Hanser, M\u00fcnchen. [2] Abele E, Cachay J, Wennemer J, 2011, Kompetenzentwicklung und Mitarbeiterf\u00fchrung bei Verbesserungsprozessen in schlanken Produktionssystemen, Industrie Management, GITO, Berlin, 27/4:14-8. [3] Cachay J, Abele E, 2012, Developing Competencies for Continuous Improvement Processes on the Shop Floor through Learning Factories, Procedia CIRP/3:638-43. [4] Erpenbeck J, Rosenstiel L von, 2007, Handbuch Kompetenzmessung, Sch\u00e4ffer-Poeschel, Stuttgart. [5] Sihn W, Gerhard D, Bleicher F, Vision and implementation of the Learning and Innovation Factory of the Vienna University of Technology. In: Sihn W. 2nd Conference on Learning Factories - Competitive production in Europe through education and training, 2012, p. 160-77. [6] Wagner U, AlGeddawy T, ElMaraghy H, M\u00fcller E, 2012, The State-of-the-Art and Prospects of Learning Factories, Procedia CIRP, 3/0:109-14. [7] Cachay J, Wennemer J, Abele E, Tenberg R, 2012, Study on action-oriented learning with a Learning Factory approach, Procedia - Social and Behavioral Sciences/55:1144-53. [8] Reiner D, 2009, Methode der kompetenzorientierten Transformation zum nachhaltig schlanken Produktionssystem, Shaker, Aachen. [9] Abele E, Bechtloff S, Cachay J, Tenberg R, 2012, Lernfabriken einer neuen Generation, Zeitschrift f\u00fcr wirtschaftlichen Fabrikbetrieb (ZWF), 107/3:147-51. [10] Kuper H, Glaab A, Albrecht K, B\u00f6ttcher L, 2012, Arbeitsplatznahe Betriebliche Lernformen. Kompendium. [11] Steffen M, May D, Deuse J, The Industrial Engineering Laboratory. In: IEEE. Global Engineering Education Conference (EDUCON), 2012, p. 1-10. [12] Abele E, Tenberg R, Wennemer J, Cachay J, 2010, Kompetenzentwicklung in Lernfabriken f\u00fcr die Produktion, Zeitschrift f\u00fcr Wirtschaftlichen Fabrikbetrieb ZWF, Carl Hanser Verlag, M\u00fcnchen, 105/10:909-913. [13] Klafki W, 1958, Didaktische Analyse als Kern der Unterrichts- vorbereitung, Die Deutsche Schule (DDS), 50/10:450-70. [14] Tenberg R, 2011, Kompetenzorientierung statt Performanz- orientierung, Berufs- und Wirtschaftsp\u00e4dagogik online (bwp), 201-17. [15] Kerres M, 2001, Multimediale und telemediale Lernumgebungen, Oldenbourg, M\u00fcnchen. [16] Tenberg R, 2011, Vermittlung fachlicher und \u00fcberfachlicher Kompetenzen in technischen Berufen, Steiner, Stuttgart. [17] Bonz B, 2009, Methodik, Schneider-Verl. Hohengehren, Baltmannsweiler. [18] Bonz B, 2006, Methoden der schulischen Berufsbildung. In: Arnold R, Lipsmeier A. Handbuch der Berufsbildung. Wiesbaden: VS Verl. f\u00fcr Sozialwiss., p. 328-41. [19] Cachay J, Abele E, 2012, Developing Competencies for Continuous Improvement Processes on the Shop Floor through Learning Factories. presentation, Athens, Greece. [20] Eraut M, 2004, Informal learning in the workplace, Studies in Continuing Education, 26/2:247-73. [21] Marsick VJ, Watkins KE, 2001, Informal and Incidental Learning, New Directions for Adult and Continuing Education, 2001/89:25-34. [22] Hacker W, 2005, Allgemeine Arbeitspsychologie, Huber, Bern."
    },
    "10.1016/j.artint.2013.03.001": {
        "Title": "On the consistency of multi-label learning",
        "Date": "June\u2013July 2013",
        "Text": "serial JL 271585 291210 291866 291867 291872 291884 31 Artificial Intelligence ARTIFICIALINTELLIGENCE 2013-04-08 2013-04-08 2013-06-27T11:13:35 1-s2.0-S0004370213000313 S0004-3702(13)00031-3 S0004370213000313 10.1016/j.artint.2013.03.001 S300 S300.1 HEAD-AND-TAIL 1-s2.0-S0004370213X00062 2017-06-15T12:25:22.685473-04:00 0 0 20130601 20130731 2013 2013-04-08T00:00:00Z rawtext articleinfo crossmark dco dateupdated tomb dateloaded datesearch indexeddate volumelist yearnav articletitlenorm authfirstinitialnorm authfirstsurnamenorm cid cids contenttype copyright dateloadedtxt docsubtype doctype doi eid ewtransactionid hubeid issn issnnorm itemstage itemtransactionid itemweight openaccess openarchive pg pgfirst pglast pii piinorm pubdateend pubdatestart pubdatetxt pubyr sortorder srctitle srctitlenorm srctype suppl volfirst volissue webpdf webpdfpagecount mmlmath affil articletitle auth authfirstini authfull authkeywords authlast primabst ref alllist content subj ssids 0004-3702 00043702 true 199 200 199 200 C Volumes 199\u2013200 3 22 44 22 44 201306 201307 June\u2013July 2013 2013-06-01 2013-07-31 2013 article fla Copyright \u00a9 2013 Elsevier B.V. All rights reserved. CONSISTENCYMULTILABELLEARNING GAO W BARTLETT 2006 138 156 P BENDAVID 2012 S PROCEEDINGS29THINTERNATIONALCONFERENCEMACHINELEARNING MINIMIZINGMISCLASSIFICATIONERRORRATEUSINGASURROGATECONVEXLOSS BOUTELL 2004 1757 1771 M BREIMAN 2004 1 11 L BUHLMANN 2003 324 339 P CARNEIRO 2007 394 410 G COSSOCK 2008 5140 5154 D CRAMMER 2001 265 292 K DEKEL 2004 O ADVANCESINNEURALINFORMATIONPROCESSINGSYSTEMS LOGLINEARMODELSFORLABELRANKING DEMBCZYNSKI 2010 279 286 K PROCEEDINGS27THINTERNATIONALCONFERENCEMACHINELEARNING BAYESOPTIMALMULTILABELCLASSIFICATIONVIAPROBABILISTICCLASSIFIERCHAINS DEMBCZYNSKI 2012 1319 1326 K PROCEEDINGS29THINTERNATIONALCONFERENCEMACHINELEARNING CONSISTENTMULTILABELRANKINGTHROUGHUNIVARIATELOSSMINIMIZATION DEMBCZYNSKI 2012 5 45 K DUCHI 2010 327 334 J PROCEEDINGS27THINTERNATIONALCONFERENCEMACHINELEARNING CONSISTENCYRANKINGALGORITHMS ELISSEEFF 2002 681 687 A ADVANCESINNEURALINFORMATIONPROCESSINGSYSTEMS AKERNELMETHODFORMULTILABELLEDCLASSIFICATION FURNKRANZ 2008 133 153 J GAO 2011 341 358 W PROCEEDINGS24THANNUALCONFERENCELEARNINGTHEORY CONSISTENCYMULTILABELLEARNING GHAMRAWI 2005 195 200 N PROCEEDINGS14THACMINTERNATIONALCONFERENCEINFORMATIONKNOWLEDGEMANAGEMENT COLLECTIVEMULTILABELCLASSIFICATION GODBOLE 2004 22 30 S PROCEEDINGS8THPACIFICASIACONFERENCEKNOWLEDGEDISCOVERYDATAMINING DISCRIMINATIVEMETHODSFORMULTILABELEDCLASSIFICATION HARIHARAN 2010 423 430 B PROCEEDINGS27THINTERNATIONALCONFERENCEMACHINELEARNING LARGESCALEMAXMARGINMULTILABELCLASSIFICATIONPRIORS HSU 2009 772 780 D ADVANCESINNEURALINFORMATIONPROCESSINGSYSTEMS MULTILABELPREDICTIONVIACOMPRESSEDSENSING HULLERMEIER 2008 1897 1916 E LIN 2002 259 275 Y MCALLESTER 2011 2205 2212 D ADVANCESINNEURALINFORMATIONPROCESSINGSYSTEMS GENERALIZATIONBOUNDSCONSISTENCYFORLATENTSTRUCTURALPROBITRAMPLOSS PETTERSON 2010 1912 1920 J ADVANCESINNEURALINFORMATIONPROCESSINGSYSTEMS REVERSEMULTILABELLEARNING QI 2007 17 26 G PROCEEDINGS15THACMINTERNATIONALCONFERENCEMULTIMEDIA CORRELATIVEMULTILABELVIDEOANNOTATION ROCKAFELLAR 1997 R CONVEXANALYSIS SCHAPIRE 2000 135 168 R STEINWART 2005 128 142 I TASKAR 2004 B ADVANCESINNEURALINFORMATIONPROCESSINGSYSTEMS MAXMARGINMARKOVNETWORKS TEWARI 2007 1007 1025 A WESTON 1998 J MULTICLASSSUPPORTVECTORMACHINES XIA 2009 2098 2106 F ADVANCESINNEURALINFORMATIONPROCESSINGSYSTEMS TOPKCONSISTENCYLEARNINGRANKMETHODS XIA 2008 1192 1199 F PROCEEDINGS25THINTERNATIONALCONFERENCEMACHINELEARNING LISTWISEAPPROACHLEARNINGRANKTHEORYALGORITHM ZHANG 2006 1338 1351 M ZHANG 2007 2038 2048 M ZHANG 2004 1225 1251 T ZHANG 2004 56 85 T ZHOU 2007 1609 1616 Z ADVANCESINNEURALINFORMATIONPROCESSINGSYSTEMS MULTIINSTANCEMULTILABELLEARNINGAPPLICATIONSCENECLASSIFICATION ZHOU 2012 2291 2320 Z GAOX2013X22 GAOX2013X22X44 GAOX2013X22XW GAOX2013X22X44XW Full 2017-06-15T17:50:27Z OA-Window ElsevierBranded http://www.elsevier.com/open-access/userlicense/1.0/ item S0004-3702(13)00031-3 S0004370213000313 1-s2.0-S0004370213000313 10.1016/j.artint.2013.03.001 271585 2013-06-27T09:51:58.489391-04:00 2013-06-01 2013-07-31 1-s2.0-S0004370213000313-main.pdf https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0004370213000313/MAIN/application/pdf/b5142f31ad8ba634c0d0e2ed572be48d/main.pdf https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0004370213000313/MAIN/application/pdf/b5142f31ad8ba634c0d0e2ed572be48d/main.pdf main.pdf pdf true 385514 MAIN 23 1-s2.0-S0004370213000313-main_1.png https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0004370213000313/PREVIEW/image/png/272e7e82d6d4cf3ffe5a46bf1ee351ea/main_1.png https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0004370213000313/PREVIEW/image/png/272e7e82d6d4cf3ffe5a46bf1ee351ea/main_1.png main_1.png png 50089 849 656 IMAGE-WEB-PDF 1 1-s2.0-S0004370213000313-si1.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0004370213000313/STRIPIN/image/gif/6eb6fae3db9d9e42436c806cda6c71cb/si1.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0004370213000313/STRIPIN/image/gif/6eb6fae3db9d9e42436c806cda6c71cb/si1.gif si1 si1.gif gif 165 10 30 ALTIMG Artificial Intelligence 199\u00e2\u20ac\u201c200 (2013) 22\u00e2\u20ac\u201c44 O W Na a Ar Re Re Ac Av Ke M M Su Ba Ra Ha 1. bi ta to m ge m th m pr an di * 00 htContents lists available at SciVerse ScienceDirect Artificial Intelligence www.elsevier.com/locate/artint n the consistency of multi-label learning ei Gao, Zhi-Hua Zhou \u00e2\u02c6\u2014 tional Key Laboratory for Novel Software Technology, Nanjing University, Nanjing 210023, China rticle info abstract ticle history: ceived 9 July 2012 ceived in revised form 17 March 2013 cepted 29 March 2013 ailable online 8 April 2013 ywords: achine learning ulti-label learning rrogate loss yes consistency nking loss mming loss Multi-label learning has attracted much attention during the past few years. Many multi- label approaches have been developed, mostly working with surrogate loss functions because multi-label loss functions are usually difficult to optimize directly owing to their non-convexity and discontinuity. These approaches are effective empirically, however, little effort has been devoted to the understanding of their consistency, i.e., the convergence of the risk of learned functions to the Bayes risk. In this paper, we present a theoretical analysis on this important issue. We first prove a necessary and sufficient condition for the consistency of multi-label learning based on surrogate loss functions. Then, we study the consistency of two well-known multi-label loss functions, i.e., ranking loss and hamming loss. For ranking loss, our results disclose that, surprisingly, none of convex surrogate loss is consistent; we present the partial ranking loss, with which some surrogate losses are proven to be consistent. We also discuss on the consistency of univariate surrogate losses. For hamming loss, we show that two multi-label learning methods, i.e., one-vs-all and pairwise comparison, which can be regarded as direct extensions from multi-class learning, are inconsistent in general cases yet consistent under the dominating setting,andsimilar results also hold for some recent multi-label approaches that are variations of one-vs-all. In addition, we discuss on the consistency of learning approaches that address multi-label learning by decomposing into a set of binary classification problems. \u00ef\u203a\u2122 2013 Elsevier B.V. All rights reserved. Introduction In traditional classification tasks, each instance is associated with a single label in a number of candidate labels, e.g., nary classification and multi-class learning. In real tasks, however, one object is usually relevant to a set of labels simul- neously. For example, in text categorization, a document about national education service may cover several predefined pics, such as government and education, indicating the content in the document [27]; in bioinformatics, a gene sequence ay be relevant to multiple functions, such as metabolism, transcription and protein synthesis, showing the functions of the ne within a cell\u00e2\u20ac\u2122s life circle [14]; in image annotation, an image may be annotated with a set of words, such as trees and ountains [6,25]. To tackle such problems, multi-label learning has been explored, and it has attracted much attention during e past decade [10,12,14,20,21,24,27,35,38,39]. In multi-label learning, many loss functions (also called evaluation criteria) have been utilized to measure the perfor- ance of learning algorithms, e.g., ranking loss, hamming loss, one-error, coverage and average precision [27,34]; accuracy, ecision, recall and F 1 [18,25]; subset accuracy [17]; etc. It is noteworthy that all of them are non-convex and discontinuous, d directly optimizing such losses often leads to NP-hard problems. To make a compromise for avoiding computational fficulties, surrogate losses that can be optimized more efficiently are usually adopted in practical algorithms, e.g., boosting Corresponding author. E-mail address: zhouzh@nju.edu.cn (Z.-H. Zhou).04-3702/$ \u00e2\u20ac\u201c see front matter \u00ef\u203a\u2122 2013 Elsevier B.V. All rights reserved. tp://dx.doi.org/10.1016/j.artint.2013.03.001 al th effi ti pr 1.1 fu ha lo co pa re se on pr 1. ri ac co st in m an pr da le (i ha se si Se w pr su se ac ra la by 1. an an 2. as laW. Gao, Z.-H. Zhou / Artificial Intelligence 199\u00e2\u20ac\u201c200 (2013) 22\u00e2\u20ac\u201c44 23 gorithm AdaBoost.MH [27],neuralnetworkalgorithmBP-MLL[34], SVM-style algorithms [14,19,29], etc. Essentially, all ese algorithms try to optimize some convex surrogate losses such as the exponential loss and hinge loss. Despite of their cient computation, there remains an important theoretical problem: Whether the expected risks of the learned func- ons converge to the Bayes risk? Or in other words, how about their consistency (also called Bayes consistency)? This paper esents a theoretical study on this important issue. . Our contr ibut ions We first prove a necessary and sufficient condition for the consistency of multi-label learning based on surrogate loss nctions. Based on this result, we examine the consistency of two well-known multi-label loss functions: ranking loss and mming loss. For ranking loss, our results disclose that none of convex surrogate loss is consistent. So, we present the partial ranking ss, with which some surrogate functions, e.g., regularized linear loss and sigmoid-type losses used for neural network, are nsistent. We also study the consistency of univariate surrogate loss, and identify a class of consistent univariate losses for rtial ranking loss, generalizing the recent results of Dembczyn\u00c2\u00b4ski et al. [11]. For hamming loss, we show that two multi-label learning methods, i.e., one-vs-all and pairwise comparison that can be garded as direct extensions from multi-class learning, are inconsistent in general cases yet consistent under the dominating tting, and similar results also hold for some recent multi-label approaches that are variations of one-vs-all. We also discuss the consistency of learning approaches that address multi-label learning by decomposing into a set of binary classification oblems. 2. Related work Consistency guarantees that optimizing a surrogate loss function will yield ultimately an optimal function with Bayes sk for the true loss function, and thus proceed in the scope of computationally efficient algorithms. Nowadays, it is well- cepted that a good learner should at least be consistent with large samples. B\u00c3\u00bchlmann and Yu [5] discussed on the nsistency of boosting algorithms with respect to least square loss, and Breiman [4] studied the convergence of arcing- yle greedy boosting algorithms to the Bayes classifier. The consistency theory on support vector machines was developed [22,28]. The most influential and fundamental work [1,37] investigated the consistency for binary classification, in which any popular algorithms (e.g., boosting, logistic regression and SVMs) are proven to be consistent. In addition, McAllester d Keshet [23] studied the consistency for latent structural probit and ramp loss. For multi-class learning, the consistent theory has been well-studied in [30,36] and many SVM-type algorithms are oven to be inconsistent. Note that multi-class learning is very different from multi-label learning. Given a set of candi- te labels, multi-class learning assumes that there is only one label which is correct for an instance, whereas multi-label arning accepts the fact that more labels can be correct and is more challenging. For multi-class learning, the 0/1loss .e., accuracy) is naturally the fundamental criterion, whereas for multi-label learning there are many criteria, among which mming loss is mostly related with accuracy. As will be shown in Section 5.1, decomposing multi-label learning into a ries of multi-class learning problems to solve, either by one-vs-all or pairwise comparison, is inconsistent. It is also pos- ble to decompose multi-label learning into a series of independent binary classification problems to solve, as studied in ction 5.3; such approach completely neglects the interaction between labels (also called label correlations) and could not ork well with a large number of labels and/or some labels lacking sufficient training data, and thus rarely adopted in actice. Much work has been devoted to the analysis of consistency for ranking problems under different learning settings, e.g., bset ranking [7], listwise ranking [33],top-k ranking [32], etc. Duchi et al. [13] studied the consistency of general ranking tting where each \u00e2\u20ac\u0153instance\u00e2\u20ac\ufffd consists of a query, a set of inputs and a weighted graph, and the goal is to order the inputs cording to the weighted graph. From some sense, multi-label learning contains some behaviors of ranking: It tends to nk relevant labels higher than irrelevant ones. However, multi-label learning requires to estimate the number of relevant bels and is more challenging than a pure ranking. Thus, some results in Section 4.1 may seem similar to those obtained Duchi et al. [13] but most are very different. 3. Organization The rest of this paper is organized as follows. Section 2 introduces some preliminaries. Section 3 presents a necessary d sufficient condition for the consistency of multi-label approaches. Sections 4 and 5 study the consistency of ranking loss d hamming loss, respectively. Section 6 presents the detailed proofs of lemmas. Section 7 concludes with future work. Preliminaries Let X be an instance space and L ={\u00ce\u00bb 1 ,\u00ce\u00bb 2 ,...,\u00ce\u00bb q } denotes a finite set of candidate labels. An instance x \u00e2\u02c6\u02c6 X is sociated with a subset of labels y \u00e2\u0160\u2020L which are called relevant labels, whereas the complement L\\ y are called irrelevantbels. For convenience, we represent the labels as a binary vector y = (y 1 , y 2 ,...,y q ) where y i =+1ifthelabel\u00ce\u00bb i is 24 re r co fo sa dr w le w tio fo i.e th w th w di De De si w It W anW. Gao, Z.-H. Zhou / Artificial Intelligence 199\u00e2\u20ac\u201c200 (2013) 22\u00e2\u20ac\u201c44 levant to x and \u00e2\u02c6\u20191 otherwise, and we further denote by Y ={+1,\u00e2\u02c6\u20191} q the set of all possible labels. For a real number r, denotes the largest integer which is no more than r. Let D denote an (unknown) underlying distribution over X \u00c3\u2014 Y . For an instance x \u00e2\u02c6\u02c6 X ,wedenotebyp(x) avectorof nditional probability over y \u00e2\u02c6\u02c6 Y , i.e., p(x)= ( p y (x) ) y\u00e2\u02c6\u02c6Y = ( Pr(y|x) ) y\u00e2\u02c6\u02c6Y , r some p(x) \u00e2\u02c6\u02c6\u00ce\u203a, where \u00ce\u203a denotes the flat simplex of R |Y| ,thatis, \u00ce\u203a= { p \u00e2\u02c6\u02c6R |Y| : \u00e2\u02c6\u2018 y\u00e2\u02c6\u02c6Y p y =1andp y 0 } . The formal description of multi-label learning in the probabilistic setting is given as follows. We are given a training mple S = { (x 1 , y 1 ), (x 2 , y 2 ),...,(x m , y m ) } awn independently and identically (i.i.d.) according to distribution D, and the objective is to learn a function h :X \u00e2\u2020\u2019 Y , hich is able to assign a set of labels to unseen instances. In general, it is not easy to learn h directly, and one instead arns a real-valued vector function f = ( f 1 , f 2 ,..., f K ) :X \u00e2\u2020\u2019R K for some integer K > 0, here K = q or K = 2 q are common choices for the design of practical algorithms. Based on this vector function f ,apredic- n function F : R K \u00e2\u2020\u2019 Y can be attained for assigning the set of relevant labels to an instance. Another popular approach r multi-label learning is to learn a real-valued vector function f = ( f 1 , f 2 ,..., f q ) s.t. f i (x)> f j (x) if y i =+1, y j =\u00e2\u02c6\u20191, ., rank relevant labels higher than irrelevant ones for example (x, y), and then, a function should be learned to determine e number of relevant labels. Essentially, multi-label approaches try to minimize the expected risk of f with respect to some loss L, i.e., R( f )= E (x,y)\u00e2\u02c6\u00bcD [ L ( f (x), y )] , (1) here f may be a prediction function or a vector of real-valued functions according to different losses. We further denote e minimal risk (also called the Bayes risk) by R \u00e2\u02c6\u2014 = inf f R( f ), here the infimum takes over all measurable functions. Throughout this paper, we mainly focus on below-bounded and stinguishable loss functions defined as follows: finition 1. A loss function L is said to be below-bounded if L(\u00c2\u00b7, \u00c2\u00b7) B for some constant B . finition 2. A loss function L is said to be distinguishable if for some \u00ce\u00b3 > 0, for every x, x \u00e2\u20ac\u00b2 \u00e2\u02c6\u02c6X and y, y \u00e2\u20ac\u00b2 \u00e2\u02c6\u02c6 Y , it holds that L ( f (x), y ) = L ( f ( x \u00e2\u20ac\u00b2 ) , y \u00e2\u20ac\u00b2 ) or \u00e2\u02c6\u00a3 \u00e2\u02c6\u00a3 L ( f (x), y ) \u00e2\u02c6\u2019 L ( f ( x \u00e2\u20ac\u00b2 ) , y \u00e2\u20ac\u00b2 )\u00e2\u02c6\u00a3 \u00e2\u02c6\u00a3 \u00ce\u00b3 . Many loss functions are below-bounded and distinguishable, e.g., ranking loss, hamming loss, one-error, average preci- on, etc., and we will study ranking loss and hamming loss in Sections 4 and 5, respectively. For notational simplicity, we will suppress dependence of p(x) and f (x) on the instance x as p and f , respectively, hen it is clear from the context. For an instance x \u00e2\u02c6\u02c6X , we define the conditional risk of f as l(p, f )= \u00e2\u02c6\u2018 y\u00e2\u02c6\u02c6Y p y L( f , y)= \u00e2\u02c6\u2018 y\u00e2\u02c6\u02c6Y Pr(y|x)L ( f (x), y ) . (2) is easy to get the expected risk and the Bayes risk, respectively, as R( f )= E x [ l(p, f ) ] and R \u00e2\u02c6\u2014 = E x [ inf f [ l(p, f ) ] ] . e further define the set of Bayes predictions as A(p)= { f : l(p, f )= inf f \u00e2\u20ac\u00b2 l ( p, f \u00e2\u20ac\u00b2 ) } ,d it is clear A(p) = \u00e2\u02c6\u2026 as L is distinguishable and below-bounded. mop co Si It 3. co co D la of Th pr Le Le th Pr It co Th in onW. Gao, Z.-H. Zhou / Artificial Intelligence 199\u00e2\u20ac\u201c200 (2013) 22\u00e2\u20ac\u201c44 25 Many multi-label loss functions L, as mentioned in Section 1, have been explored to measure the performance of ulti-label learning algorithms, whereas it is noteworthy that all of them are non-convex and discontinuous, and directly timizing such loss functions often yields NP-hard problems. Therefore, a feasible solution in practice is to consider a nvex surrogate loss \u00ce\u00a8 in place of L.Wedefinethe\u00ce\u00a8 -risk and Bayes \u00ce\u00a8 -risk of f , respectively, as R \u00ce\u00a8 ( f )= E (x,y)\u00e2\u02c6\u00bcD [ \u00ce\u00a8 ( f (x), y )] and R \u00e2\u02c6\u2014 \u00ce\u00a8 = inf f R \u00ce\u00a8 ( f ). milarly, we define the conditional surrogate risk of f and the conditional Bayes surrogate risk, respectively, as W (p, f )= \u00e2\u02c6\u2018 y\u00e2\u02c6\u02c6Y p y \u00ce\u00a8(f , y) and W \u00e2\u02c6\u2014 (p)= inf f W (p, f ). is obvious that R \u00ce\u00a8 ( f )= E x [ W (p, f ) ] and R \u00e2\u02c6\u2014 \u00ce\u00a8 = E x [ W \u00e2\u02c6\u2014 (p) ] . Multi-label consistency Many notions of consistency have been introduced in the literature, e.g., the Fisher consistency [22], infinite-sample nsistency [36], classification calibration [1,30], edge-consistency [13], etc. In this paper, we introduce the multi-label nsistency as follows: efinition 3. Given a below-bounded surrogate loss \u00ce\u00a8 where \u00ce\u00a8(\u00c2\u00b7, y) is continuous for every y \u00e2\u02c6\u02c6 Y , \u00ce\u00a8 is said to be multi- bel consistent w.r.t. the loss L if it holds, for every p \u00e2\u02c6\u02c6\u00ce\u203a, that W \u00e2\u02c6\u2014 (p)<inf f { W (p, f ): f /\u00e2\u02c6\u02c6A(p) } . The following theorem states that the multi-label consistency is a necessary and sufficient condition for the convergence \u00ce\u00a8 -risk to the Bayes \u00ce\u00a8 -risk, implying R( f )\u00e2\u2020\u2019 R \u00e2\u02c6\u2014 . eorem 4. The surrogate loss \u00ce\u00a8 is multi-label consistent w.r.t. the loss L if and only if it holds for any sequence { f n } n 1 that if R \u00ce\u00a8 ( f n )\u00e2\u2020\u2019R \u00e2\u02c6\u2014 \u00ce\u00a8 then R( f n )\u00e2\u2020\u2019 R \u00e2\u02c6\u2014 . The proof is inspired by the techniques of Zhang [36], Tewari and Bartlett [30]. We begin with two useful lemmas, whose oofs are deferred to Sections 6.1 and 6.2, respectively. mma 5. W \u00e2\u02c6\u2014 (p) is continuous on \u00ce\u203a. mma 6. If the surrogate loss function \u00ce\u00a8 is multi-label consistent w.r.t. loss function L, then for any > 0, there exists \u00ce\u00b4>0 such at, for every p \u00e2\u02c6\u02c6\u00ce\u203a, if l(p, f )\u00e2\u02c6\u2019 inf f \u00e2\u20ac\u00b2 l ( p, f \u00e2\u20ac\u00b2 ) then W (p, f )\u00e2\u02c6\u2019W \u00e2\u02c6\u2014 (p) \u00ce\u00b4. oof of Theorem 4. (\u00e2\u20ac\u0153\u00e2\u2021\u2019\u00e2\u20ac\ufffd) We first introduce a new notation H( )= inf p\u00e2\u02c6\u02c6\u00ce\u203a, f { W (p, f )\u00e2\u02c6\u2019 inf f \u00e2\u20ac\u00b2 W ( p, f \u00e2\u20ac\u00b2 ) : l(p, f )\u00e2\u02c6\u2019 inf f \u00e2\u20ac\u00b2 l ( p, f \u00e2\u20ac\u00b2 ) } . is obvious that H(0)= 0 and H( )>0for > 0 from Lemma 6. Corollary 26 of Zhang [36] guarantees the existence of a ncave function \u00ce\u00b7 on [0,\u00e2\u02c6\u017e] such that \u00ce\u00b7(0)= 0 and \u00ce\u00b7( )\u00e2\u2020\u20190as \u00e2\u2020\u2019 0 and R( f )\u00e2\u02c6\u2019 R \u00e2\u02c6\u2014 \u00ce\u00b7 ( R \u00ce\u00a8 ( f )\u00e2\u02c6\u2019 R \u00e2\u02c6\u2014 \u00ce\u00a8 ) . us, if R \u00ce\u00a8 ( f )\u00e2\u2020\u2019 R \u00e2\u02c6\u2014 \u00ce\u00a8 then R( f )\u00e2\u2020\u2019 R \u00e2\u02c6\u2014 . (\u00e2\u20ac\u0153\u00e2\u2021\ufffd\u00e2\u20ac\ufffd) We proceed by contradiction. Suppose \u00ce\u00a8 is not multi-label consistent, and thus there exists some p s.t. W \u00e2\u02c6\u2014 (p)= f f {W (p, f ): f /\u00e2\u02c6\u02c6A(p)}.Let f (n) /\u00e2\u02c6\u02c6A(p) be a sequence s.t. W (p, f (n) )\u00e2\u2020\u2019W \u00e2\u02c6\u2014 (p). For simplicity, we consider X ={x}, i.e., ly one instance, and set f n (x)= f (n) . Then,R \u00ce\u00a8 ( f n )=W ( p, f (n) ) \u00e2\u2020\u2019W \u00e2\u02c6\u2014 (p)= R \u00e2\u02c6\u2014 \u00ce\u00a8 , 26 yi w as R( th lo 4. f w w In bo H of is la W fo Le 2 3 4W. Gao, Z.-H. Zhou / Artificial Intelligence 199\u00e2\u20ac\u201c200 (2013) 22\u00e2\u20ac\u201c44 elding l(p, f (n) )\u00e2\u2020\u2019 inf f l(p, f ), whereas it is contrary to l ( p, f (n) ) inf f l(p, f )+ \u00ce\u00b3 (p), here \u00ce\u00b3 (p)= inf f /\u00e2\u02c6\u02c6A(p) l(p, f )\u00e2\u02c6\u2019 inf f l(p, f )>0, because f (n) /\u00e2\u02c6\u02c6A(p) and L is distinguishable. Thus, this theorem follows desired. Owing to the non-convexity and discontinuity of multi-label loss L, there may exist many solutions minimizing the risk h), and the set of Bayes predictions A(p) contains all global optimal solutions. For the surrogate loss \u00ce\u00a8 ,wedenoteby S(p)= { f : W (p, f )=W \u00e2\u02c6\u2014 (p) } e set of all functions which minimize the surrogate loss \u00ce\u00a8 . An intuitive explanation to Theorem 4 is that the surrogate ss \u00ce\u00a8 is multi-label consistent w.r.t. the loss L if and only if S(p)\u00e2\u0160\u2020A(p). Consistency w.r.t. ranking loss The ranking loss concerns about label pairs that are ordered reversely for an instance. For a real-valued ranking function = ( f 1 , f 2 ,..., f q ), the ranking loss is given by L rankloss ( f ,(x, y) ) = a y \u00e2\u02c6\u2018 y i =\u00e2\u02c6\u20191 y j =+1 I [ f i (x) f j (x) ] = a y \u00e2\u02c6\u2018 y i <y j I [ f i (x) f j (x) ] , (3) here a y is a non-negative penalty, and I[\u00c2\u00b7] is the indicator function which returns 1 if the argument is true and 0 other- ise. The most commonly used penalty in multi-label learning is a y = \u00e2\u02c6\u00a3 \u00e2\u02c6\u00a3 { i\u00e2\u02c6\u02c6[q]: y i =\u00e2\u02c6\u20191 }\u00e2\u02c6\u00a3 \u00e2\u02c6\u00a3 \u00e2\u02c6\u20191 \u00c3\u2014 \u00e2\u02c6\u00a3 \u00e2\u02c6\u00a3 { j\u00e2\u02c6\u02c6[q]: y j =+1 }\u00e2\u02c6\u00a3 \u00e2\u02c6\u00a3 \u00e2\u02c6\u20191 . this paper we consider the more general penalty, i.e., non-negative penalty. It is clear that the ranking loss is below- unded from L rankloss ( f ,(x, y)) 0, and it is distinguishable because for each x, x \u00e2\u20ac\u00b2 \u00e2\u02c6\u02c6X and y, y \u00e2\u20ac\u00b2 \u00e2\u02c6\u02c6Y,wehave L rankloss ( f ,(x, y) ) = L rankloss ( f , ( x \u00e2\u20ac\u00b2 , y \u00e2\u20ac\u00b2 )) or \u00e2\u02c6\u00a3 \u00e2\u02c6\u00a3 L rankloss ( f ,(x, y) ) \u00e2\u02c6\u2019 L rankloss ( f , ( x \u00e2\u20ac\u00b2 , y \u00e2\u20ac\u00b2 ))\u00e2\u02c6\u00a3 \u00e2\u02c6\u00a3 \u00ce\u00b3 . ere \u00ce\u00b3 =min y,y \u00e2\u20ac\u00b2 \u00e2\u02c6\u02c6Y,0 i, j q 2 /4 {|ia y \u00e2\u02c6\u2019 ja y \u00e2\u20ac\u00b2 |> 0},becauseEq.(3)yields L rankloss ( f ,(x, y) ) \u00e2\u02c6\u02c6 { ia y , 0 i q 2 /4 } and L rankloss ( f , ( x, y \u00e2\u20ac\u00b2 )) \u00e2\u02c6\u02c6 { ja y \u00e2\u20ac\u00b2 , 0 j q 2 /4 } . After obtaining ranking function f , there are at least two ways to exploit the ranking result to get the actual number labels. The first way [14] is to learn another function which is able to predict the number of labels. Another way [15] to insert a \u00e2\u20ac\u0153calibration\u00e2\u20ac\ufffd label between relevant and irrelevant labels for training examples, and then, after prediction, bels ranked higher than the calibration label will be regarded as relevant ones. More details can be found in Elisseeff and eston [14], F\u00c3\u00bcrnkranz et al. [15]. Before further discussion, we introduce the following notations: = \u00e2\u02c6\u2018 y\u00e2\u02c6\u02c6Y a y p y , \u00e2\u02c6\u2019 i = \u00e2\u02c6\u2018 y:y i =\u00e2\u02c6\u20191 a y p y and i, j = \u00e2\u02c6\u2018 y:y i <y j p y a y , r a given vector p \u00e2\u02c6\u02c6\u00ce\u203a and non-negative vector (a y ) y\u00e2\u02c6\u02c6Y .Itiseasytoget: mma 7. For a vector p \u00e2\u02c6\u02c6\u00ce\u203a and non-negative vector (a y ) y\u00e2\u02c6\u02c6Y , the following properties hold: 1. i,i = 0; . \u00e2\u02c6\u2019 i \u00e2\u02c6\u2019 \u00e2\u02c6\u2019 j = i, j \u00e2\u02c6\u2019 j,i ; . i,k + k, j + j,i = k,i + i, j + j,k ;. i,k k,i if i, j j,i and j,k k, j . Pr Fr th Le Pr By H w \u00cf\u2020 no Th is PrW. Gao, Z.-H. Zhou / Artificial Intelligence 199\u00e2\u20ac\u201c200 (2013) 22\u00e2\u20ac\u201c44 27 oof. Property 1 is immediate from definition, and Property 2 holds from \u00e2\u02c6\u2019 i \u00e2\u02c6\u2019 \u00e2\u02c6\u2019 j = \u00e2\u02c6\u2018 y:y i =y j =\u00e2\u02c6\u20191 a y p y + \u00e2\u02c6\u2018 y:y i <y j a y p y \u00e2\u02c6\u2019 \u00e2\u02c6\u2018 y:y i =y j =\u00e2\u02c6\u20191 a y p y \u00e2\u02c6\u2019 \u00e2\u02c6\u2018 y:y j <y i a y p y . om Property 2, we have \u00e2\u02c6\u2019 i \u00e2\u02c6\u2019 \u00e2\u02c6\u2019 j = i, j \u00e2\u02c6\u2019 j,i \u00e2\u02c6\u2019 j \u00e2\u02c6\u2019 \u00e2\u02c6\u2019 k = j,k \u00e2\u02c6\u2019 k, j \u00e2\u02c6\u2019 k \u00e2\u02c6\u2019 \u00e2\u02c6\u2019 i = k,i \u00e2\u02c6\u2019 i,k ; erefore, Property 3 follows. Property 4 holds from Property 3 directly. Based on this lemma, we get the set of Bayes predictions for ranking loss as follows: mma 8. For every p \u00e2\u02c6\u02c6\u00ce\u203a and non-negative vector (a y ) y\u00e2\u02c6\u02c6Y , the set of Bayes predictions for ranking loss is given by A(p)={f : for all i < j, f i > f j if i, j < j,i ; f i = f j if i, j = j,i ; and f i < f j otherwise}. oof. From the definition of the conditional risk given by Eq. (2), we have l(p, f )= \u00e2\u02c6\u2018 y\u00e2\u02c6\u02c6Y p y L rankloss ( f ,(x, y) ) = \u00e2\u02c6\u2018 y\u00e2\u02c6\u02c6Y p y a y \u00e2\u02c6\u2018 y i <y j I[ f i f j ] = \u00e2\u02c6\u2018 y\u00e2\u02c6\u02c6Y p y a y \u00e2\u02c6\u2018 1 i, j q I[ f i f j ]\u00c2\u00b7I[y i < y j ]. swapping the two sums, we get l(p, f )= \u00e2\u02c6\u2018 1 i, j q I[ f i f j ] \u00e2\u02c6\u2018 y:y i <y j p y a y = \u00e2\u02c6\u2018 1 i, j q I[ f i f j ] i, j = \u00e2\u02c6\u2018 1 i< j q I[ f i f j ] i, j + I[ f i f j ] j,i . ence we complete the proof by combining with Property 4 in Lemma 7. For ranking loss, it is natural to consider the following surrogate loss: \u00ce\u00a8 ( f (x), y ) = a y \u00e2\u02c6\u2018 y i <y j \u00cf\u2020 ( f j (x)\u00e2\u02c6\u2019 f i (x) ) , (4) here \u00cf\u2020 is convex and non-increasing such as the hinge loss \u00cf\u2020(x)= (1\u00e2\u02c6\u2019 x) + in Elisseeff and Weston [14], exponential loss (x)= exp(\u00e2\u02c6\u2019x) in Schapire and Singer [27], Dekel et al. [9], Zhang and Zhou [34], etc. The following theorem discloses that ne of convex surrogate loss is consistent with ranking loss. eorem 9. For any convex function \u00cf\u2020 , the surrogate loss \u00ce\u00a8 ( f (x), y ) = \u00e2\u02c6\u2018 y i <y j a y \u00cf\u2020 ( f j (x)\u00e2\u02c6\u2019 f i (x) ) inconsistent w.r.t. ranking loss. oof. For surrogate loss \u00ce\u00a8 ,wehave W (p, f )= \u00e2\u02c6\u2018 y\u00e2\u02c6\u02c6Y p y \u00ce\u00a8(f , y)= \u00e2\u02c6\u2018 y\u00e2\u02c6\u02c6Y p y a y \u00e2\u02c6\u2018 y i <y j \u00cf\u2020( f j \u00e2\u02c6\u2019 f i ) \u00e2\u02c6\u2018= 1 i< j q \u00cf\u2020( f j \u00e2\u02c6\u2019 f i ) i, j +\u00cf\u2020( f i \u00e2\u02c6\u2019 f j ) j,i . 28 Co y 1 Fr w w in gi to lo m bu w \u00e2\u02c6\u2018 of No m ex 4.1 an Th i.eW. Gao, Z.-H. Zhou / Artificial Intelligence 199\u00e2\u20ac\u201c200 (2013) 22\u00e2\u20ac\u201c44 nsider the probability vector p = (p y ) y\u00e2\u02c6\u02c6Y and penalty vector (a y ) y\u00e2\u02c6\u02c6Y s.t. p y 1 = p y 2 and a y 1 = a y 2 for every y 1 = y 2 , , y 2 \u00e2\u02c6\u02c6Y . This yields that i, j = m,n for every 1 i = j,m = n q, and thus we get W (p, f )= 1,2 \u00e2\u02c6\u2018 1 i< j q \u00cf\u2020( f j \u00e2\u02c6\u2019 f i )+\u00cf\u2020( f i \u00e2\u02c6\u2019 f j ). om the convexity of \u00cf\u2020, minimizing W (p, f ) gives W \u00e2\u02c6\u2014 (p)=W (p, \u00cb\u2020 f )= q(q\u00e2\u02c6\u2019 1)\u00cf\u2020(0) 1,2 , here \u00cb\u2020 f ={ \u00cb\u2020 f : \u00cb\u2020 f 1 = \u00cb\u2020 f 2 =\u00c2\u00b7\u00c2\u00b7\u00c2\u00b7= \u00cb\u2020 f q }. From Lemma 8,wehave \u00cb\u2020 f /\u00e2\u02c6\u02c6A(p), and W \u00e2\u02c6\u2014 (p)= inf f { W (p, f ): f /\u00e2\u02c6\u02c6A(p) } hich show the inconsistency. This theorem follows as desired. Intuitively, Property 4 of Lemma 7 implies that { i, j } defines an order for the label set L={1,2,...,q} by i j if i, j j,i . Notice that, for i j, i, j = j,i is possible. The set of Bayes predictions of a reasonable loss function should clude all functions that are compatible with this order, i.e., f \u00e2\u20ac\u2122s that enable f i f j if i j. In the definition of ranking loss ven by Eq. (3), the same penalty term is applied to f i < f j and f i = f j ; thus, the set of Bayes predictions with respect ranking loss does not include some functions that are compatible with the above order as what enforces by ranking ss is i j or j i if i, j = j,i for the label set L. For an extreme example, i.e., when all i, j \u00e2\u20ac\u2122s are equal for all i = j, inimizing the convex surrogate loss function \u00ce\u00a8 leads to the optimal solution f \u00e2\u02c6\u2014 \u00e2\u02c6\u02c6{f : f 1 = f 2 =\u00c2\u00b7\u00c2\u00b7\u00c2\u00b7= f q }, t f \u00e2\u02c6\u2014 /\u00e2\u02c6\u02c6A(p) (from Lemma 8). So, the same penalty on f i < f j and f i = f j encumbers the multi-label consistency. To overcome the deficiency of ranking loss, we present the partial ranking loss L p-rankloss ( f ,(x, y) ) = a y \u00e2\u02c6\u2018 y i <y j I [ f i (x)> f j (x) ] + 1 2 I [ f i (x)= f j (x) ] , (5) hich has been used for ranking problems. The only difference from ranking loss lies in the use of different penalties for y i <y j I[ f i = f j ], where the ranking loss uses a y whereas the partial ranking loss uses a y /2. With a proof similar to that Lemma 8, we can get the set of Bayes predictions with respect to the partial ranking loss: A(p)={f : for all i < j, f i > f j if i, j < j,i ; f i < f j if i, j > j,i }. (6) w, consider the previous extreme example in Theorem 9, i.e., i, j \u00e2\u20ac\u2122s are equal for all i = j, again. It is easy to see that by inimizing the surrogate loss function \u00ce\u00a8 , the optimal solution f \u00e2\u02c6\u2014 \u00e2\u02c6\u02c6{f : f 1 = f 2 =\u00c2\u00b7\u00c2\u00b7\u00c2\u00b7= f q }\u00e2\u0160\u2020A(p) hibits consistency. . Consistency of surrogate loss of Eq. (4) In this section, we consider the surrogate loss of Eq. (4), i.e., \u00ce\u00a8 ( f (x), y ) = a y \u00e2\u02c6\u2018 y i <y j \u00cf\u2020 ( f j (x)\u00e2\u02c6\u2019 f i (x) ) , d examine its consistency w.r.t. partial ranking loss. We begin with a sufficient condition for consistency as follows: eorem 10. If \u00cf\u2020 :R\u00e2\u2020\u2019R is a differentiable and non-increasing function such that \u00cf\u2020 \u00e2\u20ac\u00b2 (0)<0 and \u00cf\u2020(t)+\u00cf\u2020(\u00e2\u02c6\u2019t)\u00e2\u2030\u00a1 2\u00cf\u2020(0), (7)., \u00cf\u2020(t)+\u00cf\u2020(\u00e2\u02c6\u2019t)= 2\u00cf\u2020(0) for every t \u00e2\u02c6\u02c6R, then the surrogate loss \u00ce\u00a8 of Eq. (4) is consistent w.r.t. partial ranking loss. Pr co Fr w Fr Th w \u00cf\u2020 M Th By wW. Gao, Z.-H. Zhou / Artificial Intelligence 199\u00e2\u20ac\u201c200 (2013) 22\u00e2\u20ac\u201c44 29 oof. For every probability simplex p \u00e2\u02c6\u02c6 \u00ce\u203a and non-negative vector (a y ) y\u00e2\u02c6\u02c6Y , it suffices to prove that f i > f j if i, j < j,i for every f such that W \u00e2\u02c6\u2014 (p) = W (p, f ). Without loss of generality, we will prove that f 1 > f 2 if 1,2 < 2,1 by ntradiction, i.e., assuming f 1 f 2 for some vector f which satisfies W \u00e2\u02c6\u2014 (p)=W (p, f ). For the case f 1 < f 2 , we construct another f \u00e2\u20ac\u00b2 by f \u00e2\u20ac\u00b2 1 = f 2 , f \u00e2\u20ac\u00b2 2 = f 1 and f \u00e2\u20ac\u00b2 k = f k for k = 1,2. om the definition of conditional surrogate risk, we have W (p, f )= \u00e2\u02c6\u2018 1 i< j q \u00cf\u2020( f j \u00e2\u02c6\u2019 f i ) i, j +\u00cf\u2020( f i \u00e2\u02c6\u2019 f j ) j,i , hich yields that W (p, f )\u00e2\u02c6\u2019W ( p, f \u00e2\u20ac\u00b2 ) = ( 1,2 \u00e2\u02c6\u2019 2,1 ) ( \u00cf\u2020( f 2 \u00e2\u02c6\u2019 f 1 )\u00e2\u02c6\u2019\u00cf\u2020( f 1 \u00e2\u02c6\u2019 f 2 ) ) + q \u00e2\u02c6\u2018 i=3 ( 1,i \u00e2\u02c6\u2019 2,i ) ( \u00cf\u2020( f i \u00e2\u02c6\u2019 f 1 )\u00e2\u02c6\u2019\u00cf\u2020( f i \u00e2\u02c6\u2019 f 2 ) ) + q \u00e2\u02c6\u2018 i=3 ( i,1 \u00e2\u02c6\u2019 i,2 ) ( \u00cf\u2020( f 1 \u00e2\u02c6\u2019 f i )\u00e2\u02c6\u2019\u00cf\u2020( f 2 \u00e2\u02c6\u2019 f i ) ) . om Property 4 of Lemma 7,wehave 1,i \u00e2\u02c6\u2019 2,i \u00e2\u02c6\u2019 i,1 + i,2 = 1,2 \u00e2\u02c6\u2019 2,1 . (8) is follows W (p, f )\u00e2\u02c6\u2019W ( p, f \u00e2\u20ac\u00b2 ) = q \u00e2\u02c6\u2018 i=3 ( i,1 \u00e2\u02c6\u2019 i,2 ) ( \u00cf\u2020( f 1 \u00e2\u02c6\u2019 f i )+\u00cf\u2020( f i \u00e2\u02c6\u2019 f 1 )\u00e2\u02c6\u2019\u00cf\u2020( f i \u00e2\u02c6\u2019 f 2 )\u00e2\u02c6\u2019\u00cf\u2020( f 2 \u00e2\u02c6\u2019 f i ) ) + ( 1,2 \u00e2\u02c6\u2019 2,1 ) ( \u00cf\u2020( f 2 \u00e2\u02c6\u2019 f 1 )\u00e2\u02c6\u2019\u00cf\u2020( f 1 \u00e2\u02c6\u2019 f 2 ) ) + ( 1,2 \u00e2\u02c6\u2019 2,1 ) q \u00e2\u02c6\u2018 i=3 ( \u00cf\u2020( f i \u00e2\u02c6\u2019 f 1 )\u00e2\u02c6\u2019\u00cf\u2020( f i \u00e2\u02c6\u2019 f 2 ) ) = ( 1,2 \u00e2\u02c6\u2019 2,1 ) ( \u00cf\u2020( f 2 \u00e2\u02c6\u2019 f 1 )\u00e2\u02c6\u2019\u00cf\u2020( f 1 \u00e2\u02c6\u2019 f 2 ) ) + ( 1,2 \u00e2\u02c6\u2019 2,1 ) q \u00e2\u02c6\u2018 i=3 ( \u00cf\u2020( f i \u00e2\u02c6\u2019 f 1 )\u00e2\u02c6\u2019\u00cf\u2020( f i \u00e2\u02c6\u2019 f 2 ) ) , here the last equality holds from \u00cf\u2020(t) + \u00cf\u2020(\u00e2\u02c6\u2019t) \u00e2\u2030\u00a1 2\u00cf\u2020(0). For non-increasing function \u00cf\u2020 with \u00cf\u2020 \u00e2\u20ac\u00b2 (0)<0, we have \u00cf\u2020(t)< (\u00e2\u02c6\u2019t) for all t > 0, and this yields ( 1,2 \u00e2\u02c6\u2019 2,1 ) ( \u00cf\u2020( f 2 \u00e2\u02c6\u2019 f 1 )\u00e2\u02c6\u2019\u00cf\u2020( f 1 \u00e2\u02c6\u2019 f 2 ) ) > 0. eanwhile, we also have \u00cf\u2020( f i \u00e2\u02c6\u2019 f 1 ) \u00cf\u2020( f i \u00e2\u02c6\u2019 f 2 ), which yields ( 1,2 \u00e2\u02c6\u2019 2,1 ) q \u00e2\u02c6\u2018 i=3 ( \u00cf\u2020( f i \u00e2\u02c6\u2019 f 1 )\u00e2\u02c6\u2019\u00cf\u2020( f i \u00e2\u02c6\u2019 f 2 ) ) 0. us, we prove W (p, f )>W (p, f \u00e2\u20ac\u00b2 ) which is contrary to W (p, f )=W \u00e2\u02c6\u2014 (p). We now consider the case f 1 = f 2 . The subgradient conditions for optimality of \u00e2\u02c6\u201a \u00e2\u02c6\u201a f i W (p, f )=0fori = 1,2give \u00e2\u02c6\u2018 i =1 \u00cf\u2020 \u00e2\u20ac\u00b2 ( f 1 \u00e2\u02c6\u2019 f i ) i,1 = \u00e2\u02c6\u2018 i =1 \u00cf\u2020 \u00e2\u20ac\u00b2 ( f i \u00e2\u02c6\u2019 f 1 ) 1,i , \u00e2\u02c6\u2018 i =2 \u00cf\u2020 \u00e2\u20ac\u00b2 ( f i \u00e2\u02c6\u2019 f 2 ) 2,i = \u00e2\u02c6\u2018 i =2 \u00cf\u2020 \u00e2\u20ac\u00b2 ( f 2 \u00e2\u02c6\u2019 f i ) i,2 . combining Eq. (8), f 1 = f 2 and \u00cf\u2020 \u00e2\u20ac\u00b2 (t)= \u00cf\u2020 \u00e2\u20ac\u00b2 (\u00e2\u02c6\u2019t) from Eq. (7), we have ( 2,1 \u00e2\u02c6\u2019 1,2 ) ( 2\u00cf\u2020 \u00e2\u20ac\u00b2 (0)+ \u00e2\u02c6\u2018 i =1,2 \u00cf\u2020 \u00e2\u20ac\u00b2 ( f 1 \u00e2\u02c6\u2019 f i ) ) = 0, \u00e2\u02c6\u2018hich is contrary to 1,2 < 2,1 and 2\u00cf\u2020 \u00e2\u20ac\u00b2 (0)+ i =1,2 \u00cf\u2020 \u00e2\u20ac\u00b2 ( f 1 \u00e2\u02c6\u2019 f i ) 2\u00cf\u2020 \u00e2\u20ac\u00b2 (0)<0. Thus, we complete the proof. 30 Ba Co 1/ k Du be Th w w ra ra Th Eq Le tio th Pr tiv t \u00e2\u02c6\u02c6 fu In ItW. Gao, Z.-H. Zhou / Artificial Intelligence 199\u00e2\u20ac\u201c200 (2013) 22\u00e2\u20ac\u201c44 The condition \u00cf\u2020(t) + \u00cf\u2020(\u00e2\u02c6\u2019t) \u00e2\u2030\u00a1 2\u00cf\u2020(0) is motivated from linear loss and sigmoid-type losses used for neural networks. sed on this theorem, we can easily get the following consistency for sigmoid-type functions. rollary 11. The surrogate loss \u00ce\u00a8 given by Eq. (4) is consistent w.r.t. partial ranking loss for sigmoid-type loss functions \u00cf\u2020(t) = (1+ exp(t)), \u00cf\u2020(t)=\u00e2\u02c6\u2019arctan(t),etc. It is noteworthy that Theorem 10 cannot be applied directly to \u00cf\u2020(t)=\u00e2\u02c6\u2019ct 2k+1 for some constant c > 0andinteger 0, because it is not below-bounded. This problem, however, can be solved by introducing a regularization term as in chi et al. [13]. Here, the regularization can be used to control the model complexity, and guarantee that the linear loss is low-bounded. With a proof similar to that of Theorem 10,weget: eorem 12. The following surrogate loss is consistent w.r.t. partial ranking loss: \u00ce\u00a8 ( f (x), y ) = \u00e2\u02c6\u2018 y i <y j a y \u00cf\u2020 ( f j (x)\u00e2\u02c6\u2019 f i (x) ) + \u00cf\u201e\u00ce\u00a5 ( f (x) ) , here \u00cf\u201e > 0, \u00cf\u2020(x)=\u00e2\u02c6\u2019cx 2k+1 for some constant c > 0 and integer k 0,and\u00ce\u00a5 is symmetric, that is, \u00ce\u00a5 ( ..., f i (x),..., f j (x),... ) = \u00ce\u00a5 ( ..., f j (x),..., f i (x),... ) . From this theorem, we can easily construct the following convex surrogate loss function: \u00ce\u00a8 ( f (x), y ) = \u00e2\u02c6\u2018 y i <y j \u00e2\u02c6\u2019a y ( f j (x)\u00e2\u02c6\u2019 f i (x) ) + \u00cf\u201e q \u00e2\u02c6\u2018 i=1 f 2 i (x), hich is consistent w.r.t. partial ranking loss. It is worth noting that this does not imply that any convex surrogate loss \u00ce\u00a8 given by Eq. (4) is consistent w.r.t. partial nking loss. In fact, the following theorem proves that, many non-linear surrogate losses are inconsistent w.r.t. partial nking loss. eorem 13. If \u00cf\u2020 : R\u00e2\u2020\u2019 R is a convex, differentiable, non-linear and non-increasing function, then the surrogate loss \u00ce\u00a8 given by . (4) is inconsistent w.r.t. partial ranking loss. Before giving the detailed proof, we first introduce a lemma, whose proof is deferred to Section 6.3. mma 14. Let \u00cf\u2020 : R\u00e2\u2020\u2019 R be a convex, differentiable, non-linear and non-increasing function. For b > a > 0, if the following condi- ns hold: \u00cf\u2020 \u00e2\u20ac\u00b2 (b\u00e2\u02c6\u2019 a)(\u00cf\u2020 \u00e2\u20ac\u00b2 (a)+ \u00cf\u2020 \u00e2\u20ac\u00b2 (b))+ \u00cf\u2020 \u00e2\u20ac\u00b2 (b)\u00cf\u2020 \u00e2\u20ac\u00b2 (\u00e2\u02c6\u2019a) \u00cf\u2020 \u00e2\u20ac\u00b2 (a\u00e2\u02c6\u2019 b)(\u00cf\u2020 \u00e2\u20ac\u00b2 (a)+ \u00cf\u2020 \u00e2\u20ac\u00b2 (b))+ \u00cf\u2020 \u00e2\u20ac\u00b2 (b)\u00cf\u2020 \u00e2\u20ac\u00b2 (a) > 1, (9) 0< \u00cf\u2020 \u00e2\u20ac\u00b2 (\u00e2\u02c6\u2019a) \u00cf\u2020 \u00e2\u20ac\u00b2 (a) \u00cf\u2020 \u00e2\u20ac\u00b2 (\u00e2\u02c6\u2019b) \u00cf\u2020 \u00e2\u20ac\u00b2 (a) < \u00cf\u2020 \u00e2\u20ac\u00b2 (\u00e2\u02c6\u2019b) \u00cf\u2020 \u00e2\u20ac\u00b2 (b) , (10) en there exist some P 1 > P 2 > 0,P 3 > 0 and P 4 > 0 such that P 1 \u00cf\u2020 \u00e2\u20ac\u00b2 (a\u00e2\u02c6\u2019 b)\u00e2\u02c6\u2019 P 2 \u00cf\u2020 \u00e2\u20ac\u00b2 (b\u00e2\u02c6\u2019 a)= P 4 \u00cf\u2020 \u00e2\u20ac\u00b2 (b)\u00e2\u02c6\u2019 P 3 \u00cf\u2020 \u00e2\u20ac\u00b2 (\u00e2\u02c6\u2019b), (11) \u00e2\u02c6\u2019P 1 \u00cf\u2020 \u00e2\u20ac\u00b2 (a)+ P 2 \u00cf\u2020 \u00e2\u20ac\u00b2 (\u00e2\u02c6\u2019a)= P 4 ( \u00cf\u2020 \u00e2\u20ac\u00b2 (a)+ \u00cf\u2020 \u00e2\u20ac\u00b2 (b) ) \u00e2\u02c6\u2019 P 3 ( \u00cf\u2020 \u00e2\u20ac\u00b2 (\u00e2\u02c6\u2019a)+ \u00cf\u2020 \u00e2\u20ac\u00b2 (\u00e2\u02c6\u2019b) ) . (12) oof of Theorem 13. For convex function \u00cf\u2020 we have \u00cf\u2020 \u00e2\u20ac\u00b2 (t 1 ) \u00cf\u2020 \u00e2\u20ac\u00b2 (t 2 ) for every t 1 t 2 from Rockafellar [26], and the deriva- e function \u00cf\u2020 \u00e2\u20ac\u00b2 (t) is continuous for t \u00e2\u02c6\u02c6R if \u00cf\u2020 is differentiable and convex. As \u00cf\u2020 is non-increasing, we have \u00cf\u2020 \u00e2\u20ac\u00b2 (t) 0forall R, and without loss of generality, we assume \u00cf\u2020 \u00e2\u20ac\u00b2 (t)<0. We proceed by contradiction. Assume the surrogate loss \u00ce\u00a8 is consistent with partial ranking loss for some non-linear nction \u00cf\u2020. Then, from the continuity of \u00cf\u2020 \u00e2\u20ac\u00b2 (t), there exists a distinguishable (c,d) for c < d<0or0< c < d, such that \u00cf\u2020 \u00e2\u20ac\u00b2 (t 1 )<\u00cf\u2020 \u00e2\u20ac\u00b2 (t 2 ) for every t 1 < t 2 and t 1 , t 2 \u00e2\u02c6\u02c6 (c,d). the following, we focus on the case 0< c < d, and similar consideration can be made for the case c < d< 0. We first fix a \u00e2\u02c6\u02c6 (c,d) and introduce a new function G(t)= ( \u00cf\u2020 \u00e2\u20ac\u00b2 (t \u00e2\u02c6\u2019 a)\u00e2\u02c6\u2019 \u00cf\u2020 \u00e2\u20ac\u00b2 (a\u00e2\u02c6\u2019 t) )( \u00cf\u2020 \u00e2\u20ac\u00b2 (a)+ \u00cf\u2020 \u00e2\u20ac\u00b2 (t) ) + \u00cf\u2020 \u00e2\u20ac\u00b2 (t) ( \u00cf\u2020 \u00e2\u20ac\u00b2 (\u00e2\u02c6\u2019a)\u00e2\u02c6\u2019 \u00cf\u2020 \u00e2\u20ac\u00b2 (a) ) .is easy to find that G(t) is continuous and Th w M Le (p w In w Le Eq th w Co lo di Th Pr an thW. Gao, Z.-H. Zhou / Artificial Intelligence 199\u00e2\u20ac\u201c200 (2013) 22\u00e2\u20ac\u201c44 31 G(a)= \u00cf\u2020 \u00e2\u20ac\u00b2 (a) ( \u00cf\u2020 \u00e2\u20ac\u00b2 (\u00e2\u02c6\u2019a)\u00e2\u02c6\u2019 \u00cf\u2020 \u00e2\u20ac\u00b2 (a) ) > 0. us, there exists b > a and b \u00e2\u02c6\u02c6 (c,d) such that G(b)= ( \u00cf\u2020 \u00e2\u20ac\u00b2 (b\u00e2\u02c6\u2019 a)\u00e2\u02c6\u2019 \u00cf\u2020 \u00e2\u20ac\u00b2 (a\u00e2\u02c6\u2019 b) )( \u00cf\u2020 \u00e2\u20ac\u00b2 (a)+ \u00cf\u2020 \u00e2\u20ac\u00b2 (b) ) + \u00cf\u2020 \u00e2\u20ac\u00b2 (b) ( \u00cf\u2020 \u00e2\u20ac\u00b2 (\u00e2\u02c6\u2019a)\u00e2\u02c6\u2019 \u00cf\u2020 \u00e2\u20ac\u00b2 (a) ) > 0, hich gives \u00cf\u2020 \u00e2\u20ac\u00b2 (b\u00e2\u02c6\u2019 a)(\u00cf\u2020 \u00e2\u20ac\u00b2 (a)+ \u00cf\u2020 \u00e2\u20ac\u00b2 (b))+ \u00cf\u2020 \u00e2\u20ac\u00b2 (b)\u00cf\u2020 \u00e2\u20ac\u00b2 (\u00e2\u02c6\u2019a) \u00cf\u2020 \u00e2\u20ac\u00b2 (a\u00e2\u02c6\u2019 b)(\u00cf\u2020 \u00e2\u20ac\u00b2 (a)+ \u00cf\u2020 \u00e2\u20ac\u00b2 (b))+ \u00cf\u2020 \u00e2\u20ac\u00b2 (b)\u00cf\u2020 \u00e2\u20ac\u00b2 (a) > 1. (13) oreover, from \u00cf\u2020 \u00e2\u20ac\u00b2 (a)<\u00cf\u2020 \u00e2\u20ac\u00b2 (b)<0 and \u00cf\u2020 \u00e2\u20ac\u00b2 (\u00e2\u02c6\u2019b) \u00cf\u2020 \u00e2\u20ac\u00b2 (\u00e2\u02c6\u2019a)<0, we have 0< \u00cf\u2020 \u00e2\u20ac\u00b2 (\u00e2\u02c6\u2019a) \u00cf\u2020 \u00e2\u20ac\u00b2 (a) \u00cf\u2020 \u00e2\u20ac\u00b2 (\u00e2\u02c6\u2019b) \u00cf\u2020 \u00e2\u20ac\u00b2 (a) < \u00cf\u2020 \u00e2\u20ac\u00b2 (\u00e2\u02c6\u2019b) \u00cf\u2020 \u00e2\u20ac\u00b2 (b) . (14) We consider the following multi-label task with q=3labels: y 1 = (\u00e2\u02c6\u20191,+1,+1), y 2 = (+1,\u00e2\u02c6\u20191,\u00e2\u02c6\u20191), y 3 = (+1,+1,\u00e2\u02c6\u20191), y 4 = (\u00e2\u02c6\u20191,\u00e2\u02c6\u20191,+1). t f = ( f 1 , f 2 , f 3 ) be such that a = f 3 \u00e2\u02c6\u2019 f 1 and b = f 3 \u00e2\u02c6\u2019 f 2 , and thus f 1 > f 2 . For every probability simplex p = y 1 , p y 2 , p y 3 , p y 4 ) \u00e2\u02c6\u02c6\u00ce\u203a and non-negative penalty vector (a y 1 ,a y 2 ,a y 3 ,a y 4 ),wehave W (p, f )= 1,2 \u00cf\u2020( f 2 \u00e2\u02c6\u2019 f 1 )+ 2,1 \u00cf\u2020( f 1 \u00e2\u02c6\u2019 f 2 )+ 1,3 \u00cf\u2020( f 3 \u00e2\u02c6\u2019 f 1 ) + 3,1 \u00cf\u2020( f 1 \u00e2\u02c6\u2019 f 3 )+ 2,3 \u00cf\u2020( f 3 \u00e2\u02c6\u2019 f 2 )+ 3,2 \u00cf\u2020( f 2 \u00e2\u02c6\u2019 f 3 ), here 1,2 = P 1 , 2,1 = P 2 , 1,3 = P 1 + P 4 , 3,1 = P 2 + P 3 , 2,3 = P 4 and 3,2 = P 3 with P i = p y 1 a y 1 for i = 1,2,3,4. the following, we will construct some \u00c2\u00afp and (\u00c2\u00afa 1 , \u00c2\u00afa 2 , \u00c2\u00afa 3 , \u00c2\u00afa 4 ) such that W \u00e2\u02c6\u2014 ( \u00c2\u00afp)=W ( \u00c2\u00afp, f ) and 1,2 > 2,1 . The subgradient conditions for optimality of \u00e2\u02c6\u201aW (p, f ) \u00e2\u02c6\u201a f i =0(i = 1,2,3) give \u00e2\u02c6\u2019P 1 \u00cf\u2020 \u00e2\u20ac\u00b2 (a\u00e2\u02c6\u2019 b)+ P 2 \u00cf\u2020 \u00e2\u20ac\u00b2 (b\u00e2\u02c6\u2019 a)\u00e2\u02c6\u2019 (P 1 + P 4 )\u00cf\u2020 \u00e2\u20ac\u00b2 (a)+ (P 2 + P 3 )\u00cf\u2020 \u00e2\u20ac\u00b2 (\u00e2\u02c6\u2019a)= 0, P 1 \u00cf\u2020 \u00e2\u20ac\u00b2 (a\u00e2\u02c6\u2019 b)\u00e2\u02c6\u2019 P 2 \u00cf\u2020 \u00e2\u20ac\u00b2 (b\u00e2\u02c6\u2019 a)\u00e2\u02c6\u2019 P 4 \u00cf\u2020 \u00e2\u20ac\u00b2 (b)+ P 3 \u00cf\u2020 \u00e2\u20ac\u00b2 (\u00e2\u02c6\u2019b)= 0, (P 1 + P 4 )\u00cf\u2020 \u00e2\u20ac\u00b2 (a)\u00e2\u02c6\u2019 (P 2 + P 3 )\u00cf\u2020 \u00e2\u20ac\u00b2 (\u00e2\u02c6\u2019a)+ P 4 \u00cf\u2020 \u00e2\u20ac\u00b2 (b)\u00e2\u02c6\u2019 P 3 \u00cf\u2020 \u00e2\u20ac\u00b2 (\u00e2\u02c6\u2019b)= 0, hich are equivalent to P 1 \u00cf\u2020 \u00e2\u20ac\u00b2 (a\u00e2\u02c6\u2019 b)\u00e2\u02c6\u2019 P 2 \u00cf\u2020 \u00e2\u20ac\u00b2 (b\u00e2\u02c6\u2019 a)= P 4 \u00cf\u2020 \u00e2\u20ac\u00b2 (b)\u00e2\u02c6\u2019 P 3 \u00cf\u2020 \u00e2\u20ac\u00b2 (\u00e2\u02c6\u2019b), \u00e2\u02c6\u2019P 1 \u00cf\u2020 \u00e2\u20ac\u00b2 (a)+ P 2 \u00cf\u2020 \u00e2\u20ac\u00b2 (\u00e2\u02c6\u2019a)= P 4 ( \u00cf\u2020 \u00e2\u20ac\u00b2 (a)+ \u00cf\u2020 \u00e2\u20ac\u00b2 (b) ) \u00e2\u02c6\u2019 P 3 ( \u00cf\u2020 \u00e2\u20ac\u00b2 (\u00e2\u02c6\u2019a)+ \u00cf\u2020 \u00e2\u20ac\u00b2 (\u00e2\u02c6\u2019b) ) . mma 14 shows that there exist \u00c2\u00afp = ( \u00c2\u00afp y 1 , \u00c2\u00afp y 2 , \u00c2\u00afp y 3 , \u00c2\u00afp y 4 ) and (\u00c2\u00afa y 1 , \u00c2\u00afa y 2 , \u00c2\u00afa y 3 , \u00c2\u00afa y 4 ) s.t. the above hold and P 1 > P 2 from s. (13) and (14). Hence this yields W ( \u00c2\u00afp, f )= W \u00e2\u02c6\u2014 ( \u00c2\u00afp).Wealsohave f /\u00e2\u02c6\u02c6A( \u00c2\u00afp) from 1,2 = P 1 > P 2 = 2,1 yet f 1 > f 2 ; us, W \u00e2\u02c6\u2014 ( \u00c2\u00afp)= inf f {W ( \u00c2\u00afp, f ): f /\u00e2\u02c6\u02c6A( \u00c2\u00afp)}, and the theorem holds. Based on this theorem, many state-of-the-art multi-label learning approaches [9,27,34] areproventobeinconsistent .r.t. partial ranking loss. rollary 15. The surrogate loss \u00ce\u00a8 given by Eq. (4) is inconsistent w.r.t. partial ranking loss for exponential loss \u00cf\u2020(t) = exp(\u00e2\u02c6\u2019t), gistic loss \u00cf\u2020(t)= ln(1+ exp(\u00e2\u02c6\u2019t)) and least square hinge loss \u00cf\u2020(t)= (max(0,1\u00e2\u02c6\u2019 t)) 2 . It is noteworthy that Theorem 13 cannot be used directly to study the consistency of hinge loss because it is non- fferentiable, whereas the following theorem shows the inconsistency for hinge loss: eorem 16. For hinge loss \u00cf\u2020(t)=max(0,1\u00e2\u02c6\u2019 t), the surrogate loss \u00ce\u00a8 given by Eq. (4) is inconsistent w.r.t. partial ranking loss. oof. We consider the following multi-label task with q=3labels: y 1 = (\u00e2\u02c6\u20191,+1,+1), y 2 = (+1,\u00e2\u02c6\u20191,\u00e2\u02c6\u20191), y 3 = (+1,+1,\u00e2\u02c6\u20191), y 4 = (\u00e2\u02c6\u20191,\u00e2\u02c6\u20191,+1), d focus on the probability simplex p = (p y 1 , p y 2 , p y 3 , p y 4 ) \u00e2\u02c6\u02c6\u00ce\u203a and non-negative penalty vector (a y 1 ,a y 2 ,a y 3 ,a y 4 ) such at P 2 < P 1 2P 2 , P 1 + P 3 < P 2 + P 4 and P 3 < P 4 , where P i = p y i a y i for 1 i 4. For every f = ( f 1 , f 2 , f 3 ),wehave W (p, f )= 1,2 \u00cf\u2020( f 2 \u00e2\u02c6\u2019 f 1 )+ 2,1 \u00cf\u2020( f 1 \u00e2\u02c6\u2019 f 2 )+ 1,3 \u00cf\u2020( f 3 \u00e2\u02c6\u2019 f 1 )+ 3,1 \u00cf\u2020( f 1 \u00e2\u02c6\u2019 f 3 )+ 2,3 \u00cf\u2020( f 3 \u00e2\u02c6\u2019 f 2 )+ 3,2 \u00cf\u2020( f 2 \u00e2\u02c6\u2019 f 3 ), 32 w op ha Th Pr an P 2 Th w fro 4. w m Th \u00ce\u00a8 Pr It pr Th Th fo la i.eW. Gao, Z.-H. Zhou / Artificial Intelligence 199\u00e2\u20ac\u201c200 (2013) 22\u00e2\u20ac\u201c44 here 1,2 = P 1 , 2,1 = P 2 , 1,3 = P 1 + P 4 , 3,1 = P 2 + P 3 , 2,3 = P 4 and 3,2 = P 3 . Minimizing W (p, f ) gives the timal solution f = ( f 1 , f 2 , f 3 ) such that f 1 = f 2 = f 3 \u00e2\u02c6\u2019 1. This gives f /\u00e2\u02c6\u02c6A(p) from 1,2 = P 1 > P 2 = 2,1 .Thus,we ve W \u00e2\u02c6\u2014 (p)= inf f /\u00e2\u02c6\u02c6A(p) W (p, f ), and this theorem follows. Also, the following theorem shows that the least square loss is inconsistent with partial ranking loss: eorem 17. For least square loss \u00cf\u2020(t)= (1\u00e2\u02c6\u2019 t) 2 , the surrogate loss \u00ce\u00a8 given by Eq. (4) is inconsistent w.r.t. partial ranking loss. oof. We consider the following multi-label task with q= 3 labels: y 1 = (\u00e2\u02c6\u20191,+1,+1), y 2 = (+1,\u00e2\u02c6\u20191,\u00e2\u02c6\u20191), y 3 = (+1,+1,\u00e2\u02c6\u20191), d focus on the probability simplex p = (p y 1 , p y 2 , p y 3 ) \u00e2\u02c6\u02c6 \u00ce\u203a and non-negative penalty vector (a y 1 ,a y 2 ,a y 3 ) such that = 3P 1 /2 and P 3 > 5P 1 /4, where P i = p y i a y i >0for1 i 3. For least square loss, we have W (p, f )= P 1 (1\u00e2\u02c6\u2019 f 2 + f 1 ) 2 + P 2 (1\u00e2\u02c6\u2019 f 1 + f 2 ) 2 + P 1 (1\u00e2\u02c6\u2019 f 3 + f 1 ) 2 + (P 2 + P 3 )(1\u00e2\u02c6\u2019 f 1 + f 3 ) 2 + P 3 (1\u00e2\u02c6\u2019 f 2 + f 3 ) 2 . e subgradient conditions for optimality of \u00e2\u02c6\u201aW (p, f ) \u00e2\u02c6\u201a f i =0(i = 1,2,3) give the optimal solution f \u00e2\u02c6\u2014 = ( f \u00e2\u02c6\u2014 1 , f \u00e2\u02c6\u2014 2 , f \u00e2\u02c6\u2014 3 ) such that f \u00e2\u02c6\u2014 1 \u00e2\u02c6\u2019 f \u00e2\u02c6\u2014 2 = ( P 2 2 \u00e2\u02c6\u2019 P 2 1 + 2P 3 (P 2 \u00e2\u02c6\u2019 2P 1 ) ) /\u00ce\u00ba = P 1 (5/4P 1 \u00e2\u02c6\u2019 P 3 )/\u00ce\u00ba < 0 here \u00ce\u00ba = (P 1 + P 2 + P 3 ) 2 + P 3 (P 1 + P 2 ) and we use P 2 = 3P 1 /2 and P 3 > 5P 1 /4. This theorem follows since f /\u00e2\u02c6\u02c6A(p) m 1,2 = P 1 < P 2 = 2,1 . 2. Consistency of univariate surrogate loss Now we consider the univariate surrogate loss as follows: \u00ce\u00a8 ( f (x), y ) = a y q \u00e2\u02c6\u2018 i=1 \u00cf\u2020 ( y i f i (x) ) , (15) here \u00cf\u2020 is a convex function, e.g., exponential loss \u00cf\u2020(t) = exp(\u00e2\u02c6\u2019t), logistic loss \u00cf\u2020(t) = ln(1+ exp(\u00e2\u02c6\u2019t)),hingeloss\u00cf\u2020(t) = ax(0,1\u00e2\u02c6\u2019 t), etc. We have the following sufficient condition for consistency of univariate surrogate loss: eorem 18. If \u00cf\u2020 : R\u00e2\u2020\u2019 R is a convex, non-increasing and differentiable function with \u00cf\u2020 \u00e2\u20ac\u00b2 (0)<0, then the univariate surrogate loss of Eq. (15) is consistent w.r.t. partial ranking loss. oof. For every probability simplex p = (p y ) y\u00e2\u02c6\u02c6Y and non-negative vector (a y ) y\u00e2\u02c6\u02c6Y ,wehave W (p, f )= \u00e2\u02c6\u2018 y\u00e2\u02c6\u02c6Y p y a y q \u00e2\u02c6\u2018 i=1 \u00cf\u2020(y i f i )= q \u00e2\u02c6\u2018 i=1 \u00e2\u02c6\u2019 i \u00cf\u2020(\u00e2\u02c6\u2019 f i )+ ( \u00e2\u02c6\u2019 \u00e2\u02c6\u2019 i ) \u00cf\u2020( f i ). suffices to prove that f i > f j if i, j < j,i for every f such that W \u00e2\u02c6\u2014 (p)= W (p, f ). Without loss of generality, we will ove that f 1 < f 2 if 1,2 > 2,1 . From Property 2 in Lemma 7,wehave \u00e2\u02c6\u2019 1 \u00e2\u02c6\u2019 \u00e2\u02c6\u2019 2 = 1,2 \u00e2\u02c6\u2019 2,1 , and if 1,2 > 2,1 ,wehave \u00e2\u02c6\u2019 1 > \u00e2\u02c6\u2019 2 \u00e2\u2021\u2019 / \u00e2\u02c6\u2019 1 < / \u00e2\u02c6\u2019 2 \u00e2\u2021\u2019 ( \u00e2\u02c6\u2019 \u00e2\u02c6\u2019 1 ) / \u00e2\u02c6\u2019 1 < ( \u00e2\u02c6\u2019 \u00e2\u02c6\u2019 2 ) / \u00e2\u02c6\u2019 2 . e subgradient conditions for optimality of \u00e2\u02c6\u201aW (p, f ) \u00e2\u02c6\u201a f i =0(i = 1,2) give \u00e2\u02c6\u2019 1 \u00cf\u2020 \u00e2\u20ac\u00b2 (\u00e2\u02c6\u2019 f 1 )= ( \u00e2\u02c6\u2019 \u00e2\u02c6\u2019 1 ) \u00cf\u2020 \u00e2\u20ac\u00b2 ( f 1 ) and \u00e2\u02c6\u2019 2 \u00cf\u2020 \u00e2\u20ac\u00b2 (\u00e2\u02c6\u2019 f 2 )= ( \u00e2\u02c6\u2019 \u00e2\u02c6\u2019 2 ) \u00cf\u2020 \u00e2\u20ac\u00b2 ( f 2 ). is yields that \u00cf\u2020 \u00e2\u20ac\u00b2 (\u00e2\u02c6\u2019 f 1 )<0,\u00cf\u2020 \u00e2\u20ac\u00b2 ( f 1 )<0,\u00cf\u2020 \u00e2\u20ac\u00b2 (\u00e2\u02c6\u2019 f 2 )<0,\u00cf\u2020 \u00e2\u20ac\u00b2 ( f 2 )<0, r non-increasing function \u00cf\u2020 with \u00cf\u2020 \u00e2\u20ac\u00b2 (0)<0. For convex function \u00cf\u2020,itsderivative\u00cf\u2020 \u00e2\u20ac\u00b2 (t) is non-decreasing from Rockafel- r [26]. Therefore, if f 1 f 2 then \u00cf\u2020 \u00e2\u20ac\u00b2 ( f 1 ) \u00cf\u2020 \u00e2\u20ac\u00b2 ( f 2 ), and we further have \u00cf\u2020 \u00e2\u20ac\u00b2 (\u00e2\u02c6\u2019 f 1 )= \u00e2\u02c6\u2019 \u00e2\u02c6\u2019 1 \u00e2\u02c6\u2019 1 \u00cf\u2020 \u00e2\u20ac\u00b2 ( f 1 )> \u00e2\u02c6\u2019 \u00e2\u02c6\u2019 2 \u00e2\u02c6\u2019 2 \u00cf\u2020 \u00e2\u20ac\u00b2 ( f 1 ) \u00e2\u02c6\u2019 \u00e2\u02c6\u2019 2 \u00e2\u02c6\u2019 2 \u00cf\u2020 \u00e2\u20ac\u00b2 ( f 2 )= \u00cf\u2020 \u00e2\u20ac\u00b2 (\u00e2\u02c6\u2019 f 2 ), ., \u00cf\u2020 \u00e2\u20ac\u00b2 (\u00e2\u02c6\u2019 f 1 )>\u00cf\u2020 \u00e2\u20ac\u00b2 (\u00e2\u02c6\u2019 f 2 ),leadingto f 1 < f 2 , whereas it is contrary. The theorem follows as desired. lo Co \u00cf\u2020 su an sp sq Th Pr op w re fr be di Th Pr an p M Th by su biW. Gao, Z.-H. Zhou / Artificial Intelligence 199\u00e2\u20ac\u201c200 (2013) 22\u00e2\u20ac\u201c44 33 Based on this theorem, it is easy to get the consistency of the univariate surrogate loss with exponential loss, logistic ss and least square hinge loss. rollary 19. The surrogate loss \u00ce\u00a8 of Eq. (15) is consistent w.r.t. partial ranking loss for exponential loss \u00cf\u2020(t)= exp(\u00e2\u02c6\u2019t), logistic loss (t)= ln(1+ exp(\u00e2\u02c6\u2019t)) and least square hinge loss \u00cf\u2020(t)= (max(0,1\u00e2\u02c6\u2019 t)) 2 . It is noteworthy that, after we published our preliminary work [16],Dembczy\u00c2\u00b4nski et al. [11] proved that the following rrogate losses are consistent w.r.t. partial ranking loss (the partial ranking loss was referred to as ranking loss in [11]) \u00ce\u00a8(f , y)= a y q \u00e2\u02c6\u2018 i=1 exp(\u00e2\u02c6\u2019y i f i ), \u00ce\u00a8(f , y)= a y q \u00e2\u02c6\u2018 i=1 ln ( 1+ exp(\u00e2\u02c6\u2019y i f i ) ) , d they further derived their corresponding consistent bounds. It is clear that these results of Dembczyn\u00c2\u00b4ski et al. [11] are ecial cases of Theorem 18. Notice that the least square loss \u00cf\u2020(t) = (1 \u00e2\u02c6\u2019 t) 2 increases for t > 1; therefore, Theorem 18 cannot be applied to least uare loss, whereas we can obtain its consistency with partial ranking loss from the following theorem: eorem 20. For integer k> 0 and \u00cf\u2020(t)= (1\u00e2\u02c6\u2019 t) 2k , the univariate surrogate loss \u00ce\u00a8 of Eq. (15) is consistent w.r.t. partial ranking loss. oof. Similarly to the proof of Theorem 18, we will prove that f 1 < f 2 if 1,2 > 2,1 . The subgradient conditions for timality of \u00e2\u02c6\u201aW (p, f ) \u00e2\u02c6\u201a f i =0(i = 1,2) give \u00e2\u02c6\u2019 1 \u00cf\u2020 \u00e2\u20ac\u00b2 (\u00e2\u02c6\u2019 f 1 )= ( \u00e2\u02c6\u2019 \u00e2\u02c6\u2019 1 ) \u00cf\u2020 \u00e2\u20ac\u00b2 ( f 1 ) and \u00e2\u02c6\u2019 2 \u00cf\u2020 \u00e2\u20ac\u00b2 (\u00e2\u02c6\u2019 f 2 )= ( \u00e2\u02c6\u2019 \u00e2\u02c6\u2019 2 ) \u00cf\u2020 \u00e2\u20ac\u00b2 ( f 2 ), hich implies ( 1+ f 1 1\u00e2\u02c6\u2019 f 1 ) 2k\u00e2\u02c6\u20191 = \u00e2\u02c6\u2019 1 \u00e2\u02c6\u20191and ( 1+ f 2 1\u00e2\u02c6\u2019 f 2 ) 2k\u00e2\u02c6\u20191 = \u00e2\u02c6\u2019 2 \u00e2\u02c6\u2019 1, (16) spectively. From Property 2 in Lemma 7,wehave \u00e2\u02c6\u2019 1 \u00e2\u02c6\u2019 \u00e2\u02c6\u2019 2 = 1,2 \u00e2\u02c6\u2019 2,1 , and this follows that \u00e2\u02c6\u2019 1 > \u00e2\u02c6\u2019 2 \u00e2\u2021\u2019 / \u00e2\u02c6\u2019 1 < / \u00e2\u02c6\u2019 2 om 1,2 > 2,1 . Therefore, we have f 1 < f 2 from Eq. (16), and this completes the proof. It is also noteworthy that the hinge loss \u00cf\u2020(t)=max(0,1\u00e2\u02c6\u2019 t) is not differentiable at t = 1; therefore, Theorem 18 cannot used to study the consistency of hinge loss. The following theorem illustrates the difficulties for consistency without fferentiability even if \u00cf\u2020 is a convex and non-increasing function with \u00cf\u2020 \u00e2\u20ac\u00b2 (0)<0. eorem 21. For hinge loss \u00cf\u2020(t)=max(0,1\u00e2\u02c6\u2019 t), the univariate surrogate loss \u00ce\u00a8 of Eq. (15) is inconsistent w.r.t. partial ranking loss. oof. We consider a multi-label task with q=2labels: y 1 = (\u00e2\u02c6\u20191,\u00e2\u02c6\u20191), y 2 = (\u00e2\u02c6\u20191,+1), y 3 = (+1,\u00e2\u02c6\u20191), y 4 = (+1,+1), d focus on the probability simplex p = (p y 1 , p y 2 , p y 3 , p y 4 ) and non-negative vector (a y 1 ,a y 2 ,a y 3 ,a y 4 ) such that y 1 a y 1 /2> p y 2 a y 2 > p y 3 a y 3 > p y 4 a y 4 .FromEq.(15), we have W (p, f )= (p y 1 a y 1 + p y 2 a y 2 )\u00cf\u2020(\u00e2\u02c6\u2019 f 1 )+ (p y 3 a y 3 + p y 4 a y 4 )\u00cf\u2020( f 1 ) + (p y 1 a y 1 + p y 3 a y 3 )\u00cf\u2020(\u00e2\u02c6\u2019 f 2 )+ (p y 2 a y 2 + p y 4 a y 4 )\u00cf\u2020( f 2 ). inimizing W (p, f ) gives the optimal solution f = ( f 1 , f 2 ) = (\u00e2\u02c6\u20191,\u00e2\u02c6\u20191), i.e., f 1 = f 2 ,yet 1,2 = p y 2 a y 2 > p y 3 a y 3 = 2,1 . is implies f /\u00e2\u02c6\u02c6A(p), which completes the proof. Many univariate surrogate losses are proven to be consistent with partial ranking loss, although they solve the problems a series of independent (weighted) binary classifications; in other words, the success of approaches optimizing univariate rrogate losses requires that a multi-label learning problem can be learned well by decomposing them into a series ofnary classification problems. 34 5. fu w be fo an 5.1 fu M w Th lo Th haW. Gao, Z.-H. Zhou / Artificial Intelligence 199\u00e2\u20ac\u201c200 (2013) 22\u00e2\u20ac\u201c44 Consistency w.r.t. hamming loss The hamming loss concerns about how many instance-label pairs are misclassified. For a given vector f and prediction nction F , the hamming loss is given by L hamloss ( F ( f (x) ) , y ) = 1 q q \u00e2\u02c6\u2018 i=1 I[ \u00cb\u2020y i = y i ], here \u00cb\u2020y = F ( f (x)) = ( \u00cb\u2020y 1 , \u00cb\u2020y 2 ,..., \u00cb\u2020y q ). Hamming loss is below-bounded from L hamloss (F ( f (x)), y) 0, and distinguishable cause it holds that L hamloss ( F ( f (x) ) , y ) = L hamloss ( F ( f ( x \u00e2\u20ac\u00b2 )) , y \u00e2\u20ac\u00b2 ) or \u00e2\u02c6\u00a3 \u00e2\u02c6\u00a3 L hamloss ( F ( f (x) ) , y ) \u00e2\u02c6\u2019 L hamloss ( F ( f ( x \u00e2\u20ac\u00b2 )) , y \u00e2\u20ac\u00b2 )\u00e2\u02c6\u00a3 \u00e2\u02c6\u00a3 1/q, r every x, x \u00e2\u20ac\u00b2 \u00e2\u02c6\u02c6X and y, y \u00e2\u20ac\u00b2 \u00e2\u02c6\u02c6Y . Further, we have the conditional risk l ( p, F ( f (x) )) = \u00e2\u02c6\u2018 y\u00e2\u02c6\u02c6Y p y L hamloss ( \u00cb\u2020y, y)= 1 q \u00e2\u02c6\u2018 y\u00e2\u02c6\u02c6Y p y q \u00e2\u02c6\u2018 i=1 I[ \u00cb\u2020y i = y i ] = 1 q q \u00e2\u02c6\u2018 i=1 ( \u00e2\u02c6\u2018 y:y i =+1 p y I[ \u00cb\u2020y i = +1]+ \u00e2\u02c6\u2018 y:y i =\u00e2\u02c6\u20191 p y I[ \u00cb\u2020y i = \u00e2\u02c6\u20191] ) , d for hamming loss, the set of Bayes predictions is given by A(p)= { f = f (x): \u00cb\u2020y = F ( f )with \u00cb\u2020y i = sgn ( \u00e2\u02c6\u2018 y:y i =+1 p y \u00e2\u02c6\u2019 1 2 )} . (17) . Consistency of multi-class extensions It is possible to solve a multi-label problem by regarding each subset of labels as a meta-class and then try to learn 2 q nctions, i.e., f = ( f y ) y\u00e2\u02c6\u02c6Y . Then, a prediction function is given by F ( f (x) ) =max y\u00e2\u02c6\u02c6Y f y (x). (18) otivated from multi-class learning, it is natural to consider the following surrogate losses. \u00e2\u20ac\u00a2 One-vs-all: \u00ce\u00a8 ( f (x), y ) = \u00cf\u2020 ( f y (x)\u00e2\u02c6\u2019max \u00cb\u2020y =y f \u00cb\u2020y (x) ) , (19) where \u00cf\u2020 is an appropriately chosen function. This formulation has been used for multi-label learning [19,29] and multi- class learning [8]. \u00e2\u20ac\u00a2 Pairwise comparison: \u00ce\u00a8 ( f (x), y ) = \u00e2\u02c6\u2018 \u00cb\u2020y =y \u00cf\u2020 ( f y (x)\u00e2\u02c6\u2019 f \u00cb\u2020y (x) ) , (20) where \u00cf\u2020 is a convex function such as \u00cf\u2020(t)=max(0,1\u00e2\u02c6\u2019 t) in multi-class learning [31]. The following two theorems show that neither the one-vs-all method nor the pairwise comparison method is consistent .r.t. hamming loss. eorem 22. If \u00cf\u2020 is a non-increasing function with \u00cf\u2020 \u00e2\u20ac\u00b2 (0)<0, then the one-vs-all method of Eq. (19) is inconsistent with hamming ss. eorem 23. If \u00cf\u2020 is a non-increasing function with \u00cf\u2020 \u00e2\u20ac\u00b2 (0)<0, then the pairwise comparison method of Eq. (20) is inconsistent withmming loss. mex et or in Pr an p W ( f Fr Fo Fr fo Th ex an Fr m to fo Th EqW. Gao, Z.-H. Zhou / Artificial Intelligence 199\u00e2\u20ac\u201c200 (2013) 22\u00e2\u20ac\u201c44 35 Based on Theorems 22 and 23, it is clear that neither the one-vs-all method of Eq. (19) nor the pairwise comparison ethod of Eq. (20) is consistent w.r.t. hamming loss for many commonly-used loss functions, e.g., exponential loss \u00cf\u2020(t)= p(\u00e2\u02c6\u2019t), logistic loss \u00cf\u2020(t)= ln(1+ exp(\u00e2\u02c6\u2019t)),hingeloss\u00cf\u2020(t)=max(0,1\u00e2\u02c6\u2019 t), least square hinge loss \u00cf\u2020(t)= (max(0,1\u00e2\u02c6\u2019 t)) 2 , c. It is also noteworthy that the pairwise comparison method of Eq. (20) is consistent in multi-class learning [36, The- em 6] for exponential loss, logistic loss, hinge loss, etc., whereas in multi-label learning, Theorem 23 shows their consistency. oofs of Theorems 22 and 23. We consider a multi-label task with q=2labels: y 1 = (\u00e2\u02c6\u20191,\u00e2\u02c6\u20191), y 2 = (\u00e2\u02c6\u20191,+1), y 3 = (+1,+1), y 4 = (+1,\u00e2\u02c6\u20191), d focus on the probability simplex p = (p y 1 , p y 2 , p y 3 , p y 4 ) such that p y 1 > p y 2 > p y 3 > p y 4 , p y 1 + p y 4 < p y 2 + p y 3 and y 1 + p y 2 + p y 3 + p y 4 = 1. From Eqs. (17) and (18), it is easy to get the set of Bayes predictions A(p)={f : f y 2 > f y i for i = 1,3,4}. For Theorem 22,wehave,fromEq.(19), W (p, f )= 4 \u00e2\u02c6\u2018 i=1 p y i \u00cf\u2020 ( f y i \u00e2\u02c6\u2019max j =i f y j ) . e complete the proof by showing that f /\u00e2\u02c6\u02c6 A(p) for every f s.t. W (p, f ) = W \u00e2\u02c6\u2014 (p). Assume that there exists f = y 1 , f y 2 , f y 3 , f y 4 ) \u00e2\u02c6\u02c6A(p) and W (p, f )=W \u00e2\u02c6\u2014 (p). We construct another \u00cb\u2020 f = ( f y 2 , f y 1 , f y 3 , f y 4 ), and get W (p, f )\u00e2\u02c6\u2019W (p, \u00cb\u2020 f )= (p y 1 \u00e2\u02c6\u2019 p y 2 ) ( \u00cf\u2020 ( f y 1 \u00e2\u02c6\u2019max i =1 f y i ) \u00e2\u02c6\u2019 \u00cf\u2020 ( f y 2 \u00e2\u02c6\u2019max i =2 f y i )) . (21) om our assumption f \u00e2\u02c6\u02c6A(p),wehave f y 2 >max i =2 f y i and f y 1 \u00e2\u02c6\u2019 f y 2 < 0 f y 2 \u00e2\u02c6\u2019max i =2 f y i . r non-increasing function \u00cf\u2020 with \u00cf\u2020 \u00e2\u20ac\u00b2 (0)<0, it holds that \u00cf\u2020( f y 1 \u00e2\u02c6\u2019 f y 2 )>\u00cf\u2020 ( f y 2 \u00e2\u02c6\u2019max i =2 f y i ) . om Eq. (21) and p y 1 > p y 2 ,wehaveW (p, f )>W (p, \u00cb\u2020 f ), which is contrary to W (p, f ) = W \u00e2\u02c6\u2014 (p).Thus,Theorem22 llows. For Theorem 23,wehave,fromEq.(20), W (p, f )= 4 \u00e2\u02c6\u2018 i=1 p y i \u00e2\u02c6\u2018 j =i \u00cf\u2020( f y i \u00e2\u02c6\u2019 f y j ). erefore, we complete the proof by showing that f /\u00e2\u02c6\u02c6A(p) for every f such that W (p, f )= W \u00e2\u02c6\u2014 (p). Suppose that there ists f = ( f y 1 , f y 2 , f y 3 , f y 4 ) \u00e2\u02c6\u02c6A(p) such that W (p, f )=W \u00e2\u02c6\u2014 (p). Then, we can construct another \u00cb\u2020 f = ( f y 2 , f y 1 , f y 3 , f y 4 ), d get W ( p, f \u00e2\u02c6\u2014 ) \u00e2\u02c6\u2019W (p, \u00cb\u2020 f )= (p y 1 \u00e2\u02c6\u2019 p y 2 ) ( \u00cf\u2020( f y 1 \u00e2\u02c6\u2019 f y 2 )\u00e2\u02c6\u2019\u00cf\u2020( f y 2 \u00e2\u02c6\u2019 f y 1 )+ 4 \u00e2\u02c6\u2018 i=3 \u00cf\u2020( f y 1 \u00e2\u02c6\u2019 f y i )\u00e2\u02c6\u2019\u00cf\u2020( f y 2 \u00e2\u02c6\u2019 f y i ) ) . (22) om our assumption f \u00e2\u02c6\u02c6A(p),wehave f y 1 < f y 2 . For non-increasing function \u00cf\u2020,wehave \u00cf\u2020( f y 1 \u00e2\u02c6\u2019 f y i ) \u00cf\u2020( f y 2 \u00e2\u02c6\u2019 f y i ) for i = 3,4; eanwhile, we also have \u00cf\u2020( f y 1 \u00e2\u02c6\u2019 f y 2 )>\u00cf\u2020(f y 2 \u00e2\u02c6\u2019 f y 1 ) from \u00cf\u2020 \u00e2\u20ac\u00b2 (0)<0. From Eq. (22), we have W (p, f )>W (p, \u00cb\u2020 f ), contrary W (p, f )=W \u00e2\u02c6\u2014 (p). This completes the proof. Notice that Theorems 22 and 23 cannot be applied directly to least square loss \u00cf\u2020(t)= (1\u00e2\u02c6\u2019 t) 2 because it is increasing r t > 1, whereas we have: eorem 24. For least square loss \u00cf\u2020(t)= (1\u00e2\u02c6\u2019 t) 2 , neither the one-vs-all method of Eq. (19) nor the pairwise comparison method of. (20) is consistent w.r.t. hamming loss. 36 Pr w pr an m an w 5p Th m pr In th ( \u00cb\u2020y w al to Th Pr an pW. Gao, Z.-H. Zhou / Artificial Intelligence 199\u00e2\u20ac\u201c200 (2013) 22\u00e2\u20ac\u201c44 oof. Similarly to the proofs of Theorems 22 and 23, we consider the multi-label task with q=2labels: y 1 = (\u00e2\u02c6\u20191,\u00e2\u02c6\u20191), y 2 = (\u00e2\u02c6\u20191,+1), y 3 = (+1,+1), y 4 = (+1,\u00e2\u02c6\u20191), ith p y 1 > p y 2 > p y 3 > p y 4 , p y 1 + p y 4 < p y 2 + p y 3 and p y 1 + p y 2 + p y 3 + p y 4 = 1, and it is easy to get the set of Bayes edictions A(p)={f : f y 2 > f y i for i = 1,3,4}. For the one-vs-all method of Eq. (19), our proof is rather similar to the proof of Theorem 22.FromEq.(21), we have W (p, f )\u00e2\u02c6\u2019W (p, \u00cb\u2020 f )= (p y 1 \u00e2\u02c6\u2019 p y 2 ) ( \u00cf\u2020 ( f y 1 \u00e2\u02c6\u2019max i =1 f y i ) \u00e2\u02c6\u2019 \u00cf\u2020 ( f y 2 \u00e2\u02c6\u2019max i =2 f y i )) , d, for least square loss \u00cf\u2020(t) = (1 \u00e2\u02c6\u2019 t) 2 ,wehave\u00cf\u2020( f y 1 \u00e2\u02c6\u2019max i =1 f y i )>\u00cf\u2020(f y 2 \u00e2\u02c6\u2019max i =2 f y i ) from the condition f y 2 > ax i =2 f y i . This is contrary to W (p, f )=W \u00e2\u02c6\u2014 (p). For the pairwise comparison method of Eq. (20), we have W (p, f )= 4 \u00e2\u02c6\u2018 i=1 p y i \u00e2\u02c6\u2018 j =i \u00cf\u2020( f y i \u00e2\u02c6\u2019 f y j ), d the subgradient conditions for optimality of \u00e2\u02c6\u201a \u00e2\u02c6\u201a f i W (p, f )= 0 (1 i 4) give f \u00e2\u02c6\u2014 = ( f \u00e2\u02c6\u2014 1 , f \u00e2\u02c6\u2014 2 , f \u00e2\u02c6\u2014 3 , f \u00e2\u02c6\u2014 4 ) such that f \u00e2\u02c6\u2014 1 \u00e2\u02c6\u2019 f \u00e2\u02c6\u2014 2 = (p y 1 \u00e2\u02c6\u2019 p y 2 )(p y 1 + p y 2 + 5p y 3 + p y 4 )(p y 1 + p y 2 + p y 3 + 5p y 4 )/\u00ce\u00ba, here \u00ce\u00ba = p 3 y 1 + p 3 y 2 + p 3 y 3 + p 3 y 4 + 16(p y 1 p y 2 p y 3 + p y 1 p y 2 p y 4 + p y 1 p y 3 p y 4 + p y 2 p y 3 p y 4 ) + 5p 2 y 1 (p y 2 + p y 3 + p y 4 ) + 2 y 2 (p y 1 + p y 3 + p y 4 )+ 5p 2 y 3 (p y 1 + p y 2 + p y 4 )+ 5p 2 y 4 (p y 1 + p y 2 + p y 3 ).Thisleadsto f \u00e2\u02c6\u2014 1 > f \u00e2\u02c6\u2014 2 , implying that f \u00e2\u02c6\u2014 /\u00e2\u02c6\u02c6A(p). us, this theorem follows as desired. It is interesting to further understand why those algorithms are inconsistent. Intuitively, the prediction rule F ( f (x)) = ax y\u00e2\u02c6\u02c6Y f y (x) prefers to choosing y \u00e2\u02c6\u02c6 arg max{p y : y \u00e2\u02c6\u02c6 Y}, whereas for hamming loss, Eq. (17)givesthesetofBayes edictions A(p)= { f = f (x): \u00cb\u2020y = F ( f )where \u00cb\u2020y i = sgn ( \u00e2\u02c6\u2018 y:y i =+1 p y \u00e2\u02c6\u2019 1 2 )} . practice, it does not always hold that { y: y \u00e2\u02c6\u02c6 arg max{p y } } = { y: y i = sgn ( \u00e2\u02c6\u2018 y:y i =+1 p y \u00e2\u02c6\u2019 1 2 )} ; is may explain why these algorithms are inconsistent. It leads us to consider other prediction rules such as F ( f (x))= \u00cb\u2020y = 1 , \u00cb\u2020y 2 ,..., \u00cb\u2020y q ) with \u00cb\u2020y i = sgn( \u00e2\u02c6\u2018 y\u00e2\u02c6\u02c6Y,y i =+1 f y \u00e2\u02c6\u2019 \u00e2\u02c6\u2018 y\u00e2\u02c6\u02c6Y,y i =\u00e2\u02c6\u20191 f y ), and we leave it to future work. Finally, it is interesting to consider the following formulation \u00ce\u00a8 ( f (x), y ) =max \u00cb\u2020y =y \u00cf\u2020 ( \u00ce\u00b4( \u00cb\u2020y, y)+ f \u00cb\u2020y (x)\u00e2\u02c6\u2019 f y (x) ) , (23) here \u00cf\u2020(t)=max(0, t) and \u00ce\u00b4(y, \u00cb\u2020y)= \u00e2\u02c6\u2018 q i=1 I[y i = \u00cb\u2020y i ]; this formulation has been used in Hariharan et al. [19] and Taskar et . [29]. It is easy to see that these approaches [19,29] are variations of the one-vs-all method, because Eq. (23) degenerates Eq. (19) by setting \u00ce\u00b4(y, \u00cb\u2020y)= I[y = \u00cb\u2020y].Wehave eorem 25. The surrogate loss \u00ce\u00a8 of Eq. (23) is inconsistent w.r.t. hamming loss for \u00cf\u2020(t)=max(0, t) and \u00ce\u00b4( \u00cb\u2020y, y)= \u00e2\u02c6\u2018 q i=1 I[y i = \u00cb\u2020y i ]. oof. We consider the multi-label task with q=3labels: y 1 = (1,\u00e2\u02c6\u20191,\u00e2\u02c6\u20191), y 2 = (\u00e2\u02c6\u20191,1,\u00e2\u02c6\u20191), y 3 = (\u00e2\u02c6\u20191,\u00e2\u02c6\u20191,1), y 4 = (1,1,1), y 5 = (\u00e2\u02c6\u20191,\u00e2\u02c6\u20191,\u00e2\u02c6\u20191), y 6 = (1,1,\u00e2\u02c6\u20191), y 7 = (1,\u00e2\u02c6\u20191,1), y 8 = (\u00e2\u02c6\u20191,1,1), d probability simplex p = (p y 1 , p y 2 , p y 3 , p y 4 ) such that p y i = 0(i 4), p y 1 + p y 2 + p y 3 = 1, p y 1 < p y 2 + p y 3 , p y 2 < y 1 + p y 3 , p y 3 < p y 1 + p y 2 . By combining Eqs. (17) and (23), we get the set of Bayes predictionsA(p)={f : f y 5 > f y i for i = 5}. WM f sp m di in 5. m th e. D th la tr m Th co Pr Eq It f an Fr fu FrW. Gao, Z.-H. Zhou / Artificial Intelligence 199\u00e2\u20ac\u201c200 (2013) 22\u00e2\u20ac\u201c44 37 e also have W (p, f )= p y 1 max y =y 1 { \u00cf\u2020 ( \u00ce\u00b4(y, y 1 )+ f y (x)\u00e2\u02c6\u2019 f y 1 (x) )} + p y 2 max y =y 2 { \u00cf\u2020 ( \u00ce\u00b4(y, y 2 )+ f y (x)\u00e2\u02c6\u2019 f y 2 (x) )} + p y 3 max y =y 3 { \u00cf\u2020 ( \u00ce\u00b4(y, y 3 )+ f y (x)\u00e2\u02c6\u2019 f y 3 (x) )} . inimizing W (p, f ) gives an optimal solution f = ( f y 1 ,..., f y 8 ) such that f y 1 \u00e2\u02c6\u2019 3= f y 2 \u00e2\u02c6\u2019 3= f y 3 \u00e2\u02c6\u2019 3= f y 5 \u00e2\u02c6\u2019 2= f y 4 = y 6 = f y 7 = f y 8 . It is obvious that f /\u00e2\u02c6\u02c6A(p) and we complete the proof. Theorem 25 shows the inconsistency of Eq. (23) under all measurable functions. Hariharan et al. [19] considered the ecial function f = w (\u00c2\u00b5(x) \u00e2\u0160\u2014 \u00ce\u00bd(y)) based on the prior label-correlation assumption \u00ce\u00bd(y) = P y for some invertible atrix P , where \u00e2\u0160\u2014 is the Kronecker product, \u00c2\u00b5 and \u00ce\u00bd are the feature and label space mappings, respectively. An interesting rection is to study the consistency of Eq. (23) under specific function space and specific label-correlation assumptions as Hariharan et al. [19], and Ben-David et al. [2] may shed some light. 2. Consistency of dominating setting Though the previous analysis indicates that the one-vs-all and pairwise comparison methods are inconsistent with ham- ing loss in general cases, it is noteworthy that they may be used successfully in some practical applications, especially for e formulation (23) as in Hariharan et al. [19]. This is partly because that such methods may work well in special cases, g., the dominating setting: efinition 26. A multi-label task is said to be in a dominating setting if for every instance x \u00e2\u02c6\u02c6X ,thereexistsa y \u00e2\u02c6\u02c6 Y such at P (y|x)>0.5. Intuitively, the dominating setting implies that, for every instance, there exists a label subset which dominates other bel subsets, and it is sufficient to find the dominating label subset. This learning setting exists in real scenarios where the ue label set can definitely be predicted accurately. Under such setting, the following theorem shows that the one-vs-all ethod is consistent w.r.t. hamming loss. eorem 27. If \u00cf\u2020 is a continuous, convex and non-increasing function with \u00cf\u2020 \u00e2\u20ac\u00b2 (0)<0, then the one-vs-all method of Eq. (19) is nsistent with hamming loss under the dominating setting. oof. Without loss of generality, we consider a probability simplex p = (p y ) y\u00e2\u02c6\u02c6Y such that p y 1 > 0.5> p y k for k = 1. From s. (17) and (18), it is easy to get the set of Bayes predictions A(p)={f : f y 1 > f y for y = y 1 }. suffices to prove f \u00e2\u02c6\u02c6 A(p) for every f s.t. W (p, f ) = W \u00e2\u02c6\u2014 (p). We proceed by contradiction. Suppose that there exists /\u00e2\u02c6\u02c6A(p) and W (p, f )=W \u00e2\u02c6\u2014 (p), i.e., there is \u00cb\u2020y \u00e2\u02c6\u02c6 arg max y\u00e2\u02c6\u02c6Y { f y } such that y 1 = \u00cb\u2020y and f y\u00cb\u2020 f y 1 . If f y\u00cb\u2020 > f y 1 , then we construct another f \u00e2\u20ac\u00b2 by f \u00e2\u20ac\u00b2 y 1 = f \u00cb\u2020y , f \u00e2\u20ac\u00b2 \u00cb\u2020y = f y 1 , f \u00e2\u20ac\u00b2 y = f y for y = y 1 , \u00cb\u2020y, d get W (p, f )\u00e2\u02c6\u2019W ( p, f \u00e2\u20ac\u00b2 ) = (p y 1 \u00e2\u02c6\u2019 p \u00cb\u2020y ) ( \u00cf\u2020( f y 1 \u00e2\u02c6\u2019 f \u00cb\u2020y )\u00e2\u02c6\u2019 \u00cf\u2020 ( f \u00cb\u2020y \u00e2\u02c6\u2019max y = \u00cb\u2020y f y )) . (24) om \u00cb\u2020y \u00e2\u02c6\u02c6 arg max y\u00e2\u02c6\u02c6Y { f y },wehave f y 1 \u00e2\u02c6\u2019 f y\u00cb\u2020 < 0 f y\u00cb\u2020 \u00e2\u02c6\u2019max y = y\u00cb\u2020 f y , and for non-increasing function \u00cf\u2020 with \u00cf\u2020 \u00e2\u20ac\u00b2 (0)<0, we rther get \u00cf\u2020( f y 1 \u00e2\u02c6\u2019 f \u00cb\u2020y )>\u00cf\u2020 ( f \u00cb\u2020y \u00e2\u02c6\u2019max y = \u00cb\u2020y f y ) . om Eq. (24) and p y 1 > p y\u00cb\u2020 , it holds that W (p, f )>W (p, f \u00e2\u20ac\u00b2 ), which is contrary to the assumption W (p, f )=W \u00e2\u02c6\u2014 (p). We now consider the case f y\u00cb\u2020 = f y 1 . For very small \u00ce\u00be 1 >0andfrom\u00cf\u2020 \u00e2\u20ac\u00b2 (0)<0, we have\u00cf\u2020(\u00ce\u00be 1 )\u00e2\u2030\u02c6 \u00cf\u2020(0)+ \u00ce\u00be 1 \u00cf\u2020 \u00e2\u20ac\u00b2 (0), and \u00cf\u2020(\u00e2\u02c6\u2019\u00ce\u00be 1 )\u00e2\u2030\u02c6 \u00cf\u2020(0)\u00e2\u02c6\u2019 \u00ce\u00be 1 \u00cf\u2020 \u00e2\u20ac\u00b2 (0). (25) 38 W No Th w w la \u00cf\u2020 is Le an Th Eq Pr Eq It fo \u00e2\u02c6\u201aW Th w co lo usW. Gao, Z.-H. Zhou / Artificial Intelligence 199\u00e2\u20ac\u201c200 (2013) 22\u00e2\u20ac\u201c44 e further denote by B ={y \u00e2\u02c6\u02c6 Y: f y = f y 1 }.IfB = Y,thenweset\u00ce\u00be 2 =|f y 1 |/2; otherwise, \u00ce\u00be 2 = ( f y 1 \u00e2\u02c6\u2019max y /\u00e2\u02c6\u02c6B f y )/2. w, we set \u00ce\u00be =min(\u00ce\u00be 1 ,\u00ce\u00be 2 ) and construct another f \u00e2\u20ac\u00b2 by f \u00e2\u20ac\u00b2 y 1 = f y 1 , f \u00e2\u20ac\u00b2 y = f y for y /\u00e2\u02c6\u02c6 B, and f \u00e2\u20ac\u00b2 y = f y \u00e2\u02c6\u2019 \u00ce\u00be for y = y 1 and y \u00e2\u02c6\u02c6 B. is follows that, from Eq. (25), W (p, f )\u00e2\u02c6\u2019W ( p, f \u00e2\u20ac\u00b2 ) = p y 1 ( \u00cf\u2020(0)\u00e2\u02c6\u2019\u00cf\u2020(\u00ce\u00be) ) \u00e2\u02c6\u2019 \u00e2\u02c6\u2018 y\u00e2\u02c6\u02c6B y =y 1 p y ( \u00cf\u2020(\u00e2\u02c6\u2019\u00ce\u00be)\u00e2\u02c6\u2019\u00cf\u2020(0) ) \u00e2\u2030\u02c6 \u00ce\u00be\u00cf\u2020 \u00e2\u20ac\u00b2 (0) ( \u00e2\u02c6\u2018 y\u00e2\u02c6\u02c6B y =y 1 p y \u00e2\u02c6\u2019 p y 1 ) > 0, here the last inequality holds from \u00cf\u2020 \u00e2\u20ac\u00b2 (0)<0 and p y 1 > 0.5 > p y for y = y 1 . Therefore, we have W (p, f )>W (p, f \u00e2\u20ac\u00b2 ), hich is contrary to the assumption W (p, f )=W \u00e2\u02c6\u2014 (p). This theorem follows. Based on this theorem, we can see clearly that, under the dominating setting, the one-vs-all method of Eq. (19)ismulti- bel consistent w.r.t. hamming loss for exponential loss \u00cf\u2020(t) = exp(\u00e2\u02c6\u2019t), logistic loss \u00cf\u2020(t) = ln(1 + exp(\u00e2\u02c6\u2019t)),hingeloss (t)=max(0,1\u00e2\u02c6\u2019 t), least square hinge loss \u00cf\u2020(t)= (max(0,1\u00e2\u02c6\u2019 t)) 2 ,etc. Before discussing on the consistency of the pairwise comparison method, we introduce the following lemma whose proof deferred to Section 6.4. mma 28. For the pairwise comparison method of Eq. (20),if\u00cf\u2020 is a non-increasing function with \u00cf\u2020 \u00e2\u20ac\u00b2 (0)<0, then for every p \u00e2\u02c6\u02c6\u00ce\u203a d f such that W (p, f )=W \u00e2\u02c6\u2014 (p),wehave f y i f y j for p y i > p y j . Based on this lemma, we have: eorem 29. If \u00cf\u2020 is a convex, non-increasing and differentiable function with \u00cf\u2020 \u00e2\u20ac\u00b2 (0)<0, then the pairwise comparison method of . (20) is consistent w.r.t. hamming loss under the dominating setting. oof. Without loss of generality, we consider a probability simplex p = (p y ) y\u00e2\u02c6\u02c6Y such that p y 1 > 0.5> p y k for k = 1. From s. (17) and (18), it is easy to get the set of Bayes predictions A(p)={f : f y 1 > f y for y = y 1 }. suffices to prove that f \u00e2\u02c6\u02c6A(p) for every f s.t. W (p, f )=W \u00e2\u02c6\u2014 (p). From Lemma 28,wehave f y 1 f y for y = y 1 r every f s.t. W (p, f )=W \u00e2\u02c6\u2014 (p). It remains to prove f y 1 = f y for y = y 1 . Suppose that there exists f such that W (p, f ) = W \u00e2\u02c6\u2014 (p) yet f y 1 = f y 2 for y 1 = y 2 . The subgradient conditions (p, f ) \u00e2\u02c6\u201a f i =0(i = 1,2) give p y 1 \u00e2\u02c6\u2018 y =y 1 \u00cf\u2020 \u00e2\u20ac\u00b2 ( f y 1 \u00e2\u02c6\u2019 f y )\u00e2\u02c6\u2019 \u00e2\u02c6\u2018 y =y 1 p y \u00cf\u2020 \u00e2\u20ac\u00b2 ( f y \u00e2\u02c6\u2019 f y 1 )= 0, p y 2 \u00e2\u02c6\u2018 y =y 2 \u00cf\u2020 \u00e2\u20ac\u00b2 ( f y 2 \u00e2\u02c6\u2019 f y )\u00e2\u02c6\u2019 \u00e2\u02c6\u2018 y =y 2 p y \u00cf\u2020 \u00e2\u20ac\u00b2 ( f y \u00e2\u02c6\u2019 f y 2 )= 0. is yields 2(p y 1 \u00e2\u02c6\u2019 p y 2 )\u00cf\u2020 \u00e2\u20ac\u00b2 (0)+ (p y 1 \u00e2\u02c6\u2019 p y 2 ) \u00e2\u02c6\u2018 y =y 1 ,y 2 \u00cf\u2020 \u00e2\u20ac\u00b2 ( f y 1 \u00e2\u02c6\u2019 f y )= 0, hich is contrary to the facts p y 1 > p y 2 , \u00cf\u2020 \u00e2\u20ac\u00b2 (0)<0 and \u00cf\u2020 \u00e2\u20ac\u00b2 ( f y 1 \u00e2\u02c6\u2019 f y ) 0. From this theorem, we can see that, under the dominating setting, the pairwise comparison method of Eq. (20)is nsistent w.r.t. hamming loss for exponential loss \u00cf\u2020(t) = exp(\u00e2\u02c6\u2019t), logistic loss \u00cf\u2020(t) = ln(1+ exp(\u00e2\u02c6\u2019t)), least square hinge ss \u00cf\u2020(t)= (max(0,1\u00e2\u02c6\u2019 t)) 2 ,etc. It is also noteworthy that the hinge loss \u00cf\u2020(t) =max(0,1\u00e2\u02c6\u2019 t) is not differentiable at t = 1, and Theorem 29 cannot beed to study the consistency of pairwise comparison method w.r.t. hinge loss, whereas we have: Th se Pr Fr It fo co Fo Th Th \u00cb\u2020y Pr Fr It w Si Fu ThW. Gao, Z.-H. Zhou / Artificial Intelligence 199\u00e2\u20ac\u201c200 (2013) 22\u00e2\u20ac\u201c44 39 eorem 30. For hinge loss \u00cf\u2020(t) =max(0,1 \u00e2\u02c6\u2019 t), the pairwise comparison method of Eq. (20) is consistent under the dominating tting. oof. Without loss of generality, we consider the probability simplex p = (p y ) y\u00e2\u02c6\u02c6Y such that p y 1 > 0.5 > p y k for k = 1. om Eqs. (17) and (18), it is easy to get the set of Bayes predictions A(p)={f : f y 1 > f y for y = y 1 }. suffices to prove f \u00e2\u02c6\u02c6A(p) for every f s.t. W (p, f )=W \u00e2\u02c6\u2014 (p). From Lemma 28,wehave f y 1 f y for y = y 1 , r every f s.t. W (p, f )=W \u00e2\u02c6\u2014 (p). It remains to prove f \u00e2\u02c6\u2014 y 1 = f \u00e2\u02c6\u2014 y for y = y 1 . Assume that there exists f = ( f y i ) y i \u00e2\u02c6\u02c6Y such that W (p, f )= W \u00e2\u02c6\u2014 (p) yet f y 1 = f y 2 for y 1 = y 2 . For small \u00ce\u00be \u00e2\u02c6\u02c6 (0,1),we nstruct another f \u00e2\u20ac\u00b2 by f \u00e2\u20ac\u00b2 y 1 = f y 1 + \u00ce\u00be, and f \u00e2\u20ac\u00b2 y = f y for y = y 1 . r hinge loss \u00cf\u2020(t)=max(0,1\u00e2\u02c6\u2019 t),wehave W (p, f )\u00e2\u02c6\u2019W ( p, f \u00e2\u20ac\u00b2 ) = p y 1 ( \u00cf\u2020(0)\u00e2\u02c6\u2019\u00cf\u2020(\u00ce\u00be) ) + p y 1 \u00e2\u02c6\u2018 y =y 1 y =y 2 ( \u00cf\u2020( f y 1 \u00e2\u02c6\u2019 f y )\u00e2\u02c6\u2019\u00cf\u2020( f y 1 \u00e2\u02c6\u2019 f y + \u00ce\u00be) ) \u00e2\u02c6\u2019 \u00e2\u02c6\u2018 y =y 1 p y ( \u00cf\u2020( f y \u00e2\u02c6\u2019 f y 1 \u00e2\u02c6\u2019 \u00ce\u00be)\u00e2\u02c6\u2019\u00cf\u2020( f y \u00e2\u02c6\u2019 f y 1 ) ) p y 1 ( \u00cf\u2020(0)\u00e2\u02c6\u2019\u00cf\u2020(\u00ce\u00be) ) \u00e2\u02c6\u2019 \u00e2\u02c6\u2018 y =y 1 p y ( \u00cf\u2020( f y \u00e2\u02c6\u2019 f y 1 \u00e2\u02c6\u2019 \u00ce\u00be)\u00e2\u02c6\u2019\u00cf\u2020( f y \u00e2\u02c6\u2019 f y 1 ) ) = \u00ce\u00be(2p y 1 \u00e2\u02c6\u2019 1)>0. is implies W (p, f )>W (p, f \u00e2\u20ac\u00b2 ), yet it is contrary to W (p, f )=W \u00e2\u02c6\u2014 (p). We now consider the formulation (23)ofTaskaretal.[29], Hariharan et al. [19] under the dominating case: eorem 31. Under the dominating setting, the surrogate loss\u00ce\u00a8 of Eq. (23) is consistent w.r.t. hamming loss for \u00ce\u00b4( \u00cb\u2020y, y)= \u00e2\u02c6\u2018 q i=1 I[y i = i ] and \u00cf\u2020(t)=max(0, t). oof. Without loss of generality, we consider the probability simplex p = (p y ) y\u00e2\u02c6\u02c6Y such that p y 1 > 0.5 > p y k for k = 1. om Eqs. (17) and (18), it is easy to get the set of Bayes predictions A(p)={f : f y 1 > f y for y = y 1 }. suffices to prove that f \u00e2\u02c6\u02c6A(p) for every f s.t. W (p, f )=W \u00e2\u02c6\u2014 (p). Suppose that there exists f /\u00e2\u02c6\u02c6A(p) and W (p, f )=W \u00e2\u02c6\u2014 (p), i.e., it holds that f y 1 f y\u00cb\u2020 for some \u00cb\u2020y \u00e2\u02c6\u02c6Y and y 1 = \u00cb\u2020y. Then, e can construct another f \u00e2\u20ac\u00b2 by f \u00e2\u20ac\u00b2 y 1 = f y 1 + 1, f \u00e2\u20ac\u00b2 y = f y for y = y 1 , y \u00e2\u02c6\u02c6 Y. nce y 1 = \u00cb\u2020y and f y 1 f y\u00cb\u2020 ,wehave\u00ce\u00b4(y 1 , \u00cb\u2020y) 1 and p y 1 max y =y 1 { \u00cf\u2020 ( \u00ce\u00b4(y, y 1 )+ f y \u00e2\u02c6\u2019 f y 1 )} \u00e2\u02c6\u2019 p y 1 max y =y 1 { \u00cf\u2020 ( \u00ce\u00b4(y, y 1 )+ f y \u00e2\u02c6\u2019 f y 1 \u00e2\u02c6\u2019 1 )} = p y 1 . rther, it holds that p y i max y =y i { \u00cf\u2020 ( \u00ce\u00b4(y, y i )+ f y \u00e2\u02c6\u2019 f y i )} \u00e2\u02c6\u2019 p y i max y =y i { \u00cf\u2020 ( \u00ce\u00b4(y, y i )+ f \u00e2\u20ac\u00b2 y \u00e2\u02c6\u2019 f \u00e2\u20ac\u00b2 y i )} = p y i max { \u00cf\u2020 ( \u00ce\u00b4(y 1 , y i )+ f y 1 \u00e2\u02c6\u2019 f y i ) , max y =y i ,y 1 \u00cf\u2020 ( \u00ce\u00b4(y, y i )+ f y \u00e2\u02c6\u2019 f y i ) } \u00e2\u02c6\u2019 p y i max { \u00cf\u2020 ( \u00ce\u00b4(y 1 , y i )+ f y 1 + 1\u00e2\u02c6\u2019 f y i ) , max y =y i ,y 1 \u00cf\u2020 ( \u00ce\u00b4(y, y i )+ f y \u00e2\u02c6\u2019 f y i ) } \u00e2\u02c6\u2019p y i .erefore, we have 40 w 5. lo th A w ex w Th ca Th of 6.W. Gao, Z.-H. Zhou / Artificial Intelligence 199\u00e2\u20ac\u201c200 (2013) 22\u00e2\u20ac\u201c44 W (p, f )\u00e2\u02c6\u2019W ( p, f \u00e2\u20ac\u00b2 ) = p y 1 max y =y 1 { \u00cf\u2020 ( \u00ce\u00b4(y, y 1 )+ f y \u00e2\u02c6\u2019 f y 1 )} \u00e2\u02c6\u2019 p y 1 max y =y 1 { \u00cf\u2020 ( \u00ce\u00b4(y, y 1 )+ f y \u00e2\u02c6\u2019 f y 1 \u00e2\u02c6\u2019 1 )} + \u00e2\u02c6\u2018 y i =y 1 p y i max y =y i { \u00cf\u2020 ( \u00ce\u00b4(y, y i )+ f y \u00e2\u02c6\u2019 f y i )} \u00e2\u02c6\u2019 p y i max y =y i { \u00cf\u2020 ( \u00ce\u00b4(y, y i )+ f \u00e2\u20ac\u00b2 y \u00e2\u02c6\u2019 f \u00e2\u20ac\u00b2 y i )} p y 1 \u00e2\u02c6\u2019 \u00e2\u02c6\u2018 y =y 1 p y > 0, hich is contrary to W (p, f )=W \u00e2\u02c6\u2014 (p). This completes the proof. 3. Solving multi-label learning by binary classifications It is possible to decompose a multi-label learning task into q independent binary classification tasks [3] when hamming ss is concerned, especially when there are just a few labels. Now the goal is to learn q functions, f = ( f 1 , f 2 ,..., f q ), and e prediction function is given by F ( f (x) ) = ( sgn [ f 1 (x) ] , sgn [ f 2 (x) ] ,...,sgn [ f q (x) ]) . common choice for the surrogate loss is \u00ce\u00a8 ( f (x), y ) = q \u00e2\u02c6\u2018 i=1 \u00cf\u2020 ( y i f i (x) ) , (26) here \u00cf\u2020 is a convex function. For example, it was chosen as hinge loss \u00cf\u2020(t) = (1\u00e2\u02c6\u2019 t) + in Elisseeff and Weston [14] and ponential loss \u00cf\u2020(t)= exp(\u00e2\u02c6\u2019t) in Schapire and Singer [27], respectively. We have the conditional surrogate loss W (p, f )= \u00e2\u02c6\u2018 y\u00e2\u02c6\u02c6Y p y \u00ce\u00a8 ( f (x), y ) = q \u00e2\u02c6\u2018 i=1 \u00e2\u02c6\u2018 y\u00e2\u02c6\u02c6Y p y \u00cf\u2020 ( y i f i (x) ) = q \u00e2\u02c6\u2018 i=1 p + i \u00cf\u2020 ( f i (x) ) + ( 1\u00e2\u02c6\u2019 p + i ) \u00cf\u2020 ( \u00e2\u02c6\u2019 f i (x) ) , here p + i = \u00e2\u02c6\u2018 y:y i =+1 p y and 1\u00e2\u02c6\u2019 p + i = \u00e2\u02c6\u2018 y:y i =\u00e2\u02c6\u20191 p y . For simplicity, we denote W i ( p + i , f i ) = p + i \u00cf\u2020( f i )+ ( 1\u00e2\u02c6\u2019 p + i ) \u00cf\u2020(\u00e2\u02c6\u2019 f i ). is yields that minimizing W (p, f ) is equivalent to minimizing W i (p + i , f i ) for every 1 i q, that is, W \u00e2\u02c6\u2014 (p)= inf f W (p, f )= q \u00e2\u02c6\u2018 i=1 inf f i W i ( p + i , f i ) . The consistency for binary classification has been well-studied [1,37], and based on the work of Bartlett et al. [1],we n easily get: eorem 32. If \u00cf\u2020 is a convex function with \u00cf\u2020 \u00e2\u20ac\u00b2 (0)<0, then the surrogate loss \u00ce\u00a8 given by Eq. (26) is consistent w.r.t. hamming loss. It is evident from this theorem that the surrogate loss \u00ce\u00a8 given by Eq. (26) is consistent w.r.t. hamming loss if \u00cf\u2020 is any the following: \u00e2\u20ac\u00a2 Exponential loss: \u00cf\u2020(t)= exp(\u00e2\u02c6\u2019t); \u00e2\u20ac\u00a2 Hinge loss: \u00cf\u2020(t)=max(0,1\u00e2\u02c6\u2019 t); \u00e2\u20ac\u00a2 Least squares loss: \u00cf\u2020(t)= (1\u00e2\u02c6\u2019 t) 2 ; \u00e2\u20ac\u00a2 Logistic loss: \u00cf\u2020(t)= ln(1+ exp(\u00e2\u02c6\u2019t)); \u00e2\u20ac\u00a2 Least squares hinge loss: \u00cf\u2020(t)= (max(0,1\u00e2\u02c6\u2019 t)) 2 . Proofs of lemmasIn this section, we provide the detailed proofs of lemmas. 6. fo un Fr an w w 6. th Fr w Si Th f wW. Gao, Z.-H. Zhou / Artificial Intelligence 199\u00e2\u20ac\u201c200 (2013) 22\u00e2\u20ac\u201c44 41 1. Proof of Lemma 5 From the Heine definition of continuity, it is sufficient to show W \u00e2\u02c6\u2014 ( p (n) ) \u00e2\u2020\u2019W \u00e2\u02c6\u2014 (p) r any sequence p (n) \u00e2\u2020\u2019 p. Let B r be a closed ball with radius r in R K .Because|Y| is finite, we have \u00e2\u02c6\u2018 y\u00e2\u02c6\u02c6Y p (n) y \u00ce\u00a8(f , y)\u00e2\u2020\u2019 \u00e2\u02c6\u2018 y\u00e2\u02c6\u02c6Y p y \u00ce\u00a8(f , y) iformly for every f \u00e2\u02c6\u02c6 B r and every sequence p (n) \u00e2\u2020\u2019 p,leadingto inf f \u00e2\u02c6\u02c6B r \u00e2\u02c6\u2018 y\u00e2\u02c6\u02c6Y p (n) y \u00ce\u00a8(f , y)\u00e2\u2020\u2019 inf f \u00e2\u02c6\u02c6B r \u00e2\u02c6\u2018 y\u00e2\u02c6\u02c6Y p y \u00ce\u00a8(f , y). om W \u00e2\u02c6\u2014 ( p (n) ) inf f \u00e2\u02c6\u02c6B r \u00e2\u02c6\u2018 y\u00e2\u02c6\u02c6Y p (n) y \u00ce\u00a8(f , y), d letting r \u00e2\u2020\u2019\u00e2\u02c6\u017e,wehave lim sup n\u00e2\u2020\u2019\u00e2\u02c6\u017e W \u00e2\u02c6\u2014 ( p (n) ) W \u00e2\u02c6\u2014 (p). (27) Denote Y \u00e2\u20ac\u00b2 ={y|p y >0for y \u00e2\u02c6\u02c6Y} and assume \u00ce\u00a8(\u00c2\u00b7, \u00c2\u00b7) C for some constant C (since \u00ce\u00a8 is below-bounded). We have W \u00e2\u02c6\u2014 ( p (n) ) inf f \u00e2\u02c6\u2018 y\u00e2\u02c6\u02c6Y \u00e2\u20ac\u00b2 p (n) y \u00ce\u00a8(f , y)+ C \u00e2\u02c6\u2018 y\u00e2\u02c6\u02c6Y/Y \u00e2\u20ac\u00b2 p (n) y , hich yields lim inf n\u00e2\u2020\u2019\u00e2\u02c6\u017e W \u00e2\u02c6\u2014 ( p (n) ) lim inf n\u00e2\u2020\u2019\u00e2\u02c6\u017e ( inf f \u00e2\u02c6\u2018 y\u00e2\u02c6\u02c6Y \u00e2\u20ac\u00b2 p (n) y \u00ce\u00a8(f , y)+ C \u00e2\u02c6\u2018 y\u00e2\u02c6\u02c6Y/Y \u00e2\u20ac\u00b2 p (n) y ) =W \u00e2\u02c6\u2014 (p), hich completes the proof by combining Eq. (27). 2. Proof of Lemma 6 We proceed by contradiction. Suppose \u00ce\u00a8 is multi-label consistent and there exist > 0 and a sequence (p (n) , f (n) ) such at l ( p (n) , f (n) ) \u00e2\u02c6\u2019 inf f \u00e2\u20ac\u00b2 l ( p (n) , f \u00e2\u20ac\u00b2 ) and W ( p (n) , f (n) ) \u00e2\u2020\u2019W \u00e2\u02c6\u2014 ( p (n) ) . om the compactness of \u00ce\u203a, there exists a convergence sequence n k such that p (n k ) \u00e2\u2020\u2019 p for some p \u00e2\u02c6\u02c6\u00ce\u203a. From Lemma 5, e have W ( p (n k ) , f (n k ) ) \u00e2\u2020\u2019W \u00e2\u02c6\u2014 (p). milar to the proof of Lemma 5,wesetY \u00e2\u20ac\u00b2 ={y|p y >0for y \u00e2\u02c6\u02c6Y}, and get lim sup n k W ( p, f (n k ) ) = lim sup n k ( C \u00e2\u02c6\u2018 y\u00e2\u02c6\u02c6Y/Y \u00e2\u20ac\u00b2 p (n k ) y + inf f \u00e2\u02c6\u2018 y\u00e2\u02c6\u02c6Y \u00e2\u20ac\u00b2 p (n k ) y \u00ce\u00a8 ( f (n k ) , y ) ) lim n k W ( p (n k ) , f (n k ) ) =W \u00e2\u02c6\u2014 (p). is gives W (p, f (n k ) )\u00e2\u2020\u2019 W \u00e2\u02c6\u2014 (p) from the definition of W \u00e2\u02c6\u2014 (p).Since\u00ce\u00a8 is multi-label consistent, there exists a sequence (n k i ) such that l ( p, f (n k i ) ) \u00e2\u2020\u2019 inf f \u00e2\u20ac\u00b2 l ( p, f \u00e2\u20ac\u00b2 ) ,hich contradicts the assumption l(p (n) , f (n) )\u00e2\u02c6\u2019 inf f \u00e2\u20ac\u00b2 l(p (n) , f \u00e2\u20ac\u00b2 ) , and the lemma follows. 42 6. Fo w ob To Th 6. an Th Fo an Fr deW. Gao, Z.-H. Zhou / Artificial Intelligence 199\u00e2\u20ac\u201c200 (2013) 22\u00e2\u20ac\u201c44 Fig. 1. Lines I 1 (solid) and I 2 (dashed) corresponding to Eqs. (11)and(12), respectively. 3. Proof of Lemma 14 From Eq. (9), we set 1< P 1 P 2 < \u00cf\u2020 \u00e2\u20ac\u00b2 (b\u00e2\u02c6\u2019 a)(\u00cf\u2020 \u00e2\u20ac\u00b2 (a)+ \u00cf\u2020 \u00e2\u20ac\u00b2 (b))+ \u00cf\u2020 \u00e2\u20ac\u00b2 (b)\u00cf\u2020 \u00e2\u20ac\u00b2 (\u00e2\u02c6\u2019a) \u00cf\u2020 \u00e2\u20ac\u00b2 (a\u00e2\u02c6\u2019 b)(\u00cf\u2020 \u00e2\u20ac\u00b2 (a)+ \u00cf\u2020 \u00e2\u20ac\u00b2 (b))+ \u00cf\u2020 \u00e2\u20ac\u00b2 (b)\u00cf\u2020 \u00e2\u20ac\u00b2 (a) . (28) r a< b,wehave\u00cf\u2020 \u00e2\u20ac\u00b2 (a\u00e2\u02c6\u2019 b) \u00cf\u2020 \u00e2\u20ac\u00b2 (b\u00e2\u02c6\u2019 a)<0, yielding P 1 P 2 > 1 \u00cf\u2020 \u00e2\u20ac\u00b2 (b\u00e2\u02c6\u2019 a) \u00cf\u2020 \u00e2\u20ac\u00b2 (a\u00e2\u02c6\u2019 b) , hich gives P 1 \u00cf\u2020 \u00e2\u20ac\u00b2 (a \u00e2\u02c6\u2019 b) \u00e2\u02c6\u2019 P 2 \u00cf\u2020 \u00e2\u20ac\u00b2 (b \u00e2\u02c6\u2019 a)<0. Thus, Eq. (11) corresponds to the line I 1 in Fig. 1.FromEq.(10), we further tain 0< \u00cf\u2020 \u00e2\u20ac\u00b2 (\u00e2\u02c6\u2019a)+ \u00cf\u2020 \u00e2\u20ac\u00b2 (\u00e2\u02c6\u2019b) \u00cf\u2020 \u00e2\u20ac\u00b2 (a)+ \u00cf\u2020 \u00e2\u20ac\u00b2 (b) < \u00cf\u2020 \u00e2\u20ac\u00b2 (\u00e2\u02c6\u2019b) \u00cf\u2020 \u00e2\u20ac\u00b2 (b) . guarantee P 3 > 0 and P 4 > 0 satisfying Eqs. (11) and (12), as shown in Fig. 1,weneed: P 1 \u00cf\u2020 \u00e2\u20ac\u00b2 (a\u00e2\u02c6\u2019 b)\u00e2\u02c6\u2019 P 2 \u00cf\u2020 \u00e2\u20ac\u00b2 (b\u00e2\u02c6\u2019 a) \u00cf\u2020 \u00e2\u20ac\u00b2 (b) < \u00e2\u02c6\u2019P 1 \u00cf\u2020 \u00e2\u20ac\u00b2 (a)+ P 2 \u00cf\u2020 \u00e2\u20ac\u00b2 (\u00e2\u02c6\u2019a) \u00cf\u2020 \u00e2\u20ac\u00b2 (a)+ \u00cf\u2020 \u00e2\u20ac\u00b2 (b) . e above holds obviously from Eq. (28). Thus, we complete the proof. 4. Proof of Lemma 28 We proceed by contradiction. Suppose there exists a probability simplex p \u00e2\u02c6\u02c6 \u00ce\u203a and f such that f y 1 < f y 2 , p y 1 > p y 2 d W \u00e2\u02c6\u2014 (p)=W (p, f ). We can construct another f \u00e2\u20ac\u00b2 by f \u00e2\u20ac\u00b2 y 1 = f y 2 , f \u00e2\u20ac\u00b2 y 2 = f y 1 , and f \u00e2\u20ac\u00b2 y k = f y k for k = 1,2. is follows W (p, f )\u00e2\u02c6\u2019W ( p, f \u00e2\u20ac\u00b2 ) = (p y 1 \u00e2\u02c6\u2019 p y 2 ) ( \u00cf\u2020( f y 1 \u00e2\u02c6\u2019 f y 2 )\u00e2\u02c6\u2019\u00cf\u2020( f y 2 \u00e2\u02c6\u2019 f y 1 ) ) + (p y 1 \u00e2\u02c6\u2019 p y 2 ) \u00e2\u02c6\u2018 y k =y 1 y k =y 2 ( \u00cf\u2020( f y 1 \u00e2\u02c6\u2019 f y k )\u00e2\u02c6\u2019\u00cf\u2020( f y 2 \u00e2\u02c6\u2019 f y k ) ) . (29) r non-increasing function \u00cf\u2020,wehave \u00cf\u2020( f y 1 \u00e2\u02c6\u2019 f y i ) \u00cf\u2020( f y 2 \u00e2\u02c6\u2019 f y i ), d from \u00cf\u2020 \u00e2\u20ac\u00b2 (0)<0, we further get \u00cf\u2020( f y 1 \u00e2\u02c6\u2019 f y 2 )>\u00cf\u2020(f y 2 \u00e2\u02c6\u2019 f y 1 ). om Eq. (29), we have W (p, f )>W (p, f \u00e2\u20ac\u00b2 ), which is contrary to the assumption W \u00e2\u02c6\u2014 (p)= W (p, f ). The lemma holds assired. Ta Su 7. st un m an it ra re th so re in m in et ad in no pr pr al A re Fo Re [ [ [ [ [ [ [ [ [ [1 [1W. Gao, Z.-H. Zhou / Artificial Intelligence 199\u00e2\u20ac\u201c200 (2013) 22\u00e2\u20ac\u201c44 43 ble 1 mmary of consistency result, where \u00e2\u02c6\u0161 /\u00c3\u2014 indicates consistency/inconsistency. Loss function \u00cf\u2020 Ranking loss Partial ranking loss Hamming loss Eq. (4)Eq.(4)Eq.(15)Eq.(19)Eq.(20) Logistic \u00c3\u2014\u00c3\u2014 \u00e2\u02c6\u0161 \u00c3\u2014\u00c3\u2014 Hinge \u00c3\u2014 Exponential \u00e2\u02c6\u0161 Least square \u00e2\u02c6\u0161 \u00c3\u2014\u00c3\u2014 Least square hinge \u00c3\u2014\u00c3\u2014 \u00e2\u02c6\u0161 Regularized linear \u00c3\u2014 \u00e2\u02c6\u0161 Conclusion and future work During the past decade, multi-label learning has attracted significant attention in the machine learning community. Most udies have been devoted to the algorithm designs and diverse applications. Theoretical analysis, however, remains almost touched for multi-label learning. This paper extends our preliminary work [16], which tries to study the consistency of ulti-label learning based on surrogate losses. We present a necessary and sufficient condition for multi-label consistency, d study two well-known loss functions, i.e., ranking loss and hamming loss. Our main results are summarized in Table 1. The ranking loss is one of the most popularly used multi-label criteria and many approaches [9,14,27,34] try to optimize under the formulation of Eq. (4). Our analysis, however, discloses that none of convex surrogate loss is consistent w.r.t. nking loss; therefore, ranking loss might not be a good criterion for multi-label learning. The partial ranking loss is more asonable than ranking loss because, on one hand it keeps the nature of ranking loss (by ranking relevant labels higher an irrelevant ones), and on the other hand, it enables many, though not all, convex surrogate losses to be consistent. The hamming loss is also one of the most popularly used multi-label criteria, based on which it is natural to develop me learning approaches from multi-class learning, e.g., the one-vs-all method and the pairwise comparison method. Our sults disclose that these approaches are inconsistent w.r.t. hamming loss for general cases yet consistent under the dom- ating setting, and similar results also hold for some multi-label approaches [19,29] that are variations of the one-vs-all ethod. In addition, we discuss on the consistency of approaches that address multi-label learning by decomposing the task to a set of binary classification problems. An important future work is to investigate the convergence rate of consistent surrogate loss functions as in Bartlett al. [1]. How to incorporate label correlation into the study of multi-label consistency also remains an open problem. In dition, our work may motivate the consistency researches on other multi-label criteria such as one-error, F 1 ,etc.Itisalso teresting to develop some new multi-label learning approaches by minimizing the partial ranking loss. Note that we do t consider how to decide the number of relevant labels for ranking loss and partial ranking loss in this work, whereas in actice this is quite challenging. For hamming loss, it is extremely important to explore new surrogate losses and find new ediction rules for developing consistent approaches, because none of existing algorithms is consistent in general cases. It is so interesting to make a comprehensive empirical study on various approaches and formulations for multi-label learning. cknowledgement The authors want to thank the anonymous reviewers and associate editor for helpful comments and suggestions. This search was supported by the National Fundamental Research Program of China (2010CB327903), the National Science undation of China (61073097, 61021062), and Jiangsu Province University Innovative Research Project (CXZZ11_0046). ferences 1] P.L. Bartlett, M.I. Jordan, J.D. McAuliffe, Convexity, classification, and risk bounds, Journal of the American Statistical Association 101 (473) (2006) 138\u00e2\u20ac\u201c156. 2] S. Ben-David, D. Loker, N. Srebro, K. Sridharan, Minimizing the misclassification error rate using a surrogate convex loss, in: Proceedings of the 29th International Conference on Machine Learning, Edinburgh, Scotland, 2012. 3] M.R. Boutell, J. Luo, X. Shen, C. Brown, Learning multi-label scene classification, Pattern Recognition 37 (9) (2004) 1757\u00e2\u20ac\u201c1771. 4] L. Breiman, Some infinity theory for predictor ensembles, Annals of Statistics 32 (1) (2004) 1\u00e2\u20ac\u201c11. 5] P. B\u00c3\u00bchlmann, B. Yu, Boosting with l\u00e2\u02c6\u2019 2-loss: Regression and classification, Journal of the American Statistical Association 98 (462) (2003) 324\u00e2\u20ac\u201c339. 6] G. Carneiro, A. Chan, P. Moreno, N. Vasconcelos, Supervised learning of semantic classes for image annotation and retrieval, IEEE Transactions on Pattern Analysis and Machine Intelligence 29 (3) (2007) 394\u00e2\u20ac\u201c410. 7] D. Cossock, T. Zhang, Statistical analysis of Bayes optimal subset ranking, IEEE Transactions on Information Theory 54 (11) (2008) 5140\u00e2\u20ac\u201c5154. 8] K. Crammer, Y. Singer, On the algorithmic implementation of multiclass kernel-based vector machines, Journal of Machine Learning Research 2 (2001) 265\u00e2\u20ac\u201c292. 9] O. Dekel, C. Manning, Y. Singer, Log-linear models for label ranking, in: S. Thrun, L.K. Saul, B. Sch\u00c3\u00b6lkopf (Eds.), Advances in Neural Information Process- ing Systems, vol. 16, MIT Press, Cambridge, MA, 2004. 0] K. Dembczyn\u00c2\u00b4ski, W.W. Cheng, E. H\u00c3\u00bcllermeier, Bayes optimal multilabel classification via probabilistic classifier chains, in: Proceedings of the 27th International Conference on Machine Learning, Haifa, Israel, 2010, pp. 279\u00e2\u20ac\u201c286.1] K. Dembczyn\u00c2\u00b4ski, W. Kotlowski, E. H\u00c3\u00bcllermeier, Consistent multi-label ranking through univariate loss minimization, in: Proceedings of the 29th Inter- national Conference on Machine Learning, New York, NY, 2012, pp. 1319\u00e2\u20ac\u201c1326. 44 W. Gao, Z.-H. Zhou / Artificial Intelligence 199\u00e2\u20ac\u201c200 (2013) 22\u00e2\u20ac\u201c44 [12] K. Dembczyn\u00c2\u00b4ski, W. Waegeman, W. Cheng, E. H\u00c3\u00bcllermeier, On label dependence and loss minimization in multi-label classification, Machine Learn- ing 88 (1\u00e2\u20ac\u201c2) (2012) 5\u00e2\u20ac\u201c45. [13] J.C. Duchi, L.W. Mackey, M.I. Jordan, On the consistency of ranking algorithms, in: Proceedings of the 27th International Conference on Machine Learning, Haifa, Israel, 2010, pp. 327\u00e2\u20ac\u201c334. [14] A. Elisseeff, J. Weston, A kernel method for multi-labelled classification, in: T.G. Dietterich, S. Becker, Z. Ghahramani (Eds.), Advances in Neural Infor- mation Processing Systems, vol. 14, MIT Press, Cambridge, MA, 2002, pp. 681\u00e2\u20ac\u201c687. [15] J. F\u00c3\u00bcrnkranz, E. H\u00c3\u00bcllermeier, E.L. Menc\u00c3\u00ada, K. Brinker, Multilabel classification via calibrated label ranking, Machine Learning 73 (2) (2008) 133\u00e2\u20ac\u201c153. [16] W. Gao, Z.-H. Zhou, On the consistency of multi-label learning, in: Proceedings of the 24th Annual Conference on Learning Theory, Budapest, Hungary, 2011, pp. 341\u00e2\u20ac\u201c358. [17] N. Ghamrawi, A. McCallum, Collective multi-label classification, in: Proceedings of the 14th ACM International Conference on Information and Knowl- edge Management, Bremen, Germany, 2005, pp. 195\u00e2\u20ac\u201c200. [18] S. Godbole, S. Sarawagi, Discriminative methods for multi-labeled classification, in: Proceedings of the 8th Pacific-Asia Conference on Knowledge Discovery and Data Mining, Sydney, Australia, 2004, pp. 22\u00e2\u20ac\u201c30. [19] B. Hariharan, L. Zelnik-Manor, S. Vishwanathan, M. Varma, Large scale max-margin multi-label classification with priors, in: Proceedings of the 27th International Conference on Machine Learning, Haifa, Israel, 2010, pp. 423\u00e2\u20ac\u201c430. [20] D. Hsu, S.M. Kakade, J. Langford, T. Zhang, Multi-label prediction via compressed sensing, in: Y. Bengio, D. Schuurmans, J. Lafferty, C.K.I. Williams, A. Culotta (Eds.), Advances in Neural Information Processing Systems, vol. 22, MIT Press, Cambridge, MA, 2009, pp. 772\u00e2\u20ac\u201c780. [21] E. H\u00c3\u00bcllermeier, J. F\u00c3\u00bcrnkranz, W. Cheng, K. Brinker, Label ranking by learning pairwise preferences, Artificial Intelligence 172 (16\u00e2\u20ac\u201c17) (2008) 1897\u00e2\u20ac\u201c1916. [22] Y. Lin, Support vector machines and the Bayes rule in classification, Data Mining and Knowledge Discovery 6 (3) (2002) 259\u00e2\u20ac\u201c275. [23] D. McAllester, J. Keshet, Generalization bounds and consistency for latent structural probit and ramp loss, in: J. Shawe-Taylor, R.S. Zemel, P.L. Bartlett, F. Pereira, K.Q. Weinberger (Eds.), Advances in Neural Information Processing Systems, vol. 23, MIT Press, 2011, pp. 2205\u00e2\u20ac\u201c2212. [24] J. Petterson, T. Caetano, Reverse multi-label learning, in: J. Lafferty, C.K.I. Williams, J. Shawe-Taylor, R.S. Zemel, A. Culotta (Eds.), Advances in Neural Information Processing Systems, vol. 23, MIT Press, Cambridge, MA, 2010, pp. 1912\u00e2\u20ac\u201c1920. [25] G.-J. Qi, X.-S. Hua, Y. Rui, J. Tang, T. Mei, H.-J. Zhang, Correlative multi-label video annotation, in: Proceedings of the 15th ACM InternationalConference on Multimedia, Augsburg, Germany, 2007, pp. 17\u00e2\u20ac\u201c26. [26] R.T. Rockafellar, Convex Analysis, Princeton University Press, Princeton, NJ, 1997. [2 [2 [2 [3 [3 [3 [3 [3 [3 [3 [3 [3 [37] R.E. Schapire, Y. Singer, BoosTexter: A boosting-based system for text categorization, Machine Learning 39 (2) (2000) 135\u00e2\u20ac\u201c168. 8] I. Steinwart, Consistency of support vector machines and other regularized kernel classifiers, IEEE Transactions on Information Theory 51 (1) (2005) 128\u00e2\u20ac\u201c142. 9] B. Taskar, C. Guestrin, D. Koller, Max-margin Markov networks, in: S. Thrun, L. Saul, B. Sch\u00c3\u00b6lkopf (Eds.), Advances in Neural Information Processing Systems, vol. 16, MIT Press, Cambridge, MA, 2004. 0] A. Tewari, P.L. Bartlett, On the consistency of multiclass classification methods, Journal of Machine Learning Research 8 (2007) 1007\u00e2\u20ac\u201c1025. 1] J. Weston, C. Watkins, Multi-class support vector machines, Tech. Rep. CSD-TR-98-04, Royal Holloway, 1998. 2] F. Xia, T.Y. Liu, H. Li, Top-k consistency of learning to rank methods, in: Y. Bengio, D. Schuurmans, J. Lafferty, C.K.I. Williams, A. Culotta (Eds.), Advances in Neural Information Processing Systems, vol. 22, MIT Press, Cambridge, MA, 2009, pp. 2098\u00e2\u20ac\u201c2106. 3] F. Xia, T.Y. Liu, J. Wang, W. Zhang, H. Li, Listwise approach to learning to rank: Theory and algorithm, in: Proceedings of the 25th International Conference on Machine Learning, Helsinki, Finland, 2008, pp. 1192\u00e2\u20ac\u201c1199. 4] M.-L. Zhang, Z.-H. Zhou, Multi-label neural network with applications to functional genomics and text categorization, IEEE Transactions on Knowledge and Data Engineering 18 (10) (2006) 1338\u00e2\u20ac\u201c1351. 5] M.-L. Zhang, Z.-H. Zhou, ML-KNN: A lazy learning approach to multi-label learning, Pattern Recognition 40 (7) (2007) 2038\u00e2\u20ac\u201c2048. 6] T. Zhang, Statistical analysis of some multi-category large margin classification methods, Journal of Machine Learning Research 5 (2004) 1225\u00e2\u20ac\u201c1251. 7] T. Zhang, Statistical behavior and consistency of classification methods based on convex risk minimization, Annals of Statistics 32 (1) (2004) 56\u00e2\u20ac\u201c85. 8] Z.-H. Zhou, M.-L. Zhang, Multi-instance multi-label learning with application to scene classification, in: B. Sch\u00c3\u00b6lkopf, J. Platt, T. Hofmann (Eds.), Ad- vances in Neural Information Processing Systems, vol. 19, MIT Press, Cambridge, MA, 2007, pp. 1609\u00e2\u20ac\u201c1616. 9] Z.-H. Zhou, M.-L. Zhang, S.-J. Huang, Y.-F. Li, Multi-instance multi-label learning, Artificial Intelligence 176 (1) (2012) 2291\u00e2\u20ac\u201c2320. 8th Pacific-Asia Conference on Knowledge Discovery and Data Mining, Sydney, Australia, 2004, pp. 22\u00e2\u20ac\u201c30. [19] B. Hariharan, L. Zelnik-Manor, S. Vishwanathan, M. Varma, Large scale max-margin multi-label classification with priors, in: Proceedings of the 27th International Conference on Machine Learning, Haifa, Israel, 2010, pp. 423\u00e2\u20ac\u201c430. [20] D. Hsu, S.M. Kakade, J. Langfo ARTINT 2702 S0004-3702(13)00031-3 10.1016/j.artint.2013.03.001 Elsevier B.V. \u00a9 2013 Elsevier B.V. All rights reserved. On the consistency of multi-label learning Wei Gao Zhi-Hua Zhou \u204e National Key Laboratory for Novel Software Technology, Nanjing University, Nanjing 210023, China National Key Laboratory for Novel Software Technology Nanjing University Nanjing 210023 China \u204e Corresponding author. Multi-label learning has attracted much attention during the past few years. Many multi-label approaches have been developed, mostly working with surrogate loss functions because multi-label loss functions are usually difficult to optimize directly owing to their non-convexity and discontinuity. These approaches are effective empirically, however, little effort has been devoted to the understanding of their consistency, i.e., the convergence of the risk of learned functions to the Bayes risk. In this paper, we present a theoretical analysis on this important issue. We first prove a necessary and sufficient condition for the consistency of multi-label learning based on surrogate loss functions. Then, we study the consistency of two well-known multi-label loss functions, i.e., ranking loss and hamming loss. For ranking loss, our results disclose that, surprisingly, none of convex surrogate loss is consistent; we present the partial ranking loss, with which some surrogate losses are proven to be consistent. We also discuss on the consistency of univariate surrogate losses. For hamming loss, we show that two multi-label learning methods, i.e., one-vs-all and pairwise comparison, which can be regarded as direct extensions from multi-class learning, are inconsistent in general cases yet consistent under the dominating setting, and similar results also hold for some recent multi-label approaches that are variations of one-vs-all. In addition, we discuss on the consistency of learning approaches that address multi-label learning by decomposing into a set of binary classification problems. Keywords Machine learning Multi-label learning Surrogate loss Bayes consistency Ranking loss Hamming loss References [1] P.L. Bartlett M.I. Jordan J.D. McAuliffe Convexity, classification, and risk bounds Journal of the American Statistical Association 101 473 2006 138 156 [2] S. Ben-David D. Loker N. Srebro K. Sridharan Minimizing the misclassification error rate using a surrogate convex loss Proceedings of the 29th International Conference on Machine Learning Edinburgh, Scotland 2012 [3] M.R. Boutell J. Luo X. Shen C. Brown Learning multi-label scene classification Pattern Recognition 37 9 2004 1757 1771 [4] L. Breiman Some infinity theory for predictor ensembles Annals of Statistics 32 1 2004 1 11 [5] P. B\u00fchlmann B. Yu Boosting with l \u2212 2 -loss: Regression and classification Journal of the American Statistical Association 98 462 2003 324 339 [6] G. Carneiro A. Chan P. Moreno N. Vasconcelos Supervised learning of semantic classes for image annotation and retrieval IEEE Transactions on Pattern Analysis and Machine Intelligence 29 3 2007 394 410 [7] D. Cossock T. Zhang Statistical analysis of Bayes optimal subset ranking IEEE Transactions on Information Theory 54 11 2008 5140 5154 [8] K. Crammer Y. Singer On the algorithmic implementation of multiclass kernel-based vector machines Journal of Machine Learning Research 2 2001 265 292 [9] O. Dekel C. Manning Y. Singer Log-linear models for label ranking S. Thrun L.K. Saul B. Sch\u00f6lkopf Advances in Neural Information Processing Systems vol. 16 2004 MIT Press Cambridge, MA [10] K. Dembczy\u0144ski W.W. Cheng E. H\u00fcllermeier Bayes optimal multilabel classification via probabilistic classifier chains Proceedings of the 27th International Conference on Machine Learning Haifa, Israel 2010 279 286 [11] K. Dembczy\u0144ski W. Kotlowski E. H\u00fcllermeier Consistent multi-label ranking through univariate loss minimization Proceedings of the 29th International Conference on Machine Learning New York, NY 2012 1319 1326 [12] K. Dembczy\u0144ski W. Waegeman W. Cheng E. H\u00fcllermeier On label dependence and loss minimization in multi-label classification Machine Learning 88 1\u20132 2012 5 45 [13] J.C. Duchi L.W. Mackey M.I. Jordan On the consistency of ranking algorithms Proceedings of the 27th International Conference on Machine Learning Haifa, Israel 2010 327 334 [14] A. Elisseeff J. Weston A kernel method for multi-labelled classification T.G. Dietterich S. Becker Z. Ghahramani Advances in Neural Information Processing Systems vol. 14 2002 MIT Press Cambridge, MA 681 687 [15] J. F\u00fcrnkranz E. H\u00fcllermeier E.L. Menc\u00eda K. Brinker Multilabel classification via calibrated label ranking Machine Learning 73 2 2008 133 153 [16] W. Gao Z.-H. Zhou On the consistency of multi-label learning Proceedings of the 24th Annual Conference on Learning Theory Budapest, Hungary 2011 341 358 [17] N. Ghamrawi A. McCallum Collective multi-label classification Proceedings of the 14th ACM International Conference on Information and Knowledge Management Bremen, Germany 2005 195 200 [18] S. Godbole S. Sarawagi Discriminative methods for multi-labeled classification Proceedings of the 8th Pacific-Asia Conference on Knowledge Discovery and Data Mining Sydney, Australia 2004 22 30 [19] B. Hariharan L. Zelnik-Manor S. Vishwanathan M. Varma Large scale max-margin multi-label classification with priors Proceedings of the 27th International Conference on Machine Learning Haifa, Israel 2010 423 430 [20] D. Hsu S.M. Kakade J. Langford T. Zhang Multi-label prediction via compressed sensing Y. Bengio D. Schuurmans J. Lafferty C.K.I. Williams A. Culotta Advances in Neural Information Processing Systems vol. 22 2009 MIT Press Cambridge, MA 772 780 [21] E. H\u00fcllermeier J. F\u00fcrnkranz W. Cheng K. Brinker Label ranking by learning pairwise preferences Artificial Intelligence 172 16\u201317 2008 1897 1916 [22] Y. Lin Support vector machines and the Bayes rule in classification Data Mining and Knowledge Discovery 6 3 2002 259 275 [23] D. McAllester J. Keshet Generalization bounds and consistency for latent structural probit and ramp loss J. Shawe-Taylor R.S. Zemel P.L. Bartlett F. Pereira K.Q. Weinberger Advances in Neural Information Processing Systems vol. 23 2011 MIT Press 2205 2212 [24] J. Petterson T. Caetano Reverse multi-label learning J. Lafferty C.K.I. Williams J. Shawe-Taylor R.S. Zemel A. Culotta Advances in Neural Information Processing Systems vol. 23 2010 MIT Press Cambridge, MA 1912 1920 [25] G.-J. Qi X.-S. Hua Y. Rui J. Tang T. Mei H.-J. Zhang Correlative multi-label video annotation Proceedings of the 15th ACM International Conference on Multimedia Augsburg, Germany 2007 17 26 [26] R.T. Rockafellar Convex Analysis 1997 Princeton University Press Princeton, NJ [27] R.E. Schapire Y. Singer BoosTexter: A boosting-based system for text categorization Machine Learning 39 2 2000 135 168 [28] I. Steinwart Consistency of support vector machines and other regularized kernel classifiers IEEE Transactions on Information Theory 51 1 2005 128 142 [29] B. Taskar C. Guestrin D. Koller Max-margin Markov networks S. Thrun L. Saul B. Sch\u00f6lkopf Advances in Neural Information Processing Systems vol. 16 2004 MIT Press Cambridge, MA [30] A. Tewari P.L. Bartlett On the consistency of multiclass classification methods Journal of Machine Learning Research 8 2007 1007 1025 [31] J. Weston C. Watkins Multi-class support vector machines Tech. Rep. CSD-TR-98-04 1998 Royal Holloway [32] F. Xia T.Y. Liu H. Li Top-k consistency of learning to rank methods Y. Bengio D. Schuurmans J. Lafferty C.K.I. Williams A. Culotta Advances in Neural Information Processing Systems vol. 22 2009 MIT Press Cambridge, MA 2098 2106 [33] F. Xia T.Y. Liu J. Wang W. Zhang H. Li Listwise approach to learning to rank: Theory and algorithm Proceedings of the 25th International Conference on Machine Learning Helsinki, Finland 2008 1192 1199 [34] M.-L. Zhang Z.-H. Zhou Multi-label neural network with applications to functional genomics and text categorization IEEE Transactions on Knowledge and Data Engineering 18 10 2006 1338 1351 [35] M.-L. Zhang Z.-H. Zhou ML-KNN: A lazy learning approach to multi-label learning Pattern Recognition 40 7 2007 2038 2048 [36] T. Zhang Statistical analysis of some multi-category large margin classification methods Journal of Machine Learning Research 5 2004 1225 1251 [37] T. Zhang Statistical behavior and consistency of classification methods based on convex risk minimization Annals of Statistics 32 1 2004 56 85 [38] Z.-H. Zhou M.-L. Zhang Multi-instance multi-label learning with application to scene classification B. Sch\u00f6lkopf J. Platt T. Hofmann Advances in Neural Information Processing Systems vol. 19 2007 MIT Press Cambridge, MA 1609 1616 [39] Z.-H. Zhou M.-L. Zhang S.-J. Huang Y.-F. Li Multi-instance multi-label learning Artificial Intelligence 176 1 2012 2291 2320"
    }
}